{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":1,"renderable":1},{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":1,"renderable":1},{"_id":"source/assets/img/favicon.png","path":"assets/img/favicon.png","modified":1,"renderable":0},{"_id":"source/assets/img/head.jpeg","path":"assets/img/head.jpeg","modified":1,"renderable":0},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":1,"renderable":1},{"_id":"source/assets/img/wxpay.jpg","path":"assets/img/wxpay.jpg","modified":1,"renderable":0},{"_id":"source/assets/img/alipay.jpg","path":"assets/img/alipay.jpg","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"908d3d2462b08908c37439643c95193df6b2f969","modified":1553250616000},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1552904738979},{"_id":"themes/yilia/_config.yml","hash":"772b0e84259525687f78d05dbc6f7ff9aca09ac3","modified":1553339171444},{"_id":"themes/yilia/package.json","hash":"367cb9579d35968a942c243ab248a5f5ebfaf462","modified":1552904735042},{"_id":"themes/yilia/webpack.config.js","hash":"05ba46a4ae744272f5312e684928910dccad3755","modified":1552904744418},{"_id":"source/_posts/20171012工作日记.md","hash":"f8155bab808cce66d2607a5077566ed492a1f087","modified":1553337329701},{"_id":"source/_posts/2019新目标-新里程.md","hash":"d75c3c84c6848785744029ad14dee0795a1fcebd","modified":1553335638894},{"_id":"source/_posts/CPU时间片.md","hash":"7fefeca280191ce1abd5c3391bf4e4302a187744","modified":1553337863854},{"_id":"source/_posts/DNS原理及其解析过程.md","hash":"fdcec40c39d1d511c0746a9228e29d15af276504","modified":1553336670751},{"_id":"source/_posts/Dnsmasq 安装配置.md","hash":"8a100a3ca70e00808acd111c8ea48fa02a14ec70","modified":1553336771949},{"_id":"source/_posts/Git仓库完全迁移，包括所有的分支和标签，当然也包括日志.md","hash":"61b558daa782af0be2327cb754b4ccf22b5a3137","modified":1553338987593},{"_id":"source/_posts/JavaScript判断知否支持h5-video标签.md","hash":"ed5c7e89912d1feef44796f04bd2d131a51321f1","modified":1553337136725},{"_id":"source/_posts/Linux-网络速度测试工具.md","hash":"bdda02d645d44d194c49554b472982a658d84aed","modified":1553337926760},{"_id":"source/_posts/Let-s-Encrypt：用免费的-SSL-证书，让网站支持-HTTPS.md","hash":"08517b9bb8fff56ec20cc58e249f09cd552acbce","modified":1553336970821},{"_id":"source/_posts/Nginx后端服务器组配置的5个指令.md","hash":"5241d28aef1da1b2c73f7a49cd2adb5917e5a466","modified":1553337549213},{"_id":"source/_posts/Node-js-Sequelize如何实现数据库的读写分离.md","hash":"981b0692e651847cf45f572aa24661604fe1647a","modified":1553336325738},{"_id":"source/_posts/SQL基础.md","hash":"22290024e0f03f2e6f631b5c6686e2ae2f7cba2a","modified":1553335274474},{"_id":"source/_posts/centos-6-安装n来控制node版本.md","hash":"b368ab53e6c68bfbac6c2bcfa234aabd35fc9bae","modified":1553336396415},{"_id":"source/_posts/centos-安装-dig.md","hash":"2df1d9f3a2c6af59b4f8ec660d1676c529fd312f","modified":1553337935394},{"_id":"source/_posts/Rewrite功能的配置（1）.md","hash":"a3e0ccdae048229cf1e433046bcac010e3dc2ed9","modified":1553337536007},{"_id":"source/_posts/centos7-安装nvm.md","hash":"b92b963cacf01f68d3cb5be4ae119a814ab73199","modified":1553337990046},{"_id":"source/_posts/centos6.7 安装 redis并配置开机启动.md","hash":"a1d4fd7865f0f014719a1da9c9c8babd93e89a32","modified":1553337424797},{"_id":"source/_posts/centos7 安装 redis并配置开机启动.md","hash":"b11af9f3f0de6bd4fa4d8b5ba8ad58e3dc7143fc","modified":1553337435298},{"_id":"source/_posts/chown命令.md","hash":"00adad0301e2e616b4dc82135daae6fd9ed6ea3b","modified":1553337510902},{"_id":"source/_posts/free命令.md","hash":"bef6b4b7a0aff756dab063954cea73e5c1f7ec00","modified":1553336602903},{"_id":"source/_posts/dnsmasq官方文档.md","hash":"780cc50e77bc3572de37657658e8b66f8060a831","modified":1553336783332},{"_id":"source/_posts/curl命令.md","hash":"96e4855c0ffabf4d7906fee654fbebda5fd548be","modified":1553336635477},{"_id":"source/_posts/dnsmasq.conf 配置.md","hash":"394eef8937ab67649c9d6d76632d7c8a960c326d","modified":1553336759776},{"_id":"source/_posts/linux查看端口占用情况.md","hash":"f59b6ab0c40f6e168086073a0ddde0947f4ff6ee","modified":1553336366081},{"_id":"source/_posts/koajs框架下创建二维码生成服务.md","hash":"3ada005040229a5e40ba288e0219ec05ca4e972f","modified":1553337125692},{"_id":"source/_posts/mkdir-用法.md","hash":"1a4d5db49207c3867c213310c1c92cb6e902aff8","modified":1553336876648},{"_id":"source/_posts/nginx单页应用基本配置.md","hash":"478c96127feb3e1479e14930d84abdf3e68ef1b6","modified":1553336460263},{"_id":"source/_posts/nginx设置cookie点滴感悟.md","hash":"452033696458a5d9da5faf6fb1f99fe5dfa9e09f","modified":1553336296434},{"_id":"source/_posts/nodejs项目缓存策略.md","hash":"1d536be8fa76b3cd908564df9eb622c6c73bd585","modified":1553336746847},{"_id":"source/_posts/nodejs+redis应用.md","hash":"4e93d8d0c2ff688d014b1d3dc2498808b1be1ce1","modified":1553337445459},{"_id":"source/_posts/npm使用淘宝镜像.md","hash":"ed9d4ffcd6ee652cdd6be60e5001818684d321d9","modified":1553337962525},{"_id":"source/_posts/nvm-切换node版本.md","hash":"3581c535a43ff21d35f810c317460a24ac43b042","modified":1553337909030},{"_id":"source/_posts/pm2启动npm下服务的命令.md","hash":"7c825bc0304185c041dc5f8c427937ca7a006042","modified":1553337949572},{"_id":"source/_posts/pomelo之rpc坑.md","hash":"77c41177cb0d13260b847ca8c1c9f8911191da2e","modified":1553336472966},{"_id":"source/_posts/pomelo的HelloWorld.md","hash":"975b96bb69a9b55808447564f1ad656f11eec2b3","modified":1553336500513},{"_id":"source/_posts/vagrant-ssh-本机连接方式.md","hash":"d943026647d21316e0780db83166c6b8eb2bfb14","modified":1553336353067},{"_id":"source/_posts/uptime命令.md","hash":"853df7b1130bb7a1a37381b82568c410336ee63f","modified":1553336611339},{"_id":"source/_posts/vi命令.md","hash":"071987e959e96f59df018ac85f3113507e1ac0c5","modified":1553336621476},{"_id":"source/_posts/wget命令.md","hash":"05eb360af9137ff0d34649504a2ce78e72383ae8","modified":1553336643609},{"_id":"source/_posts/一些广告术语汇总.md","hash":"802573c56ca4edc0c119249dbc220a422789cef9","modified":1553335706937},{"_id":"source/_posts/websocket-https-连接.md","hash":"6ed67943cc7f66f253326f38a4a364af5cd9d84d","modified":1553336427267},{"_id":"source/_posts/一些职位的简写.md","hash":"2f418fe2b3593337076bce3c788f5006667b8150","modified":1553336591899},{"_id":"source/_posts/升级Jenkins方法.md","hash":"06671670aa7497f1ba1ebdaddf43857d15745d9b","modified":1553337803904},{"_id":"source/_posts/使用js判断浏览器.md","hash":"288248e0b446807e771e8d6d54a139458c798e93","modified":1553336023656},{"_id":"source/_posts/什么叫ocpm、ocpc、ocpa？.md","hash":"96fd2050edd4c0542ad2b905efadf758c042e96b","modified":1553335465299},{"_id":"source/_posts/在 CentOS 7 下安装配置 shadowsocks.md","hash":"fd16f10cb9cd1c7719f3de65ebb8f13d7993b0e5","modified":1553337064490},{"_id":"source/_posts/如何使用electron自动更新功能.md","hash":"fe2d2ea3dca6366bd38904d35cf2a7830e71286b","modified":1553335449852},{"_id":"source/_posts/如何通过linux-ssh远程linux不用输入密码登入.md","hash":"c41d221f14e2f3d2f3e67d4129a6cc0527deb7cc","modified":1553336378807},{"_id":"source/_posts/域名解析中A记录、CNAME、MX记录、NS记录的区别和联系.md","hash":"83a6edb8b65e43f7a05f738667dfe966cfa57f03","modified":1553336701960},{"_id":"source/_posts/更改location的URI.md","hash":"f2d781f24b1c2d55bbcae113db18ae15e92f3559","modified":1553337689033},{"_id":"source/_posts/本机连接vagrant虚拟机创建的mysql数据库.md","hash":"d4dcb15ff076def21c8f9bb1f997e2770f5e131d","modified":1553336538625},{"_id":"source/_posts/安装pomelo.md","hash":"e466a608b6d4f3b0f8aa80bcbc37feb82ca17699","modified":1553336508090},{"_id":"source/_posts/每天读一遍，不就你就会有改变.md","hash":"1d9777724811b0a204929f14d72f8f220301ce7d","modified":1553337308376},{"_id":"source/_posts/每个人都背负这一个十字架.md","hash":"a74c739e33ef66ee906d0f73cf38908aa27ba705","modified":1553337209560},{"_id":"source/_posts/看懂UML类图和时序图.md","hash":"caffab8acd1d3fc48e2813920d3ce5eb2ff06425","modified":1553336562515},{"_id":"source/_posts/欢迎使用pomelo.md","hash":"35ffb7421c97848084b30616a2ff9932185e617f","modified":1553336516701},{"_id":"source/_posts/留不住的心就让他飞吧.md","hash":"36c6294ead4f9ac50bf34af869f2f417d29eee42","modified":1553337286183},{"_id":"source/_posts/移动端开发调试工具神器-Weinre使用方法.md","hash":"4a3c4fa47da5f234e2a4a8e8b6972dc5d0966d00","modified":1553336252093},{"_id":"source/_posts/网页中常见的错误码.md","hash":"b96f70fd5f1e2fa703131e92b7fcdc06364e7987","modified":1553337844306},{"_id":"source/_posts/自定义服务日志.md","hash":"32c675d452a45ce91d255be7357529d463db3095","modified":1553337764125},{"_id":"source/_posts/虚拟服务器.md","hash":"aa2dc2a6a5e16e5e29f037566c6fa62c9bfae0cd","modified":1553337818722},{"_id":"source/_posts/被遗忘的Logrotate.md","hash":"ac2372ee05859358cedad9fa8ab3b4b52d392681","modified":1553337501510},{"_id":"source/_posts/设置网站的默认首页.md","hash":"ba08cfa33087ab4194dd2fc4944bf5464f0a0494","modified":1553337680190},{"_id":"source/_posts/设置webstorm自动删除行尾分号.md","hash":"df353811af8670aca0104e8909551ef45b4e5720","modified":1553336276136},{"_id":"source/_posts/设置网站的错误页面.md","hash":"d9a040d83f9db6faa60465a2ed74d0528110e58a","modified":1553337557339},{"_id":"source/_posts/配置最大连接数.md","hash":"855b3d4eb612d825ba4ea8e8dc90ff027ce5190c","modified":1553337777416},{"_id":"source/_posts/配置允许生成的worker-process数.md","hash":"ddc93ab453a3648da739c8c830aa410b0f7baa4d","modified":1553337790372},{"_id":"source/_posts/配置location块.md","hash":"5503847584fca70564cae5bc5661bff062c862fc","modified":1553337756117},{"_id":"source/_posts/配置请求的根目录.md","hash":"62b95bca4f07c679bb873f94c27b6f11f4f3cdd9","modified":1553337698037},{"_id":"source/_posts/配置运行Nginx服务用户（组）.md","hash":"814474f6c26421a5fe68645a26e65c451db2d228","modified":1553337812537},{"_id":"source/_posts/马云团队.md","hash":"ed638cc24bbe80d86fb8870bc08d2404f199a49b","modified":1553337269765},{"_id":"source/_posts/高性能网站性能进阶指南-笔记.md","hash":"3340aced2533ee582850aa5aa48ff11224899bc4","modified":1553337488817},{"_id":"themes/yilia/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1552904745549},{"_id":"themes/yilia/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1552904745050},{"_id":"themes/yilia/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1552904744984},{"_id":"themes/yilia/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1552904745085},{"_id":"themes/yilia/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1552904745067},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1552904745109},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1552904745673},{"_id":"themes/yilia/layout/index.ejs","hash":"a35dc900203f9d8dd863ea4c1722198d6d457ec8","modified":1552904737869},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1552904739799},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1552904737768},{"_id":"themes/yilia/layout/layout.ejs","hash":"0a332bdbd3b86c231d690614687f5b97186b85d5","modified":1552904737366},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1552904737975},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1552904738983},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1552904738003},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1552904735149},{"_id":"themes/yilia/source-src/css.ejs","hash":"94dbdb02ca11849e415d54fb28546a598f2cffb1","modified":1552904744363},{"_id":"themes/yilia/source/slider.e37972.js","hash":"6dec4e220c89049037eebc44404abd8455d22ad7","modified":1552904734387},{"_id":"themes/yilia/source-src/script.ejs","hash":"c21381e1317db7bb157f1d182b8c088cb7cba411","modified":1552904744360},{"_id":"source/_posts/nodejs-redis-doc.md","hash":"cd0ff0e242c83849e65ea64243bdf73595bbe176","modified":1553337405451},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1552904735450},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"993fadeb5f6d296e9d997a49ee20dc97333ceab7","modified":1552904735179},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"01b35e71e37aa2849664eb5daf26daede2278398","modified":1552904735121},{"_id":"source/assets/img/favicon.png","hash":"01c39180f2afc68b5e801f95a0b2fb4f0272cb0a","modified":1552904791929},{"_id":"source/assets/img/head.jpeg","hash":"48e38533b47bebb7e37412c43ac769d97e5ad68c","modified":1552904792034},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"b86b248720ad415ec1b5fee53fb583776c776f83","modified":1552904736055},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a6e94061ac55b9eb55275f87b608d62f6ea35659","modified":1552904735357},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"1f7d4819b7f67602c4a1b99871808d2160b60978","modified":1552904736350},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"630c6ec866d056657d3d91e34b4c64eb993c0654","modified":1552904736029},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"8edbd7993b9b061611a193533a664e2e85eae748","modified":1552904736000},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"f0e6e88f9f7eb08b8fe51449a8a3016273507924","modified":1552904737348},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1552904735377},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1552904738714},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"64f092186b5a744aa1603ce22bb1d44a34446add","modified":1552904736160},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"6387a93dad7c3d778eb91e3821852fbf6813880c","modified":1552904735059},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"9d982389f1cb0c5c6fa6ae789834bc0811dbdfc1","modified":1552904735768},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"183d7ca4ba8e7c80694ffdc8cf39957092238346","modified":1552904736272},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"151a1ef2173ba7b6789d349f0f8da89616cc1394","modified":1552904735421},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"7fbbfabf5e29525b24ada14613c21a26789132b4","modified":1552904735746},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"e495790b2abe2290875817e42bd505bc611d3e26","modified":1552904735404},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"c41341b9618e591538e1136a2d1637587c1bbd90","modified":1552904735714},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1552904734726},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1552904734762},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"f9304e5714d20861be7d8f4d36687e88e86b9e1b","modified":1552904734405},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1552904734665},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1552904734287},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1552904734763},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1552904734404},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1552904734665},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1552904734409},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"93a50dd19a93485712da1f8d0a1672482dd1eabc","modified":1552904741109},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"24f347a2412abbf58318369152504da9538f8d3b","modified":1552904742770},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"d79f2d35a06de83a2a226ca790b7a0a34789c115","modified":1552904742061},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"7d27e22ac898e8fafec14549e940c73cbea1fba8","modified":1552904739798},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"3fad68bd74260326f83090b0974dd80707e7bac7","modified":1552904743264},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"578a67464dd0f542197f7fcee158c991db058563","modified":1552904742086},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"43e507f2a48504079afd9471353337e23ca47470","modified":1552904739960},{"_id":"themes/yilia/source-src/css/article.scss","hash":"0f6d61af99ed4db87f8589db1feaea7747b55963","modified":1552904740887},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"cafe3834017a3bf47420f37543725025225a2c89","modified":1552904743238},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"97b8fba41c914145710b90091f400b845879577f","modified":1552904742376},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7c995410b25baaf61dfc5e148e22ca60330abcd3","modified":1552904742368},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"3719994c2c9393813cc1d42b657205c368a329cb","modified":1552904742544},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1552904741031},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"849a29fcd7150214fcf7b9715fa5dc71d1f9b896","modified":1552904741977},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"f053c609d84df0dd9eee1d11ddf0c19163a456be","modified":1552904743229},{"_id":"themes/yilia/source-src/css/left.scss","hash":"0d30c0e7cdb831c3881a017006c782f2214ac195","modified":1552904741331},{"_id":"themes/yilia/source-src/css/main.scss","hash":"2f86a014af93583caba78a563d9549826bf28294","modified":1552904740626},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"ace041d72f95b419f6a5e443191703c2b62007f4","modified":1552904740654},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"80a4fcf9171d4a33235da96ac8a2b7dcabc45dfb","modified":1552904739884},{"_id":"themes/yilia/source-src/css/page.scss","hash":"bf206bb7f7d0967bc8b7fdf01b7ffc99aff9ba88","modified":1552904741069},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"9c8dfd1c76854ef063494ca76fac6360b391ed6d","modified":1552904740203},{"_id":"themes/yilia/source-src/css/share.scss","hash":"150c6425f6582e7ec78a873256ce49c9930e8805","modified":1552904740700},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"c8aa84fca93862d3caae77c552873b8610f33327","modified":1552904740853},{"_id":"themes/yilia/source-src/css/social.scss","hash":"724162ccf3977e70a45d189abfaa20b6e2fba87b","modified":1552904742917},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"ac67a3c7097849206244db9b0ba91daaba017ef5","modified":1552904740416},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"1b1aa0908e58cf942b28e3881d07c5573c4129e1","modified":1552904741008},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"53d5a554bc2f38e9bb3d26400a47767013c05216","modified":1552904739942},{"_id":"themes/yilia/source-src/js/anm.js","hash":"4a4c5d82b09a3063f91a434388e6aa064fd7fd98","modified":1552904744022},{"_id":"themes/yilia/source-src/js/aside.js","hash":"754f771264548a6c5a8ad842908e59ae4e7ed099","modified":1552904743789},{"_id":"themes/yilia/source-src/js/browser.js","hash":"04095b38cfd4316a23f8eb14b1ffaf95f78a4260","modified":1552904743442},{"_id":"themes/yilia/source-src/js/fix.js","hash":"d6782d53c992e712af39c84e804eccaf38830b94","modified":1552904743553},{"_id":"themes/yilia/source-src/js/main.js","hash":"3894e60827c817319e43c9ff3ed045fc3d7336ce","modified":1552904743441},{"_id":"themes/yilia/source-src/js/Q.js","hash":"d011af172064b6c6e0c7051d8f9879373ddac113","modified":1552904744046},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"4d823b039fd296d24a454eae5a798b93c44560cb","modified":1552904744003},{"_id":"themes/yilia/source-src/js/report.js","hash":"b3171e1accc51fc3421d1830316658b4ec729034","modified":1553249789060},{"_id":"themes/yilia/source-src/js/util.js","hash":"8456e9d6b19532742582c99b2fb9d09e146e1c58","modified":1552904744059},{"_id":"themes/yilia/source-src/js/share.js","hash":"b090f82cf80cba7da764753906d9e2cc2acdf30d","modified":1552904744154},{"_id":"themes/yilia/source-src/js/slider.js","hash":"e846bcc5aac9c68b93f7b8de353df54d8d29f666","modified":1552904743569},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"2577deb6a9fe4f5436360b2ce9afcc7f9a7f0116","modified":1552904743584},{"_id":"source/assets/img/wxpay.jpg","hash":"b4f20b97db937642f71776de1c83490b70f8970e","modified":1552904791866},{"_id":"source/assets/img/alipay.jpg","hash":"329b84bba584d559a644be593752160540eab3ef","modified":1552904791966},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"4cb685f07e89dd5175c2a576e73a1a957aec5637","modified":1552904735852},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"0809a4829aabeb4e911a3ed04ec28db4df7dfe3f","modified":1552904737251},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"5f99b55980da64a723a8e14d5a7daba0d6504647","modified":1552904737038},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"ef71c4081e866a494367575c59610e7e6339ece0","modified":1552904736467},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"e8399025ed3b980aedb821c92855889f5f12fd5b","modified":1552904736580},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"e68bbac9ffb1ad27b56837c9abad6ed6bb7daa0c","modified":1552904737044},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"1036c8e4e1a7bc935ba173744da735a0d6ed09cd","modified":1552904736730},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"5dccfbe165b23a101f1333cc65ed8efbd197453c","modified":1552904736693},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2e783e68755abb852760eb0e627a3fbb50a05a55","modified":1552904736985},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"2f275739b6f1193c123646a5a31f37d48644c667","modified":1552904737106},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"ea41c462168d9697caef9485862e9cac718a12c1","modified":1552904736369},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"63a37f26276f9207405afe0f2d65339ce295bbaf","modified":1552904738960},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"491ab3378d5c11005ba65c607608bb36b368a9d5","modified":1552904739535},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"3bba5c77bad5981eac859fe05c9561d580ba7fa9","modified":1552904739550},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"fab871fa93bd542e76a71a56428f2994a4aaf443","modified":1552904739636},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"fb511c505d1309249f21dc577d4ad2bad99a764f","modified":1552904739481},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1552904741430},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1552904741564},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1552904740379},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1552904741784},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"f9304e5714d20861be7d8f4d36687e88e86b9e1b","modified":1552904741781},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1552904740202},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1552904740202}],"Category":[{"name":"项目总结","_id":"cjtle1egb0002gyavc6fxe6q7"},{"name":"后端开发","_id":"cjtle1ehe000kgyav3s2qwth8"},{"name":"Web开发","_id":"cjtle1ehm000rgyavdj2rf3zr"},{"name":"NodeJS","_id":"cjtle1eid001cgyavrugel09i"},{"name":"生活玩乐","_id":"cjtle1emi004ugyavix3vzrrm"},{"name":"H5开发","_id":"cjtle1en2005dgyavvjk8aqzk"},{"name":"性能优化","_id":"cjtle1eoz006tgyavs1nw0ml6"}],"Data":[],"Page":[],"Post":[{"title":"20171012工作日记","originContent":"今天给广告部门做一个代理层接口，目的是为了记录第三方接口请求日志，由于第三方与我们以及百度统计到的数据都不同，因此需要通过增加代理层验证准确性。\n\n<!-- more -->\n\n思路必然是通过某台服务器，然后记录日志，怎样做比较简单呢？\n\n1. 部署到pc播放页服务器上，直接通过nginx代理转发，发现有问题，第三方接口是https，而代理转发不支持https的转发\n2. nginx rewrite，也不行，请求得到结果会出现302状态码，这个不是我们想要的\n3. 只能通过node做一个逻辑处理了，我们在node里边增加了https发送模块，将返回的结果通过console.info记录在日志里边\n4. 部署上线的时候pc发现新问题，pc会走cdn缓存，这样很多请求打不到我们的服务器上，也就无法记录日志\n5. 放在M站服务器上，由于M站没有走cdn所以这里可以直接配置修改。\n6. 修改M站的时候我们发现一级uri会有问题，因为M站会把一级uri作为频道页重写\n7. 最终接口请求为**.**.com/proxy/ad\n8. 好了 下边就是收集日志分析日志的工作了\n\n然后问题基本结束了，但是下午沟通发现又有新问题了，代理转发的第三方接口并不是固定的，之前讨论是固定的是把问题简单化了，为了避免麻烦，我们重新做了处理\n\n1. 支持通过send参数将第三方接口传递给我们代理层\n2. 传递给代理层以后，要判断第三方请求是http还是https，决定下一步的请求方式\n3. 同时需要把header原样带给第三方接口，这里有个小插曲，代理接口header里边的host要删掉后才能再传给第三方接口才不会报错，理由很简单，那个host是代理的host，而第三方不需要也不识别。\n\n最后就上线了……","toc":false,"date":"2017-10-12T06:22:24.000Z","_content":"\n今天给广告部门做一个代理层接口，目的是为了记录第三方接口请求日志，由于第三方与我们以及百度统计到的数据都不同，因此需要通过增加代理层验证准确性。\n\n<!-- more -->\n\n思路必然是通过某台服务器，然后记录日志，怎样做比较简单呢？\n\n1. 部署到pc播放页服务器上，直接通过nginx代理转发，发现有问题，第三方接口是https，而代理转发不支持https的转发\n2. nginx rewrite，也不行，请求得到结果会出现302状态码，这个不是我们想要的\n3. 只能通过node做一个逻辑处理了，我们在node里边增加了https发送模块，将返回的结果通过console.info记录在日志里边\n4. 部署上线的时候pc发现新问题，pc会走cdn缓存，这样很多请求打不到我们的服务器上，也就无法记录日志\n5. 放在M站服务器上，由于M站没有走cdn所以这里可以直接配置修改。\n6. 修改M站的时候我们发现一级uri会有问题，因为M站会把一级uri作为频道页重写\n7. 最终接口请求为**.**.com/proxy/ad\n8. 好了 下边就是收集日志分析日志的工作了\n\n然后问题基本结束了，但是下午沟通发现又有新问题了，代理转发的第三方接口并不是固定的，之前讨论是固定的是把问题简单化了，为了避免麻烦，我们重新做了处理\n\n1. 支持通过send参数将第三方接口传递给我们代理层\n2. 传递给代理层以后，要判断第三方请求是http还是https，决定下一步的请求方式\n3. 同时需要把header原样带给第三方接口，这里有个小插曲，代理接口header里边的host要删掉后才能再传给第三方接口才不会报错，理由很简单，那个host是代理的host，而第三方不需要也不识别。\n\n最后就上线了……","source":"_posts/20171012工作日记.md","raw":"---\ntitle: 20171012工作日记\ntags:\n  - nginx\noriginContent: >-\n  今天给广告部门做一个代理层接口，目的是为了记录第三方接口请求日志，由于第三方与我们以及百度统计到的数据都不同，因此需要通过增加代理层验证准确性。\n\n\n  <!-- more -->\n\n\n  思路必然是通过某台服务器，然后记录日志，怎样做比较简单呢？\n\n\n  1. 部署到pc播放页服务器上，直接通过nginx代理转发，发现有问题，第三方接口是https，而代理转发不支持https的转发\n\n  2. nginx rewrite，也不行，请求得到结果会出现302状态码，这个不是我们想要的\n\n  3. 只能通过node做一个逻辑处理了，我们在node里边增加了https发送模块，将返回的结果通过console.info记录在日志里边\n\n  4. 部署上线的时候pc发现新问题，pc会走cdn缓存，这样很多请求打不到我们的服务器上，也就无法记录日志\n\n  5. 放在M站服务器上，由于M站没有走cdn所以这里可以直接配置修改。\n\n  6. 修改M站的时候我们发现一级uri会有问题，因为M站会把一级uri作为频道页重写\n\n  7. 最终接口请求为**.**.com/proxy/ad\n\n  8. 好了 下边就是收集日志分析日志的工作了\n\n\n  然后问题基本结束了，但是下午沟通发现又有新问题了，代理转发的第三方接口并不是固定的，之前讨论是固定的是把问题简单化了，为了避免麻烦，我们重新做了处理\n\n\n  1. 支持通过send参数将第三方接口传递给我们代理层\n\n  2. 传递给代理层以后，要判断第三方请求是http还是https，决定下一步的请求方式\n\n  3.\n  同时需要把header原样带给第三方接口，这里有个小插曲，代理接口header里边的host要删掉后才能再传给第三方接口才不会报错，理由很简单，那个host是代理的host，而第三方不需要也不识别。\n\n\n  最后就上线了……\ncategories:\n  - 项目总结\ntoc: false\ndate: 2017-10-12 14:22:24\n---\n\n今天给广告部门做一个代理层接口，目的是为了记录第三方接口请求日志，由于第三方与我们以及百度统计到的数据都不同，因此需要通过增加代理层验证准确性。\n\n<!-- more -->\n\n思路必然是通过某台服务器，然后记录日志，怎样做比较简单呢？\n\n1. 部署到pc播放页服务器上，直接通过nginx代理转发，发现有问题，第三方接口是https，而代理转发不支持https的转发\n2. nginx rewrite，也不行，请求得到结果会出现302状态码，这个不是我们想要的\n3. 只能通过node做一个逻辑处理了，我们在node里边增加了https发送模块，将返回的结果通过console.info记录在日志里边\n4. 部署上线的时候pc发现新问题，pc会走cdn缓存，这样很多请求打不到我们的服务器上，也就无法记录日志\n5. 放在M站服务器上，由于M站没有走cdn所以这里可以直接配置修改。\n6. 修改M站的时候我们发现一级uri会有问题，因为M站会把一级uri作为频道页重写\n7. 最终接口请求为**.**.com/proxy/ad\n8. 好了 下边就是收集日志分析日志的工作了\n\n然后问题基本结束了，但是下午沟通发现又有新问题了，代理转发的第三方接口并不是固定的，之前讨论是固定的是把问题简单化了，为了避免麻烦，我们重新做了处理\n\n1. 支持通过send参数将第三方接口传递给我们代理层\n2. 传递给代理层以后，要判断第三方请求是http还是https，决定下一步的请求方式\n3. 同时需要把header原样带给第三方接口，这里有个小插曲，代理接口header里边的host要删掉后才能再传给第三方接口才不会报错，理由很简单，那个host是代理的host，而第三方不需要也不识别。\n\n最后就上线了……","slug":"20171012工作日记","published":1,"updated":"2019-03-23T10:35:29.701Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1efr0000gyavd0t049oo"},{"title":"2019新目标 新里程","originContent":"## 2019年新目标\n新的一年开始了，虽然今天已经三号，但还是要在年初定一个基本目标\n\n1. 移动端应用开发\n2. 熟练使用后端服务开发各种业务场景\n3. 桌面版应用程序开发\n\n## 2019年新里程\n\n1. 家庭为主，事业为辅","toc":false,"date":"2019-01-03T02:09:04.000Z","_content":"\n## 2019年新目标\n新的一年开始了，虽然今天已经三号，但还是要在年初定一个基本目标\n\n1. 移动端应用开发\n2. 熟练使用后端服务开发各种业务场景\n3. 桌面版应用程序开发\n\n## 2019年新里程\n\n1. 家庭为主，事业为辅","source":"_posts/2019新目标-新里程.md","raw":"---\ntitle: 2019新目标 新里程\ntags:\n  - 计划\noriginContent: |-\n  ## 2019年新目标\n  新的一年开始了，虽然今天已经三号，但还是要在年初定一个基本目标\n\n  1. 移动端应用开发\n  2. 熟练使用后端服务开发各种业务场景\n  3. 桌面版应用程序开发\n\n  ## 2019年新里程\n\n  1. 家庭为主，事业为辅\ncategories:\n  - 项目总结\ntoc: false\ndate: 2019-01-03 10:09:04\n---\n\n## 2019年新目标\n新的一年开始了，虽然今天已经三号，但还是要在年初定一个基本目标\n\n1. 移动端应用开发\n2. 熟练使用后端服务开发各种业务场景\n3. 桌面版应用程序开发\n\n## 2019年新里程\n\n1. 家庭为主，事业为辅","slug":"2019新目标-新里程","published":1,"updated":"2019-03-23T10:07:18.894Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eg20001gyavrpdieoml"},{"title":"CPU时间片","originContent":"# 时间片即CPU分配给各个程序的时间\n\n<!-- more -->\n\n每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。","toc":false,"date":"2017-07-19T02:00:00.000Z","_content":"\n# 时间片即CPU分配给各个程序的时间\n\n<!-- more -->\n\n每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。","source":"_posts/CPU时间片.md","raw":"---\ntitle: CPU时间片\ntags:\n  - 基本知识\noriginContent: >-\n  # 时间片即CPU分配给各个程序的时间\n\n\n  <!-- more -->\n\n\n  每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。\ncategories:\n  - 项目总结\ntoc: false\ndate: 2017-07-19 10:00:00\n---\n\n# 时间片即CPU分配给各个程序的时间\n\n<!-- more -->\n\n每个线程被分配一个时间段，称作它的时间片，即该进程允许运行的时间，使各个程序从表面上看是同时进行的。如果在时间片结束时进程还在运行，则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则CPU当即进行切换。而不会造成CPU资源浪费。在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。但在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，每个程序轮流执行。","slug":"CPU时间片","published":1,"updated":"2019-03-23T10:44:23.854Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1egg0004gyav8cd4y2c9"},{"title":"DNS原理及其解析过程","originContent":"## 什么是DNS？ \nDNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”。 \n\n![DNS的作用](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/1.jpg)\n\n<!-- more -->\n\n## 域的划分\n域名系统作为一个层次结构和分布式数据库，包含各种类型的数据，包括主机名和域名。DNS数据库中的名称形成一个分层树状结构称为域命名空间。域名包含单个标签分隔点，例如：im.qq.com。 \n\n完全限定的域名 (FQDN) 唯一地标识在 DNS 分层树中的主机的位置，通过指定的路径中点分隔从根引用的主机的名称列表。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/2.jpg)\n\n按其功能命名空间中用来描述 DNS 域名称的五个类别的介绍详见下表中，以及与每个名称类型的示例。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/3.jpg)\n\n### 根域\n就是所谓的“.”，其实我们的网址www.qq.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点。根域服务器我们知道有13台，但是这是错误的观点。根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了任播的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。 \n\n### 顶级域\n根域下来就是顶级域或者叫一级域。一些常见的DNS域名称如下图： \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/4.jpg)\n\n### 域名服务器\n每个域都会有域名服务器，也叫权威域名服务器。 \n\n能提供域名解析的服务器，上面的记录类型可以是A(address)记录,NS记录（name server）,MX（mail）,CNAME等。 \n\n### 资源记录 \nDNS 数据库中包含的资源记录 (RR)。 每个 RR 标识数据库中的特定资源。我们在建立DNS服务器时，经常会用到SOA,NS,A之类的记录，在维护DNS服务器时，会用到MX，CNAME记录。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/5.jpg)\n\n## DNS服务的工作过程 \n当 DNS 客户机需要查询程序中使用的名称时，它会查询本地DNS 服务器来解析该名称。客户机发送的每条查询消息都包括3条信息，以指定服务器应回答的问题。 \n\n1. 指定的 DNS 域名，表示为完全合格的域名 (FQDN) 。 \n2. 指定的查询类型，它可根据类型指定资源记录，或作为查询操作的专门类型。 \n3。 DNS域名的指定类别。 \n\n对于DNS 服务器，它始终应指定为 Internet 类别。例如，指定的名称可以是计算机的完全合格的域名，如im.qq.com，并且指定的查询类型用于通过该名称搜索地址资源记录。 \n\nDNS 查询以各种不同的方式进行解析。客户机有时也可通过使用从以前查询获得的缓存信息就地应答查询。DNS 服务器可使用其自身的资源记录信息缓存来应答查询，也可代表请求客户机来查询或联系其他 DNS 服务器，以完全解析该名称，并随后将应答返回至客户机。这个过程称为递归。 \n\n另外，客户机自己也可尝试联系其他的 DNS 服务器来解析名称。如果客户机这么做，它会使用基于服务器应答的独立和附加的查询，该过程称作迭代，即DNS服务器之间的交互查询就是迭代查询。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/6.jpg) \n\n1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 \n2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 \n3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 \n4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 \n5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名(.com)服务器的一个IP。 \n6. 本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。 \n7. 当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 \n8. 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。\n\n\n\n\n[原文地址](http://blog.csdn.net/benbenzhuhwp/article/details/44704307)","toc":false,"date":"2018-01-11T08:12:49.000Z","_content":"\n## 什么是DNS？ \nDNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”。 \n\n![DNS的作用](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/1.jpg)\n\n<!-- more -->\n\n## 域的划分\n域名系统作为一个层次结构和分布式数据库，包含各种类型的数据，包括主机名和域名。DNS数据库中的名称形成一个分层树状结构称为域命名空间。域名包含单个标签分隔点，例如：im.qq.com。 \n\n完全限定的域名 (FQDN) 唯一地标识在 DNS 分层树中的主机的位置，通过指定的路径中点分隔从根引用的主机的名称列表。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/2.jpg)\n\n按其功能命名空间中用来描述 DNS 域名称的五个类别的介绍详见下表中，以及与每个名称类型的示例。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/3.jpg)\n\n### 根域\n就是所谓的“.”，其实我们的网址www.qq.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点。根域服务器我们知道有13台，但是这是错误的观点。根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了任播的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。 \n\n### 顶级域\n根域下来就是顶级域或者叫一级域。一些常见的DNS域名称如下图： \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/4.jpg)\n\n### 域名服务器\n每个域都会有域名服务器，也叫权威域名服务器。 \n\n能提供域名解析的服务器，上面的记录类型可以是A(address)记录,NS记录（name server）,MX（mail）,CNAME等。 \n\n### 资源记录 \nDNS 数据库中包含的资源记录 (RR)。 每个 RR 标识数据库中的特定资源。我们在建立DNS服务器时，经常会用到SOA,NS,A之类的记录，在维护DNS服务器时，会用到MX，CNAME记录。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/5.jpg)\n\n## DNS服务的工作过程 \n当 DNS 客户机需要查询程序中使用的名称时，它会查询本地DNS 服务器来解析该名称。客户机发送的每条查询消息都包括3条信息，以指定服务器应回答的问题。 \n\n1. 指定的 DNS 域名，表示为完全合格的域名 (FQDN) 。 \n2. 指定的查询类型，它可根据类型指定资源记录，或作为查询操作的专门类型。 \n3。 DNS域名的指定类别。 \n\n对于DNS 服务器，它始终应指定为 Internet 类别。例如，指定的名称可以是计算机的完全合格的域名，如im.qq.com，并且指定的查询类型用于通过该名称搜索地址资源记录。 \n\nDNS 查询以各种不同的方式进行解析。客户机有时也可通过使用从以前查询获得的缓存信息就地应答查询。DNS 服务器可使用其自身的资源记录信息缓存来应答查询，也可代表请求客户机来查询或联系其他 DNS 服务器，以完全解析该名称，并随后将应答返回至客户机。这个过程称为递归。 \n\n另外，客户机自己也可尝试联系其他的 DNS 服务器来解析名称。如果客户机这么做，它会使用基于服务器应答的独立和附加的查询，该过程称作迭代，即DNS服务器之间的交互查询就是迭代查询。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/6.jpg) \n\n1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 \n2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 \n3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 \n4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 \n5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名(.com)服务器的一个IP。 \n6. 本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。 \n7. 当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 \n8. 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。\n\n\n\n\n[原文地址](http://blog.csdn.net/benbenzhuhwp/article/details/44704307)","source":"_posts/DNS原理及其解析过程.md","raw":"---\ntitle: DNS原理及其解析过程\ntags:\n  - 广告\noriginContent: >-\n  ## 什么是DNS？ \n\n  DNS( Domain Name\n  System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”。 \n\n\n  ![DNS的作用](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/1.jpg)\n\n\n  <!-- more -->\n\n\n  ## 域的划分\n\n  域名系统作为一个层次结构和分布式数据库，包含各种类型的数据，包括主机名和域名。DNS数据库中的名称形成一个分层树状结构称为域命名空间。域名包含单个标签分隔点，例如：im.qq.com。 \n\n\n  完全限定的域名 (FQDN) 唯一地标识在 DNS 分层树中的主机的位置，通过指定的路径中点分隔从根引用的主机的名称列表。 \n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/2.jpg)\n\n\n  按其功能命名空间中用来描述 DNS 域名称的五个类别的介绍详见下表中，以及与每个名称类型的示例。 \n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/3.jpg)\n\n\n  ### 根域\n\n  就是所谓的“.”，其实我们的网址www.qq.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点。根域服务器我们知道有13台，但是这是错误的观点。根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了任播的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。 \n\n\n  ### 顶级域\n\n  根域下来就是顶级域或者叫一级域。一些常见的DNS域名称如下图： \n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/4.jpg)\n\n\n  ### 域名服务器\n\n  每个域都会有域名服务器，也叫权威域名服务器。 \n\n\n  能提供域名解析的服务器，上面的记录类型可以是A(address)记录,NS记录（name server）,MX（mail）,CNAME等。 \n\n\n  ### 资源记录 \n\n  DNS 数据库中包含的资源记录 (RR)。 每个 RR\n  标识数据库中的特定资源。我们在建立DNS服务器时，经常会用到SOA,NS,A之类的记录，在维护DNS服务器时，会用到MX，CNAME记录。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/5.jpg)\n\n\n  ## DNS服务的工作过程 \n\n  当 DNS 客户机需要查询程序中使用的名称时，它会查询本地DNS 服务器来解析该名称。客户机发送的每条查询消息都包括3条信息，以指定服务器应回答的问题。 \n\n\n  1. 指定的 DNS 域名，表示为完全合格的域名 (FQDN) 。 \n\n  2. 指定的查询类型，它可根据类型指定资源记录，或作为查询操作的专门类型。 \n\n  3。 DNS域名的指定类别。 \n\n\n  对于DNS 服务器，它始终应指定为 Internet\n  类别。例如，指定的名称可以是计算机的完全合格的域名，如im.qq.com，并且指定的查询类型用于通过该名称搜索地址资源记录。 \n\n\n  DNS 查询以各种不同的方式进行解析。客户机有时也可通过使用从以前查询获得的缓存信息就地应答查询。DNS\n  服务器可使用其自身的资源记录信息缓存来应答查询，也可代表请求客户机来查询或联系其他 DNS\n  服务器，以完全解析该名称，并随后将应答返回至客户机。这个过程称为递归。 \n\n\n  另外，客户机自己也可尝试联系其他的 DNS\n  服务器来解析名称。如果客户机这么做，它会使用基于服务器应答的独立和附加的查询，该过程称作迭代，即DNS服务器之间的交互查询就是迭代查询。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/6.jpg) \n\n\n  1.\n  在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 \n\n  2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 \n\n  3.\n  如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 \n\n  4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 \n\n  5.\n  如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名(.com)服务器的一个IP。 \n\n  6.\n  本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。 \n\n  7. 当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 \n\n  8.\n  如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。\n\n\n\n\n\n  [原文地址](http://blog.csdn.net/benbenzhuhwp/article/details/44704307)\ncategories:\n  - 项目总结\ntoc: false\ndate: 2018-01-11 16:12:49\n---\n\n## 什么是DNS？ \nDNS( Domain Name System)是“域名系统”的英文缩写，是一种组织成域层次结构的计算机和网络服务命名系统，它用于TCP/IP网络，它所提供的服务是用来将主机名和域名转换为IP地址的工作。DNS就是这样的一位“翻译官”。 \n\n![DNS的作用](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/1.jpg)\n\n<!-- more -->\n\n## 域的划分\n域名系统作为一个层次结构和分布式数据库，包含各种类型的数据，包括主机名和域名。DNS数据库中的名称形成一个分层树状结构称为域命名空间。域名包含单个标签分隔点，例如：im.qq.com。 \n\n完全限定的域名 (FQDN) 唯一地标识在 DNS 分层树中的主机的位置，通过指定的路径中点分隔从根引用的主机的名称列表。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/2.jpg)\n\n按其功能命名空间中用来描述 DNS 域名称的五个类别的介绍详见下表中，以及与每个名称类型的示例。 \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/3.jpg)\n\n### 根域\n就是所谓的“.”，其实我们的网址www.qq.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点。根域服务器我们知道有13台，但是这是错误的观点。根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了任播的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。 \n\n### 顶级域\n根域下来就是顶级域或者叫一级域。一些常见的DNS域名称如下图： \n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/4.jpg)\n\n### 域名服务器\n每个域都会有域名服务器，也叫权威域名服务器。 \n\n能提供域名解析的服务器，上面的记录类型可以是A(address)记录,NS记录（name server）,MX（mail）,CNAME等。 \n\n### 资源记录 \nDNS 数据库中包含的资源记录 (RR)。 每个 RR 标识数据库中的特定资源。我们在建立DNS服务器时，经常会用到SOA,NS,A之类的记录，在维护DNS服务器时，会用到MX，CNAME记录。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/5.jpg)\n\n## DNS服务的工作过程 \n当 DNS 客户机需要查询程序中使用的名称时，它会查询本地DNS 服务器来解析该名称。客户机发送的每条查询消息都包括3条信息，以指定服务器应回答的问题。 \n\n1. 指定的 DNS 域名，表示为完全合格的域名 (FQDN) 。 \n2. 指定的查询类型，它可根据类型指定资源记录，或作为查询操作的专门类型。 \n3。 DNS域名的指定类别。 \n\n对于DNS 服务器，它始终应指定为 Internet 类别。例如，指定的名称可以是计算机的完全合格的域名，如im.qq.com，并且指定的查询类型用于通过该名称搜索地址资源记录。 \n\nDNS 查询以各种不同的方式进行解析。客户机有时也可通过使用从以前查询获得的缓存信息就地应答查询。DNS 服务器可使用其自身的资源记录信息缓存来应答查询，也可代表请求客户机来查询或联系其他 DNS 服务器，以完全解析该名称，并随后将应答返回至客户机。这个过程称为递归。 \n\n另外，客户机自己也可尝试联系其他的 DNS 服务器来解析名称。如果客户机这么做，它会使用基于服务器应答的独立和附加的查询，该过程称作迭代，即DNS服务器之间的交互查询就是迭代查询。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/DNS%E8%A7%A3%E6%9E%90%E5%8E%9F%E7%90%86/6.jpg) \n\n1. 在浏览器中输入www.qq.com域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。 \n2. 如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。 \n3. 如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/IP参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。 \n4. 如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。 \n5. 如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名(.com)服务器的一个IP。 \n6. 本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(qq.com)给本地DNS服务器。 \n7. 当本地DNS服务器收到这个地址后，就会找qq.com域服务器，重复上面的动作，进行查询，直至找到www.qq.com主机。 \n8. 如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。\n\n\n\n\n[原文地址](http://blog.csdn.net/benbenzhuhwp/article/details/44704307)","slug":"DNS原理及其解析过程","published":1,"updated":"2019-03-23T10:24:30.751Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1egn0005gyavvnaluqyr"},{"title":"Dnsmasq 安装配置","originContent":"Dnsmasq  官网 [http://www.thekelleys.org.uk/dnsmasq/doc.html](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n\nUnbuntu 安装 Dnsmasq 参见 [https://help.ubuntu.com/community/Dnsmasq](https://help.ubuntu.com/community/Dnsmasq)\n<!-- more -->\n## 介绍\nDNSmasq 提供两种服务，每种服务可以单独运行：\n\n1. DNS 服务\n2. DHCP 服务\n\n本地 DNS 缓存可以加速网络访问，因为用户的浏览器不需要对先前查询过域名再次向 DNS服务器查询。\n\nDNCP 允许用户的电脑为同一个无线或有限环境中的其他计算机分配 IP 地址。\n\n## 安装\n\n```\n$ sudo apt-get install dnsmasq \n```\n\n## 配置\ndnsmasq 配置文件地址\n\n```\n$ /etc/dnsmasq.conf\n```\n\n本地 DNS 缓存设置\n\n修改\n\n```\n#listen-address=\n```\n\n成\n\n```\nlisten-address=127.0.0.1\n```\n\n接下来修改 /etc/resolv.conf，确保新设置的 DNS 服务器 127.0.0.1 出现在 DNS 服务器列表的顶端。无论何时用户的电脑需要解析一个域名，它会首先请求 dnsmasq （其跑在 127.0.0.1） \n\n```\ncat  /etc/resolv.conf\nsearch yourisp.com\nnameserver 127.0.0.1\nnameserver 192.168.0.1\nnameserver 205.171.3.25\nnameserver 205.171.3.26\n```\n\n修改后配置后重启服务生效\n\n```\n$ sudo /etc/init.d/dnsmasq restart\n```\n\n[原文地址](http://www.cnblogs.com/DillGao/p/7372014.html)","toc":false,"date":"2018-01-10T09:17:10.000Z","_content":"\nDnsmasq  官网 [http://www.thekelleys.org.uk/dnsmasq/doc.html](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n\nUnbuntu 安装 Dnsmasq 参见 [https://help.ubuntu.com/community/Dnsmasq](https://help.ubuntu.com/community/Dnsmasq)\n<!-- more -->\n## 介绍\nDNSmasq 提供两种服务，每种服务可以单独运行：\n\n1. DNS 服务\n2. DHCP 服务\n\n本地 DNS 缓存可以加速网络访问，因为用户的浏览器不需要对先前查询过域名再次向 DNS服务器查询。\n\nDNCP 允许用户的电脑为同一个无线或有限环境中的其他计算机分配 IP 地址。\n\n## 安装\n\n```\n$ sudo apt-get install dnsmasq \n```\n\n## 配置\ndnsmasq 配置文件地址\n\n```\n$ /etc/dnsmasq.conf\n```\n\n本地 DNS 缓存设置\n\n修改\n\n```\n#listen-address=\n```\n\n成\n\n```\nlisten-address=127.0.0.1\n```\n\n接下来修改 /etc/resolv.conf，确保新设置的 DNS 服务器 127.0.0.1 出现在 DNS 服务器列表的顶端。无论何时用户的电脑需要解析一个域名，它会首先请求 dnsmasq （其跑在 127.0.0.1） \n\n```\ncat  /etc/resolv.conf\nsearch yourisp.com\nnameserver 127.0.0.1\nnameserver 192.168.0.1\nnameserver 205.171.3.25\nnameserver 205.171.3.26\n```\n\n修改后配置后重启服务生效\n\n```\n$ sudo /etc/init.d/dnsmasq restart\n```\n\n[原文地址](http://www.cnblogs.com/DillGao/p/7372014.html)","source":"_posts/Dnsmasq 安装配置.md","raw":"---\ntitle: Dnsmasq 安装配置\ntags:\n  - 运维\noriginContent: >-\n  Dnsmasq  官网\n  [http://www.thekelleys.org.uk/dnsmasq/doc.html](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n\n\n  Unbuntu 安装 Dnsmasq 参见\n  [https://help.ubuntu.com/community/Dnsmasq](https://help.ubuntu.com/community/Dnsmasq)\n\n  <!-- more -->\n\n  ## 介绍\n\n  DNSmasq 提供两种服务，每种服务可以单独运行：\n\n\n  1. DNS 服务\n\n  2. DHCP 服务\n\n\n  本地 DNS 缓存可以加速网络访问，因为用户的浏览器不需要对先前查询过域名再次向 DNS服务器查询。\n\n\n  DNCP 允许用户的电脑为同一个无线或有限环境中的其他计算机分配 IP 地址。\n\n\n  ## 安装\n\n\n  ```\n\n  $ sudo apt-get install dnsmasq \n\n  ```\n\n\n  ## 配置\n\n  dnsmasq 配置文件地址\n\n\n  ```\n\n  $ /etc/dnsmasq.conf\n\n  ```\n\n\n  本地 DNS 缓存设置\n\n\n  修改\n\n\n  ```\n\n  #listen-address=\n\n  ```\n\n\n  成\n\n\n  ```\n\n  listen-address=127.0.0.1\n\n  ```\n\n\n  接下来修改 /etc/resolv.conf，确保新设置的 DNS 服务器 127.0.0.1 出现在 DNS\n  服务器列表的顶端。无论何时用户的电脑需要解析一个域名，它会首先请求 dnsmasq （其跑在 127.0.0.1） \n\n\n  ```\n\n  cat  /etc/resolv.conf\n\n  search yourisp.com\n\n  nameserver 127.0.0.1\n\n  nameserver 192.168.0.1\n\n  nameserver 205.171.3.25\n\n  nameserver 205.171.3.26\n\n  ```\n\n\n  修改后配置后重启服务生效\n\n\n  ```\n\n  $ sudo /etc/init.d/dnsmasq restart\n\n  ```\n\n\n  [原文地址](http://www.cnblogs.com/DillGao/p/7372014.html)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-10 17:17:10\n---\n\nDnsmasq  官网 [http://www.thekelleys.org.uk/dnsmasq/doc.html](http://www.thekelleys.org.uk/dnsmasq/doc.html)\n\nUnbuntu 安装 Dnsmasq 参见 [https://help.ubuntu.com/community/Dnsmasq](https://help.ubuntu.com/community/Dnsmasq)\n<!-- more -->\n## 介绍\nDNSmasq 提供两种服务，每种服务可以单独运行：\n\n1. DNS 服务\n2. DHCP 服务\n\n本地 DNS 缓存可以加速网络访问，因为用户的浏览器不需要对先前查询过域名再次向 DNS服务器查询。\n\nDNCP 允许用户的电脑为同一个无线或有限环境中的其他计算机分配 IP 地址。\n\n## 安装\n\n```\n$ sudo apt-get install dnsmasq \n```\n\n## 配置\ndnsmasq 配置文件地址\n\n```\n$ /etc/dnsmasq.conf\n```\n\n本地 DNS 缓存设置\n\n修改\n\n```\n#listen-address=\n```\n\n成\n\n```\nlisten-address=127.0.0.1\n```\n\n接下来修改 /etc/resolv.conf，确保新设置的 DNS 服务器 127.0.0.1 出现在 DNS 服务器列表的顶端。无论何时用户的电脑需要解析一个域名，它会首先请求 dnsmasq （其跑在 127.0.0.1） \n\n```\ncat  /etc/resolv.conf\nsearch yourisp.com\nnameserver 127.0.0.1\nnameserver 192.168.0.1\nnameserver 205.171.3.25\nnameserver 205.171.3.26\n```\n\n修改后配置后重启服务生效\n\n```\n$ sudo /etc/init.d/dnsmasq restart\n```\n\n[原文地址](http://www.cnblogs.com/DillGao/p/7372014.html)","slug":"Dnsmasq 安装配置","published":1,"updated":"2019-03-23T10:26:11.949Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1egw0006gyav4owv4dob"},{"title":"Git仓库完全迁移，包括所有的分支和标签，当然也包括日志","originContent":"度娘了一堆git仓库迁移的内容，一个个都比较麻烦，而且本地下了代码，还要删去库地址，再切换到新库的地址上传。\n\n一般这种操作都只是master分支，其他分支还要一个一个来，后来在51CTO上找了一个文章，简单明了，一下就全搞定了。\n\n包括所有的分支、标签、日志，一个不少。\n\n当然账号对应的事就没办法了。\n\n四行命令：\n\n```\ngit clone --mirror <URL to my OLD repo location>\ncd <New directory where your OLD repo was cloned>\ngit remote set-url origin <URL to my NEW repo location>\ngit push -f origin\n```","toc":false,"date":"2018-07-11T09:27:57.000Z","_content":"\n度娘了一堆git仓库迁移的内容，一个个都比较麻烦，而且本地下了代码，还要删去库地址，再切换到新库的地址上传。\n\n一般这种操作都只是master分支，其他分支还要一个一个来，后来在51CTO上找了一个文章，简单明了，一下就全搞定了。\n\n包括所有的分支、标签、日志，一个不少。\n\n当然账号对应的事就没办法了。\n\n四行命令：\n\n```\ngit clone --mirror <URL to my OLD repo location>\ncd <New directory where your OLD repo was cloned>\ngit remote set-url origin <URL to my NEW repo location>\ngit push -f origin\n```","source":"_posts/Git仓库完全迁移，包括所有的分支和标签，当然也包括日志.md","raw":"---\ntitle: Git仓库完全迁移，包括所有的分支和标签，当然也包括日志\ntags:\n  - git迁移\noriginContent: |-\n  度娘了一堆git仓库迁移的内容，一个个都比较麻烦，而且本地下了代码，还要删去库地址，再切换到新库的地址上传。\n\n  一般这种操作都只是master分支，其他分支还要一个一个来，后来在51CTO上找了一个文章，简单明了，一下就全搞定了。\n\n  包括所有的分支、标签、日志，一个不少。\n\n  当然账号对应的事就没办法了。\n\n  四行命令：\n\n  ```\n  git clone --mirror <URL to my OLD repo location>\n  cd <New directory where your OLD repo was cloned>\n  git remote set-url origin <URL to my NEW repo location>\n  git push -f origin\n  ```\ncategories:\n  - 项目总结\ntoc: false\ndate: 2018-07-11 17:27:57\n---\n\n度娘了一堆git仓库迁移的内容，一个个都比较麻烦，而且本地下了代码，还要删去库地址，再切换到新库的地址上传。\n\n一般这种操作都只是master分支，其他分支还要一个一个来，后来在51CTO上找了一个文章，简单明了，一下就全搞定了。\n\n包括所有的分支、标签、日志，一个不少。\n\n当然账号对应的事就没办法了。\n\n四行命令：\n\n```\ngit clone --mirror <URL to my OLD repo location>\ncd <New directory where your OLD repo was cloned>\ngit remote set-url origin <URL to my NEW repo location>\ngit push -f origin\n```","slug":"Git仓库完全迁移，包括所有的分支和标签，当然也包括日志","published":1,"updated":"2019-03-23T11:03:07.593Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eh2000agyavf6rjqiv7"},{"title":"JavaScript判断知否支持h5 video标签","originContent":"也就一行代码：\n\n```\n!!document.createElement('video').canPlayType\n```\n\n记下来做个备忘","toc":false,"date":"2017-10-27T06:36:10.000Z","_content":"\n也就一行代码：\n\n```\n!!document.createElement('video').canPlayType\n```\n\n记下来做个备忘","source":"_posts/JavaScript判断知否支持h5-video标签.md","raw":"---\ntitle: JavaScript判断知否支持h5 video标签\ntags:\n  - javascript\noriginContent: |-\n  也就一行代码：\n\n  ```\n  !!document.createElement('video').canPlayType\n  ```\n\n  记下来做个备忘\ncategories:\n  - Web开发\ntoc: false\ndate: 2017-10-27 14:36:10\n---\n\n也就一行代码：\n\n```\n!!document.createElement('video').canPlayType\n```\n\n记下来做个备忘","slug":"JavaScript判断知否支持h5-video标签","published":1,"updated":"2019-03-23T10:32:16.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eh5000bgyav6pbt6dwl"},{"title":"Let's Encrypt：用免费的 SSL 证书，让网站支持 HTTPS","originContent":"申请 Let's Encrypt 提供的免费 SSL 证书，配置网站使用 HTTPS，让网站应用更安全。\n直接在运行网站的服务器上去申请 SSL 证书更方便一些，你也可以在一台服务器上去为在\n其它服务器上运行的网站申请 SSL 证书，这需要做额外的验证。操作都非常简单，不用紧张：）\n<!-- more -->\n我在一台 CentOS  7 服务器上申请了 Let's Encrypt 签发的 SSL 证书，我的网站的 Web 服务器用的是 Nginx。\n\n## 安装EPEL仓库\n\n在 CentOS 的 EPEL 仓库里可以找到签发 Let's Encrypt 证书用的工具。所以先安装一下这个仓库，执行：\n\n```\nsudo yum install epel-release -y\n```\n\n公司内网不能用，可以在本地虚拟机安装，然后通过下边的『为其他服务器申请证书的流程走』\n\n## 安装签发证书工具\n\n用 Certbot 工具申请 Let's Encrypt 证书，先安装一下：\n\n```\nsudo yum install certbot-nginx\n```\n\n运行 certbot 工具时报错：\n\n```\nImportError: No module named 'requests.packages.urllib3'\n```\n\n执行下面的命令解决了上面的问题：\n\n```\npip install --upgrade --force-reinstall 'requests==2.6.0' urllib3\n```\n\n## 申请证书\n### 网站运行在申请 SSL 证书用的服务器上\n\n你要申请 SSL 证书的主机名已经指向了申请用的服务器的 IP 地址，\n在服务器上用的是 Nginx Web 服务器。保证 Nginx 正在运行，并\n且已经配置好了 Nginx ，绑定上了要申请 SSL 证书的主机名。就是\n你应该在 Nginx 的配置里面，有一个配置是为要申请 SSL 证书的主\n机名准备的。\n\n一开始我们在服务器上安装的 Certbot 可以自动修改指定主机名的\n Nginx 配置，为主机名申请证书，下载证书，并且会自动修改 Nginx\n 的配置，让它支持 HTTPS。\n\n执行：\n\n```\nsudo certbot --nginx\n```\n\nCertbot 会自动查找当前服务器上的 Nginx 里面的虚拟主机。提示：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator nginx, Installer nginx\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\n\nWhich names would you like to activate HTTPS for?\n-------------------------------------------------------------------------------\n1: houjiyi.com\n2: galary.houjiyi.com\n3: www.houjiyi.com\n-------------------------------------------------------------------------------\nSelect the appropriate numbers separated by commas and/or spaces, or leave input\nblank to select all options shown (Enter 'c' to cancel):\n```\n\n比如我的服务器上有两个 Nginx 虚拟主机，上面会提示想给哪个主机名申请 SSL 证书，输入序号选择，\n或留为空白直接回车选择所有。验证成功，Let's Encrypt 就会立即给你签发 SSL 证书，并且会自动\n修改主机的 Nginx 配置，让它支持 HTTPS。过程中会提示：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\ntls-sni-01 challenge for houjiyi.com\nWaiting for verification...\nCleaning up challenges\nDeployed Certificate to VirtualHost /etc/nginx/conf.d/www.conf for set(['houjiyi.com'])\n\nPlease choose whether or not to redirect HTTP traffic to HTTPS, removing HTTP access.\n-------------------------------------------------------------------------------\n1: No redirect - Make no further changes to the webserver configuration.\n2: Redirect - Make all requests redirect to secure HTTPS access. Choose this for\nnew sites, or if you're confident your site works on HTTPS. You can undo this\nchange by editing your web server's configuration.\n-------------------------------------------------------------------------------\nSelect the appropriate number [1-2] then [enter] (press 'c' to cancel):\n```\n\n意思是，想不想把 HTTP 的请求重定向到 HTTPS ，如果选择 Redirect，Certbot 会自动在主机的 Nginx 配置里添加重定向用的配置。成功以后会提示：\n\n```\nThe appropriate server block is already redirecting traffic. To enable redirect anyway, uncomment the redirect lines in /etc/nginx/conf.d/www.conf.\n\n-------------------------------------------------------------------------------\nCongratulations! You have successfully enabled https://houjiyi.com\n\nYou should test your configuration at:\nhttps://www.ssllabs.com/ssltest/analyze.html?d=houjiyi.com\n-------------------------------------------------------------------------------\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/houjiyi.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/houjiyi.com/privkey.pem\n   Your cert will expire on 2018-04-02. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot again\n   with the \"certonly\" option. To non-interactively renew *all* of\n   your certificates, run \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n上面会告诉你申请的 Let's Encrypt 证书保存的位置，一般是在：\n\n```\n/etc/letsencrypt/live/主机名\n```\n\n再打开网站的 Nginx 配置检查一下，配置里会有一些东西是 Certbot 自动添加的，配置的后面都会有注释 managed by Certbot：\n\n```\nserver {\n    listen        80;\n    server_name   houjiyi.com;\n\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/houjiyi.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/houjiyi.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n\n    if ($scheme = \"https\") {\n        return 301 https://www.$host$request_uri;\n    }\n}\n```\n\n如果你只想为跟 Nginx 绑定的主机名申请证书，不想让 Certbot 修改 Nginx 的配置，可以执行：\n\n```\nsudo certbot --nginx certonly\n```\n\n### 网站运行在申请 SSL 证书以外的服务器上\n\n我们在一个 CentOS 服务器上，也可以为运行在其它服务器上的网站申请 Let's Encrypt 证书，只需要多做一步验证。\n\n执行：\n\n```\nsudo certbot certonly --manual\n```\n\n提示让你输入想要申请证书的主机名：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator manual, Installer None\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\nPlease enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\nto cancel): t2.m.le.com\n```\n\n继续又会提示要记录服务器的 IP 地址，是不是同意这样：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for t2.m.le.com\n\n-------------------------------------------------------------------------------\nNOTE: The IP of this machine will be publicly logged as having requested this\ncertificate. If you're running certbot in manual mode on a machine that is not\nyour server, please ensure you're okay with that.\n\nAre you OK with your IP being logged?\n-------------------------------------------------------------------------------\n(Y)es/(N)o: Y\n```\n\n下面要做一步验证，把一串字符放在指定的文件里，而且要用指定的路径可以访问到这个文件，这样就可以完成验证了。\n\n```\nCreate a file containing just this data:\n\nKIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw.dfvuyqod4KGCve8xM-wotdjimoIXlfb6a4dkaSFN7LI\n\nAnd make it available on your web server at this URL:\n\nhttp://t2.m.le.com/.well-known/acme-challenge/KIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw\n\n-------------------------------------------------------------------------------\nPress Enter to Continue\n```\n\n一切正常，验证通过就会签发证书：\n\n```\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/privkey.pem\n   Your cert will expire on 2018-03-12. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n## 结语\n\n阿里云申请的免费的赛门铁克的证书有效期是一年，同时赛门铁克证书在以后的chrome版本可能不被信任，\n因此换一个证书。这个证书有效期为3个月，到期后操作一遍即可。","toc":false,"date":"2017-12-31T10:23:46.000Z","_content":"\n申请 Let's Encrypt 提供的免费 SSL 证书，配置网站使用 HTTPS，让网站应用更安全。\n直接在运行网站的服务器上去申请 SSL 证书更方便一些，你也可以在一台服务器上去为在\n其它服务器上运行的网站申请 SSL 证书，这需要做额外的验证。操作都非常简单，不用紧张：）\n<!-- more -->\n我在一台 CentOS  7 服务器上申请了 Let's Encrypt 签发的 SSL 证书，我的网站的 Web 服务器用的是 Nginx。\n\n## 安装EPEL仓库\n\n在 CentOS 的 EPEL 仓库里可以找到签发 Let's Encrypt 证书用的工具。所以先安装一下这个仓库，执行：\n\n```\nsudo yum install epel-release -y\n```\n\n公司内网不能用，可以在本地虚拟机安装，然后通过下边的『为其他服务器申请证书的流程走』\n\n## 安装签发证书工具\n\n用 Certbot 工具申请 Let's Encrypt 证书，先安装一下：\n\n```\nsudo yum install certbot-nginx\n```\n\n运行 certbot 工具时报错：\n\n```\nImportError: No module named 'requests.packages.urllib3'\n```\n\n执行下面的命令解决了上面的问题：\n\n```\npip install --upgrade --force-reinstall 'requests==2.6.0' urllib3\n```\n\n## 申请证书\n### 网站运行在申请 SSL 证书用的服务器上\n\n你要申请 SSL 证书的主机名已经指向了申请用的服务器的 IP 地址，\n在服务器上用的是 Nginx Web 服务器。保证 Nginx 正在运行，并\n且已经配置好了 Nginx ，绑定上了要申请 SSL 证书的主机名。就是\n你应该在 Nginx 的配置里面，有一个配置是为要申请 SSL 证书的主\n机名准备的。\n\n一开始我们在服务器上安装的 Certbot 可以自动修改指定主机名的\n Nginx 配置，为主机名申请证书，下载证书，并且会自动修改 Nginx\n 的配置，让它支持 HTTPS。\n\n执行：\n\n```\nsudo certbot --nginx\n```\n\nCertbot 会自动查找当前服务器上的 Nginx 里面的虚拟主机。提示：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator nginx, Installer nginx\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\n\nWhich names would you like to activate HTTPS for?\n-------------------------------------------------------------------------------\n1: houjiyi.com\n2: galary.houjiyi.com\n3: www.houjiyi.com\n-------------------------------------------------------------------------------\nSelect the appropriate numbers separated by commas and/or spaces, or leave input\nblank to select all options shown (Enter 'c' to cancel):\n```\n\n比如我的服务器上有两个 Nginx 虚拟主机，上面会提示想给哪个主机名申请 SSL 证书，输入序号选择，\n或留为空白直接回车选择所有。验证成功，Let's Encrypt 就会立即给你签发 SSL 证书，并且会自动\n修改主机的 Nginx 配置，让它支持 HTTPS。过程中会提示：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\ntls-sni-01 challenge for houjiyi.com\nWaiting for verification...\nCleaning up challenges\nDeployed Certificate to VirtualHost /etc/nginx/conf.d/www.conf for set(['houjiyi.com'])\n\nPlease choose whether or not to redirect HTTP traffic to HTTPS, removing HTTP access.\n-------------------------------------------------------------------------------\n1: No redirect - Make no further changes to the webserver configuration.\n2: Redirect - Make all requests redirect to secure HTTPS access. Choose this for\nnew sites, or if you're confident your site works on HTTPS. You can undo this\nchange by editing your web server's configuration.\n-------------------------------------------------------------------------------\nSelect the appropriate number [1-2] then [enter] (press 'c' to cancel):\n```\n\n意思是，想不想把 HTTP 的请求重定向到 HTTPS ，如果选择 Redirect，Certbot 会自动在主机的 Nginx 配置里添加重定向用的配置。成功以后会提示：\n\n```\nThe appropriate server block is already redirecting traffic. To enable redirect anyway, uncomment the redirect lines in /etc/nginx/conf.d/www.conf.\n\n-------------------------------------------------------------------------------\nCongratulations! You have successfully enabled https://houjiyi.com\n\nYou should test your configuration at:\nhttps://www.ssllabs.com/ssltest/analyze.html?d=houjiyi.com\n-------------------------------------------------------------------------------\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/houjiyi.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/houjiyi.com/privkey.pem\n   Your cert will expire on 2018-04-02. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot again\n   with the \"certonly\" option. To non-interactively renew *all* of\n   your certificates, run \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n上面会告诉你申请的 Let's Encrypt 证书保存的位置，一般是在：\n\n```\n/etc/letsencrypt/live/主机名\n```\n\n再打开网站的 Nginx 配置检查一下，配置里会有一些东西是 Certbot 自动添加的，配置的后面都会有注释 managed by Certbot：\n\n```\nserver {\n    listen        80;\n    server_name   houjiyi.com;\n\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/houjiyi.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/houjiyi.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n\n    if ($scheme = \"https\") {\n        return 301 https://www.$host$request_uri;\n    }\n}\n```\n\n如果你只想为跟 Nginx 绑定的主机名申请证书，不想让 Certbot 修改 Nginx 的配置，可以执行：\n\n```\nsudo certbot --nginx certonly\n```\n\n### 网站运行在申请 SSL 证书以外的服务器上\n\n我们在一个 CentOS 服务器上，也可以为运行在其它服务器上的网站申请 Let's Encrypt 证书，只需要多做一步验证。\n\n执行：\n\n```\nsudo certbot certonly --manual\n```\n\n提示让你输入想要申请证书的主机名：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator manual, Installer None\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\nPlease enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\nto cancel): t2.m.le.com\n```\n\n继续又会提示要记录服务器的 IP 地址，是不是同意这样：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for t2.m.le.com\n\n-------------------------------------------------------------------------------\nNOTE: The IP of this machine will be publicly logged as having requested this\ncertificate. If you're running certbot in manual mode on a machine that is not\nyour server, please ensure you're okay with that.\n\nAre you OK with your IP being logged?\n-------------------------------------------------------------------------------\n(Y)es/(N)o: Y\n```\n\n下面要做一步验证，把一串字符放在指定的文件里，而且要用指定的路径可以访问到这个文件，这样就可以完成验证了。\n\n```\nCreate a file containing just this data:\n\nKIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw.dfvuyqod4KGCve8xM-wotdjimoIXlfb6a4dkaSFN7LI\n\nAnd make it available on your web server at this URL:\n\nhttp://t2.m.le.com/.well-known/acme-challenge/KIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw\n\n-------------------------------------------------------------------------------\nPress Enter to Continue\n```\n\n一切正常，验证通过就会签发证书：\n\n```\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/privkey.pem\n   Your cert will expire on 2018-03-12. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n## 结语\n\n阿里云申请的免费的赛门铁克的证书有效期是一年，同时赛门铁克证书在以后的chrome版本可能不被信任，\n因此换一个证书。这个证书有效期为3个月，到期后操作一遍即可。","source":"_posts/Let-s-Encrypt：用免费的-SSL-证书，让网站支持-HTTPS.md","raw":"---\ntitle: Let's Encrypt：用免费的 SSL 证书，让网站支持 HTTPS\ntags:\n  - 域名\noriginContent: >-\n  申请 Let's Encrypt 提供的免费 SSL 证书，配置网站使用 HTTPS，让网站应用更安全。\n\n  直接在运行网站的服务器上去申请 SSL 证书更方便一些，你也可以在一台服务器上去为在\n\n  其它服务器上运行的网站申请 SSL 证书，这需要做额外的验证。操作都非常简单，不用紧张：）\n\n  <!-- more -->\n\n  我在一台 CentOS  7 服务器上申请了 Let's Encrypt 签发的 SSL 证书，我的网站的 Web 服务器用的是 Nginx。\n\n\n  ## 安装EPEL仓库\n\n\n  在 CentOS 的 EPEL 仓库里可以找到签发 Let's Encrypt 证书用的工具。所以先安装一下这个仓库，执行：\n\n\n  ```\n\n  sudo yum install epel-release -y\n\n  ```\n\n\n  公司内网不能用，可以在本地虚拟机安装，然后通过下边的『为其他服务器申请证书的流程走』\n\n\n  ## 安装签发证书工具\n\n\n  用 Certbot 工具申请 Let's Encrypt 证书，先安装一下：\n\n\n  ```\n\n  sudo yum install certbot-nginx\n\n  ```\n\n\n  运行 certbot 工具时报错：\n\n\n  ```\n\n  ImportError: No module named 'requests.packages.urllib3'\n\n  ```\n\n\n  执行下面的命令解决了上面的问题：\n\n\n  ```\n\n  pip install --upgrade --force-reinstall 'requests==2.6.0' urllib3\n\n  ```\n\n\n  ## 申请证书\n\n  ### 网站运行在申请 SSL 证书用的服务器上\n\n\n  你要申请 SSL 证书的主机名已经指向了申请用的服务器的 IP 地址，\n\n  在服务器上用的是 Nginx Web 服务器。保证 Nginx 正在运行，并\n\n  且已经配置好了 Nginx ，绑定上了要申请 SSL 证书的主机名。就是\n\n  你应该在 Nginx 的配置里面，有一个配置是为要申请 SSL 证书的主\n\n  机名准备的。\n\n\n  一开始我们在服务器上安装的 Certbot 可以自动修改指定主机名的\n   Nginx 配置，为主机名申请证书，下载证书，并且会自动修改 Nginx\n   的配置，让它支持 HTTPS。\n\n  执行：\n\n\n  ```\n\n  sudo certbot --nginx\n\n  ```\n\n\n  Certbot 会自动查找当前服务器上的 Nginx 里面的虚拟主机。提示：\n\n\n  ```\n\n  Saving debug log to /var/log/letsencrypt/letsencrypt.log\n\n  Plugins selected: Authenticator nginx, Installer nginx\n\n  Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org\n\n\n  Which names would you like to activate HTTPS for?\n\n  -------------------------------------------------------------------------------\n\n  1: houjiyi.com\n\n  2: galary.houjiyi.com\n\n  3: www.houjiyi.com\n\n  -------------------------------------------------------------------------------\n\n  Select the appropriate numbers separated by commas and/or spaces, or leave\n  input\n\n  blank to select all options shown (Enter 'c' to cancel):\n\n  ```\n\n\n  比如我的服务器上有两个 Nginx 虚拟主机，上面会提示想给哪个主机名申请 SSL 证书，输入序号选择，\n\n  或留为空白直接回车选择所有。验证成功，Let's Encrypt 就会立即给你签发 SSL 证书，并且会自动\n\n  修改主机的 Nginx 配置，让它支持 HTTPS。过程中会提示：\n\n\n  ```\n\n  Obtaining a new certificate\n\n  Performing the following challenges:\n\n  tls-sni-01 challenge for houjiyi.com\n\n  Waiting for verification...\n\n  Cleaning up challenges\n\n  Deployed Certificate to VirtualHost /etc/nginx/conf.d/www.conf for\n  set(['houjiyi.com'])\n\n\n  Please choose whether or not to redirect HTTP traffic to HTTPS, removing HTTP\n  access.\n\n  -------------------------------------------------------------------------------\n\n  1: No redirect - Make no further changes to the webserver configuration.\n\n  2: Redirect - Make all requests redirect to secure HTTPS access. Choose this\n  for\n\n  new sites, or if you're confident your site works on HTTPS. You can undo this\n\n  change by editing your web server's configuration.\n\n  -------------------------------------------------------------------------------\n\n  Select the appropriate number [1-2] then [enter] (press 'c' to cancel):\n\n  ```\n\n\n  意思是，想不想把 HTTP 的请求重定向到 HTTPS ，如果选择 Redirect，Certbot 会自动在主机的 Nginx\n  配置里添加重定向用的配置。成功以后会提示：\n\n\n  ```\n\n  The appropriate server block is already redirecting traffic. To enable\n  redirect anyway, uncomment the redirect lines in /etc/nginx/conf.d/www.conf.\n\n\n  -------------------------------------------------------------------------------\n\n  Congratulations! You have successfully enabled https://houjiyi.com\n\n\n  You should test your configuration at:\n\n  https://www.ssllabs.com/ssltest/analyze.html?d=houjiyi.com\n\n  -------------------------------------------------------------------------------\n\n\n  IMPORTANT NOTES:\n   - Congratulations! Your certificate and chain have been saved at:\n     /etc/letsencrypt/live/houjiyi.com/fullchain.pem\n     Your key file has been saved at:\n     /etc/letsencrypt/live/houjiyi.com/privkey.pem\n     Your cert will expire on 2018-04-02. To obtain a new or tweaked\n     version of this certificate in the future, simply run certbot again\n     with the \"certonly\" option. To non-interactively renew *all* of\n     your certificates, run \"certbot renew\"\n   - If you like Certbot, please consider supporting our work by:\n\n     Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n     Donating to EFF:                    https://eff.org/donate-le\n  ```\n\n\n  上面会告诉你申请的 Let's Encrypt 证书保存的位置，一般是在：\n\n\n  ```\n\n  /etc/letsencrypt/live/主机名\n\n  ```\n\n\n  再打开网站的 Nginx 配置检查一下，配置里会有一些东西是 Certbot 自动添加的，配置的后面都会有注释 managed by Certbot：\n\n\n  ```\n\n  server {\n      listen        80;\n      server_name   houjiyi.com;\n\n      listen 443 ssl;\n      ssl_certificate /etc/letsencrypt/live/houjiyi.com/fullchain.pem;\n      ssl_certificate_key /etc/letsencrypt/live/houjiyi.com/privkey.pem;\n      include /etc/letsencrypt/options-ssl-nginx.conf;\n      ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n\n      if ($scheme = \"https\") {\n          return 301 https://www.$host$request_uri;\n      }\n  }\n\n  ```\n\n\n  如果你只想为跟 Nginx 绑定的主机名申请证书，不想让 Certbot 修改 Nginx 的配置，可以执行：\n\n\n  ```\n\n  sudo certbot --nginx certonly\n\n  ```\n\n\n  ### 网站运行在申请 SSL 证书以外的服务器上\n\n\n  我们在一个 CentOS 服务器上，也可以为运行在其它服务器上的网站申请 Let's Encrypt 证书，只需要多做一步验证。\n\n\n  执行：\n\n\n  ```\n\n  sudo certbot certonly --manual\n\n  ```\n\n\n  提示让你输入想要申请证书的主机名：\n\n\n  ```\n\n  Saving debug log to /var/log/letsencrypt/letsencrypt.log\n\n  Plugins selected: Authenticator manual, Installer None\n\n  Starting new HTTPS connection (1): acme-v01.api.letsencrypt.org\n\n  Please enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\n\n  to cancel): t2.m.le.com\n\n  ```\n\n\n  继续又会提示要记录服务器的 IP 地址，是不是同意这样：\n\n\n  ```\n\n  Obtaining a new certificate\n\n  Performing the following challenges:\n\n  http-01 challenge for t2.m.le.com\n\n\n  -------------------------------------------------------------------------------\n\n  NOTE: The IP of this machine will be publicly logged as having requested this\n\n  certificate. If you're running certbot in manual mode on a machine that is not\n\n  your server, please ensure you're okay with that.\n\n\n  Are you OK with your IP being logged?\n\n  -------------------------------------------------------------------------------\n\n  (Y)es/(N)o: Y\n\n  ```\n\n\n  下面要做一步验证，把一串字符放在指定的文件里，而且要用指定的路径可以访问到这个文件，这样就可以完成验证了。\n\n\n  ```\n\n  Create a file containing just this data:\n\n\n  KIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw.dfvuyqod4KGCve8xM-wotdjimoIXlfb6a4dkaSFN7LI\n\n\n  And make it available on your web server at this URL:\n\n\n  http://t2.m.le.com/.well-known/acme-challenge/KIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw\n\n\n  -------------------------------------------------------------------------------\n\n  Press Enter to Continue\n\n  ```\n\n\n  一切正常，验证通过就会签发证书：\n\n\n  ```\n\n  Waiting for verification...\n\n  Cleaning up challenges\n\n\n  IMPORTANT NOTES:\n   - Congratulations! Your certificate and chain have been saved at:\n     /etc/letsencrypt/live/t2.m.le.com/fullchain.pem\n     Your key file has been saved at:\n     /etc/letsencrypt/live/t2.m.le.com/privkey.pem\n     Your cert will expire on 2018-03-12. To obtain a new or tweaked\n     version of this certificate in the future, simply run certbot\n     again. To non-interactively renew *all* of your certificates, run\n     \"certbot renew\"\n   - If you like Certbot, please consider supporting our work by:\n\n     Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n     Donating to EFF:                    https://eff.org/donate-le\n  ```\n\n\n  ## 结语\n\n\n  阿里云申请的免费的赛门铁克的证书有效期是一年，同时赛门铁克证书在以后的chrome版本可能不被信任，\n\n  因此换一个证书。这个证书有效期为3个月，到期后操作一遍即可。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-12-31 18:23:46\n---\n\n申请 Let's Encrypt 提供的免费 SSL 证书，配置网站使用 HTTPS，让网站应用更安全。\n直接在运行网站的服务器上去申请 SSL 证书更方便一些，你也可以在一台服务器上去为在\n其它服务器上运行的网站申请 SSL 证书，这需要做额外的验证。操作都非常简单，不用紧张：）\n<!-- more -->\n我在一台 CentOS  7 服务器上申请了 Let's Encrypt 签发的 SSL 证书，我的网站的 Web 服务器用的是 Nginx。\n\n## 安装EPEL仓库\n\n在 CentOS 的 EPEL 仓库里可以找到签发 Let's Encrypt 证书用的工具。所以先安装一下这个仓库，执行：\n\n```\nsudo yum install epel-release -y\n```\n\n公司内网不能用，可以在本地虚拟机安装，然后通过下边的『为其他服务器申请证书的流程走』\n\n## 安装签发证书工具\n\n用 Certbot 工具申请 Let's Encrypt 证书，先安装一下：\n\n```\nsudo yum install certbot-nginx\n```\n\n运行 certbot 工具时报错：\n\n```\nImportError: No module named 'requests.packages.urllib3'\n```\n\n执行下面的命令解决了上面的问题：\n\n```\npip install --upgrade --force-reinstall 'requests==2.6.0' urllib3\n```\n\n## 申请证书\n### 网站运行在申请 SSL 证书用的服务器上\n\n你要申请 SSL 证书的主机名已经指向了申请用的服务器的 IP 地址，\n在服务器上用的是 Nginx Web 服务器。保证 Nginx 正在运行，并\n且已经配置好了 Nginx ，绑定上了要申请 SSL 证书的主机名。就是\n你应该在 Nginx 的配置里面，有一个配置是为要申请 SSL 证书的主\n机名准备的。\n\n一开始我们在服务器上安装的 Certbot 可以自动修改指定主机名的\n Nginx 配置，为主机名申请证书，下载证书，并且会自动修改 Nginx\n 的配置，让它支持 HTTPS。\n\n执行：\n\n```\nsudo certbot --nginx\n```\n\nCertbot 会自动查找当前服务器上的 Nginx 里面的虚拟主机。提示：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator nginx, Installer nginx\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\n\nWhich names would you like to activate HTTPS for?\n-------------------------------------------------------------------------------\n1: houjiyi.com\n2: galary.houjiyi.com\n3: www.houjiyi.com\n-------------------------------------------------------------------------------\nSelect the appropriate numbers separated by commas and/or spaces, or leave input\nblank to select all options shown (Enter 'c' to cancel):\n```\n\n比如我的服务器上有两个 Nginx 虚拟主机，上面会提示想给哪个主机名申请 SSL 证书，输入序号选择，\n或留为空白直接回车选择所有。验证成功，Let's Encrypt 就会立即给你签发 SSL 证书，并且会自动\n修改主机的 Nginx 配置，让它支持 HTTPS。过程中会提示：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\ntls-sni-01 challenge for houjiyi.com\nWaiting for verification...\nCleaning up challenges\nDeployed Certificate to VirtualHost /etc/nginx/conf.d/www.conf for set(['houjiyi.com'])\n\nPlease choose whether or not to redirect HTTP traffic to HTTPS, removing HTTP access.\n-------------------------------------------------------------------------------\n1: No redirect - Make no further changes to the webserver configuration.\n2: Redirect - Make all requests redirect to secure HTTPS access. Choose this for\nnew sites, or if you're confident your site works on HTTPS. You can undo this\nchange by editing your web server's configuration.\n-------------------------------------------------------------------------------\nSelect the appropriate number [1-2] then [enter] (press 'c' to cancel):\n```\n\n意思是，想不想把 HTTP 的请求重定向到 HTTPS ，如果选择 Redirect，Certbot 会自动在主机的 Nginx 配置里添加重定向用的配置。成功以后会提示：\n\n```\nThe appropriate server block is already redirecting traffic. To enable redirect anyway, uncomment the redirect lines in /etc/nginx/conf.d/www.conf.\n\n-------------------------------------------------------------------------------\nCongratulations! You have successfully enabled https://houjiyi.com\n\nYou should test your configuration at:\nhttps://www.ssllabs.com/ssltest/analyze.html?d=houjiyi.com\n-------------------------------------------------------------------------------\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/houjiyi.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/houjiyi.com/privkey.pem\n   Your cert will expire on 2018-04-02. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot again\n   with the \"certonly\" option. To non-interactively renew *all* of\n   your certificates, run \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n上面会告诉你申请的 Let's Encrypt 证书保存的位置，一般是在：\n\n```\n/etc/letsencrypt/live/主机名\n```\n\n再打开网站的 Nginx 配置检查一下，配置里会有一些东西是 Certbot 自动添加的，配置的后面都会有注释 managed by Certbot：\n\n```\nserver {\n    listen        80;\n    server_name   houjiyi.com;\n\n    listen 443 ssl;\n    ssl_certificate /etc/letsencrypt/live/houjiyi.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/houjiyi.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n\n    if ($scheme = \"https\") {\n        return 301 https://www.$host$request_uri;\n    }\n}\n```\n\n如果你只想为跟 Nginx 绑定的主机名申请证书，不想让 Certbot 修改 Nginx 的配置，可以执行：\n\n```\nsudo certbot --nginx certonly\n```\n\n### 网站运行在申请 SSL 证书以外的服务器上\n\n我们在一个 CentOS 服务器上，也可以为运行在其它服务器上的网站申请 Let's Encrypt 证书，只需要多做一步验证。\n\n执行：\n\n```\nsudo certbot certonly --manual\n```\n\n提示让你输入想要申请证书的主机名：\n\n```\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\nPlugins selected: Authenticator manual, Installer None\nStarting new HTTPS connection (1): acme-v01.api.letsencrypt.org\nPlease enter in your domain name(s) (comma and/or space separated)  (Enter 'c'\nto cancel): t2.m.le.com\n```\n\n继续又会提示要记录服务器的 IP 地址，是不是同意这样：\n\n```\nObtaining a new certificate\nPerforming the following challenges:\nhttp-01 challenge for t2.m.le.com\n\n-------------------------------------------------------------------------------\nNOTE: The IP of this machine will be publicly logged as having requested this\ncertificate. If you're running certbot in manual mode on a machine that is not\nyour server, please ensure you're okay with that.\n\nAre you OK with your IP being logged?\n-------------------------------------------------------------------------------\n(Y)es/(N)o: Y\n```\n\n下面要做一步验证，把一串字符放在指定的文件里，而且要用指定的路径可以访问到这个文件，这样就可以完成验证了。\n\n```\nCreate a file containing just this data:\n\nKIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw.dfvuyqod4KGCve8xM-wotdjimoIXlfb6a4dkaSFN7LI\n\nAnd make it available on your web server at this URL:\n\nhttp://t2.m.le.com/.well-known/acme-challenge/KIad2acPdKiF5pLpjlv4fK19PJDchhO7ClJZI_P3zbw\n\n-------------------------------------------------------------------------------\nPress Enter to Continue\n```\n\n一切正常，验证通过就会签发证书：\n\n```\nWaiting for verification...\nCleaning up challenges\n\nIMPORTANT NOTES:\n - Congratulations! Your certificate and chain have been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/fullchain.pem\n   Your key file has been saved at:\n   /etc/letsencrypt/live/t2.m.le.com/privkey.pem\n   Your cert will expire on 2018-03-12. To obtain a new or tweaked\n   version of this certificate in the future, simply run certbot\n   again. To non-interactively renew *all* of your certificates, run\n   \"certbot renew\"\n - If you like Certbot, please consider supporting our work by:\n\n   Donating to ISRG / Let's Encrypt:   https://letsencrypt.org/donate\n   Donating to EFF:                    https://eff.org/donate-le\n```\n\n## 结语\n\n阿里云申请的免费的赛门铁克的证书有效期是一年，同时赛门铁克证书在以后的chrome版本可能不被信任，\n因此换一个证书。这个证书有效期为3个月，到期后操作一遍即可。","slug":"Let-s-Encrypt：用免费的-SSL-证书，让网站支持-HTTPS","published":1,"updated":"2019-03-23T10:29:30.821Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eh9000fgyavfh6vkn8d"},{"title":"Linux 网络速度测试工具","originContent":"只需要安装一个工具即可:\n\n```\nwget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\n\nchmod a+rx speedtest.py\n\nmv speedtest.py /usr/local/bin/speedtest-cli\n\nchown root:root /usr/local/bin/speedtest-cli\n\n```","toc":false,"date":"2017-12-26T07:28:52.000Z","_content":"\n只需要安装一个工具即可:\n\n```\nwget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\n\nchmod a+rx speedtest.py\n\nmv speedtest.py /usr/local/bin/speedtest-cli\n\nchown root:root /usr/local/bin/speedtest-cli\n\n```","source":"_posts/Linux-网络速度测试工具.md","raw":"---\ntitle: Linux 网络速度测试工具\ntags:\n  - linux\noriginContent: |-\n  只需要安装一个工具即可:\n\n  ```\n  wget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\n\n  chmod a+rx speedtest.py\n\n  mv speedtest.py /usr/local/bin/speedtest-cli\n\n  chown root:root /usr/local/bin/speedtest-cli\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-12-26 15:28:52\n---\n\n只需要安装一个工具即可:\n\n```\nwget https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py\n\nchmod a+rx speedtest.py\n\nmv speedtest.py /usr/local/bin/speedtest-cli\n\nchown root:root /usr/local/bin/speedtest-cli\n\n```","slug":"Linux-网络速度测试工具","published":1,"updated":"2019-03-23T10:45:26.760Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ehc000igyavjwqi7771"},{"title":"Nginx后端服务器组配置的5个指令","originContent":"Nginx服务器支持设置一组服务器作为后端服务器。\n\n服务器组的设置包括几个指令，他们是由标准HTTP模块ngx_http_upstream_module进行解析和处理的，我们在这里分别介绍一下。\n\n<!-- more -->\n\n### upstream 指令\n\n该指令是设置后端服务器组的主要指令，其他的指令都在该指令中进行设置。其语法结构为：\n\n```\nupstream name {\n  ...\n}\n```\n\n其中，name是给后端服务器组起得组名。花括号中列出后端服务器组中包含的服务器，其中可以使用下面是介绍的其他指令。\n\n默认情况下，某个服务器组接收到请求以后，按照轮叫调度（Round-Robin，RR）策略顺序选择组内服务器处理请求。如果一个服务器在处理请求的过程中出现错误，请求会被顺次交给组内的下一个服务器进行处理，以此类推，知道返回正常响应。如果所有的组内服务器都出错，则返回最后一个服务器的处理结果。当然我们可以根据各个服务器处理能力或者资源配置情况的不同，给各个服务器配置不同的权重，让能力强的服务器多处理请求，能力弱的少处理。配置权重的变量包含在server指令中。\n\n### server 指令\n\n该指令用于这只组内的服务器，其语法结构为：\n\n ```\n server address [parameters];\n ```\n\n > address，服务器的地址，可以是包含端口号的IP地址（IP:Port）、域名或者以『unix:』为前缀用于进程间通信的Unix Domain Socket。\n\n > parameters，为当前服务器配置更多属性。这些属性变量包含以下内容：\n\n >> weight=number，为组内服务器设置权重，权重值高的服务器被优先用于处理请求。此时组内服务器的选择策略为加权轮叫策略。组内所有服务器的权重默认设置为1，即采用一般轮叫调度原则处理请求。\n\n >> max_fails=number，设置一个请求失败的次数。在一定事件范围内，当对组内某台服务器请求失败的次数超过该变量设置的值时，认为该服务器无效（down）。请求失败的各种情况与proxy_next_upstream指令（在学习Nginx服务器的缓存机制时，是fastcgi_next_upstream指令或者memcached_next_upstream指令）的配置相匹配。默认设置为1。如果设置为0，则不适用上面的办法检查服务器是否有效\n\n >> 注意：HTTP 404 状态不被认为是请求失败\n\n >> fail_timeout=time，有两个作用，一时设置max_fails指令尝试请求某台组内服务器的时间，即学习max_fails指令时提到的\"一定时间范围内\"；另一个作用是在检查服务器是否有效时，如果一台服务器被认为是无效（down）的，该变量设置的时间为认为服务器无效的持续时间。在这个时间内不再检查该服务器的状态，并一直认为它是无效（down）的。默认设置为10s。\n\n >> backup，将某台组内服务器标记为备用服务器，只有当正常的服务器处于无效（down）状态或者繁忙（busy）状态时，该服务器才被用来处理客户端请求。\n\n >> down，将某台组内服务器标记为永久的无效状态，通常与ip_hash指令配合使用。该指令在Nginx 0.6.7 及以上版本中提供。\n\n 我们来通过实例深入对server指令配置的理解：\n\n```\nupstream backend {\n  server backend1.example.com weight=5;\n  server 127.0.0.1:8080 max_fails=3 fail_timeout=30s;\n  server unix:/tmp/backend3;\n}\n```\n\n在该实例中，我们设置了一个名叫backend的服务器组，组内包含三台服务器，分别是基于域名的backend1.example.com、基于IP地址的127.0.0.1:8080和用于进程间通信的Unix Domain Socket。backend1.example.com的权重设置为5，为组内最大，优先接受和处理请求；对本地服务器127.0.0.1:8080的检查设置是，如果30s内连续产生3次请求失败，则改服务器在之后的30s内被认为是无效（down）状态。  \n\n### ip_hash 指令\n\n该指令用于实现会话保持功能，将某个客户端的多次请求定向到组内同一台服务器上，保证客户端与服务器之间建立稳定的会话。只有当该服务器处于无效（down）状态时，客户端请求才会被下一个服务器接收和处理。其语法结构为：\n```\nip_hash;\n```\n\nip_hash技术在一些情况下非常有用，能够避免我们关心的服务器组内个服务器之间会话共享的问题。但是ip_hash技术再实际使用过程中也有限制。\n\n首先，ip_hash指令不能与server指令中的weight变量一起使用。其次，由于ip_hash技术主要根据客户端IP地址分配服务器，因此在整个系统中，Nginx服务器应该是处于最前端的服务器，这样才能够获取到客户端的IP地址，否则他得到的IP地址将是位于它前面的服务器地址，从而就会产生问题。同事要注意，客户端IP地址必须是C类地址。Nginx 1.3.2开发版本和Nginx 1.2.2稳定版本开始支持IPv6地址。\n\n我们来看下面这个实例：\n\n```\nupstream backend {\n  ip_hash;\n  server myback1.proxy.com;\n  server myback2.proxy.com;\n}\n```\n\n该实例中配置了一个名叫backend的服务器组，包含两台后端服务器myback1.proxy.com和myback2.proxy.com。在添加ip_hash指令后，我们使用同一个客户端向Nginx服务器发送请求，将会看到一只是有服务器myback1.proxy.com响应；如果注释掉ip_hash指令后进行相同的操作，发现组内的两台服务器轮流响应请求。\n\n### keepalive 指令\n\n该指令用于控制网络连接保持功能。通过该指令，能够保证Nginx服务器的工作进程为服务区组打开一部分网络连接，并且将数量控制在一定的范围之内。其语法结构为：\n```\nkeepalive connections;\n```\n\n其中，connections为 Nginx 服务器的每个工作进程允许该服务器组保持的空闲网络连接数的上限值。如果超过该值，工作进程将采用最近最少使用的策略关闭网络连接。\n\n该指令从Nginx 1.1.4开始被支持。\n\n> 注意：该指令不能限制Nginx服务器工作进程能够为服务器组开启的总网络连接数。connections变量在设置时也不要设置得太大，否则会影响服务器组与新网络连接的建立。\n\n### least_conn 指令\n\n该指令用于配置Nginx服务器使用负载均衡策略为网络连接分配服务器组内的服务器。该指令在功能上实现了最少连接负载均衡算法，在选择组内的服务器时，考虑各服务器权重的同时，每次选择的都是当前网络连接最少的那台服务器，如果这样的服务器有多台，就采用加权轮叫原则选择权重最大的服务器。其语法结构为：\n```\nleast_conn;\n```","toc":false,"date":"2017-09-02T00:20:49.000Z","_content":"\nNginx服务器支持设置一组服务器作为后端服务器。\n\n服务器组的设置包括几个指令，他们是由标准HTTP模块ngx_http_upstream_module进行解析和处理的，我们在这里分别介绍一下。\n\n<!-- more -->\n\n### upstream 指令\n\n该指令是设置后端服务器组的主要指令，其他的指令都在该指令中进行设置。其语法结构为：\n\n```\nupstream name {\n  ...\n}\n```\n\n其中，name是给后端服务器组起得组名。花括号中列出后端服务器组中包含的服务器，其中可以使用下面是介绍的其他指令。\n\n默认情况下，某个服务器组接收到请求以后，按照轮叫调度（Round-Robin，RR）策略顺序选择组内服务器处理请求。如果一个服务器在处理请求的过程中出现错误，请求会被顺次交给组内的下一个服务器进行处理，以此类推，知道返回正常响应。如果所有的组内服务器都出错，则返回最后一个服务器的处理结果。当然我们可以根据各个服务器处理能力或者资源配置情况的不同，给各个服务器配置不同的权重，让能力强的服务器多处理请求，能力弱的少处理。配置权重的变量包含在server指令中。\n\n### server 指令\n\n该指令用于这只组内的服务器，其语法结构为：\n\n ```\n server address [parameters];\n ```\n\n > address，服务器的地址，可以是包含端口号的IP地址（IP:Port）、域名或者以『unix:』为前缀用于进程间通信的Unix Domain Socket。\n\n > parameters，为当前服务器配置更多属性。这些属性变量包含以下内容：\n\n >> weight=number，为组内服务器设置权重，权重值高的服务器被优先用于处理请求。此时组内服务器的选择策略为加权轮叫策略。组内所有服务器的权重默认设置为1，即采用一般轮叫调度原则处理请求。\n\n >> max_fails=number，设置一个请求失败的次数。在一定事件范围内，当对组内某台服务器请求失败的次数超过该变量设置的值时，认为该服务器无效（down）。请求失败的各种情况与proxy_next_upstream指令（在学习Nginx服务器的缓存机制时，是fastcgi_next_upstream指令或者memcached_next_upstream指令）的配置相匹配。默认设置为1。如果设置为0，则不适用上面的办法检查服务器是否有效\n\n >> 注意：HTTP 404 状态不被认为是请求失败\n\n >> fail_timeout=time，有两个作用，一时设置max_fails指令尝试请求某台组内服务器的时间，即学习max_fails指令时提到的\"一定时间范围内\"；另一个作用是在检查服务器是否有效时，如果一台服务器被认为是无效（down）的，该变量设置的时间为认为服务器无效的持续时间。在这个时间内不再检查该服务器的状态，并一直认为它是无效（down）的。默认设置为10s。\n\n >> backup，将某台组内服务器标记为备用服务器，只有当正常的服务器处于无效（down）状态或者繁忙（busy）状态时，该服务器才被用来处理客户端请求。\n\n >> down，将某台组内服务器标记为永久的无效状态，通常与ip_hash指令配合使用。该指令在Nginx 0.6.7 及以上版本中提供。\n\n 我们来通过实例深入对server指令配置的理解：\n\n```\nupstream backend {\n  server backend1.example.com weight=5;\n  server 127.0.0.1:8080 max_fails=3 fail_timeout=30s;\n  server unix:/tmp/backend3;\n}\n```\n\n在该实例中，我们设置了一个名叫backend的服务器组，组内包含三台服务器，分别是基于域名的backend1.example.com、基于IP地址的127.0.0.1:8080和用于进程间通信的Unix Domain Socket。backend1.example.com的权重设置为5，为组内最大，优先接受和处理请求；对本地服务器127.0.0.1:8080的检查设置是，如果30s内连续产生3次请求失败，则改服务器在之后的30s内被认为是无效（down）状态。  \n\n### ip_hash 指令\n\n该指令用于实现会话保持功能，将某个客户端的多次请求定向到组内同一台服务器上，保证客户端与服务器之间建立稳定的会话。只有当该服务器处于无效（down）状态时，客户端请求才会被下一个服务器接收和处理。其语法结构为：\n```\nip_hash;\n```\n\nip_hash技术在一些情况下非常有用，能够避免我们关心的服务器组内个服务器之间会话共享的问题。但是ip_hash技术再实际使用过程中也有限制。\n\n首先，ip_hash指令不能与server指令中的weight变量一起使用。其次，由于ip_hash技术主要根据客户端IP地址分配服务器，因此在整个系统中，Nginx服务器应该是处于最前端的服务器，这样才能够获取到客户端的IP地址，否则他得到的IP地址将是位于它前面的服务器地址，从而就会产生问题。同事要注意，客户端IP地址必须是C类地址。Nginx 1.3.2开发版本和Nginx 1.2.2稳定版本开始支持IPv6地址。\n\n我们来看下面这个实例：\n\n```\nupstream backend {\n  ip_hash;\n  server myback1.proxy.com;\n  server myback2.proxy.com;\n}\n```\n\n该实例中配置了一个名叫backend的服务器组，包含两台后端服务器myback1.proxy.com和myback2.proxy.com。在添加ip_hash指令后，我们使用同一个客户端向Nginx服务器发送请求，将会看到一只是有服务器myback1.proxy.com响应；如果注释掉ip_hash指令后进行相同的操作，发现组内的两台服务器轮流响应请求。\n\n### keepalive 指令\n\n该指令用于控制网络连接保持功能。通过该指令，能够保证Nginx服务器的工作进程为服务区组打开一部分网络连接，并且将数量控制在一定的范围之内。其语法结构为：\n```\nkeepalive connections;\n```\n\n其中，connections为 Nginx 服务器的每个工作进程允许该服务器组保持的空闲网络连接数的上限值。如果超过该值，工作进程将采用最近最少使用的策略关闭网络连接。\n\n该指令从Nginx 1.1.4开始被支持。\n\n> 注意：该指令不能限制Nginx服务器工作进程能够为服务器组开启的总网络连接数。connections变量在设置时也不要设置得太大，否则会影响服务器组与新网络连接的建立。\n\n### least_conn 指令\n\n该指令用于配置Nginx服务器使用负载均衡策略为网络连接分配服务器组内的服务器。该指令在功能上实现了最少连接负载均衡算法，在选择组内的服务器时，考虑各服务器权重的同时，每次选择的都是当前网络连接最少的那台服务器，如果这样的服务器有多台，就采用加权轮叫原则选择权重最大的服务器。其语法结构为：\n```\nleast_conn;\n```","source":"_posts/Nginx后端服务器组配置的5个指令.md","raw":"---\ntitle: Nginx后端服务器组配置的5个指令\ntags:\n  - nginx\noriginContent: >-\n  Nginx服务器支持设置一组服务器作为后端服务器。\n\n\n  服务器组的设置包括几个指令，他们是由标准HTTP模块ngx_http_upstream_module进行解析和处理的，我们在这里分别介绍一下。\n\n\n  <!-- more -->\n\n\n  ### upstream 指令\n\n\n  该指令是设置后端服务器组的主要指令，其他的指令都在该指令中进行设置。其语法结构为：\n\n\n  ```\n\n  upstream name {\n    ...\n  }\n\n  ```\n\n\n  其中，name是给后端服务器组起得组名。花括号中列出后端服务器组中包含的服务器，其中可以使用下面是介绍的其他指令。\n\n\n  默认情况下，某个服务器组接收到请求以后，按照轮叫调度（Round-Robin，RR）策略顺序选择组内服务器处理请求。如果一个服务器在处理请求的过程中出现错误，请求会被顺次交给组内的下一个服务器进行处理，以此类推，知道返回正常响应。如果所有的组内服务器都出错，则返回最后一个服务器的处理结果。当然我们可以根据各个服务器处理能力或者资源配置情况的不同，给各个服务器配置不同的权重，让能力强的服务器多处理请求，能力弱的少处理。配置权重的变量包含在server指令中。\n\n\n  ### server 指令\n\n\n  该指令用于这只组内的服务器，其语法结构为：\n\n   ```\n   server address [parameters];\n   ```\n\n   > address，服务器的地址，可以是包含端口号的IP地址（IP:Port）、域名或者以『unix:』为前缀用于进程间通信的Unix Domain Socket。\n\n   > parameters，为当前服务器配置更多属性。这些属性变量包含以下内容：\n\n   >> weight=number，为组内服务器设置权重，权重值高的服务器被优先用于处理请求。此时组内服务器的选择策略为加权轮叫策略。组内所有服务器的权重默认设置为1，即采用一般轮叫调度原则处理请求。\n\n   >> max_fails=number，设置一个请求失败的次数。在一定事件范围内，当对组内某台服务器请求失败的次数超过该变量设置的值时，认为该服务器无效（down）。请求失败的各种情况与proxy_next_upstream指令（在学习Nginx服务器的缓存机制时，是fastcgi_next_upstream指令或者memcached_next_upstream指令）的配置相匹配。默认设置为1。如果设置为0，则不适用上面的办法检查服务器是否有效\n\n   >> 注意：HTTP 404 状态不被认为是请求失败\n\n   >> fail_timeout=time，有两个作用，一时设置max_fails指令尝试请求某台组内服务器的时间，即学习max_fails指令时提到的\"一定时间范围内\"；另一个作用是在检查服务器是否有效时，如果一台服务器被认为是无效（down）的，该变量设置的时间为认为服务器无效的持续时间。在这个时间内不再检查该服务器的状态，并一直认为它是无效（down）的。默认设置为10s。\n\n   >> backup，将某台组内服务器标记为备用服务器，只有当正常的服务器处于无效（down）状态或者繁忙（busy）状态时，该服务器才被用来处理客户端请求。\n\n   >> down，将某台组内服务器标记为永久的无效状态，通常与ip_hash指令配合使用。该指令在Nginx 0.6.7 及以上版本中提供。\n\n   我们来通过实例深入对server指令配置的理解：\n\n  ```\n\n  upstream backend {\n    server backend1.example.com weight=5;\n    server 127.0.0.1:8080 max_fails=3 fail_timeout=30s;\n    server unix:/tmp/backend3;\n  }\n\n  ```\n\n\n  在该实例中，我们设置了一个名叫backend的服务器组，组内包含三台服务器，分别是基于域名的backend1.example.com、基于IP地址的127.0.0.1:8080和用于进程间通信的Unix\n  Domain\n  Socket。backend1.example.com的权重设置为5，为组内最大，优先接受和处理请求；对本地服务器127.0.0.1:8080的检查设置是，如果30s内连续产生3次请求失败，则改服务器在之后的30s内被认为是无效（down）状态。  \n\n\n  ### ip_hash 指令\n\n\n  该指令用于实现会话保持功能，将某个客户端的多次请求定向到组内同一台服务器上，保证客户端与服务器之间建立稳定的会话。只有当该服务器处于无效（down）状态时，客户端请求才会被下一个服务器接收和处理。其语法结构为：\n\n  ```\n\n  ip_hash;\n\n  ```\n\n\n  ip_hash技术在一些情况下非常有用，能够避免我们关心的服务器组内个服务器之间会话共享的问题。但是ip_hash技术再实际使用过程中也有限制。\n\n\n  首先，ip_hash指令不能与server指令中的weight变量一起使用。其次，由于ip_hash技术主要根据客户端IP地址分配服务器，因此在整个系统中，Nginx服务器应该是处于最前端的服务器，这样才能够获取到客户端的IP地址，否则他得到的IP地址将是位于它前面的服务器地址，从而就会产生问题。同事要注意，客户端IP地址必须是C类地址。Nginx\n  1.3.2开发版本和Nginx 1.2.2稳定版本开始支持IPv6地址。\n\n\n  我们来看下面这个实例：\n\n\n  ```\n\n  upstream backend {\n    ip_hash;\n    server myback1.proxy.com;\n    server myback2.proxy.com;\n  }\n\n  ```\n\n\n  该实例中配置了一个名叫backend的服务器组，包含两台后端服务器myback1.proxy.com和myback2.proxy.com。在添加ip_hash指令后，我们使用同一个客户端向Nginx服务器发送请求，将会看到一只是有服务器myback1.proxy.com响应；如果注释掉ip_hash指令后进行相同的操作，发现组内的两台服务器轮流响应请求。\n\n\n  ### keepalive 指令\n\n\n  该指令用于控制网络连接保持功能。通过该指令，能够保证Nginx服务器的工作进程为服务区组打开一部分网络连接，并且将数量控制在一定的范围之内。其语法结构为：\n\n  ```\n\n  keepalive connections;\n\n  ```\n\n\n  其中，connections为 Nginx\n  服务器的每个工作进程允许该服务器组保持的空闲网络连接数的上限值。如果超过该值，工作进程将采用最近最少使用的策略关闭网络连接。\n\n\n  该指令从Nginx 1.1.4开始被支持。\n\n\n  >\n  注意：该指令不能限制Nginx服务器工作进程能够为服务器组开启的总网络连接数。connections变量在设置时也不要设置得太大，否则会影响服务器组与新网络连接的建立。\n\n\n  ### least_conn 指令\n\n\n  该指令用于配置Nginx服务器使用负载均衡策略为网络连接分配服务器组内的服务器。该指令在功能上实现了最少连接负载均衡算法，在选择组内的服务器时，考虑各服务器权重的同时，每次选择的都是当前网络连接最少的那台服务器，如果这样的服务器有多台，就采用加权轮叫原则选择权重最大的服务器。其语法结构为：\n\n  ```\n\n  least_conn;\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-09-02 08:20:49\n---\n\nNginx服务器支持设置一组服务器作为后端服务器。\n\n服务器组的设置包括几个指令，他们是由标准HTTP模块ngx_http_upstream_module进行解析和处理的，我们在这里分别介绍一下。\n\n<!-- more -->\n\n### upstream 指令\n\n该指令是设置后端服务器组的主要指令，其他的指令都在该指令中进行设置。其语法结构为：\n\n```\nupstream name {\n  ...\n}\n```\n\n其中，name是给后端服务器组起得组名。花括号中列出后端服务器组中包含的服务器，其中可以使用下面是介绍的其他指令。\n\n默认情况下，某个服务器组接收到请求以后，按照轮叫调度（Round-Robin，RR）策略顺序选择组内服务器处理请求。如果一个服务器在处理请求的过程中出现错误，请求会被顺次交给组内的下一个服务器进行处理，以此类推，知道返回正常响应。如果所有的组内服务器都出错，则返回最后一个服务器的处理结果。当然我们可以根据各个服务器处理能力或者资源配置情况的不同，给各个服务器配置不同的权重，让能力强的服务器多处理请求，能力弱的少处理。配置权重的变量包含在server指令中。\n\n### server 指令\n\n该指令用于这只组内的服务器，其语法结构为：\n\n ```\n server address [parameters];\n ```\n\n > address，服务器的地址，可以是包含端口号的IP地址（IP:Port）、域名或者以『unix:』为前缀用于进程间通信的Unix Domain Socket。\n\n > parameters，为当前服务器配置更多属性。这些属性变量包含以下内容：\n\n >> weight=number，为组内服务器设置权重，权重值高的服务器被优先用于处理请求。此时组内服务器的选择策略为加权轮叫策略。组内所有服务器的权重默认设置为1，即采用一般轮叫调度原则处理请求。\n\n >> max_fails=number，设置一个请求失败的次数。在一定事件范围内，当对组内某台服务器请求失败的次数超过该变量设置的值时，认为该服务器无效（down）。请求失败的各种情况与proxy_next_upstream指令（在学习Nginx服务器的缓存机制时，是fastcgi_next_upstream指令或者memcached_next_upstream指令）的配置相匹配。默认设置为1。如果设置为0，则不适用上面的办法检查服务器是否有效\n\n >> 注意：HTTP 404 状态不被认为是请求失败\n\n >> fail_timeout=time，有两个作用，一时设置max_fails指令尝试请求某台组内服务器的时间，即学习max_fails指令时提到的\"一定时间范围内\"；另一个作用是在检查服务器是否有效时，如果一台服务器被认为是无效（down）的，该变量设置的时间为认为服务器无效的持续时间。在这个时间内不再检查该服务器的状态，并一直认为它是无效（down）的。默认设置为10s。\n\n >> backup，将某台组内服务器标记为备用服务器，只有当正常的服务器处于无效（down）状态或者繁忙（busy）状态时，该服务器才被用来处理客户端请求。\n\n >> down，将某台组内服务器标记为永久的无效状态，通常与ip_hash指令配合使用。该指令在Nginx 0.6.7 及以上版本中提供。\n\n 我们来通过实例深入对server指令配置的理解：\n\n```\nupstream backend {\n  server backend1.example.com weight=5;\n  server 127.0.0.1:8080 max_fails=3 fail_timeout=30s;\n  server unix:/tmp/backend3;\n}\n```\n\n在该实例中，我们设置了一个名叫backend的服务器组，组内包含三台服务器，分别是基于域名的backend1.example.com、基于IP地址的127.0.0.1:8080和用于进程间通信的Unix Domain Socket。backend1.example.com的权重设置为5，为组内最大，优先接受和处理请求；对本地服务器127.0.0.1:8080的检查设置是，如果30s内连续产生3次请求失败，则改服务器在之后的30s内被认为是无效（down）状态。  \n\n### ip_hash 指令\n\n该指令用于实现会话保持功能，将某个客户端的多次请求定向到组内同一台服务器上，保证客户端与服务器之间建立稳定的会话。只有当该服务器处于无效（down）状态时，客户端请求才会被下一个服务器接收和处理。其语法结构为：\n```\nip_hash;\n```\n\nip_hash技术在一些情况下非常有用，能够避免我们关心的服务器组内个服务器之间会话共享的问题。但是ip_hash技术再实际使用过程中也有限制。\n\n首先，ip_hash指令不能与server指令中的weight变量一起使用。其次，由于ip_hash技术主要根据客户端IP地址分配服务器，因此在整个系统中，Nginx服务器应该是处于最前端的服务器，这样才能够获取到客户端的IP地址，否则他得到的IP地址将是位于它前面的服务器地址，从而就会产生问题。同事要注意，客户端IP地址必须是C类地址。Nginx 1.3.2开发版本和Nginx 1.2.2稳定版本开始支持IPv6地址。\n\n我们来看下面这个实例：\n\n```\nupstream backend {\n  ip_hash;\n  server myback1.proxy.com;\n  server myback2.proxy.com;\n}\n```\n\n该实例中配置了一个名叫backend的服务器组，包含两台后端服务器myback1.proxy.com和myback2.proxy.com。在添加ip_hash指令后，我们使用同一个客户端向Nginx服务器发送请求，将会看到一只是有服务器myback1.proxy.com响应；如果注释掉ip_hash指令后进行相同的操作，发现组内的两台服务器轮流响应请求。\n\n### keepalive 指令\n\n该指令用于控制网络连接保持功能。通过该指令，能够保证Nginx服务器的工作进程为服务区组打开一部分网络连接，并且将数量控制在一定的范围之内。其语法结构为：\n```\nkeepalive connections;\n```\n\n其中，connections为 Nginx 服务器的每个工作进程允许该服务器组保持的空闲网络连接数的上限值。如果超过该值，工作进程将采用最近最少使用的策略关闭网络连接。\n\n该指令从Nginx 1.1.4开始被支持。\n\n> 注意：该指令不能限制Nginx服务器工作进程能够为服务器组开启的总网络连接数。connections变量在设置时也不要设置得太大，否则会影响服务器组与新网络连接的建立。\n\n### least_conn 指令\n\n该指令用于配置Nginx服务器使用负载均衡策略为网络连接分配服务器组内的服务器。该指令在功能上实现了最少连接负载均衡算法，在选择组内的服务器时，考虑各服务器权重的同时，每次选择的都是当前网络连接最少的那台服务器，如果这样的服务器有多台，就采用加权轮叫原则选择权重最大的服务器。其语法结构为：\n```\nleast_conn;\n```","slug":"Nginx后端服务器组配置的5个指令","published":1,"updated":"2019-03-23T10:39:09.213Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ehf000mgyavfv1dwwwo"},{"title":"Node.js Sequelize如何实现数据库的读写分离","originContent":"一、前言\n\n在构建高并发的Web应用时，除了应用层要采取负载均衡方案外，数据库也要支持高可用和高并发性。使用较多的数据库优化方案是：通过主从复制(Master-Slave)的方式来同步数据，再通过读写分离(MySQL-Proxy)来提升数据库的并发负载能力。\n\n1. replication选项与读写分离\n\nSequelize 支持读/写分离，要实现读/写分离可以分别为读和写各创建一个Sequelize实例，更方便的使用方式是在创建实例时，通过replication选项分别指定读/写数据库。\n\n要在Sequelize中使用读/写复制，可以在初始化Sequelize时有时向其replication选项传递一个对象.这个对象read、write两个属性。write是一个单一的对象(即：由单台服务器处理写入)，而read是一个包含对象的数组(即：由多台服务器处理读取)。每台read、write服务器都可以包含以下属性：\n\n· host - 数据库服务器的主机\n\n· port - 数据库服务器的主机端口\n\n· username - 验证用户名\n\n· password - 验证密码\n\n· database - 要连接的数据库\n\n2. Sequelize读/写分离示例\n\n在使用主从复制的多台数据库集群中，可以通过在replication对象的read属性中设置，该属性是一个数组，可以在其中传入一个或多个服务器连接副本。读操作相当于对数据库集群中的从节点进行操作，它会处理所有SELECT查询操作(读操作)。而replication对象的write属性是一个表示服务器连接的对象，写操作相当于主节点，它会处理所有插入、更新、删除操作(写操作)。\n\n```\nvar sequelize = new Sequelize('database', null, null, {\n dialect: 'mysql',\n port: 3306\n replication: {\n  read: [\n   { host: '192.168.1.33', username: 'itbilu.com', password: 'pwd' },\n   { host: 'localhost', username: 'root', password: null }\n  ],\n  write: { host: 'localhost', username: 'root', password: null }\n },\n pool: { // 如果需要重写链接池，请在 pool 选项中修改\n  maxConnections: 20,\n  maxIdleTime: 30000\n },\n})\n```\n\n我这边的真实代码：\n\n```\nimport Sequelize from 'sequelize'\nimport { DB as DBConfig, System as SystemConfig } from '../config'\n\nexport default new Sequelize(DBConfig.database, null, null, {\n  dialect: SystemConfig.db_type,\n  port: DBConfig.port,\n  replication: {\n    read: [\n      {\n        host: DBConfig.read.host,\n        username: DBConfig.read.username,\n        password: DBConfig.read.passwd\n      }\n    ],\n    write: {\n      host: DBConfig.write.host,\n      username: DBConfig.write.username,\n      password: DBConfig.write.passwd\n    }\n  },\n  dialectOptions: { // MySQL > 5.5，其它数据库删除此项\n    charset: 'utf8mb4',\n    collate: 'utf8mb4_unicode_520_ci',\n    supportBigNumbers: true,\n    bigNumberStrings: true\n  },\n  pool: {\n    max: 50,\n    min: 0,\n    idle: 10000\n  }\n})\n\n```\n\n所有的整体性设置，都会适用于所有节点副本，所以并不需要为每个实例单独指定。在上例中，数据库名和端口号会应用于所有节点副本，用户名和密码选项也同样适用。如果某一节点副本不使用全局设置，则需要在replication选项中单独指定。\n\n注意：Sequelize 并不会设置主从复制节点及节点间的数据同步(复制)，这些操作实际由MySQL(或你所使用的数据库)完成。而 Sequelize 只负责从主从节点写入或读取数据。\n\nSequelize 会使用连接池来管理节点副本。\n\n默认选项是：\n\n```\n{\n maxConnections: 10,\n minConnections: 0,\n maxIdleTime:1000\n}\n```","toc":false,"date":"2018-04-11T04:05:07.000Z","_content":"\n一、前言\n\n在构建高并发的Web应用时，除了应用层要采取负载均衡方案外，数据库也要支持高可用和高并发性。使用较多的数据库优化方案是：通过主从复制(Master-Slave)的方式来同步数据，再通过读写分离(MySQL-Proxy)来提升数据库的并发负载能力。\n\n1. replication选项与读写分离\n\nSequelize 支持读/写分离，要实现读/写分离可以分别为读和写各创建一个Sequelize实例，更方便的使用方式是在创建实例时，通过replication选项分别指定读/写数据库。\n\n要在Sequelize中使用读/写复制，可以在初始化Sequelize时有时向其replication选项传递一个对象.这个对象read、write两个属性。write是一个单一的对象(即：由单台服务器处理写入)，而read是一个包含对象的数组(即：由多台服务器处理读取)。每台read、write服务器都可以包含以下属性：\n\n· host - 数据库服务器的主机\n\n· port - 数据库服务器的主机端口\n\n· username - 验证用户名\n\n· password - 验证密码\n\n· database - 要连接的数据库\n\n2. Sequelize读/写分离示例\n\n在使用主从复制的多台数据库集群中，可以通过在replication对象的read属性中设置，该属性是一个数组，可以在其中传入一个或多个服务器连接副本。读操作相当于对数据库集群中的从节点进行操作，它会处理所有SELECT查询操作(读操作)。而replication对象的write属性是一个表示服务器连接的对象，写操作相当于主节点，它会处理所有插入、更新、删除操作(写操作)。\n\n```\nvar sequelize = new Sequelize('database', null, null, {\n dialect: 'mysql',\n port: 3306\n replication: {\n  read: [\n   { host: '192.168.1.33', username: 'itbilu.com', password: 'pwd' },\n   { host: 'localhost', username: 'root', password: null }\n  ],\n  write: { host: 'localhost', username: 'root', password: null }\n },\n pool: { // 如果需要重写链接池，请在 pool 选项中修改\n  maxConnections: 20,\n  maxIdleTime: 30000\n },\n})\n```\n\n我这边的真实代码：\n\n```\nimport Sequelize from 'sequelize'\nimport { DB as DBConfig, System as SystemConfig } from '../config'\n\nexport default new Sequelize(DBConfig.database, null, null, {\n  dialect: SystemConfig.db_type,\n  port: DBConfig.port,\n  replication: {\n    read: [\n      {\n        host: DBConfig.read.host,\n        username: DBConfig.read.username,\n        password: DBConfig.read.passwd\n      }\n    ],\n    write: {\n      host: DBConfig.write.host,\n      username: DBConfig.write.username,\n      password: DBConfig.write.passwd\n    }\n  },\n  dialectOptions: { // MySQL > 5.5，其它数据库删除此项\n    charset: 'utf8mb4',\n    collate: 'utf8mb4_unicode_520_ci',\n    supportBigNumbers: true,\n    bigNumberStrings: true\n  },\n  pool: {\n    max: 50,\n    min: 0,\n    idle: 10000\n  }\n})\n\n```\n\n所有的整体性设置，都会适用于所有节点副本，所以并不需要为每个实例单独指定。在上例中，数据库名和端口号会应用于所有节点副本，用户名和密码选项也同样适用。如果某一节点副本不使用全局设置，则需要在replication选项中单独指定。\n\n注意：Sequelize 并不会设置主从复制节点及节点间的数据同步(复制)，这些操作实际由MySQL(或你所使用的数据库)完成。而 Sequelize 只负责从主从节点写入或读取数据。\n\nSequelize 会使用连接池来管理节点副本。\n\n默认选项是：\n\n```\n{\n maxConnections: 10,\n minConnections: 0,\n maxIdleTime:1000\n}\n```","source":"_posts/Node-js-Sequelize如何实现数据库的读写分离.md","raw":"---\ntitle: Node.js Sequelize如何实现数据库的读写分离\ntags:\n  - 数据库\noriginContent: >-\n  一、前言\n\n\n  在构建高并发的Web应用时，除了应用层要采取负载均衡方案外，数据库也要支持高可用和高并发性。使用较多的数据库优化方案是：通过主从复制(Master-Slave)的方式来同步数据，再通过读写分离(MySQL-Proxy)来提升数据库的并发负载能力。\n\n\n  1. replication选项与读写分离\n\n\n  Sequelize\n  支持读/写分离，要实现读/写分离可以分别为读和写各创建一个Sequelize实例，更方便的使用方式是在创建实例时，通过replication选项分别指定读/写数据库。\n\n\n  要在Sequelize中使用读/写复制，可以在初始化Sequelize时有时向其replication选项传递一个对象.这个对象read、write两个属性。write是一个单一的对象(即：由单台服务器处理写入)，而read是一个包含对象的数组(即：由多台服务器处理读取)。每台read、write服务器都可以包含以下属性：\n\n\n  · host - 数据库服务器的主机\n\n\n  · port - 数据库服务器的主机端口\n\n\n  · username - 验证用户名\n\n\n  · password - 验证密码\n\n\n  · database - 要连接的数据库\n\n\n  2. Sequelize读/写分离示例\n\n\n  在使用主从复制的多台数据库集群中，可以通过在replication对象的read属性中设置，该属性是一个数组，可以在其中传入一个或多个服务器连接副本。读操作相当于对数据库集群中的从节点进行操作，它会处理所有SELECT查询操作(读操作)。而replication对象的write属性是一个表示服务器连接的对象，写操作相当于主节点，它会处理所有插入、更新、删除操作(写操作)。\n\n\n  ```\n\n  var sequelize = new Sequelize('database', null, null, {\n   dialect: 'mysql',\n   port: 3306\n   replication: {\n    read: [\n     { host: '192.168.1.33', username: 'itbilu.com', password: 'pwd' },\n     { host: 'localhost', username: 'root', password: null }\n    ],\n    write: { host: 'localhost', username: 'root', password: null }\n   },\n   pool: { // 如果需要重写链接池，请在 pool 选项中修改\n    maxConnections: 20,\n    maxIdleTime: 30000\n   },\n  })\n\n  ```\n\n\n  我这边的真实代码：\n\n\n  ```\n\n  import Sequelize from 'sequelize'\n\n  import { DB as DBConfig, System as SystemConfig } from '../config'\n\n\n  export default new Sequelize(DBConfig.database, null, null, {\n    dialect: SystemConfig.db_type,\n    port: DBConfig.port,\n    replication: {\n      read: [\n        {\n          host: DBConfig.read.host,\n          username: DBConfig.read.username,\n          password: DBConfig.read.passwd\n        }\n      ],\n      write: {\n        host: DBConfig.write.host,\n        username: DBConfig.write.username,\n        password: DBConfig.write.passwd\n      }\n    },\n    dialectOptions: { // MySQL > 5.5，其它数据库删除此项\n      charset: 'utf8mb4',\n      collate: 'utf8mb4_unicode_520_ci',\n      supportBigNumbers: true,\n      bigNumberStrings: true\n    },\n    pool: {\n      max: 50,\n      min: 0,\n      idle: 10000\n    }\n  })\n\n\n  ```\n\n\n  所有的整体性设置，都会适用于所有节点副本，所以并不需要为每个实例单独指定。在上例中，数据库名和端口号会应用于所有节点副本，用户名和密码选项也同样适用。如果某一节点副本不使用全局设置，则需要在replication选项中单独指定。\n\n\n  注意：Sequelize 并不会设置主从复制节点及节点间的数据同步(复制)，这些操作实际由MySQL(或你所使用的数据库)完成。而 Sequelize\n  只负责从主从节点写入或读取数据。\n\n\n  Sequelize 会使用连接池来管理节点副本。\n\n\n  默认选项是：\n\n\n  ```\n\n  {\n   maxConnections: 10,\n   minConnections: 0,\n   maxIdleTime:1000\n  }\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-04-11 12:05:07\n---\n\n一、前言\n\n在构建高并发的Web应用时，除了应用层要采取负载均衡方案外，数据库也要支持高可用和高并发性。使用较多的数据库优化方案是：通过主从复制(Master-Slave)的方式来同步数据，再通过读写分离(MySQL-Proxy)来提升数据库的并发负载能力。\n\n1. replication选项与读写分离\n\nSequelize 支持读/写分离，要实现读/写分离可以分别为读和写各创建一个Sequelize实例，更方便的使用方式是在创建实例时，通过replication选项分别指定读/写数据库。\n\n要在Sequelize中使用读/写复制，可以在初始化Sequelize时有时向其replication选项传递一个对象.这个对象read、write两个属性。write是一个单一的对象(即：由单台服务器处理写入)，而read是一个包含对象的数组(即：由多台服务器处理读取)。每台read、write服务器都可以包含以下属性：\n\n· host - 数据库服务器的主机\n\n· port - 数据库服务器的主机端口\n\n· username - 验证用户名\n\n· password - 验证密码\n\n· database - 要连接的数据库\n\n2. Sequelize读/写分离示例\n\n在使用主从复制的多台数据库集群中，可以通过在replication对象的read属性中设置，该属性是一个数组，可以在其中传入一个或多个服务器连接副本。读操作相当于对数据库集群中的从节点进行操作，它会处理所有SELECT查询操作(读操作)。而replication对象的write属性是一个表示服务器连接的对象，写操作相当于主节点，它会处理所有插入、更新、删除操作(写操作)。\n\n```\nvar sequelize = new Sequelize('database', null, null, {\n dialect: 'mysql',\n port: 3306\n replication: {\n  read: [\n   { host: '192.168.1.33', username: 'itbilu.com', password: 'pwd' },\n   { host: 'localhost', username: 'root', password: null }\n  ],\n  write: { host: 'localhost', username: 'root', password: null }\n },\n pool: { // 如果需要重写链接池，请在 pool 选项中修改\n  maxConnections: 20,\n  maxIdleTime: 30000\n },\n})\n```\n\n我这边的真实代码：\n\n```\nimport Sequelize from 'sequelize'\nimport { DB as DBConfig, System as SystemConfig } from '../config'\n\nexport default new Sequelize(DBConfig.database, null, null, {\n  dialect: SystemConfig.db_type,\n  port: DBConfig.port,\n  replication: {\n    read: [\n      {\n        host: DBConfig.read.host,\n        username: DBConfig.read.username,\n        password: DBConfig.read.passwd\n      }\n    ],\n    write: {\n      host: DBConfig.write.host,\n      username: DBConfig.write.username,\n      password: DBConfig.write.passwd\n    }\n  },\n  dialectOptions: { // MySQL > 5.5，其它数据库删除此项\n    charset: 'utf8mb4',\n    collate: 'utf8mb4_unicode_520_ci',\n    supportBigNumbers: true,\n    bigNumberStrings: true\n  },\n  pool: {\n    max: 50,\n    min: 0,\n    idle: 10000\n  }\n})\n\n```\n\n所有的整体性设置，都会适用于所有节点副本，所以并不需要为每个实例单独指定。在上例中，数据库名和端口号会应用于所有节点副本，用户名和密码选项也同样适用。如果某一节点副本不使用全局设置，则需要在replication选项中单独指定。\n\n注意：Sequelize 并不会设置主从复制节点及节点间的数据同步(复制)，这些操作实际由MySQL(或你所使用的数据库)完成。而 Sequelize 只负责从主从节点写入或读取数据。\n\nSequelize 会使用连接池来管理节点副本。\n\n默认选项是：\n\n```\n{\n maxConnections: 10,\n minConnections: 0,\n maxIdleTime:1000\n}\n```","slug":"Node-js-Sequelize如何实现数据库的读写分离","published":1,"updated":"2019-03-23T10:18:45.738Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ehj000pgyavbjsw8t1u"},{"title":"SQL基础","originContent":"## SQL分类\nSQL语句主要可以划分为一下三个类别。\n\n1. DDL（Data Definition Languages）语句：数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、alter等。\n2. DML（Data Manipulation Languages）语句：数据操作语句，用于添加、删除、更新和查询数据库记录，并检验数据完整性。常用的语句关键字主要包括insert、delete、update和select等。\n3. DCL（Data Control Language）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的关键字包括grant、revoke等。\n\n## DDL语句","toc":false,"date":"2018-02-26T07:12:24.000Z","_content":"\n## SQL分类\nSQL语句主要可以划分为一下三个类别。\n\n1. DDL（Data Definition Languages）语句：数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、alter等。\n2. DML（Data Manipulation Languages）语句：数据操作语句，用于添加、删除、更新和查询数据库记录，并检验数据完整性。常用的语句关键字主要包括insert、delete、update和select等。\n3. DCL（Data Control Language）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的关键字包括grant、revoke等。\n\n## DDL语句","source":"_posts/SQL基础.md","raw":"---\ntitle: SQL基础\ntags:\n  - mysql\noriginContent: >-\n  ## SQL分类\n\n  SQL语句主要可以划分为一下三个类别。\n\n\n  1. DDL（Data Definition\n  Languages）语句：数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、alter等。\n\n  2. DML（Data Manipulation\n  Languages）语句：数据操作语句，用于添加、删除、更新和查询数据库记录，并检验数据完整性。常用的语句关键字主要包括insert、delete、update和select等。\n\n  3. DCL（Data Control\n  Language）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的关键字包括grant、revoke等。\n\n\n  ## DDL语句\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-02-26 15:12:24\n---\n\n## SQL分类\nSQL语句主要可以划分为一下三个类别。\n\n1. DDL（Data Definition Languages）语句：数据定义语句，这些语句定义了不同的数据段、数据库、表、列、索引等数据库对象。常用的语句关键字主要包括create、drop、alter等。\n2. DML（Data Manipulation Languages）语句：数据操作语句，用于添加、删除、更新和查询数据库记录，并检验数据完整性。常用的语句关键字主要包括insert、delete、update和select等。\n3. DCL（Data Control Language）语句：数据控制语句，用于控制不同数据段直接的许可和访问级别的语句。这些语句定义了数据库、表、字段、用户的访问权限和安全级别。主要的关键字包括grant、revoke等。\n\n## DDL语句","slug":"SQL基础","published":1,"updated":"2019-03-23T10:01:14.474Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eho000ugyavpw05mpui"},{"title":"centos 6 安装n来控制node版本","originContent":"centos6发现无法安装nvm，原因：https://github.com/creationix/nvm/issues/1661\n\n解决办法没有给出，于是换成使用n来安装node版本\n\n自己找到一种办法，就是将已经安装过nvm的机器上压缩.nvm文件夹，然后上传不能安装的到服务器上,解压以后再在.bash_profile里边增加如下代码\n\n```\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm\n```\n\n删除调.nvm里边的version/node下的版本，否则会有一些问题\n\n执行下边代码让设置生效：\n\n```\nsource .bash_profile\n```\n\nn需要通过nvm安装，因此先试用centos yum工具来安装一个默认版本node和npm\n\n```\nyum install nodejs -y\nyum install npm -y\n```\n\n<!-- more -->\n\n完了以后可以看到node版本很低，不满足我们的需求，于是使用n来升级node版本\n\n1、首先通过npm安装node的版本管理工具“n“，不用惊讶，名字就是这么简单，就叫n。据了解，n是node下的一个模块，作者是Express框架的开发者。\n\n```\nnpm i -g n\n```\n\n2、检查n模块\n\n先查看系统node的安装路径，n模块的默认路径为 ‘/usr/local’。\n\n```\n$ which node\n```\n```\n/data/home/server/nodejs/bin/node   #举个例子\n```\n\n如果路径与n模块的默认路径相同可以跳过3步骤。\n\n3、通过N_PREFIX变量来修改 n 的默认node安装路径。\n\n(1) 编辑环境配置文件\n\n```\nvim ~/.bash_profile\n```\n\n(2) 将下面两行代码插入到文件末尾\n\n```\nexport N_PREFIX=/data/home/server/nodejs #node实际安装位置\nexport PATH=$N_PREFIX/bin:$PATH\n```\n\n(3) :wq保存退出；\n\n执行source使修改生效。\n\n```\n$ source ~/.bash_profile\n```\n\n(4) 确认一下环境变量是否生效。\n\n```\necho $N_PREFIX\n/data/home/server/nodejs\n```\n\n4、n模块常用命令\n\n```\nCommands:\n  n                              Output versions installed\n  n latest                       Install or activate the latest node release\n  n -a x86 latest                As above but force 32 bit architecture\n  n stable                       Install or activate the latest stable node release\n  n lts                          Install or activate the latest LTS node release\n  n <version>                    Install node <version>\n  n use <version> [args ...]     Execute node <version> with [args ...]\n  n bin <version>                Output bin path for <version>\n  n rm <version ...>             Remove the given version(s)\n  n prune                        Remove all versions except the current version\n  n --latest                     Output the latest node version available\n  n --stable                     Output the latest stable node version available\n  n --lts                        Output the latest LTS node version available\n  n ls                           Output the versions of node available\n```\n\n(1) 安装node最新版本\n\n```\nn latest\n```\n\n(2) 安装稳定版\n\n```\nn stable\n```\n\n(3) 安装指定版本\n\n```\nn v9.5.0\n```\n\n(4) 查看已安装版本\n\n```\nn\n```\n(5) 删除指定版本\n\n```\nn rm 6.4.0\n```","toc":false,"date":"2018-04-02T10:03:35.000Z","_content":"\ncentos6发现无法安装nvm，原因：https://github.com/creationix/nvm/issues/1661\n\n解决办法没有给出，于是换成使用n来安装node版本\n\n自己找到一种办法，就是将已经安装过nvm的机器上压缩.nvm文件夹，然后上传不能安装的到服务器上,解压以后再在.bash_profile里边增加如下代码\n\n```\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm\n```\n\n删除调.nvm里边的version/node下的版本，否则会有一些问题\n\n执行下边代码让设置生效：\n\n```\nsource .bash_profile\n```\n\nn需要通过nvm安装，因此先试用centos yum工具来安装一个默认版本node和npm\n\n```\nyum install nodejs -y\nyum install npm -y\n```\n\n<!-- more -->\n\n完了以后可以看到node版本很低，不满足我们的需求，于是使用n来升级node版本\n\n1、首先通过npm安装node的版本管理工具“n“，不用惊讶，名字就是这么简单，就叫n。据了解，n是node下的一个模块，作者是Express框架的开发者。\n\n```\nnpm i -g n\n```\n\n2、检查n模块\n\n先查看系统node的安装路径，n模块的默认路径为 ‘/usr/local’。\n\n```\n$ which node\n```\n```\n/data/home/server/nodejs/bin/node   #举个例子\n```\n\n如果路径与n模块的默认路径相同可以跳过3步骤。\n\n3、通过N_PREFIX变量来修改 n 的默认node安装路径。\n\n(1) 编辑环境配置文件\n\n```\nvim ~/.bash_profile\n```\n\n(2) 将下面两行代码插入到文件末尾\n\n```\nexport N_PREFIX=/data/home/server/nodejs #node实际安装位置\nexport PATH=$N_PREFIX/bin:$PATH\n```\n\n(3) :wq保存退出；\n\n执行source使修改生效。\n\n```\n$ source ~/.bash_profile\n```\n\n(4) 确认一下环境变量是否生效。\n\n```\necho $N_PREFIX\n/data/home/server/nodejs\n```\n\n4、n模块常用命令\n\n```\nCommands:\n  n                              Output versions installed\n  n latest                       Install or activate the latest node release\n  n -a x86 latest                As above but force 32 bit architecture\n  n stable                       Install or activate the latest stable node release\n  n lts                          Install or activate the latest LTS node release\n  n <version>                    Install node <version>\n  n use <version> [args ...]     Execute node <version> with [args ...]\n  n bin <version>                Output bin path for <version>\n  n rm <version ...>             Remove the given version(s)\n  n prune                        Remove all versions except the current version\n  n --latest                     Output the latest node version available\n  n --stable                     Output the latest stable node version available\n  n --lts                        Output the latest LTS node version available\n  n ls                           Output the versions of node available\n```\n\n(1) 安装node最新版本\n\n```\nn latest\n```\n\n(2) 安装稳定版\n\n```\nn stable\n```\n\n(3) 安装指定版本\n\n```\nn v9.5.0\n```\n\n(4) 查看已安装版本\n\n```\nn\n```\n(5) 删除指定版本\n\n```\nn rm 6.4.0\n```","source":"_posts/centos-6-安装n来控制node版本.md","raw":"---\ntitle: centos 6 安装n来控制node版本\ntags:\n  - nodejs\noriginContent: |-\n  centos6发现无法安装nvm，原因：https://github.com/creationix/nvm/issues/1661\n\n  解决办法没有给出，于是换成使用n来安装node版本\n\n  自己找到一种办法，就是将已经安装过nvm的机器上压缩.nvm文件夹，然后上传不能安装的到服务器上,解压以后再在.bash_profile里边增加如下代码\n\n  ```\n  export NVM_DIR=\"$HOME/.nvm\"\n  [ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm\n  ```\n\n  删除调.nvm里边的version/node下的版本，否则会有一些问题\n\n  执行下边代码让设置生效：\n\n  ```\n  source .bash_profile\n  ```\n\n  n需要通过nvm安装，因此先试用centos yum工具来安装一个默认版本node和npm\n\n  ```\n  yum install nodejs -y\n  yum install npm -y\n  ```\n\n  <!-- more -->\n\n  完了以后可以看到node版本很低，不满足我们的需求，于是使用n来升级node版本\n\n  1、首先通过npm安装node的版本管理工具“n“，不用惊讶，名字就是这么简单，就叫n。据了解，n是node下的一个模块，作者是Express框架的开发者。\n\n  ```\n  npm i -g n\n  ```\n\n  2、检查n模块\n\n  先查看系统node的安装路径，n模块的默认路径为 ‘/usr/local’。\n\n  ```\n  $ which node\n  ```\n  ```\n  /data/home/server/nodejs/bin/node   #举个例子\n  ```\n\n  如果路径与n模块的默认路径相同可以跳过3步骤。\n\n  3、通过N_PREFIX变量来修改 n 的默认node安装路径。\n\n  (1) 编辑环境配置文件\n\n  ```\n  vim ~/.bash_profile\n  ```\n\n  (2) 将下面两行代码插入到文件末尾\n\n  ```\n  export N_PREFIX=/data/home/server/nodejs #node实际安装位置\n  export PATH=$N_PREFIX/bin:$PATH\n  ```\n\n  (3) :wq保存退出；\n\n  执行source使修改生效。\n\n  ```\n  $ source ~/.bash_profile\n  ```\n\n  (4) 确认一下环境变量是否生效。\n\n  ```\n  echo $N_PREFIX\n  /data/home/server/nodejs\n  ```\n\n  4、n模块常用命令\n\n  ```\n  Commands:\n    n                              Output versions installed\n    n latest                       Install or activate the latest node release\n    n -a x86 latest                As above but force 32 bit architecture\n    n stable                       Install or activate the latest stable node release\n    n lts                          Install or activate the latest LTS node release\n    n <version>                    Install node <version>\n    n use <version> [args ...]     Execute node <version> with [args ...]\n    n bin <version>                Output bin path for <version>\n    n rm <version ...>             Remove the given version(s)\n    n prune                        Remove all versions except the current version\n    n --latest                     Output the latest node version available\n    n --stable                     Output the latest stable node version available\n    n --lts                        Output the latest LTS node version available\n    n ls                           Output the versions of node available\n  ```\n\n  (1) 安装node最新版本\n\n  ```\n  n latest\n  ```\n\n  (2) 安装稳定版\n\n  ```\n  n stable\n  ```\n\n  (3) 安装指定版本\n\n  ```\n  n v9.5.0\n  ```\n\n  (4) 查看已安装版本\n\n  ```\n  n\n  ```\n  (5) 删除指定版本\n\n  ```\n  n rm 6.4.0\n  ```\ncategories:\n  - NodeJS\ntoc: false\ndate: 2018-04-02 18:03:35\n---\n\ncentos6发现无法安装nvm，原因：https://github.com/creationix/nvm/issues/1661\n\n解决办法没有给出，于是换成使用n来安装node版本\n\n自己找到一种办法，就是将已经安装过nvm的机器上压缩.nvm文件夹，然后上传不能安装的到服务器上,解压以后再在.bash_profile里边增加如下代码\n\n```\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\" # This loads nvm\n```\n\n删除调.nvm里边的version/node下的版本，否则会有一些问题\n\n执行下边代码让设置生效：\n\n```\nsource .bash_profile\n```\n\nn需要通过nvm安装，因此先试用centos yum工具来安装一个默认版本node和npm\n\n```\nyum install nodejs -y\nyum install npm -y\n```\n\n<!-- more -->\n\n完了以后可以看到node版本很低，不满足我们的需求，于是使用n来升级node版本\n\n1、首先通过npm安装node的版本管理工具“n“，不用惊讶，名字就是这么简单，就叫n。据了解，n是node下的一个模块，作者是Express框架的开发者。\n\n```\nnpm i -g n\n```\n\n2、检查n模块\n\n先查看系统node的安装路径，n模块的默认路径为 ‘/usr/local’。\n\n```\n$ which node\n```\n```\n/data/home/server/nodejs/bin/node   #举个例子\n```\n\n如果路径与n模块的默认路径相同可以跳过3步骤。\n\n3、通过N_PREFIX变量来修改 n 的默认node安装路径。\n\n(1) 编辑环境配置文件\n\n```\nvim ~/.bash_profile\n```\n\n(2) 将下面两行代码插入到文件末尾\n\n```\nexport N_PREFIX=/data/home/server/nodejs #node实际安装位置\nexport PATH=$N_PREFIX/bin:$PATH\n```\n\n(3) :wq保存退出；\n\n执行source使修改生效。\n\n```\n$ source ~/.bash_profile\n```\n\n(4) 确认一下环境变量是否生效。\n\n```\necho $N_PREFIX\n/data/home/server/nodejs\n```\n\n4、n模块常用命令\n\n```\nCommands:\n  n                              Output versions installed\n  n latest                       Install or activate the latest node release\n  n -a x86 latest                As above but force 32 bit architecture\n  n stable                       Install or activate the latest stable node release\n  n lts                          Install or activate the latest LTS node release\n  n <version>                    Install node <version>\n  n use <version> [args ...]     Execute node <version> with [args ...]\n  n bin <version>                Output bin path for <version>\n  n rm <version ...>             Remove the given version(s)\n  n prune                        Remove all versions except the current version\n  n --latest                     Output the latest node version available\n  n --stable                     Output the latest stable node version available\n  n --lts                        Output the latest LTS node version available\n  n ls                           Output the versions of node available\n```\n\n(1) 安装node最新版本\n\n```\nn latest\n```\n\n(2) 安装稳定版\n\n```\nn stable\n```\n\n(3) 安装指定版本\n\n```\nn v9.5.0\n```\n\n(4) 查看已安装版本\n\n```\nn\n```\n(5) 删除指定版本\n\n```\nn rm 6.4.0\n```","slug":"centos-6-安装n来控制node版本","published":1,"updated":"2019-03-23T10:19:56.415Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ehr000wgyavi09ha456"},{"title":"centos 安装 dig","originContent":"执行以下命令：\n\n```\nyum install bind-utils\n```\n\n<!-- more -->\n\n例如：\n\n```\n# dig www.le.com\n\n; <<>> DiG 9.9.4-RedHat-9.9.4-51.el7_4.1 <<>> www.le.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 42461\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 5, ADDITIONAL: 6\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;www.le.com.\t\t\tIN\tA\n\n;; ANSWER SECTION:\nwww.le.com.\t\t        525\t    IN\tCNAME\tletvimg.sf.cdnle.com.\nletvimg.sf.cdnle.com.\t598\t    IN\tCNAME\tforeign.sf.cdnle.com.\nforeign.sf.cdnle.com.\t3235\tIN\tCNAME\tvip.sf.cdnle.com.\nvip.sf.cdnle.com.\t    45\t    IN\tA\t    123.125.39.240\n\n;; AUTHORITY SECTION:\ncdnle.com.\t\t171361\tIN\tNS\tns2.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns4.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns1.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns5.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns3.cdnle.com.\n\n;; ADDITIONAL SECTION:\nns1.cdnle.com.\t\t171361\tIN\tA\t211.154.225.249\nns2.cdnle.com.\t\t171361\tIN\tA\t123.125.47.222\nns3.cdnle.com.\t\t171361\tIN\tA\t36.110.161.240\nns4.cdnle.com.\t\t171361\tIN\tA\t123.59.122.247\nns5.cdnle.com.\t\t171361\tIN\tA\t36.110.223.236\n\n;; Query time: 25 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: 四 1月 11 06:24:03 UTC 2018\n;; MSG SIZE  rcvd: 296\n```","toc":false,"date":"2018-01-11T06:22:49.000Z","_content":"\n执行以下命令：\n\n```\nyum install bind-utils\n```\n\n<!-- more -->\n\n例如：\n\n```\n# dig www.le.com\n\n; <<>> DiG 9.9.4-RedHat-9.9.4-51.el7_4.1 <<>> www.le.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 42461\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 5, ADDITIONAL: 6\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;www.le.com.\t\t\tIN\tA\n\n;; ANSWER SECTION:\nwww.le.com.\t\t        525\t    IN\tCNAME\tletvimg.sf.cdnle.com.\nletvimg.sf.cdnle.com.\t598\t    IN\tCNAME\tforeign.sf.cdnle.com.\nforeign.sf.cdnle.com.\t3235\tIN\tCNAME\tvip.sf.cdnle.com.\nvip.sf.cdnle.com.\t    45\t    IN\tA\t    123.125.39.240\n\n;; AUTHORITY SECTION:\ncdnle.com.\t\t171361\tIN\tNS\tns2.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns4.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns1.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns5.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns3.cdnle.com.\n\n;; ADDITIONAL SECTION:\nns1.cdnle.com.\t\t171361\tIN\tA\t211.154.225.249\nns2.cdnle.com.\t\t171361\tIN\tA\t123.125.47.222\nns3.cdnle.com.\t\t171361\tIN\tA\t36.110.161.240\nns4.cdnle.com.\t\t171361\tIN\tA\t123.59.122.247\nns5.cdnle.com.\t\t171361\tIN\tA\t36.110.223.236\n\n;; Query time: 25 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: 四 1月 11 06:24:03 UTC 2018\n;; MSG SIZE  rcvd: 296\n```","source":"_posts/centos-安装-dig.md","raw":"---\ntitle: centos 安装 dig\ntags:\n  - linux\noriginContent: \"执行以下命令：\\n\\n```\\nyum install bind-utils\\n```\\n\\n<!-- more -->\\n\\n例如：\\n\\n```\\n# dig www.le.com\\n\\n; <<>> DiG 9.9.4-RedHat-9.9.4-51.el7_4.1 <<>> www.le.com\\n;; global options: +cmd\\n;; Got answer:\\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 42461\\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 5, ADDITIONAL: 6\\n\\n;; OPT PSEUDOSECTION:\\n; EDNS: version: 0, flags:; udp: 4096\\n;; QUESTION SECTION:\\n;www.le.com.\\t\\t\\tIN\\tA\\n\\n;; ANSWER SECTION:\\nwww.le.com.\\t\\t        525\\t    IN\\tCNAME\\tletvimg.sf.cdnle.com.\\nletvimg.sf.cdnle.com.\\t598\\t    IN\\tCNAME\\tforeign.sf.cdnle.com.\\nforeign.sf.cdnle.com.\\t3235\\tIN\\tCNAME\\tvip.sf.cdnle.com.\\nvip.sf.cdnle.com.\\t    45\\t    IN\\tA\\t    123.125.39.240\\n\\n;; AUTHORITY SECTION:\\ncdnle.com.\\t\\t171361\\tIN\\tNS\\tns2.cdnle.com.\\ncdnle.com.\\t\\t171361\\tIN\\tNS\\tns4.cdnle.com.\\ncdnle.com.\\t\\t171361\\tIN\\tNS\\tns1.cdnle.com.\\ncdnle.com.\\t\\t171361\\tIN\\tNS\\tns5.cdnle.com.\\ncdnle.com.\\t\\t171361\\tIN\\tNS\\tns3.cdnle.com.\\n\\n;; ADDITIONAL SECTION:\\nns1.cdnle.com.\\t\\t171361\\tIN\\tA\\t211.154.225.249\\nns2.cdnle.com.\\t\\t171361\\tIN\\tA\\t123.125.47.222\\nns3.cdnle.com.\\t\\t171361\\tIN\\tA\\t36.110.161.240\\nns4.cdnle.com.\\t\\t171361\\tIN\\tA\\t123.59.122.247\\nns5.cdnle.com.\\t\\t171361\\tIN\\tA\\t36.110.223.236\\n\\n;; Query time: 25 msec\\n;; SERVER: 10.0.2.3#53(10.0.2.3)\\n;; WHEN: 四 1月 11 06:24:03 UTC 2018\\n;; MSG SIZE  rcvd: 296\\n```\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-11 14:22:49\n---\n\n执行以下命令：\n\n```\nyum install bind-utils\n```\n\n<!-- more -->\n\n例如：\n\n```\n# dig www.le.com\n\n; <<>> DiG 9.9.4-RedHat-9.9.4-51.el7_4.1 <<>> www.le.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 42461\n;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 5, ADDITIONAL: 6\n\n;; OPT PSEUDOSECTION:\n; EDNS: version: 0, flags:; udp: 4096\n;; QUESTION SECTION:\n;www.le.com.\t\t\tIN\tA\n\n;; ANSWER SECTION:\nwww.le.com.\t\t        525\t    IN\tCNAME\tletvimg.sf.cdnle.com.\nletvimg.sf.cdnle.com.\t598\t    IN\tCNAME\tforeign.sf.cdnle.com.\nforeign.sf.cdnle.com.\t3235\tIN\tCNAME\tvip.sf.cdnle.com.\nvip.sf.cdnle.com.\t    45\t    IN\tA\t    123.125.39.240\n\n;; AUTHORITY SECTION:\ncdnle.com.\t\t171361\tIN\tNS\tns2.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns4.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns1.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns5.cdnle.com.\ncdnle.com.\t\t171361\tIN\tNS\tns3.cdnle.com.\n\n;; ADDITIONAL SECTION:\nns1.cdnle.com.\t\t171361\tIN\tA\t211.154.225.249\nns2.cdnle.com.\t\t171361\tIN\tA\t123.125.47.222\nns3.cdnle.com.\t\t171361\tIN\tA\t36.110.161.240\nns4.cdnle.com.\t\t171361\tIN\tA\t123.59.122.247\nns5.cdnle.com.\t\t171361\tIN\tA\t36.110.223.236\n\n;; Query time: 25 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: 四 1月 11 06:24:03 UTC 2018\n;; MSG SIZE  rcvd: 296\n```","slug":"centos-安装-dig","published":1,"updated":"2019-03-23T10:45:35.394Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ehx000zgyavqqwjaot5"},{"title":"Rewrite功能的配置（1）","originContent":"![游戏机](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/80%E5%90%8E/1cd4edf0c7c6d0e7a7c44120d7197168.jpg)\n\nRewrite 是 Nginx 服务器提供的一个重要基本功能，骑在Web服务器产品中几乎是必备的功能，用于实现URL的重写。URL的重写是非常有用的功能，比如他可以让我们在改变网站结构后，无需要求客户端用户修改原来的书签，也无需其他网站修改对我们网站的友情链接；他还可以在一定程度上提高网站的安全性；能够让我们的网站显得更加专业。\n\n<!-- more -->\n\n适当利用Rewrite功能，可以给我们带来很多好处，这一节我们就重点学习一下 Nginx 服务器的Rewrite功能。Nginx服务器的Rewrite功能的实现依赖于PCRE（Perl Compatible Regular Expressions，Perl兼容的正则表达式）的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。\n\n> 提示：有关PCRE的介绍和PCRE库的相关下载请参阅其[官方网站](http://www.pcre.org/)。\n> Nginx服务器使用ngx_http_rewrite_module模块解析和处理Rewrite功能的相关配置。\n\n## 『地址重写』与『地址转发』\n\n『地址重写』与『转发』在计算机网络领域是两个重要概念，经常被大家提起。但许多人对这两个概念的区别不清楚，甚至混为一谈。在学习Nginx服务器的Rewrite功能之前，我们有必要先将这对概念进行一下分析和对比，让大家能够有一个清晰的认识。\n\n『地址重写』，实际上是为了实现地址标准化。那么，什么是地址标准化呢？我们来举一个例子。比如在访问Google首页的时候，我们在地址栏中可以输入www.google.com，也可以输入google.cn，他们都能够准确的指向Google首页，从客户端来看，Google首页同时对应了两个地址，实际上，Google服务器是在不同的地址中选择了确定的一个，即www.google.com，进而返回服务器响应的。这个过程就是地址标准化的过程。google.cn这个地址在服务器中被改变为www.google.com的过程就是地址重定向的过程。\n\n『转发』的概念最初和网页的访问并没有太大关系，他是指在网络数据传输过程中数据分组到达路由器或者桥接器后该设备通过检查分组地址并将数据转到相邻局域网上的过程。后来该概念被用在网页访问中，出现了『地址转发』的说法。『地址转发』是指将一个域名知道另一个已有站点的过程。\n\n从上面的解释，我们可以看到『地址重写』和『地址转发』代表的两个过程是不同的。我们可以总结这两个过程的几点区别：\n\n> 地址转发后客户端浏览器中的地址显示时不改变的；而地址重写后客户端浏览器地址栏中的地址改变为服务器选择确定的地址。\n> 在一次地址转发整个过程中，只产生一次网络请求；而一次地址重写一般会产生两次请求。\n> 地址转发一般发生在统一站点项目内；二地址重写没有该限制\n> 地址转发到的页面可以不用全路径名标识，二地址重写到的页面必须使用完整的路径名表示\n> 地址转发过程中，可以将客户端请求的request范围内属性传递给新的页面，但地址重写不可以\n> 地址转发的速度较地址重定向快。\n\n## Rewrite规则\nRewrite规则是学习和使用Nginx服务器Rewrite功能的基础，可以借助PCRE实现URI的重写，并且她还支持Nginx预设变量。Rewrite规则的核心就是PCRE。\n\n正则表达式（Regular Expression，缩写为regex、regexp或RE），是用于描述或者匹配一系列符合某个句法规则的字符串的一个字符串。大家应该都是用过Windows/Dos平台下用于文件查找的通配符\"\\*\" 和 \"?\"，如果要查找某个目录下所有的word文档，就是用\"\\*.doc\"进行搜索，『\\*』会被解释成替换符合某个句法模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。PCRE就是在Perl中内建的功能强大的正则表达式引擎，可以被许多工具使用的库。正则表达式有多种不同的分割，并且不同版本再对句法规则的匹配处理上也有一定的差异。\n\n在Nginx服务器中，使用ngx_http_rewrite_module模块支持URL重写功能。该模块是Nginx服务器的标准HTTP模块。\n\n由于正则表达式的知识超出了本书的范围，我们不在正文中对其详细阐述。在『附录A』中，笔者为大家整理了PCRE库支持的正则表达式元字符表，并对这些元字符在正则表达式上下文中的行为进行了说明，同时也列举了大量的使用实例供大家参考。\n\n在这里，建议大家学习正则表达式时，一定要将思维从『字符创』的概念转变为『字符』的概念，将『词句』的概念转变为『字』的概念，多结合实例进行操作，这样才能准确理解和运用正则表达式。另外，网络上有不少PCRE正则表达式的测试工具，大家可以搜索下载，这些工具对我们在学习和使用正则表达式的过程中很有帮助。\n\n在Nginx配置中，有关Rewrite的配置指令不多，但是它们已经能够提供比较完善的功能了。\n\n### if指令\n该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置，可以在server块或location块中配置该指令，其语法结构为：\n```\nif ( condition ) {...}\n```\n\n其中，花括号代表一个作用域，形成一个if配置块，是条件为真时的Nginx配置。condition为判断条件（true、false），他可以支持以下几种设置方法：\n#### 变量名。\n如果变量的值为空字符串或以『0』开头的任意字符串，if指令认为条件为false，其他情况认为条件为true。比如：\n\n```\nif ($slow) {\n  ... #Nginx 配置\n}\n```\n\n#### 使用'='（等于）和'!='（不等于）\n比较变量和字符串是否相等，相等时if指令为true，反之为false。\n\n```\nif ($request_method = POST) {\n\treturn 405;\n}\n```\n> 注意：这里的字符串不需要加引号。\n\n#### 使用正则表达式对变量进行匹配\n匹配成功时 if 指令认为条件为true，否则为false。变量与正则表达式之间用\"~\"、\"~*\"、\"!~\"或\"!~\\*\"连接，『~』表示匹配过程中对大小写敏感，『~\\*』表示匹配过程中对大小写不敏感；使用『!~』和\"!~\\*\"，匹配失败时if指令认为条件为true，否则为false。在正则表达式中，可以使用小括号对变量值进行截取，在花括号中使用$1...$9引用截取的值。比如：\n\n```\nif ($http_user_agent ~ MSIE) {\n\t# $http_user_agent的值中是否包含有MSIE字符串，如果包含，为true\n\t...\n}\n```\n\n\n\n> 注意：整个正则表达式字符串一般不需要加引号，但如果含有右花括号\"}\"或者分号\";\"字符时，必须要给整个正则表达式添加引号。\n\n#### 判断请求的文件是否存在使用\"-f\"和\"!-f\"。\n当使用\"-f\"时，如果请求的文件存在，if指令认为条件为true，如果请求的文件不存在为false；使用\"!-f\"时，如果请求的文件不存在但该文件所在的目录存在，if指令认为条件为true，如果该文件和她所在的目录都不存在，则为false，如果请求的文件存在，也为false。使用的方法如下：\n\n```\nif (-f $request_filename) {\n\t# 判断请求的文件是否存在\n\t...\n}\nif (!-f $request_filename) {\n\t# 判断请求的文件是否不存在\n}\n```\n\n#### 判断请求的目录是否存在使用\"-d\"和\"!-d\".\n当使用\"-d\"时，如果请求的目录存在，if指令认为条件为true，如果请求的目录不存在，则为false；当使用\"!-d\"时，如果请求的目录不存在但该目录的上级目录存在，if指令认为条件为true，如果该目录和它的上级目录都不存在，则为false，如果请求的目录存在，也为false。使用方式见\"-f\"和\"!-f\"的使用。\n\n#### 判断请求的目录或文件是否存在使用\"-e\"和\"!-e\"。\n当使用\"-e\"时，如果请求的目录或者文件存在时，if指令认为条件为true，否则为false。当使用\"!-e\"时，如果请求的文件和该文件所在路径上的目录都不存在，为true，否则为false。使用方式见\"-f\"和\"!-f\"的使用。\n#### 判断请求的文件是否可执行使用\"-x\"和\"!-x\"。\n当使用\"-x\"时，如果请求的文件可执行，if指令认为条件为true，否则为false；当使用\"!-x\"时，如果请求的文件不可执行，为true，否则为false。使用方法见\"-f\"和\"!-f\"的使用\n\n### break指令\n该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。Nginx服务器在根据配置处理请求的过程中遇到该指令时，回到上一层作用域继续向下读取配置。该指令可以在server块和location快以及if块中使用，其语法结构为：\n\n```\nbreak;\n```\n\n我们通过一个例子加深理解：\n\n```\nlocation / {\n\tif ($slow) {\n\t\tset $id $1;\t\t\t#处于break指令之前，配置有效\n\t\tbreak;\n\t\tlimit_rate 10k;\t\t#处于break指令之后，配置无效\n\t}\n\t...\t\t\t\t\t\t\t#其他Nginx配置，处于break指令所在作用域的上一层作用域，配置有效\n}\n```\n\n#### return指令\n该指令用于完成对请求的处理，直接向客户端返回响应状态码。处于该指令后的所有Nginx配置都是无效的。该指令可以在server块和location块以及if块中使用，其语法结构有以下几种：\n\n```\nreturn [text];\nreturn code URL;\nreturn URL;\n```\n\n> code，为返回给客户端的HTTP状态代码。可以返回的状态代码为0-999的任意HTTP状态码。非标准的444代码可以强制关闭服务器与客户端的连接而不返回任何响应信息给客户端。\n> \n> text，为返回给客户端的响应体内容，支持变量的使用。`return 200 'hello from nginx;'`\n> \n> URL，为返回给客户端的URL地址。\n\n从Nginx 0.8.42 开始，当code使用301（表示被请求资源永久移动到新的位置）、302（表示请求的资源现在临时从不同的URL响应，要求使用GET昂视请求）、303（表示对应当前请求的相应可以在另一个URL上找到，并且客户端应当采用GET方式访问那个资源）和307（请求的资源临时从不同的URL响应）代码时，可以使用结构2将新的URL返回给客户端；当code使用除上面提到的其他代码时，可以使用结构1指定text想客户端发送指定的响应体内容。\n\n当返回状态吗未302或307时，可以使用结构3对URL进行配置。返回的URL中应该包含\"http://\"、\"https://\"或者直接使用\"$scheme\"变量（Request Scheme，代表传输协议，Nginx内置变量）指定。\n\n> 注意：在Nginx 0.7.51之前的版本中，只支持返回204、400、402-406、608、410、413、416和500-504等状态代码。\n\n### rewrite指令\n该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。\n> 提示：\n> \n> URI与URL的区别和联系。\n> \n> URI（Universal Resource Identifier，通用资源标识符），用于对网络中的各种资源进行标识，由存放资源的主机名、片段标识符和相对URI三部分组成。存放资源的主机名一版由传输协议（Scheme）、主机和资源路径三部分组成；片段标识符指向资源内容的具体元素；相对URI表示资源在主机上的相对路径。一版格式为：Scheme:[//][用户名[:密码]@主机名[:端口号]][/资源路径]。\n> \n> URL（Uniform Resource Location，统一资源定位符），是用于在Interner中描述资源的字符串，是URI的子集，主要包括传输协议（Scheme）、主机（IP、端口号或者域名）和资源具体地址（目录和文件名）等三部分。一版格式为：Scheme://主机名[:端口号][/资源路径]。\n\n该指令可以在server块或者location块中配置，其语法结构为：\n```\nrewrite regex replacement [flag];\n```\n\n> regex，用于匹配URI的正则表达式。使用\"()\"标记要截取的内容。\n\n注意：\n\nrewrite接收到的URI不包括host地址。因此，regex不可能匹配到URI的host地址。我们看下面这个例子：\n\n```\nrewrite myweb.com http://newweb.com/parmanent;\n```\n\n现在我们希望上面的rewrite指令重写http://myweb.com/source是办不到的，因为rewrite指令接收到的URI是\"/source\"，不包含\"myweb.com\"。\n\n另外，请求URL中的请求指令是不包含在rewrite指令接收到的URI内容中的。比如:\n\n`http://myweb.com/source?agr1=value&agr2=value2`;\n\nrewrite指令接收到奥的URI为\"source\",不包含\"?agr1=value&agr2=value2\"。\n\n> replacement，成功匹配后用于替换URI中被截取内容的字符串。默认情况下，如果该字符串是由\"http://\"或者\"https://\"开头的，则不会继续向下对URI进行其他处理，而是直接将重写后的URI返回给客户端。\n\n提示：\n\n刚才学习regex变量时我们提到，rewrite模块快接收到的URI不包含请求URL中的请求指令，但是如果我们希望将这些指令传给重写后的URI，该怎么做呢？我们可以使用Nginx全局变量$request_uri，比如：\n`rewrite myweb.com http://example.com$request_uri? permanent;`\n\n注意：\n\n在$request_uri变量后要添加问号\"? \".replacement变量中支持Nginx全局变量的使用，常用的还有$uri和$args等。\n\n> flag，用于设置rewrite对URI的处理行为，可以为以下标志中的一个：\n>> last，终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标识将重写后徐的URI重新再server块中执行，为重写后的URI提供了转入到其他location块的机会。我们通过一个例子来加深理解：\n>> \n```\nlocation / {\n\trewrite ^(/myweb/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra last;\n}\n```\n>> 如果URI在第二行被匹配成功并处理，Nginx服务器不会继续使用第三行的配置匹配和处理新的URI，而是让所有的location块重新匹配和处理新的URI。\n>> \n>> break，将此处重写的URI作为一个新的URI，在本快中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会讲新的URI专项到其他的location块。看下面的例子：\n>> \n```\nlocation /myweb/ {\n\trewrite ^(/myweb/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra break;\n}\n```\n如果某URI在第二行被匹配成功并处理，Nginx服务器将新的URI继续在该location块中使用第三行进行匹配和处理。新的URI始终是在同一个location块中。\n>> \n>> redirect, 将重写后的URI返回给客户端，状态代码为302，指明是临时重定向的URI，主要用在replacement变量不是以\"http://\"或者\"https://\"开头的情况下。\n>> \n>> permanent，将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI。\n\n在使用flag指令时，一定要注意各个标志之间的配合。我们再来回顾刚才学习break标志时的例子，对比last标志里的例子，如果我们将第二个例子中的break标志换成last标志，会发生什么情况呢？\n\n细心的读者可能已经发现，在第二个例子中，location块的uri指令是\"/myweb/\"，而重写后的URI仍然是包含\"/myweb/\"的，如果使用last标志，重写后的URI还可能会被该location块匹配到，这样就形成了无限循环。Nginx服务器遇到这样的情况，会尝试10次循环之后返回错误状态代码500。\n\n\n### rewrite_log指令\n该指令配置是否开启URL重写日志的输出功能，其语法结构为：\n```\nrewrite_log on | off;\n```\n默认设置为off。如果配置为开启（on),URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件中。\n\n### set指令\n该指令用于设置一个新的变量，其语法结构为：\n\n```\nset variable value;\n```\n> variable，为变量的名称。注意要用符号\"$\"作为变量的第一个字符，且变量不能与Nginx服务器预设的全局变量同名。\n> \n> value，为变量的值，可以使字符串、其他变量或者变量的组合等。\n\n### uninitialized\\_variable\\_warn指令\n该指令用于配置使用为初始化的变量时，是否记录警告日志，其语法结构为：\n\n```\nuninitialized_variable_warn on | off;\n```\n默认设置为开启（on）状态。\n\n### Rewrite 常用全局变量\n|变量|说明|\n|:---|:---|\n|**$args**|变量中存放了请求URL中的请求指令。比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"arg1=value1&arg2=value2\"|\n|$content_length|变量中存放了请求头中的Content-length字段|\n|$content_type|变量中存放了请求头中的Content-type字段|\n|$document_root|变量中存放了针对当前请求的根路径|\n|$document_uri|变量中存放了请求中的当前URI，并且不包括请求指令，比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"/server/source\"|\n|**$host**|变量中存放了请求URL中的主机部分字段，比如http://www.myweb.name/server中的\"www.myweb.name\"。如果请求中的主机部分字段不可用或者为空，则存放Nginx配置中server块中server_name指令的配置值|\n|$http_user_agent|变量中存放客户端的代理信息|\n|**$http_cookie**|变量中存放客户端的cookie信息|\n|$limit_rate|变量中存放Nginx服务器对网络连接速率的限制，也就是Nginx配置中limit_rate指令的配置值|\n|**$remote_addr**|变量中存放了客户端的地址|\n|$remote_port|变量中存放了客户端与服务器建立连接的端口号|\n|$remote_user|变量中存放了客户端的用户名|\n|$request_body_file|变量中存放了发给后端服务器的本地文件资源的名称|\n|**$request_method**|变量中存放了客户端的请求方式，如『GET』、『POST』等|\n|$request_filename|变量中存放了当前请求的资源文件的路径名|\n|**$request_uri**|变量中存放了当前请求的URI，并且带请求指令|\n|**$query_string**|与变量$args含义相同|\n|**$scheme**|变量中存放了客户端请求使用的协议，比如\"http\"、\"https\"和\"ftp\"等|\n|$server_protocol|变量中存放了客户端请求协议的版本，比如\"HTTP/1.0\"、\"HTTP/1.1\"等|\n|$server_addr|变量中存放了服务器的地址|\n|$server_name|变量中存放了客户端请求到达的服务器的名称|\n|$server_port|变量中存放了客户端请求到达的服务器的端口号|\n|$uri|与变量$document_uri含义相同|","toc":false,"date":"2017-09-02T09:21:17.000Z","_content":"\n![游戏机](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/80%E5%90%8E/1cd4edf0c7c6d0e7a7c44120d7197168.jpg)\n\nRewrite 是 Nginx 服务器提供的一个重要基本功能，骑在Web服务器产品中几乎是必备的功能，用于实现URL的重写。URL的重写是非常有用的功能，比如他可以让我们在改变网站结构后，无需要求客户端用户修改原来的书签，也无需其他网站修改对我们网站的友情链接；他还可以在一定程度上提高网站的安全性；能够让我们的网站显得更加专业。\n\n<!-- more -->\n\n适当利用Rewrite功能，可以给我们带来很多好处，这一节我们就重点学习一下 Nginx 服务器的Rewrite功能。Nginx服务器的Rewrite功能的实现依赖于PCRE（Perl Compatible Regular Expressions，Perl兼容的正则表达式）的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。\n\n> 提示：有关PCRE的介绍和PCRE库的相关下载请参阅其[官方网站](http://www.pcre.org/)。\n> Nginx服务器使用ngx_http_rewrite_module模块解析和处理Rewrite功能的相关配置。\n\n## 『地址重写』与『地址转发』\n\n『地址重写』与『转发』在计算机网络领域是两个重要概念，经常被大家提起。但许多人对这两个概念的区别不清楚，甚至混为一谈。在学习Nginx服务器的Rewrite功能之前，我们有必要先将这对概念进行一下分析和对比，让大家能够有一个清晰的认识。\n\n『地址重写』，实际上是为了实现地址标准化。那么，什么是地址标准化呢？我们来举一个例子。比如在访问Google首页的时候，我们在地址栏中可以输入www.google.com，也可以输入google.cn，他们都能够准确的指向Google首页，从客户端来看，Google首页同时对应了两个地址，实际上，Google服务器是在不同的地址中选择了确定的一个，即www.google.com，进而返回服务器响应的。这个过程就是地址标准化的过程。google.cn这个地址在服务器中被改变为www.google.com的过程就是地址重定向的过程。\n\n『转发』的概念最初和网页的访问并没有太大关系，他是指在网络数据传输过程中数据分组到达路由器或者桥接器后该设备通过检查分组地址并将数据转到相邻局域网上的过程。后来该概念被用在网页访问中，出现了『地址转发』的说法。『地址转发』是指将一个域名知道另一个已有站点的过程。\n\n从上面的解释，我们可以看到『地址重写』和『地址转发』代表的两个过程是不同的。我们可以总结这两个过程的几点区别：\n\n> 地址转发后客户端浏览器中的地址显示时不改变的；而地址重写后客户端浏览器地址栏中的地址改变为服务器选择确定的地址。\n> 在一次地址转发整个过程中，只产生一次网络请求；而一次地址重写一般会产生两次请求。\n> 地址转发一般发生在统一站点项目内；二地址重写没有该限制\n> 地址转发到的页面可以不用全路径名标识，二地址重写到的页面必须使用完整的路径名表示\n> 地址转发过程中，可以将客户端请求的request范围内属性传递给新的页面，但地址重写不可以\n> 地址转发的速度较地址重定向快。\n\n## Rewrite规则\nRewrite规则是学习和使用Nginx服务器Rewrite功能的基础，可以借助PCRE实现URI的重写，并且她还支持Nginx预设变量。Rewrite规则的核心就是PCRE。\n\n正则表达式（Regular Expression，缩写为regex、regexp或RE），是用于描述或者匹配一系列符合某个句法规则的字符串的一个字符串。大家应该都是用过Windows/Dos平台下用于文件查找的通配符\"\\*\" 和 \"?\"，如果要查找某个目录下所有的word文档，就是用\"\\*.doc\"进行搜索，『\\*』会被解释成替换符合某个句法模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。PCRE就是在Perl中内建的功能强大的正则表达式引擎，可以被许多工具使用的库。正则表达式有多种不同的分割，并且不同版本再对句法规则的匹配处理上也有一定的差异。\n\n在Nginx服务器中，使用ngx_http_rewrite_module模块支持URL重写功能。该模块是Nginx服务器的标准HTTP模块。\n\n由于正则表达式的知识超出了本书的范围，我们不在正文中对其详细阐述。在『附录A』中，笔者为大家整理了PCRE库支持的正则表达式元字符表，并对这些元字符在正则表达式上下文中的行为进行了说明，同时也列举了大量的使用实例供大家参考。\n\n在这里，建议大家学习正则表达式时，一定要将思维从『字符创』的概念转变为『字符』的概念，将『词句』的概念转变为『字』的概念，多结合实例进行操作，这样才能准确理解和运用正则表达式。另外，网络上有不少PCRE正则表达式的测试工具，大家可以搜索下载，这些工具对我们在学习和使用正则表达式的过程中很有帮助。\n\n在Nginx配置中，有关Rewrite的配置指令不多，但是它们已经能够提供比较完善的功能了。\n\n### if指令\n该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置，可以在server块或location块中配置该指令，其语法结构为：\n```\nif ( condition ) {...}\n```\n\n其中，花括号代表一个作用域，形成一个if配置块，是条件为真时的Nginx配置。condition为判断条件（true、false），他可以支持以下几种设置方法：\n#### 变量名。\n如果变量的值为空字符串或以『0』开头的任意字符串，if指令认为条件为false，其他情况认为条件为true。比如：\n\n```\nif ($slow) {\n  ... #Nginx 配置\n}\n```\n\n#### 使用'='（等于）和'!='（不等于）\n比较变量和字符串是否相等，相等时if指令为true，反之为false。\n\n```\nif ($request_method = POST) {\n\treturn 405;\n}\n```\n> 注意：这里的字符串不需要加引号。\n\n#### 使用正则表达式对变量进行匹配\n匹配成功时 if 指令认为条件为true，否则为false。变量与正则表达式之间用\"~\"、\"~*\"、\"!~\"或\"!~\\*\"连接，『~』表示匹配过程中对大小写敏感，『~\\*』表示匹配过程中对大小写不敏感；使用『!~』和\"!~\\*\"，匹配失败时if指令认为条件为true，否则为false。在正则表达式中，可以使用小括号对变量值进行截取，在花括号中使用$1...$9引用截取的值。比如：\n\n```\nif ($http_user_agent ~ MSIE) {\n\t# $http_user_agent的值中是否包含有MSIE字符串，如果包含，为true\n\t...\n}\n```\n\n\n\n> 注意：整个正则表达式字符串一般不需要加引号，但如果含有右花括号\"}\"或者分号\";\"字符时，必须要给整个正则表达式添加引号。\n\n#### 判断请求的文件是否存在使用\"-f\"和\"!-f\"。\n当使用\"-f\"时，如果请求的文件存在，if指令认为条件为true，如果请求的文件不存在为false；使用\"!-f\"时，如果请求的文件不存在但该文件所在的目录存在，if指令认为条件为true，如果该文件和她所在的目录都不存在，则为false，如果请求的文件存在，也为false。使用的方法如下：\n\n```\nif (-f $request_filename) {\n\t# 判断请求的文件是否存在\n\t...\n}\nif (!-f $request_filename) {\n\t# 判断请求的文件是否不存在\n}\n```\n\n#### 判断请求的目录是否存在使用\"-d\"和\"!-d\".\n当使用\"-d\"时，如果请求的目录存在，if指令认为条件为true，如果请求的目录不存在，则为false；当使用\"!-d\"时，如果请求的目录不存在但该目录的上级目录存在，if指令认为条件为true，如果该目录和它的上级目录都不存在，则为false，如果请求的目录存在，也为false。使用方式见\"-f\"和\"!-f\"的使用。\n\n#### 判断请求的目录或文件是否存在使用\"-e\"和\"!-e\"。\n当使用\"-e\"时，如果请求的目录或者文件存在时，if指令认为条件为true，否则为false。当使用\"!-e\"时，如果请求的文件和该文件所在路径上的目录都不存在，为true，否则为false。使用方式见\"-f\"和\"!-f\"的使用。\n#### 判断请求的文件是否可执行使用\"-x\"和\"!-x\"。\n当使用\"-x\"时，如果请求的文件可执行，if指令认为条件为true，否则为false；当使用\"!-x\"时，如果请求的文件不可执行，为true，否则为false。使用方法见\"-f\"和\"!-f\"的使用\n\n### break指令\n该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。Nginx服务器在根据配置处理请求的过程中遇到该指令时，回到上一层作用域继续向下读取配置。该指令可以在server块和location快以及if块中使用，其语法结构为：\n\n```\nbreak;\n```\n\n我们通过一个例子加深理解：\n\n```\nlocation / {\n\tif ($slow) {\n\t\tset $id $1;\t\t\t#处于break指令之前，配置有效\n\t\tbreak;\n\t\tlimit_rate 10k;\t\t#处于break指令之后，配置无效\n\t}\n\t...\t\t\t\t\t\t\t#其他Nginx配置，处于break指令所在作用域的上一层作用域，配置有效\n}\n```\n\n#### return指令\n该指令用于完成对请求的处理，直接向客户端返回响应状态码。处于该指令后的所有Nginx配置都是无效的。该指令可以在server块和location块以及if块中使用，其语法结构有以下几种：\n\n```\nreturn [text];\nreturn code URL;\nreturn URL;\n```\n\n> code，为返回给客户端的HTTP状态代码。可以返回的状态代码为0-999的任意HTTP状态码。非标准的444代码可以强制关闭服务器与客户端的连接而不返回任何响应信息给客户端。\n> \n> text，为返回给客户端的响应体内容，支持变量的使用。`return 200 'hello from nginx;'`\n> \n> URL，为返回给客户端的URL地址。\n\n从Nginx 0.8.42 开始，当code使用301（表示被请求资源永久移动到新的位置）、302（表示请求的资源现在临时从不同的URL响应，要求使用GET昂视请求）、303（表示对应当前请求的相应可以在另一个URL上找到，并且客户端应当采用GET方式访问那个资源）和307（请求的资源临时从不同的URL响应）代码时，可以使用结构2将新的URL返回给客户端；当code使用除上面提到的其他代码时，可以使用结构1指定text想客户端发送指定的响应体内容。\n\n当返回状态吗未302或307时，可以使用结构3对URL进行配置。返回的URL中应该包含\"http://\"、\"https://\"或者直接使用\"$scheme\"变量（Request Scheme，代表传输协议，Nginx内置变量）指定。\n\n> 注意：在Nginx 0.7.51之前的版本中，只支持返回204、400、402-406、608、410、413、416和500-504等状态代码。\n\n### rewrite指令\n该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。\n> 提示：\n> \n> URI与URL的区别和联系。\n> \n> URI（Universal Resource Identifier，通用资源标识符），用于对网络中的各种资源进行标识，由存放资源的主机名、片段标识符和相对URI三部分组成。存放资源的主机名一版由传输协议（Scheme）、主机和资源路径三部分组成；片段标识符指向资源内容的具体元素；相对URI表示资源在主机上的相对路径。一版格式为：Scheme:[//][用户名[:密码]@主机名[:端口号]][/资源路径]。\n> \n> URL（Uniform Resource Location，统一资源定位符），是用于在Interner中描述资源的字符串，是URI的子集，主要包括传输协议（Scheme）、主机（IP、端口号或者域名）和资源具体地址（目录和文件名）等三部分。一版格式为：Scheme://主机名[:端口号][/资源路径]。\n\n该指令可以在server块或者location块中配置，其语法结构为：\n```\nrewrite regex replacement [flag];\n```\n\n> regex，用于匹配URI的正则表达式。使用\"()\"标记要截取的内容。\n\n注意：\n\nrewrite接收到的URI不包括host地址。因此，regex不可能匹配到URI的host地址。我们看下面这个例子：\n\n```\nrewrite myweb.com http://newweb.com/parmanent;\n```\n\n现在我们希望上面的rewrite指令重写http://myweb.com/source是办不到的，因为rewrite指令接收到的URI是\"/source\"，不包含\"myweb.com\"。\n\n另外，请求URL中的请求指令是不包含在rewrite指令接收到的URI内容中的。比如:\n\n`http://myweb.com/source?agr1=value&agr2=value2`;\n\nrewrite指令接收到奥的URI为\"source\",不包含\"?agr1=value&agr2=value2\"。\n\n> replacement，成功匹配后用于替换URI中被截取内容的字符串。默认情况下，如果该字符串是由\"http://\"或者\"https://\"开头的，则不会继续向下对URI进行其他处理，而是直接将重写后的URI返回给客户端。\n\n提示：\n\n刚才学习regex变量时我们提到，rewrite模块快接收到的URI不包含请求URL中的请求指令，但是如果我们希望将这些指令传给重写后的URI，该怎么做呢？我们可以使用Nginx全局变量$request_uri，比如：\n`rewrite myweb.com http://example.com$request_uri? permanent;`\n\n注意：\n\n在$request_uri变量后要添加问号\"? \".replacement变量中支持Nginx全局变量的使用，常用的还有$uri和$args等。\n\n> flag，用于设置rewrite对URI的处理行为，可以为以下标志中的一个：\n>> last，终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标识将重写后徐的URI重新再server块中执行，为重写后的URI提供了转入到其他location块的机会。我们通过一个例子来加深理解：\n>> \n```\nlocation / {\n\trewrite ^(/myweb/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra last;\n}\n```\n>> 如果URI在第二行被匹配成功并处理，Nginx服务器不会继续使用第三行的配置匹配和处理新的URI，而是让所有的location块重新匹配和处理新的URI。\n>> \n>> break，将此处重写的URI作为一个新的URI，在本快中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会讲新的URI专项到其他的location块。看下面的例子：\n>> \n```\nlocation /myweb/ {\n\trewrite ^(/myweb/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra break;\n}\n```\n如果某URI在第二行被匹配成功并处理，Nginx服务器将新的URI继续在该location块中使用第三行进行匹配和处理。新的URI始终是在同一个location块中。\n>> \n>> redirect, 将重写后的URI返回给客户端，状态代码为302，指明是临时重定向的URI，主要用在replacement变量不是以\"http://\"或者\"https://\"开头的情况下。\n>> \n>> permanent，将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI。\n\n在使用flag指令时，一定要注意各个标志之间的配合。我们再来回顾刚才学习break标志时的例子，对比last标志里的例子，如果我们将第二个例子中的break标志换成last标志，会发生什么情况呢？\n\n细心的读者可能已经发现，在第二个例子中，location块的uri指令是\"/myweb/\"，而重写后的URI仍然是包含\"/myweb/\"的，如果使用last标志，重写后的URI还可能会被该location块匹配到，这样就形成了无限循环。Nginx服务器遇到这样的情况，会尝试10次循环之后返回错误状态代码500。\n\n\n### rewrite_log指令\n该指令配置是否开启URL重写日志的输出功能，其语法结构为：\n```\nrewrite_log on | off;\n```\n默认设置为off。如果配置为开启（on),URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件中。\n\n### set指令\n该指令用于设置一个新的变量，其语法结构为：\n\n```\nset variable value;\n```\n> variable，为变量的名称。注意要用符号\"$\"作为变量的第一个字符，且变量不能与Nginx服务器预设的全局变量同名。\n> \n> value，为变量的值，可以使字符串、其他变量或者变量的组合等。\n\n### uninitialized\\_variable\\_warn指令\n该指令用于配置使用为初始化的变量时，是否记录警告日志，其语法结构为：\n\n```\nuninitialized_variable_warn on | off;\n```\n默认设置为开启（on）状态。\n\n### Rewrite 常用全局变量\n|变量|说明|\n|:---|:---|\n|**$args**|变量中存放了请求URL中的请求指令。比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"arg1=value1&arg2=value2\"|\n|$content_length|变量中存放了请求头中的Content-length字段|\n|$content_type|变量中存放了请求头中的Content-type字段|\n|$document_root|变量中存放了针对当前请求的根路径|\n|$document_uri|变量中存放了请求中的当前URI，并且不包括请求指令，比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"/server/source\"|\n|**$host**|变量中存放了请求URL中的主机部分字段，比如http://www.myweb.name/server中的\"www.myweb.name\"。如果请求中的主机部分字段不可用或者为空，则存放Nginx配置中server块中server_name指令的配置值|\n|$http_user_agent|变量中存放客户端的代理信息|\n|**$http_cookie**|变量中存放客户端的cookie信息|\n|$limit_rate|变量中存放Nginx服务器对网络连接速率的限制，也就是Nginx配置中limit_rate指令的配置值|\n|**$remote_addr**|变量中存放了客户端的地址|\n|$remote_port|变量中存放了客户端与服务器建立连接的端口号|\n|$remote_user|变量中存放了客户端的用户名|\n|$request_body_file|变量中存放了发给后端服务器的本地文件资源的名称|\n|**$request_method**|变量中存放了客户端的请求方式，如『GET』、『POST』等|\n|$request_filename|变量中存放了当前请求的资源文件的路径名|\n|**$request_uri**|变量中存放了当前请求的URI，并且带请求指令|\n|**$query_string**|与变量$args含义相同|\n|**$scheme**|变量中存放了客户端请求使用的协议，比如\"http\"、\"https\"和\"ftp\"等|\n|$server_protocol|变量中存放了客户端请求协议的版本，比如\"HTTP/1.0\"、\"HTTP/1.1\"等|\n|$server_addr|变量中存放了服务器的地址|\n|$server_name|变量中存放了客户端请求到达的服务器的名称|\n|$server_port|变量中存放了客户端请求到达的服务器的端口号|\n|$uri|与变量$document_uri含义相同|","source":"_posts/Rewrite功能的配置（1）.md","raw":"---\ntitle: Rewrite功能的配置（1）\ntags:\n  - nginx\noriginContent: \"![游戏机](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/80%E5%90%8E/1cd4edf0c7c6d0e7a7c44120d7197168.jpg)\\n\\nRewrite 是 Nginx 服务器提供的一个重要基本功能，骑在Web服务器产品中几乎是必备的功能，用于实现URL的重写。URL的重写是非常有用的功能，比如他可以让我们在改变网站结构后，无需要求客户端用户修改原来的书签，也无需其他网站修改对我们网站的友情链接；他还可以在一定程度上提高网站的安全性；能够让我们的网站显得更加专业。\\n\\n<!-- more -->\\n\\n适当利用Rewrite功能，可以给我们带来很多好处，这一节我们就重点学习一下 Nginx 服务器的Rewrite功能。Nginx服务器的Rewrite功能的实现依赖于PCRE（Perl Compatible Regular Expressions，Perl兼容的正则表达式）的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。\\n\\n> 提示：有关PCRE的介绍和PCRE库的相关下载请参阅其[官方网站](http://www.pcre.org/)。\\n> Nginx服务器使用ngx_http_rewrite_module模块解析和处理Rewrite功能的相关配置。\\n\\n## 『地址重写』与『地址转发』\\n\\n『地址重写』与『转发』在计算机网络领域是两个重要概念，经常被大家提起。但许多人对这两个概念的区别不清楚，甚至混为一谈。在学习Nginx服务器的Rewrite功能之前，我们有必要先将这对概念进行一下分析和对比，让大家能够有一个清晰的认识。\\n\\n『地址重写』，实际上是为了实现地址标准化。那么，什么是地址标准化呢？我们来举一个例子。比如在访问Google首页的时候，我们在地址栏中可以输入www.google.com，也可以输入google.cn，他们都能够准确的指向Google首页，从客户端来看，Google首页同时对应了两个地址，实际上，Google服务器是在不同的地址中选择了确定的一个，即www.google.com，进而返回服务器响应的。这个过程就是地址标准化的过程。google.cn这个地址在服务器中被改变为www.google.com的过程就是地址重定向的过程。\\n\\n『转发』的概念最初和网页的访问并没有太大关系，他是指在网络数据传输过程中数据分组到达路由器或者桥接器后该设备通过检查分组地址并将数据转到相邻局域网上的过程。后来该概念被用在网页访问中，出现了『地址转发』的说法。『地址转发』是指将一个域名知道另一个已有站点的过程。\\n\\n从上面的解释，我们可以看到『地址重写』和『地址转发』代表的两个过程是不同的。我们可以总结这两个过程的几点区别：\\n\\n> 地址转发后客户端浏览器中的地址显示时不改变的；而地址重写后客户端浏览器地址栏中的地址改变为服务器选择确定的地址。\\n> 在一次地址转发整个过程中，只产生一次网络请求；而一次地址重写一般会产生两次请求。\\n> 地址转发一般发生在统一站点项目内；二地址重写没有该限制\\n> 地址转发到的页面可以不用全路径名标识，二地址重写到的页面必须使用完整的路径名表示\\n> 地址转发过程中，可以将客户端请求的request范围内属性传递给新的页面，但地址重写不可以\\n> 地址转发的速度较地址重定向快。\\n\\n## Rewrite规则\\nRewrite规则是学习和使用Nginx服务器Rewrite功能的基础，可以借助PCRE实现URI的重写，并且她还支持Nginx预设变量。Rewrite规则的核心就是PCRE。\\n\\n正则表达式（Regular Expression，缩写为regex、regexp或RE），是用于描述或者匹配一系列符合某个句法规则的字符串的一个字符串。大家应该都是用过Windows/Dos平台下用于文件查找的通配符\\\"\\\\*\\\" 和 \\\"?\\\"，如果要查找某个目录下所有的word文档，就是用\\\"\\\\*.doc\\\"进行搜索，『\\\\*』会被解释成替换符合某个句法模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。PCRE就是在Perl中内建的功能强大的正则表达式引擎，可以被许多工具使用的库。正则表达式有多种不同的分割，并且不同版本再对句法规则的匹配处理上也有一定的差异。\\n\\n在Nginx服务器中，使用ngx_http_rewrite_module模块支持URL重写功能。该模块是Nginx服务器的标准HTTP模块。\\n\\n由于正则表达式的知识超出了本书的范围，我们不在正文中对其详细阐述。在『附录A』中，笔者为大家整理了PCRE库支持的正则表达式元字符表，并对这些元字符在正则表达式上下文中的行为进行了说明，同时也列举了大量的使用实例供大家参考。\\n\\n在这里，建议大家学习正则表达式时，一定要将思维从『字符创』的概念转变为『字符』的概念，将『词句』的概念转变为『字』的概念，多结合实例进行操作，这样才能准确理解和运用正则表达式。另外，网络上有不少PCRE正则表达式的测试工具，大家可以搜索下载，这些工具对我们在学习和使用正则表达式的过程中很有帮助。\\n\\n在Nginx配置中，有关Rewrite的配置指令不多，但是它们已经能够提供比较完善的功能了。\\n\\n### if指令\\n该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置，可以在server块或location块中配置该指令，其语法结构为：\\n```\\nif ( condition ) {...}\\n```\\n\\n其中，花括号代表一个作用域，形成一个if配置块，是条件为真时的Nginx配置。condition为判断条件（true、false），他可以支持以下几种设置方法：\\n#### 变量名。\\n如果变量的值为空字符串或以『0』开头的任意字符串，if指令认为条件为false，其他情况认为条件为true。比如：\\n\\n```\\nif ($slow) {\\n  ... #Nginx 配置\\n}\\n```\\n\\n#### 使用'='（等于）和'!='（不等于）\\n比较变量和字符串是否相等，相等时if指令为true，反之为false。\\n\\n```\\nif ($request_method = POST) {\\n\\treturn 405;\\n}\\n```\\n> 注意：这里的字符串不需要加引号。\\n\\n#### 使用正则表达式对变量进行匹配\\n匹配成功时 if 指令认为条件为true，否则为false。变量与正则表达式之间用\\\"~\\\"、\\\"~*\\\"、\\\"!~\\\"或\\\"!~\\\\*\\\"连接，『~』表示匹配过程中对大小写敏感，『~\\\\*』表示匹配过程中对大小写不敏感；使用『!~』和\\\"!~\\\\*\\\"，匹配失败时if指令认为条件为true，否则为false。在正则表达式中，可以使用小括号对变量值进行截取，在花括号中使用$1...$9引用截取的值。比如：\\n\\n```\\nif ($http_user_agent ~ MSIE) {\\n\\t# $http_user_agent的值中是否包含有MSIE字符串，如果包含，为true\\n\\t...\\n}\\n```\\n\\n\\n\\n> 注意：整个正则表达式字符串一般不需要加引号，但如果含有右花括号\\\"}\\\"或者分号\\\";\\\"字符时，必须要给整个正则表达式添加引号。\\n\\n#### 判断请求的文件是否存在使用\\\"-f\\\"和\\\"!-f\\\"。\\n当使用\\\"-f\\\"时，如果请求的文件存在，if指令认为条件为true，如果请求的文件不存在为false；使用\\\"!-f\\\"时，如果请求的文件不存在但该文件所在的目录存在，if指令认为条件为true，如果该文件和她所在的目录都不存在，则为false，如果请求的文件存在，也为false。使用的方法如下：\\n\\n```\\nif (-f $request_filename) {\\n\\t# 判断请求的文件是否存在\\n\\t...\\n}\\nif (!-f $request_filename) {\\n\\t# 判断请求的文件是否不存在\\n}\\n```\\n\\n#### 判断请求的目录是否存在使用\\\"-d\\\"和\\\"!-d\\\".\\n当使用\\\"-d\\\"时，如果请求的目录存在，if指令认为条件为true，如果请求的目录不存在，则为false；当使用\\\"!-d\\\"时，如果请求的目录不存在但该目录的上级目录存在，if指令认为条件为true，如果该目录和它的上级目录都不存在，则为false，如果请求的目录存在，也为false。使用方式见\\\"-f\\\"和\\\"!-f\\\"的使用。\\n\\n#### 判断请求的目录或文件是否存在使用\\\"-e\\\"和\\\"!-e\\\"。\\n当使用\\\"-e\\\"时，如果请求的目录或者文件存在时，if指令认为条件为true，否则为false。当使用\\\"!-e\\\"时，如果请求的文件和该文件所在路径上的目录都不存在，为true，否则为false。使用方式见\\\"-f\\\"和\\\"!-f\\\"的使用。\\n#### 判断请求的文件是否可执行使用\\\"-x\\\"和\\\"!-x\\\"。\\n当使用\\\"-x\\\"时，如果请求的文件可执行，if指令认为条件为true，否则为false；当使用\\\"!-x\\\"时，如果请求的文件不可执行，为true，否则为false。使用方法见\\\"-f\\\"和\\\"!-f\\\"的使用\\n\\n### break指令\\n该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。Nginx服务器在根据配置处理请求的过程中遇到该指令时，回到上一层作用域继续向下读取配置。该指令可以在server块和location快以及if块中使用，其语法结构为：\\n\\n```\\nbreak;\\n```\\n\\n我们通过一个例子加深理解：\\n\\n```\\nlocation / {\\n\\tif ($slow) {\\n\\t\\tset $id $1;\\t\\t\\t#处于break指令之前，配置有效\\n\\t\\tbreak;\\n\\t\\tlimit_rate 10k;\\t\\t#处于break指令之后，配置无效\\n\\t}\\n\\t...\\t\\t\\t\\t\\t\\t\\t#其他Nginx配置，处于break指令所在作用域的上一层作用域，配置有效\\n}\\n```\\n\\n#### return指令\\n该指令用于完成对请求的处理，直接向客户端返回响应状态码。处于该指令后的所有Nginx配置都是无效的。该指令可以在server块和location块以及if块中使用，其语法结构有以下几种：\\n\\n```\\nreturn [text];\\nreturn code URL;\\nreturn URL;\\n```\\n\\n> code，为返回给客户端的HTTP状态代码。可以返回的状态代码为0-999的任意HTTP状态码。非标准的444代码可以强制关闭服务器与客户端的连接而不返回任何响应信息给客户端。\\n> \\n> text，为返回给客户端的响应体内容，支持变量的使用。`return 200 'hello from nginx;'`\\n> \\n> URL，为返回给客户端的URL地址。\\n\\n从Nginx 0.8.42 开始，当code使用301（表示被请求资源永久移动到新的位置）、302（表示请求的资源现在临时从不同的URL响应，要求使用GET昂视请求）、303（表示对应当前请求的相应可以在另一个URL上找到，并且客户端应当采用GET方式访问那个资源）和307（请求的资源临时从不同的URL响应）代码时，可以使用结构2将新的URL返回给客户端；当code使用除上面提到的其他代码时，可以使用结构1指定text想客户端发送指定的响应体内容。\\n\\n当返回状态吗未302或307时，可以使用结构3对URL进行配置。返回的URL中应该包含\\\"http://\\\"、\\\"https://\\\"或者直接使用\\\"$scheme\\\"变量（Request Scheme，代表传输协议，Nginx内置变量）指定。\\n\\n> 注意：在Nginx 0.7.51之前的版本中，只支持返回204、400、402-406、608、410、413、416和500-504等状态代码。\\n\\n### rewrite指令\\n该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。\\n> 提示：\\n> \\n> URI与URL的区别和联系。\\n> \\n> URI（Universal Resource Identifier，通用资源标识符），用于对网络中的各种资源进行标识，由存放资源的主机名、片段标识符和相对URI三部分组成。存放资源的主机名一版由传输协议（Scheme）、主机和资源路径三部分组成；片段标识符指向资源内容的具体元素；相对URI表示资源在主机上的相对路径。一版格式为：Scheme:[//][用户名[:密码]@主机名[:端口号]][/资源路径]。\\n> \\n> URL（Uniform Resource Location，统一资源定位符），是用于在Interner中描述资源的字符串，是URI的子集，主要包括传输协议（Scheme）、主机（IP、端口号或者域名）和资源具体地址（目录和文件名）等三部分。一版格式为：Scheme://主机名[:端口号][/资源路径]。\\n\\n该指令可以在server块或者location块中配置，其语法结构为：\\n```\\nrewrite regex replacement [flag];\\n```\\n\\n> regex，用于匹配URI的正则表达式。使用\\\"()\\\"标记要截取的内容。\\n\\n注意：\\n\\nrewrite接收到的URI不包括host地址。因此，regex不可能匹配到URI的host地址。我们看下面这个例子：\\n\\n```\\nrewrite myweb.com http://newweb.com/parmanent;\\n```\\n\\n现在我们希望上面的rewrite指令重写http://myweb.com/source是办不到的，因为rewrite指令接收到的URI是\\\"/source\\\"，不包含\\\"myweb.com\\\"。\\n\\n另外，请求URL中的请求指令是不包含在rewrite指令接收到的URI内容中的。比如:\\n\\n`http://myweb.com/source?agr1=value&agr2=value2`;\\n\\nrewrite指令接收到奥的URI为\\\"source\\\",不包含\\\"?agr1=value&agr2=value2\\\"。\\n\\n> replacement，成功匹配后用于替换URI中被截取内容的字符串。默认情况下，如果该字符串是由\\\"http://\\\"或者\\\"https://\\\"开头的，则不会继续向下对URI进行其他处理，而是直接将重写后的URI返回给客户端。\\n\\n提示：\\n\\n刚才学习regex变量时我们提到，rewrite模块快接收到的URI不包含请求URL中的请求指令，但是如果我们希望将这些指令传给重写后的URI，该怎么做呢？我们可以使用Nginx全局变量$request_uri，比如：\\n`rewrite myweb.com http://example.com$request_uri? permanent;`\\n\\n注意：\\n\\n在$request_uri变量后要添加问号\\\"? \\\".replacement变量中支持Nginx全局变量的使用，常用的还有$uri和$args等。\\n\\n> flag，用于设置rewrite对URI的处理行为，可以为以下标志中的一个：\\n>> last，终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标识将重写后徐的URI重新再server块中执行，为重写后的URI提供了转入到其他location块的机会。我们通过一个例子来加深理解：\\n>> \\n```\\nlocation / {\\n\\trewrite ^(/myweb/.*)/media/(.*)\\\\..*$ $1/mp3/$2.mp3 last;\\n\\trewrite ^(/myweb/.*)/audio/(.*)\\\\.*$ $1/mp3/$2.ra last;\\n}\\n```\\n>> 如果URI在第二行被匹配成功并处理，Nginx服务器不会继续使用第三行的配置匹配和处理新的URI，而是让所有的location块重新匹配和处理新的URI。\\n>> \\n>> break，将此处重写的URI作为一个新的URI，在本快中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会讲新的URI专项到其他的location块。看下面的例子：\\n>> \\n```\\nlocation /myweb/ {\\n\\trewrite ^(/myweb/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break;\\n\\trewrite ^(/myweb/.*)/audio/(.*)\\\\.*$ $1/mp3/$2.ra break;\\n}\\n```\\n如果某URI在第二行被匹配成功并处理，Nginx服务器将新的URI继续在该location块中使用第三行进行匹配和处理。新的URI始终是在同一个location块中。\\n>> \\n>> redirect, 将重写后的URI返回给客户端，状态代码为302，指明是临时重定向的URI，主要用在replacement变量不是以\\\"http://\\\"或者\\\"https://\\\"开头的情况下。\\n>> \\n>> permanent，将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI。\\n\\n在使用flag指令时，一定要注意各个标志之间的配合。我们再来回顾刚才学习break标志时的例子，对比last标志里的例子，如果我们将第二个例子中的break标志换成last标志，会发生什么情况呢？\\n\\n细心的读者可能已经发现，在第二个例子中，location块的uri指令是\\\"/myweb/\\\"，而重写后的URI仍然是包含\\\"/myweb/\\\"的，如果使用last标志，重写后的URI还可能会被该location块匹配到，这样就形成了无限循环。Nginx服务器遇到这样的情况，会尝试10次循环之后返回错误状态代码500。\\n\\n\\n### rewrite_log指令\\n该指令配置是否开启URL重写日志的输出功能，其语法结构为：\\n```\\nrewrite_log on | off;\\n```\\n默认设置为off。如果配置为开启（on),URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件中。\\n\\n### set指令\\n该指令用于设置一个新的变量，其语法结构为：\\n\\n```\\nset variable value;\\n```\\n> variable，为变量的名称。注意要用符号\\\"$\\\"作为变量的第一个字符，且变量不能与Nginx服务器预设的全局变量同名。\\n> \\n> value，为变量的值，可以使字符串、其他变量或者变量的组合等。\\n\\n### uninitialized\\\\_variable\\\\_warn指令\\n该指令用于配置使用为初始化的变量时，是否记录警告日志，其语法结构为：\\n\\n```\\nuninitialized_variable_warn on | off;\\n```\\n默认设置为开启（on）状态。\\n\\n### Rewrite 常用全局变量\\n|变量|说明|\\n|:---|:---|\\n|**$args**|变量中存放了请求URL中的请求指令。比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\\\"arg1=value1&arg2=value2\\\"|\\n|$content_length|变量中存放了请求头中的Content-length字段|\\n|$content_type|变量中存放了请求头中的Content-type字段|\\n|$document_root|变量中存放了针对当前请求的根路径|\\n|$document_uri|变量中存放了请求中的当前URI，并且不包括请求指令，比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\\\"/server/source\\\"|\\n|**$host**|变量中存放了请求URL中的主机部分字段，比如http://www.myweb.name/server中的\\\"www.myweb.name\\\"。如果请求中的主机部分字段不可用或者为空，则存放Nginx配置中server块中server_name指令的配置值|\\n|$http_user_agent|变量中存放客户端的代理信息|\\n|**$http_cookie**|变量中存放客户端的cookie信息|\\n|$limit_rate|变量中存放Nginx服务器对网络连接速率的限制，也就是Nginx配置中limit_rate指令的配置值|\\n|**$remote_addr**|变量中存放了客户端的地址|\\n|$remote_port|变量中存放了客户端与服务器建立连接的端口号|\\n|$remote_user|变量中存放了客户端的用户名|\\n|$request_body_file|变量中存放了发给后端服务器的本地文件资源的名称|\\n|**$request_method**|变量中存放了客户端的请求方式，如『GET』、『POST』等|\\n|$request_filename|变量中存放了当前请求的资源文件的路径名|\\n|**$request_uri**|变量中存放了当前请求的URI，并且带请求指令|\\n|**$query_string**|与变量$args含义相同|\\n|**$scheme**|变量中存放了客户端请求使用的协议，比如\\\"http\\\"、\\\"https\\\"和\\\"ftp\\\"等|\\n|$server_protocol|变量中存放了客户端请求协议的版本，比如\\\"HTTP/1.0\\\"、\\\"HTTP/1.1\\\"等|\\n|$server_addr|变量中存放了服务器的地址|\\n|$server_name|变量中存放了客户端请求到达的服务器的名称|\\n|$server_port|变量中存放了客户端请求到达的服务器的端口号|\\n|$uri|与变量$document_uri含义相同|\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-09-02 17:21:17\n---\n\n![游戏机](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/80%E5%90%8E/1cd4edf0c7c6d0e7a7c44120d7197168.jpg)\n\nRewrite 是 Nginx 服务器提供的一个重要基本功能，骑在Web服务器产品中几乎是必备的功能，用于实现URL的重写。URL的重写是非常有用的功能，比如他可以让我们在改变网站结构后，无需要求客户端用户修改原来的书签，也无需其他网站修改对我们网站的友情链接；他还可以在一定程度上提高网站的安全性；能够让我们的网站显得更加专业。\n\n<!-- more -->\n\n适当利用Rewrite功能，可以给我们带来很多好处，这一节我们就重点学习一下 Nginx 服务器的Rewrite功能。Nginx服务器的Rewrite功能的实现依赖于PCRE（Perl Compatible Regular Expressions，Perl兼容的正则表达式）的支持，因此在编译安装Nginx服务器之前，需要安装PCRE库。\n\n> 提示：有关PCRE的介绍和PCRE库的相关下载请参阅其[官方网站](http://www.pcre.org/)。\n> Nginx服务器使用ngx_http_rewrite_module模块解析和处理Rewrite功能的相关配置。\n\n## 『地址重写』与『地址转发』\n\n『地址重写』与『转发』在计算机网络领域是两个重要概念，经常被大家提起。但许多人对这两个概念的区别不清楚，甚至混为一谈。在学习Nginx服务器的Rewrite功能之前，我们有必要先将这对概念进行一下分析和对比，让大家能够有一个清晰的认识。\n\n『地址重写』，实际上是为了实现地址标准化。那么，什么是地址标准化呢？我们来举一个例子。比如在访问Google首页的时候，我们在地址栏中可以输入www.google.com，也可以输入google.cn，他们都能够准确的指向Google首页，从客户端来看，Google首页同时对应了两个地址，实际上，Google服务器是在不同的地址中选择了确定的一个，即www.google.com，进而返回服务器响应的。这个过程就是地址标准化的过程。google.cn这个地址在服务器中被改变为www.google.com的过程就是地址重定向的过程。\n\n『转发』的概念最初和网页的访问并没有太大关系，他是指在网络数据传输过程中数据分组到达路由器或者桥接器后该设备通过检查分组地址并将数据转到相邻局域网上的过程。后来该概念被用在网页访问中，出现了『地址转发』的说法。『地址转发』是指将一个域名知道另一个已有站点的过程。\n\n从上面的解释，我们可以看到『地址重写』和『地址转发』代表的两个过程是不同的。我们可以总结这两个过程的几点区别：\n\n> 地址转发后客户端浏览器中的地址显示时不改变的；而地址重写后客户端浏览器地址栏中的地址改变为服务器选择确定的地址。\n> 在一次地址转发整个过程中，只产生一次网络请求；而一次地址重写一般会产生两次请求。\n> 地址转发一般发生在统一站点项目内；二地址重写没有该限制\n> 地址转发到的页面可以不用全路径名标识，二地址重写到的页面必须使用完整的路径名表示\n> 地址转发过程中，可以将客户端请求的request范围内属性传递给新的页面，但地址重写不可以\n> 地址转发的速度较地址重定向快。\n\n## Rewrite规则\nRewrite规则是学习和使用Nginx服务器Rewrite功能的基础，可以借助PCRE实现URI的重写，并且她还支持Nginx预设变量。Rewrite规则的核心就是PCRE。\n\n正则表达式（Regular Expression，缩写为regex、regexp或RE），是用于描述或者匹配一系列符合某个句法规则的字符串的一个字符串。大家应该都是用过Windows/Dos平台下用于文件查找的通配符\"\\*\" 和 \"?\"，如果要查找某个目录下所有的word文档，就是用\"\\*.doc\"进行搜索，『\\*』会被解释成替换符合某个句法模式的文本内容。许多程序设计语言都支持利用正则表达式进行字符串操作。PCRE就是在Perl中内建的功能强大的正则表达式引擎，可以被许多工具使用的库。正则表达式有多种不同的分割，并且不同版本再对句法规则的匹配处理上也有一定的差异。\n\n在Nginx服务器中，使用ngx_http_rewrite_module模块支持URL重写功能。该模块是Nginx服务器的标准HTTP模块。\n\n由于正则表达式的知识超出了本书的范围，我们不在正文中对其详细阐述。在『附录A』中，笔者为大家整理了PCRE库支持的正则表达式元字符表，并对这些元字符在正则表达式上下文中的行为进行了说明，同时也列举了大量的使用实例供大家参考。\n\n在这里，建议大家学习正则表达式时，一定要将思维从『字符创』的概念转变为『字符』的概念，将『词句』的概念转变为『字』的概念，多结合实例进行操作，这样才能准确理解和运用正则表达式。另外，网络上有不少PCRE正则表达式的测试工具，大家可以搜索下载，这些工具对我们在学习和使用正则表达式的过程中很有帮助。\n\n在Nginx配置中，有关Rewrite的配置指令不多，但是它们已经能够提供比较完善的功能了。\n\n### if指令\n该指令用来支持条件判断，并根据条件判断结果选择不同的Nginx配置，可以在server块或location块中配置该指令，其语法结构为：\n```\nif ( condition ) {...}\n```\n\n其中，花括号代表一个作用域，形成一个if配置块，是条件为真时的Nginx配置。condition为判断条件（true、false），他可以支持以下几种设置方法：\n#### 变量名。\n如果变量的值为空字符串或以『0』开头的任意字符串，if指令认为条件为false，其他情况认为条件为true。比如：\n\n```\nif ($slow) {\n  ... #Nginx 配置\n}\n```\n\n#### 使用'='（等于）和'!='（不等于）\n比较变量和字符串是否相等，相等时if指令为true，反之为false。\n\n```\nif ($request_method = POST) {\n\treturn 405;\n}\n```\n> 注意：这里的字符串不需要加引号。\n\n#### 使用正则表达式对变量进行匹配\n匹配成功时 if 指令认为条件为true，否则为false。变量与正则表达式之间用\"~\"、\"~*\"、\"!~\"或\"!~\\*\"连接，『~』表示匹配过程中对大小写敏感，『~\\*』表示匹配过程中对大小写不敏感；使用『!~』和\"!~\\*\"，匹配失败时if指令认为条件为true，否则为false。在正则表达式中，可以使用小括号对变量值进行截取，在花括号中使用$1...$9引用截取的值。比如：\n\n```\nif ($http_user_agent ~ MSIE) {\n\t# $http_user_agent的值中是否包含有MSIE字符串，如果包含，为true\n\t...\n}\n```\n\n\n\n> 注意：整个正则表达式字符串一般不需要加引号，但如果含有右花括号\"}\"或者分号\";\"字符时，必须要给整个正则表达式添加引号。\n\n#### 判断请求的文件是否存在使用\"-f\"和\"!-f\"。\n当使用\"-f\"时，如果请求的文件存在，if指令认为条件为true，如果请求的文件不存在为false；使用\"!-f\"时，如果请求的文件不存在但该文件所在的目录存在，if指令认为条件为true，如果该文件和她所在的目录都不存在，则为false，如果请求的文件存在，也为false。使用的方法如下：\n\n```\nif (-f $request_filename) {\n\t# 判断请求的文件是否存在\n\t...\n}\nif (!-f $request_filename) {\n\t# 判断请求的文件是否不存在\n}\n```\n\n#### 判断请求的目录是否存在使用\"-d\"和\"!-d\".\n当使用\"-d\"时，如果请求的目录存在，if指令认为条件为true，如果请求的目录不存在，则为false；当使用\"!-d\"时，如果请求的目录不存在但该目录的上级目录存在，if指令认为条件为true，如果该目录和它的上级目录都不存在，则为false，如果请求的目录存在，也为false。使用方式见\"-f\"和\"!-f\"的使用。\n\n#### 判断请求的目录或文件是否存在使用\"-e\"和\"!-e\"。\n当使用\"-e\"时，如果请求的目录或者文件存在时，if指令认为条件为true，否则为false。当使用\"!-e\"时，如果请求的文件和该文件所在路径上的目录都不存在，为true，否则为false。使用方式见\"-f\"和\"!-f\"的使用。\n#### 判断请求的文件是否可执行使用\"-x\"和\"!-x\"。\n当使用\"-x\"时，如果请求的文件可执行，if指令认为条件为true，否则为false；当使用\"!-x\"时，如果请求的文件不可执行，为true，否则为false。使用方法见\"-f\"和\"!-f\"的使用\n\n### break指令\n该指令用于中断当前相同作用域中的其他Nginx配置。与该指令处于同一作用域的Nginx配置中，位于它前面的指令配置生效，位于后面的指令配置无效。Nginx服务器在根据配置处理请求的过程中遇到该指令时，回到上一层作用域继续向下读取配置。该指令可以在server块和location快以及if块中使用，其语法结构为：\n\n```\nbreak;\n```\n\n我们通过一个例子加深理解：\n\n```\nlocation / {\n\tif ($slow) {\n\t\tset $id $1;\t\t\t#处于break指令之前，配置有效\n\t\tbreak;\n\t\tlimit_rate 10k;\t\t#处于break指令之后，配置无效\n\t}\n\t...\t\t\t\t\t\t\t#其他Nginx配置，处于break指令所在作用域的上一层作用域，配置有效\n}\n```\n\n#### return指令\n该指令用于完成对请求的处理，直接向客户端返回响应状态码。处于该指令后的所有Nginx配置都是无效的。该指令可以在server块和location块以及if块中使用，其语法结构有以下几种：\n\n```\nreturn [text];\nreturn code URL;\nreturn URL;\n```\n\n> code，为返回给客户端的HTTP状态代码。可以返回的状态代码为0-999的任意HTTP状态码。非标准的444代码可以强制关闭服务器与客户端的连接而不返回任何响应信息给客户端。\n> \n> text，为返回给客户端的响应体内容，支持变量的使用。`return 200 'hello from nginx;'`\n> \n> URL，为返回给客户端的URL地址。\n\n从Nginx 0.8.42 开始，当code使用301（表示被请求资源永久移动到新的位置）、302（表示请求的资源现在临时从不同的URL响应，要求使用GET昂视请求）、303（表示对应当前请求的相应可以在另一个URL上找到，并且客户端应当采用GET方式访问那个资源）和307（请求的资源临时从不同的URL响应）代码时，可以使用结构2将新的URL返回给客户端；当code使用除上面提到的其他代码时，可以使用结构1指定text想客户端发送指定的响应体内容。\n\n当返回状态吗未302或307时，可以使用结构3对URL进行配置。返回的URL中应该包含\"http://\"、\"https://\"或者直接使用\"$scheme\"变量（Request Scheme，代表传输协议，Nginx内置变量）指定。\n\n> 注意：在Nginx 0.7.51之前的版本中，只支持返回204、400、402-406、608、410、413、416和500-504等状态代码。\n\n### rewrite指令\n该指令通过正则表达式的使用来改变URI。可以同时存在一个或者多个指令，按照顺序依次对URL进行匹配和处理。\n> 提示：\n> \n> URI与URL的区别和联系。\n> \n> URI（Universal Resource Identifier，通用资源标识符），用于对网络中的各种资源进行标识，由存放资源的主机名、片段标识符和相对URI三部分组成。存放资源的主机名一版由传输协议（Scheme）、主机和资源路径三部分组成；片段标识符指向资源内容的具体元素；相对URI表示资源在主机上的相对路径。一版格式为：Scheme:[//][用户名[:密码]@主机名[:端口号]][/资源路径]。\n> \n> URL（Uniform Resource Location，统一资源定位符），是用于在Interner中描述资源的字符串，是URI的子集，主要包括传输协议（Scheme）、主机（IP、端口号或者域名）和资源具体地址（目录和文件名）等三部分。一版格式为：Scheme://主机名[:端口号][/资源路径]。\n\n该指令可以在server块或者location块中配置，其语法结构为：\n```\nrewrite regex replacement [flag];\n```\n\n> regex，用于匹配URI的正则表达式。使用\"()\"标记要截取的内容。\n\n注意：\n\nrewrite接收到的URI不包括host地址。因此，regex不可能匹配到URI的host地址。我们看下面这个例子：\n\n```\nrewrite myweb.com http://newweb.com/parmanent;\n```\n\n现在我们希望上面的rewrite指令重写http://myweb.com/source是办不到的，因为rewrite指令接收到的URI是\"/source\"，不包含\"myweb.com\"。\n\n另外，请求URL中的请求指令是不包含在rewrite指令接收到的URI内容中的。比如:\n\n`http://myweb.com/source?agr1=value&agr2=value2`;\n\nrewrite指令接收到奥的URI为\"source\",不包含\"?agr1=value&agr2=value2\"。\n\n> replacement，成功匹配后用于替换URI中被截取内容的字符串。默认情况下，如果该字符串是由\"http://\"或者\"https://\"开头的，则不会继续向下对URI进行其他处理，而是直接将重写后的URI返回给客户端。\n\n提示：\n\n刚才学习regex变量时我们提到，rewrite模块快接收到的URI不包含请求URL中的请求指令，但是如果我们希望将这些指令传给重写后的URI，该怎么做呢？我们可以使用Nginx全局变量$request_uri，比如：\n`rewrite myweb.com http://example.com$request_uri? permanent;`\n\n注意：\n\n在$request_uri变量后要添加问号\"? \".replacement变量中支持Nginx全局变量的使用，常用的还有$uri和$args等。\n\n> flag，用于设置rewrite对URI的处理行为，可以为以下标志中的一个：\n>> last，终止继续在本location块中处理接收到的URI，并将此处重写的URI作为一个新的URI，使用各location块进行处理。该标识将重写后徐的URI重新再server块中执行，为重写后的URI提供了转入到其他location块的机会。我们通过一个例子来加深理解：\n>> \n```\nlocation / {\n\trewrite ^(/myweb/.*)/media/(.*)\\..*$ $1/mp3/$2.mp3 last;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra last;\n}\n```\n>> 如果URI在第二行被匹配成功并处理，Nginx服务器不会继续使用第三行的配置匹配和处理新的URI，而是让所有的location块重新匹配和处理新的URI。\n>> \n>> break，将此处重写的URI作为一个新的URI，在本快中继续进行处理。该标志将重写后的地址在当前的location块中执行，不会讲新的URI专项到其他的location块。看下面的例子：\n>> \n```\nlocation /myweb/ {\n\trewrite ^(/myweb/.*)/media/(.*)..*$ $1/mp3/$2.mp3 break;\n\trewrite ^(/myweb/.*)/audio/(.*)\\.*$ $1/mp3/$2.ra break;\n}\n```\n如果某URI在第二行被匹配成功并处理，Nginx服务器将新的URI继续在该location块中使用第三行进行匹配和处理。新的URI始终是在同一个location块中。\n>> \n>> redirect, 将重写后的URI返回给客户端，状态代码为302，指明是临时重定向的URI，主要用在replacement变量不是以\"http://\"或者\"https://\"开头的情况下。\n>> \n>> permanent，将重写后的URI返回给客户端，状态码为301，指明是永久重定向URI。\n\n在使用flag指令时，一定要注意各个标志之间的配合。我们再来回顾刚才学习break标志时的例子，对比last标志里的例子，如果我们将第二个例子中的break标志换成last标志，会发生什么情况呢？\n\n细心的读者可能已经发现，在第二个例子中，location块的uri指令是\"/myweb/\"，而重写后的URI仍然是包含\"/myweb/\"的，如果使用last标志，重写后的URI还可能会被该location块匹配到，这样就形成了无限循环。Nginx服务器遇到这样的情况，会尝试10次循环之后返回错误状态代码500。\n\n\n### rewrite_log指令\n该指令配置是否开启URL重写日志的输出功能，其语法结构为：\n```\nrewrite_log on | off;\n```\n默认设置为off。如果配置为开启（on),URL重写的相关日志将以notice级别输出到error_log指令配置的日志文件中。\n\n### set指令\n该指令用于设置一个新的变量，其语法结构为：\n\n```\nset variable value;\n```\n> variable，为变量的名称。注意要用符号\"$\"作为变量的第一个字符，且变量不能与Nginx服务器预设的全局变量同名。\n> \n> value，为变量的值，可以使字符串、其他变量或者变量的组合等。\n\n### uninitialized\\_variable\\_warn指令\n该指令用于配置使用为初始化的变量时，是否记录警告日志，其语法结构为：\n\n```\nuninitialized_variable_warn on | off;\n```\n默认设置为开启（on）状态。\n\n### Rewrite 常用全局变量\n|变量|说明|\n|:---|:---|\n|**$args**|变量中存放了请求URL中的请求指令。比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"arg1=value1&arg2=value2\"|\n|$content_length|变量中存放了请求头中的Content-length字段|\n|$content_type|变量中存放了请求头中的Content-type字段|\n|$document_root|变量中存放了针对当前请求的根路径|\n|$document_uri|变量中存放了请求中的当前URI，并且不包括请求指令，比如http://www.myweb.name/server/source?arg1=value1&arg2=value2中的\"/server/source\"|\n|**$host**|变量中存放了请求URL中的主机部分字段，比如http://www.myweb.name/server中的\"www.myweb.name\"。如果请求中的主机部分字段不可用或者为空，则存放Nginx配置中server块中server_name指令的配置值|\n|$http_user_agent|变量中存放客户端的代理信息|\n|**$http_cookie**|变量中存放客户端的cookie信息|\n|$limit_rate|变量中存放Nginx服务器对网络连接速率的限制，也就是Nginx配置中limit_rate指令的配置值|\n|**$remote_addr**|变量中存放了客户端的地址|\n|$remote_port|变量中存放了客户端与服务器建立连接的端口号|\n|$remote_user|变量中存放了客户端的用户名|\n|$request_body_file|变量中存放了发给后端服务器的本地文件资源的名称|\n|**$request_method**|变量中存放了客户端的请求方式，如『GET』、『POST』等|\n|$request_filename|变量中存放了当前请求的资源文件的路径名|\n|**$request_uri**|变量中存放了当前请求的URI，并且带请求指令|\n|**$query_string**|与变量$args含义相同|\n|**$scheme**|变量中存放了客户端请求使用的协议，比如\"http\"、\"https\"和\"ftp\"等|\n|$server_protocol|变量中存放了客户端请求协议的版本，比如\"HTTP/1.0\"、\"HTTP/1.1\"等|\n|$server_addr|变量中存放了服务器的地址|\n|$server_name|变量中存放了客户端请求到达的服务器的名称|\n|$server_port|变量中存放了客户端请求到达的服务器的端口号|\n|$uri|与变量$document_uri含义相同|","slug":"Rewrite功能的配置（1）","published":1,"updated":"2019-03-23T10:38:56.007Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ei20013gyavrfolo7z7"},{"title":"centos7 安装nvm","originContent":"网上找了一些发现这个比较好用：\n\n```\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash\n```\n\n重启命令行，否则不生效，如果用secureCRT则退出再进入即可\n\n下边命令安装稳定版\n\n```\nnvm install stable\n```\n\n如果是国内环境可以像修改npm一样修改nvm的源：\n\n```\n把环境变量 NVM_NODEJS_ORG_MIRROR, 加入到 .bash_profile 文件中:\n# nvm\nexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node\n```","toc":false,"date":"2017-12-04T07:03:11.000Z","_content":"\n网上找了一些发现这个比较好用：\n\n```\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash\n```\n\n重启命令行，否则不生效，如果用secureCRT则退出再进入即可\n\n下边命令安装稳定版\n\n```\nnvm install stable\n```\n\n如果是国内环境可以像修改npm一样修改nvm的源：\n\n```\n把环境变量 NVM_NODEJS_ORG_MIRROR, 加入到 .bash_profile 文件中:\n# nvm\nexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node\n```","source":"_posts/centos7-安装nvm.md","raw":"---\ntitle: centos7 安装nvm\ntags:\n  - nodejs\noriginContent: >-\n  网上找了一些发现这个比较好用：\n\n\n  ```\n\n  curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh |\n  bash\n\n  ```\n\n\n  重启命令行，否则不生效，如果用secureCRT则退出再进入即可\n\n\n  下边命令安装稳定版\n\n\n  ```\n\n  nvm install stable\n\n  ```\n\n\n  如果是国内环境可以像修改npm一样修改nvm的源：\n\n\n  ```\n\n  把环境变量 NVM_NODEJS_ORG_MIRROR, 加入到 .bash_profile 文件中:\n\n  # nvm\n\n  export NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node\n\n  ```\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-12-04 15:03:11\n---\n\n网上找了一些发现这个比较好用：\n\n```\ncurl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash\n```\n\n重启命令行，否则不生效，如果用secureCRT则退出再进入即可\n\n下边命令安装稳定版\n\n```\nnvm install stable\n```\n\n如果是国内环境可以像修改npm一样修改nvm的源：\n\n```\n把环境变量 NVM_NODEJS_ORG_MIRROR, 加入到 .bash_profile 文件中:\n# nvm\nexport NVM_NODEJS_ORG_MIRROR=https://npm.taobao.org/mirrors/node\n```","slug":"centos7-安装nvm","published":1,"updated":"2019-03-23T10:46:30.046Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ei70016gyavontbjgpw"},{"title":"centos6.7 安装 redis并配置开机启动","originContent":"在实际开发中有时候我们生产环境使用的服务器并不是centos7，这样造成我们安装软件需要使用更加通用的方式。\n\n1. 首先安装wget工具，下载redis包，我们在github下载release包，官网地址目前无法访问\n\t\n\t```\n\tyum install wget -y\n\twget https://github.com/antirez/redis/archive/4.0.2.tar.gz\n\t```\n<!-- more -->\n\n2. 解压&make&安装\n\t```\n\ttar zxvf 4.0.2.tar.gz \n\tcd redis-4.0.2/\n\tmake\n\tcd src && make install\n\t```\n\t![make && make install](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175039.png)\n\t执行完make install以后，会把redis-cli、redis-server放到/usr/local/bin/下边，由于服务器并没有把这个路径加到环境变量里边，因此我们需要多一步操作\n3. 修改环境变量，使redis命令生效\n\n\t```\n\tcd ~/\n\tvi .bashrc\n\t\n\t# 然后再文件末尾添加如下命令\n\tPATH=$PATH:/usr/local/bin/\n\t\n\t#保存后执行下边命令\n\tsource .bashrc\n\t```\n\t![修改环境变量](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175531.png)\n4. 复制配置文件到/etc 目录下\n\n\t```\n\tcp ~/redis-4.0.2/redis.conf /etc/\n\t```\n\t\n5. 建立用户与日志目录，建议为Redis单独建立一个用户，并新建data和日志文件夹\n\n\t```\n\tsudo useradd redis  \n\tsudo mkdir -p /var/lib/redis  \n\tsudo mkdir -p /var/log/redis  \n\tsudo chown redis.redis /var/lib/redis  \n\tsudo chown redis.redis /var/log/redis \n\t```\n6. 修改配置文件\n\t\n\t```\n\tvi /etc/redis.conf\n\t```\n\t\n\t修改绑定IP，让本机之外的IP也能够访问redis bind 0.0.0.0\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180325.png)\n\t\n\t修改启动模式为后台启动 daemonize yes\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180500.png)\n\t\n\t修改数据文件存储位置 dir /var/lib/redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180751.png)\n\t\n7. 配置init脚本\n\n\t```\n\tvi /etc/init.d/redis\n\t```\n\t\n\t```\n\t# chkconfig:   2345 90 10  \n  \n\t# description:  Redis is a persistent key-value database  \n\t  \n\t###########################  \n\tPATH=/usr/local/bin:/sbin:/usr/bin:/bin  \n\t     \n\tREDISPORT=6379  \n\tEXEC=/usr/local/bin/redis-server  \n\tREDIS_CLI=/usr/local/bin/redis-cli  \n\t     \n\tPIDFILE=/var/run/redis.pid  \n\tCONF=\"/etc/redis.conf\"  \n\t     \n\tcase \"$1\" in  \n\t    start)  \n\t        if [ -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE exists, process is already running or crashed\"  \n\t        else  \n\t                echo \"Starting Redis server...\"  \n\t                $EXEC $CONF  \n\t        fi  \n\t        if [ \"$?\"=\"0\" ]   \n\t        then  \n\t              echo \"Redis is running...\"  \n\t        fi  \n\t        ;;  \n\t    stop)  \n\t        if [ ! -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE does not exist, process is not running\"  \n\t        else  \n\t                PID=$(cat $PIDFILE)  \n\t                echo \"Stopping ...\"  \n\t                $REDIS_CLI -p $REDISPORT SHUTDOWN  \n\t                while [ -x ${PIDFILE} ]  \n\t               do  \n\t                    echo \"Waiting for Redis to shutdown ...\"  \n\t                    sleep 1  \n\t                done  \n\t                echo \"Redis stopped\"  \n\t        fi  \n\t        ;;  \n\t   restart|force-reload)  \n\t        ${0} stop  \n\t        ${0} start  \n\t        ;;  \n\t  *)  \n\t    echo \"Usage: /etc/init.d/redis {start|stop|restart|force-reload}\" >&2  \n\t        exit 1  \n\tesac  \n\t##############################  \n\t```\n8. 添加执行权限\n\n\t```\n\tchmod +x /etc/init.d/redis  \n\t```\n\t\n9. 设定开机启动服务\n\n\t```\n\tsudo chkconfig redis on    \n\t```\n10. 启动，停止redis\n\t\n\t```\n\tservice redis start    \n\tservice redis stop \n\t```\n\t\n11. 测试redis\n\n\t```\n\tredis-cli\n\t```\n12. 通过rdm连接\n\t\n\t![通过rdm连接](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-183804@2x.png)","toc":false,"date":"2017-10-10T10:20:26.000Z","_content":"\n在实际开发中有时候我们生产环境使用的服务器并不是centos7，这样造成我们安装软件需要使用更加通用的方式。\n\n1. 首先安装wget工具，下载redis包，我们在github下载release包，官网地址目前无法访问\n\t\n\t```\n\tyum install wget -y\n\twget https://github.com/antirez/redis/archive/4.0.2.tar.gz\n\t```\n<!-- more -->\n\n2. 解压&make&安装\n\t```\n\ttar zxvf 4.0.2.tar.gz \n\tcd redis-4.0.2/\n\tmake\n\tcd src && make install\n\t```\n\t![make && make install](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175039.png)\n\t执行完make install以后，会把redis-cli、redis-server放到/usr/local/bin/下边，由于服务器并没有把这个路径加到环境变量里边，因此我们需要多一步操作\n3. 修改环境变量，使redis命令生效\n\n\t```\n\tcd ~/\n\tvi .bashrc\n\t\n\t# 然后再文件末尾添加如下命令\n\tPATH=$PATH:/usr/local/bin/\n\t\n\t#保存后执行下边命令\n\tsource .bashrc\n\t```\n\t![修改环境变量](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175531.png)\n4. 复制配置文件到/etc 目录下\n\n\t```\n\tcp ~/redis-4.0.2/redis.conf /etc/\n\t```\n\t\n5. 建立用户与日志目录，建议为Redis单独建立一个用户，并新建data和日志文件夹\n\n\t```\n\tsudo useradd redis  \n\tsudo mkdir -p /var/lib/redis  \n\tsudo mkdir -p /var/log/redis  \n\tsudo chown redis.redis /var/lib/redis  \n\tsudo chown redis.redis /var/log/redis \n\t```\n6. 修改配置文件\n\t\n\t```\n\tvi /etc/redis.conf\n\t```\n\t\n\t修改绑定IP，让本机之外的IP也能够访问redis bind 0.0.0.0\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180325.png)\n\t\n\t修改启动模式为后台启动 daemonize yes\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180500.png)\n\t\n\t修改数据文件存储位置 dir /var/lib/redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180751.png)\n\t\n7. 配置init脚本\n\n\t```\n\tvi /etc/init.d/redis\n\t```\n\t\n\t```\n\t# chkconfig:   2345 90 10  \n  \n\t# description:  Redis is a persistent key-value database  \n\t  \n\t###########################  \n\tPATH=/usr/local/bin:/sbin:/usr/bin:/bin  \n\t     \n\tREDISPORT=6379  \n\tEXEC=/usr/local/bin/redis-server  \n\tREDIS_CLI=/usr/local/bin/redis-cli  \n\t     \n\tPIDFILE=/var/run/redis.pid  \n\tCONF=\"/etc/redis.conf\"  \n\t     \n\tcase \"$1\" in  \n\t    start)  \n\t        if [ -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE exists, process is already running or crashed\"  \n\t        else  \n\t                echo \"Starting Redis server...\"  \n\t                $EXEC $CONF  \n\t        fi  \n\t        if [ \"$?\"=\"0\" ]   \n\t        then  \n\t              echo \"Redis is running...\"  \n\t        fi  \n\t        ;;  \n\t    stop)  \n\t        if [ ! -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE does not exist, process is not running\"  \n\t        else  \n\t                PID=$(cat $PIDFILE)  \n\t                echo \"Stopping ...\"  \n\t                $REDIS_CLI -p $REDISPORT SHUTDOWN  \n\t                while [ -x ${PIDFILE} ]  \n\t               do  \n\t                    echo \"Waiting for Redis to shutdown ...\"  \n\t                    sleep 1  \n\t                done  \n\t                echo \"Redis stopped\"  \n\t        fi  \n\t        ;;  \n\t   restart|force-reload)  \n\t        ${0} stop  \n\t        ${0} start  \n\t        ;;  \n\t  *)  \n\t    echo \"Usage: /etc/init.d/redis {start|stop|restart|force-reload}\" >&2  \n\t        exit 1  \n\tesac  \n\t##############################  \n\t```\n8. 添加执行权限\n\n\t```\n\tchmod +x /etc/init.d/redis  \n\t```\n\t\n9. 设定开机启动服务\n\n\t```\n\tsudo chkconfig redis on    \n\t```\n10. 启动，停止redis\n\t\n\t```\n\tservice redis start    \n\tservice redis stop \n\t```\n\t\n11. 测试redis\n\n\t```\n\tredis-cli\n\t```\n12. 通过rdm连接\n\t\n\t![通过rdm连接](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-183804@2x.png)","source":"_posts/centos6.7 安装 redis并配置开机启动.md","raw":"---\ntitle: centos6.7 安装 redis并配置开机启动\ntags:\n  - redis\noriginContent: \"在实际开发中有时候我们生产环境使用的服务器并不是centos7，这样造成我们安装软件需要使用更加通用的方式。\\n\\n1. 首先安装wget工具，下载redis包，我们在github下载release包，官网地址目前无法访问\\n\\t\\n\\t```\\n\\tyum install wget -y\\n\\twget https://github.com/antirez/redis/archive/4.0.2.tar.gz\\n\\t```\\n<!-- more -->\\n\\n2. 解压&make&安装\\n\\t```\\n\\ttar zxvf 4.0.2.tar.gz \\n\\tcd redis-4.0.2/\\n\\tmake\\n\\tcd src && make install\\n\\t```\\n\\t![make && make install](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175039.png)\\n\\t执行完make install以后，会把redis-cli、redis-server放到/usr/local/bin/下边，由于服务器并没有把这个路径加到环境变量里边，因此我们需要多一步操作\\n3. 修改环境变量，使redis命令生效\\n\\n\\t```\\n\\tcd ~/\\n\\tvi .bashrc\\n\\t\\n\\t# 然后再文件末尾添加如下命令\\n\\tPATH=$PATH:/usr/local/bin/\\n\\t\\n\\t#保存后执行下边命令\\n\\tsource .bashrc\\n\\t```\\n\\t![修改环境变量](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175531.png)\\n4. 复制配置文件到/etc 目录下\\n\\n\\t```\\n\\tcp ~/redis-4.0.2/redis.conf /etc/\\n\\t```\\n\\t\\n5. 建立用户与日志目录，建议为Redis单独建立一个用户，并新建data和日志文件夹\\n\\n\\t```\\n\\tsudo useradd redis  \\n\\tsudo mkdir -p /var/lib/redis  \\n\\tsudo mkdir -p /var/log/redis  \\n\\tsudo chown redis.redis /var/lib/redis  \\n\\tsudo chown redis.redis /var/log/redis \\n\\t```\\n6. 修改配置文件\\n\\t\\n\\t```\\n\\tvi /etc/redis.conf\\n\\t```\\n\\t\\n\\t修改绑定IP，让本机之外的IP也能够访问redis bind 0.0.0.0\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180325.png)\\n\\t\\n\\t修改启动模式为后台启动 daemonize yes\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180500.png)\\n\\t\\n\\t修改数据文件存储位置 dir /var/lib/redis\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180751.png)\\n\\t\\n7. 配置init脚本\\n\\n\\t```\\n\\tvi /etc/init.d/redis\\n\\t```\\n\\t\\n\\t```\\n\\t# chkconfig:   2345 90 10  \\n  \\n\\t# description:  Redis is a persistent key-value database  \\n\\t  \\n\\t###########################  \\n\\tPATH=/usr/local/bin:/sbin:/usr/bin:/bin  \\n\\t     \\n\\tREDISPORT=6379  \\n\\tEXEC=/usr/local/bin/redis-server  \\n\\tREDIS_CLI=/usr/local/bin/redis-cli  \\n\\t     \\n\\tPIDFILE=/var/run/redis.pid  \\n\\tCONF=\\\"/etc/redis.conf\\\"  \\n\\t     \\n\\tcase \\\"$1\\\" in  \\n\\t    start)  \\n\\t        if [ -f $PIDFILE ]  \\n\\t        then  \\n\\t                echo \\\"$PIDFILE exists, process is already running or crashed\\\"  \\n\\t        else  \\n\\t                echo \\\"Starting Redis server...\\\"  \\n\\t                $EXEC $CONF  \\n\\t        fi  \\n\\t        if [ \\\"$?\\\"=\\\"0\\\" ]   \\n\\t        then  \\n\\t              echo \\\"Redis is running...\\\"  \\n\\t        fi  \\n\\t        ;;  \\n\\t    stop)  \\n\\t        if [ ! -f $PIDFILE ]  \\n\\t        then  \\n\\t                echo \\\"$PIDFILE does not exist, process is not running\\\"  \\n\\t        else  \\n\\t                PID=$(cat $PIDFILE)  \\n\\t                echo \\\"Stopping ...\\\"  \\n\\t                $REDIS_CLI -p $REDISPORT SHUTDOWN  \\n\\t                while [ -x ${PIDFILE} ]  \\n\\t               do  \\n\\t                    echo \\\"Waiting for Redis to shutdown ...\\\"  \\n\\t                    sleep 1  \\n\\t                done  \\n\\t                echo \\\"Redis stopped\\\"  \\n\\t        fi  \\n\\t        ;;  \\n\\t   restart|force-reload)  \\n\\t        ${0} stop  \\n\\t        ${0} start  \\n\\t        ;;  \\n\\t  *)  \\n\\t    echo \\\"Usage: /etc/init.d/redis {start|stop|restart|force-reload}\\\" >&2  \\n\\t        exit 1  \\n\\tesac  \\n\\t##############################  \\n\\t```\\n8. 添加执行权限\\n\\n\\t```\\n\\tchmod +x /etc/init.d/redis  \\n\\t```\\n\\t\\n9. 设定开机启动服务\\n\\n\\t```\\n\\tsudo chkconfig redis on    \\n\\t```\\n10. 启动，停止redis\\n\\t\\n\\t```\\n\\tservice redis start    \\n\\tservice redis stop \\n\\t```\\n\\t\\n11. 测试redis\\n\\n\\t```\\n\\tredis-cli\\n\\t```\\n12. 通过rdm连接\\n\\t\\n\\t![通过rdm连接](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-183804@2x.png)\"\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-10-10 18:20:26\n---\n\n在实际开发中有时候我们生产环境使用的服务器并不是centos7，这样造成我们安装软件需要使用更加通用的方式。\n\n1. 首先安装wget工具，下载redis包，我们在github下载release包，官网地址目前无法访问\n\t\n\t```\n\tyum install wget -y\n\twget https://github.com/antirez/redis/archive/4.0.2.tar.gz\n\t```\n<!-- more -->\n\n2. 解压&make&安装\n\t```\n\ttar zxvf 4.0.2.tar.gz \n\tcd redis-4.0.2/\n\tmake\n\tcd src && make install\n\t```\n\t![make && make install](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175039.png)\n\t执行完make install以后，会把redis-cli、redis-server放到/usr/local/bin/下边，由于服务器并没有把这个路径加到环境变量里边，因此我们需要多一步操作\n3. 修改环境变量，使redis命令生效\n\n\t```\n\tcd ~/\n\tvi .bashrc\n\t\n\t# 然后再文件末尾添加如下命令\n\tPATH=$PATH:/usr/local/bin/\n\t\n\t#保存后执行下边命令\n\tsource .bashrc\n\t```\n\t![修改环境变量](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-175531.png)\n4. 复制配置文件到/etc 目录下\n\n\t```\n\tcp ~/redis-4.0.2/redis.conf /etc/\n\t```\n\t\n5. 建立用户与日志目录，建议为Redis单独建立一个用户，并新建data和日志文件夹\n\n\t```\n\tsudo useradd redis  \n\tsudo mkdir -p /var/lib/redis  \n\tsudo mkdir -p /var/log/redis  \n\tsudo chown redis.redis /var/lib/redis  \n\tsudo chown redis.redis /var/log/redis \n\t```\n6. 修改配置文件\n\t\n\t```\n\tvi /etc/redis.conf\n\t```\n\t\n\t修改绑定IP，让本机之外的IP也能够访问redis bind 0.0.0.0\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180325.png)\n\t\n\t修改启动模式为后台启动 daemonize yes\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180500.png)\n\t\n\t修改数据文件存储位置 dir /var/lib/redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-180751.png)\n\t\n7. 配置init脚本\n\n\t```\n\tvi /etc/init.d/redis\n\t```\n\t\n\t```\n\t# chkconfig:   2345 90 10  \n  \n\t# description:  Redis is a persistent key-value database  \n\t  \n\t###########################  \n\tPATH=/usr/local/bin:/sbin:/usr/bin:/bin  \n\t     \n\tREDISPORT=6379  \n\tEXEC=/usr/local/bin/redis-server  \n\tREDIS_CLI=/usr/local/bin/redis-cli  \n\t     \n\tPIDFILE=/var/run/redis.pid  \n\tCONF=\"/etc/redis.conf\"  \n\t     \n\tcase \"$1\" in  \n\t    start)  \n\t        if [ -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE exists, process is already running or crashed\"  \n\t        else  \n\t                echo \"Starting Redis server...\"  \n\t                $EXEC $CONF  \n\t        fi  \n\t        if [ \"$?\"=\"0\" ]   \n\t        then  \n\t              echo \"Redis is running...\"  \n\t        fi  \n\t        ;;  \n\t    stop)  \n\t        if [ ! -f $PIDFILE ]  \n\t        then  \n\t                echo \"$PIDFILE does not exist, process is not running\"  \n\t        else  \n\t                PID=$(cat $PIDFILE)  \n\t                echo \"Stopping ...\"  \n\t                $REDIS_CLI -p $REDISPORT SHUTDOWN  \n\t                while [ -x ${PIDFILE} ]  \n\t               do  \n\t                    echo \"Waiting for Redis to shutdown ...\"  \n\t                    sleep 1  \n\t                done  \n\t                echo \"Redis stopped\"  \n\t        fi  \n\t        ;;  \n\t   restart|force-reload)  \n\t        ${0} stop  \n\t        ${0} start  \n\t        ;;  \n\t  *)  \n\t    echo \"Usage: /etc/init.d/redis {start|stop|restart|force-reload}\" >&2  \n\t        exit 1  \n\tesac  \n\t##############################  \n\t```\n8. 添加执行权限\n\n\t```\n\tchmod +x /etc/init.d/redis  \n\t```\n\t\n9. 设定开机启动服务\n\n\t```\n\tsudo chkconfig redis on    \n\t```\n10. 启动，停止redis\n\t\n\t```\n\tservice redis start    \n\tservice redis stop \n\t```\n\t\n11. 测试redis\n\n\t```\n\tredis-cli\n\t```\n12. 通过rdm连接\n\t\n\t![通过rdm连接](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-183804@2x.png)","slug":"centos6.7 安装 redis并配置开机启动","published":1,"updated":"2019-03-23T10:37:04.797Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eia001agyaveiygztrf"},{"title":"centos7 安装 redis并配置开机启动","originContent":"由于centos7系统已经出现很久，所以优先使用centos7来安装redis，这里做个记录。这里我使用的centos7是通过vagrant创建的一个虚拟机，能够让我最大限度的还原真实服务器环境。\n\n<!-- more -->\n\n1. 首先安装wget工具，下载自动更新ius包文件\n\n\t```\n\tyum install wget -y\n\twget -O setup.sh setup.ius.io\n\tsh ./setup.sh\n\t```\n\t\n\t[https://ius.io/GettingStarted/](https://ius.io/GettingStarted/)这个网站有几种更新yum包的方式，我们这里使用的是自动安装方式，命令也比手动的方式要简单好记，实际工作中我们记住切实可行的就行了。\n\n2. 安装完成以后执行\n\t\n\t```\n\tyum install redis -y\n\t```\n3. 启动redis并设置开机启动redis\n\n\t```\n\tsystemctl start redis\n\tsystemctl enable redis\n\t```\n4. 设置除了本机可访问，其他机器也可以访问\n\t\n\t```\n\twhereis redis\n\t```\n\t通过这个命令获取redis配置文件地址：\n\t![redis配置文件地址](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-171857.png)\n\t然后修改这个文件中NETWORK注释下的bind 127.0.0.1为bind 0.0.0.0\n\t![修改配置文件](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172037.png)\n5. 重启redis\n\n\t```\n\tsystemctl restart redis\n\t```\n6. 通过rdm连接服务器redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172353.png)\n7. 本机连接redis\n\n\t```\n\tredis-cli\n\t```\n\n后记：在centos7上安装软件总是那么顺手，但是在我们的生产环境由于历史原因服务器也许不是centos7，这时候安装就变得异常啰嗦与复杂，当然也许是由于我个人用的比较少，觉得麻烦而已。在centos6.7上我也尝试安装了一次，记录如下。","toc":false,"date":"2017-10-10T06:20:26.000Z","_content":"\n由于centos7系统已经出现很久，所以优先使用centos7来安装redis，这里做个记录。这里我使用的centos7是通过vagrant创建的一个虚拟机，能够让我最大限度的还原真实服务器环境。\n\n<!-- more -->\n\n1. 首先安装wget工具，下载自动更新ius包文件\n\n\t```\n\tyum install wget -y\n\twget -O setup.sh setup.ius.io\n\tsh ./setup.sh\n\t```\n\t\n\t[https://ius.io/GettingStarted/](https://ius.io/GettingStarted/)这个网站有几种更新yum包的方式，我们这里使用的是自动安装方式，命令也比手动的方式要简单好记，实际工作中我们记住切实可行的就行了。\n\n2. 安装完成以后执行\n\t\n\t```\n\tyum install redis -y\n\t```\n3. 启动redis并设置开机启动redis\n\n\t```\n\tsystemctl start redis\n\tsystemctl enable redis\n\t```\n4. 设置除了本机可访问，其他机器也可以访问\n\t\n\t```\n\twhereis redis\n\t```\n\t通过这个命令获取redis配置文件地址：\n\t![redis配置文件地址](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-171857.png)\n\t然后修改这个文件中NETWORK注释下的bind 127.0.0.1为bind 0.0.0.0\n\t![修改配置文件](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172037.png)\n5. 重启redis\n\n\t```\n\tsystemctl restart redis\n\t```\n6. 通过rdm连接服务器redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172353.png)\n7. 本机连接redis\n\n\t```\n\tredis-cli\n\t```\n\n后记：在centos7上安装软件总是那么顺手，但是在我们的生产环境由于历史原因服务器也许不是centos7，这时候安装就变得异常啰嗦与复杂，当然也许是由于我个人用的比较少，觉得麻烦而已。在centos6.7上我也尝试安装了一次，记录如下。","source":"_posts/centos7 安装 redis并配置开机启动.md","raw":"---\ntitle: centos7 安装 redis并配置开机启动\ntags:\n  - redis\noriginContent: \"由于centos7系统已经出现很久，所以优先使用centos7来安装redis，这里做个记录。这里我使用的centos7是通过vagrant创建的一个虚拟机，能够让我最大限度的还原真实服务器环境。\\n\\n<!-- more -->\\n\\n1. 首先安装wget工具，下载自动更新ius包文件\\n\\n\\t```\\n\\tyum install wget -y\\n\\twget -O setup.sh setup.ius.io\\n\\tsh ./setup.sh\\n\\t```\\n\\t\\n\\t[https://ius.io/GettingStarted/](https://ius.io/GettingStarted/)这个网站有几种更新yum包的方式，我们这里使用的是自动安装方式，命令也比手动的方式要简单好记，实际工作中我们记住切实可行的就行了。\\n\\n2. 安装完成以后执行\\n\\t\\n\\t```\\n\\tyum install redis -y\\n\\t```\\n3. 启动redis并设置开机启动redis\\n\\n\\t```\\n\\tsystemctl start redis\\n\\tsystemctl enable redis\\n\\t```\\n4. 设置除了本机可访问，其他机器也可以访问\\n\\t\\n\\t```\\n\\twhereis redis\\n\\t```\\n\\t通过这个命令获取redis配置文件地址：\\n\\t![redis配置文件地址](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-171857.png)\\n\\t然后修改这个文件中NETWORK注释下的bind 127.0.0.1为bind 0.0.0.0\\n\\t![修改配置文件](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172037.png)\\n5. 重启redis\\n\\n\\t```\\n\\tsystemctl restart redis\\n\\t```\\n6. 通过rdm连接服务器redis\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172353.png)\\n7. 本机连接redis\\n\\n\\t```\\n\\tredis-cli\\n\\t```\\n\\n后记：在centos7上安装软件总是那么顺手，但是在我们的生产环境由于历史原因服务器也许不是centos7，这时候安装就变得异常啰嗦与复杂，当然也许是由于我个人用的比较少，觉得麻烦而已。在centos6.7上我也尝试安装了一次，记录如下。\"\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-10-10 14:20:26\n---\n\n由于centos7系统已经出现很久，所以优先使用centos7来安装redis，这里做个记录。这里我使用的centos7是通过vagrant创建的一个虚拟机，能够让我最大限度的还原真实服务器环境。\n\n<!-- more -->\n\n1. 首先安装wget工具，下载自动更新ius包文件\n\n\t```\n\tyum install wget -y\n\twget -O setup.sh setup.ius.io\n\tsh ./setup.sh\n\t```\n\t\n\t[https://ius.io/GettingStarted/](https://ius.io/GettingStarted/)这个网站有几种更新yum包的方式，我们这里使用的是自动安装方式，命令也比手动的方式要简单好记，实际工作中我们记住切实可行的就行了。\n\n2. 安装完成以后执行\n\t\n\t```\n\tyum install redis -y\n\t```\n3. 启动redis并设置开机启动redis\n\n\t```\n\tsystemctl start redis\n\tsystemctl enable redis\n\t```\n4. 设置除了本机可访问，其他机器也可以访问\n\t\n\t```\n\twhereis redis\n\t```\n\t通过这个命令获取redis配置文件地址：\n\t![redis配置文件地址](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-171857.png)\n\t然后修改这个文件中NETWORK注释下的bind 127.0.0.1为bind 0.0.0.0\n\t![修改配置文件](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172037.png)\n5. 重启redis\n\n\t```\n\tsystemctl restart redis\n\t```\n6. 通过rdm连接服务器redis\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-172353.png)\n7. 本机连接redis\n\n\t```\n\tredis-cli\n\t```\n\n后记：在centos7上安装软件总是那么顺手，但是在我们的生产环境由于历史原因服务器也许不是centos7，这时候安装就变得异常啰嗦与复杂，当然也许是由于我个人用的比较少，觉得麻烦而已。在centos6.7上我也尝试安装了一次，记录如下。","slug":"centos7 安装 redis并配置开机启动","published":1,"updated":"2019-03-23T10:37:15.298Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eie001egyav6lpu06th"},{"title":"chown命令","originContent":"chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 \n\n<!-- more -->\n\n1. 命令格式：\n\n\t**chown [选项]... [所有者][:[组]] 文件...**\n\n2. 命令功能：\n\n\t通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。\n\n3. 命令参数：\n\n\t必要参数:\n\n　　　　-c 显示更改的部分的信息\n\n　　　　-f 忽略错误信息\n\n　　　　-h 修复符号链接\n\n　　　　**-R 处理指定目录以及其子目录下的所有文件**\n\n　　　　**-v 显示详细的处理信息**\n\n　　　　-deference 作用于符号链接的指向，而不是链接文件本身\n\n　　选择参数:\n\n　　　　--reference=<目录或文件> 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组\n\n　　　　--from=<当前用户：当前群组> 只有当前用户和群组跟指定的用户和群组相同时才进行改变\n\n　　　　--help 显示帮助信息\n\n　　　　--version 显示版本信息\n\n4．使用实例：\n\n　　**实例1：改变拥有者和群组**\n\n　　命令：\n\n　　chown mail:mail log2012.log\n\t\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root users 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown mail:mail log2012.log \n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例2：改变文件拥有者和群组**\n\n　　命令：\n\n　　　　chown root: log2012.log\n\n　　输出：　　　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown root: log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例3：改变文件群组**\n\n　　命令：\n\n　　　　chown :mail log2012.log\n\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown :mail log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n```\n说明：\n\n　　**实例4：改变指定目录以及其子目录下的所有文件的拥有者和群组 **\n\n　　命令：\n\n　　　　**chown -R *-v* root:mail test6**\n\n　　输出：　　\n\n```\n[root@localhost test]# ll\ndrwxr-xr-x 2 root users   4096 11-30 08:39 test6\n[root@localhost test]# chown -R -v root:mail test6\n“test6/log2014.log” 的所有者已更改为 root:mail\n“test6/linklog.log” 的所有者已更改为 root:mail\n“test6/log2015.log” 的所有者已更改为 root:mail\n“test6/log2013.log” 的所有者已更改为 root:mail\n“test6/log2012.log” 的所有者已保留为 root:mail\n“test6/log2017.log” 的所有者已更改为 root:mail\n“test6/log2016.log” 的所有者已更改为 root:mail\n“test6” 的所有者已更改为 root:mail\n[root@localhost test]# ll\ndrwxr-xr-x 2 root mail   4096 11-30 08:39 test6\n[root@localhost test]# cd test6\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root mail     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2017.log\n```\n\t\n说明：","toc":false,"date":"2017-10-09T05:20:26.000Z","_content":"\nchown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 \n\n<!-- more -->\n\n1. 命令格式：\n\n\t**chown [选项]... [所有者][:[组]] 文件...**\n\n2. 命令功能：\n\n\t通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。\n\n3. 命令参数：\n\n\t必要参数:\n\n　　　　-c 显示更改的部分的信息\n\n　　　　-f 忽略错误信息\n\n　　　　-h 修复符号链接\n\n　　　　**-R 处理指定目录以及其子目录下的所有文件**\n\n　　　　**-v 显示详细的处理信息**\n\n　　　　-deference 作用于符号链接的指向，而不是链接文件本身\n\n　　选择参数:\n\n　　　　--reference=<目录或文件> 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组\n\n　　　　--from=<当前用户：当前群组> 只有当前用户和群组跟指定的用户和群组相同时才进行改变\n\n　　　　--help 显示帮助信息\n\n　　　　--version 显示版本信息\n\n4．使用实例：\n\n　　**实例1：改变拥有者和群组**\n\n　　命令：\n\n　　chown mail:mail log2012.log\n\t\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root users 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown mail:mail log2012.log \n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例2：改变文件拥有者和群组**\n\n　　命令：\n\n　　　　chown root: log2012.log\n\n　　输出：　　　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown root: log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例3：改变文件群组**\n\n　　命令：\n\n　　　　chown :mail log2012.log\n\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown :mail log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n```\n说明：\n\n　　**实例4：改变指定目录以及其子目录下的所有文件的拥有者和群组 **\n\n　　命令：\n\n　　　　**chown -R *-v* root:mail test6**\n\n　　输出：　　\n\n```\n[root@localhost test]# ll\ndrwxr-xr-x 2 root users   4096 11-30 08:39 test6\n[root@localhost test]# chown -R -v root:mail test6\n“test6/log2014.log” 的所有者已更改为 root:mail\n“test6/linklog.log” 的所有者已更改为 root:mail\n“test6/log2015.log” 的所有者已更改为 root:mail\n“test6/log2013.log” 的所有者已更改为 root:mail\n“test6/log2012.log” 的所有者已保留为 root:mail\n“test6/log2017.log” 的所有者已更改为 root:mail\n“test6/log2016.log” 的所有者已更改为 root:mail\n“test6” 的所有者已更改为 root:mail\n[root@localhost test]# ll\ndrwxr-xr-x 2 root mail   4096 11-30 08:39 test6\n[root@localhost test]# cd test6\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root mail     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2017.log\n```\n\t\n说明：","source":"_posts/chown命令.md","raw":"---\ntitle: chown命令\ntags:\n  - linux\noriginContent: \"chown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 \\n\\n<!-- more -->\\n\\n1. 命令格式：\\n\\n\\t**chown [选项]... [所有者][:[组]] 文件...**\\n\\n2. 命令功能：\\n\\n\\t通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。\\n\\n3. 命令参数：\\n\\n\\t必要参数:\\n\\n　　　　-c 显示更改的部分的信息\\n\\n　　　　-f 忽略错误信息\\n\\n　　　　-h 修复符号链接\\n\\n　　　　**-R 处理指定目录以及其子目录下的所有文件**\\n\\n　　　　**-v 显示详细的处理信息**\\n\\n　　　　-deference 作用于符号链接的指向，而不是链接文件本身\\n\\n　　选择参数:\\n\\n　　　　--reference=<目录或文件> 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组\\n\\n　　　　--from=<当前用户：当前群组> 只有当前用户和群组跟指定的用户和群组相同时才进行改变\\n\\n　　　　--help 显示帮助信息\\n\\n　　　　--version 显示版本信息\\n\\n4．使用实例：\\n\\n　　**实例1：改变拥有者和群组**\\n\\n　　命令：\\n\\n　　chown mail:mail log2012.log\\n\\t\\n　　输出：　　\\n\\n```\\n[root@localhost test6]# ll\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 root users 302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n[root@localhost test6]# chown mail:mail log2012.log \\n[root@localhost test6]# ll\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n[root@localhost test6]#\\n```\\n说明：\\n\\n　　**实例2：改变文件拥有者和群组**\\n\\n　　命令：\\n\\n　　　　chown root: log2012.log\\n\\n　　输出：　　　　\\n\\n```\\n[root@localhost test6]# ll\\n总计 604\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n[root@localhost test6]# chown root: log2012.log \\n[root@localhost test6]# ll\\n总计 604\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n[root@localhost test6]#\\n```\\n说明：\\n\\n　　**实例3：改变文件群组**\\n\\n　　命令：\\n\\n　　　　chown :mail log2012.log\\n\\n　　输出：　　\\n\\n```\\n[root@localhost test6]# ll\\n总计 604\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n[root@localhost test6]# chown :mail log2012.log \\n[root@localhost test6]# ll\\n总计 604\\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 root mail  302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\\n```\\n说明：\\n\\n　　**实例4：改变指定目录以及其子目录下的所有文件的拥有者和群组 **\\n\\n　　命令：\\n\\n　　　　**chown -R *-v* root:mail test6**\\n\\n　　输出：　　\\n\\n```\\n[root@localhost test]# ll\\ndrwxr-xr-x 2 root users   4096 11-30 08:39 test6\\n[root@localhost test]# chown -R -v root:mail test6\\n“test6/log2014.log” 的所有者已更改为 root:mail\\n“test6/linklog.log” 的所有者已更改为 root:mail\\n“test6/log2015.log” 的所有者已更改为 root:mail\\n“test6/log2013.log” 的所有者已更改为 root:mail\\n“test6/log2012.log” 的所有者已保留为 root:mail\\n“test6/log2017.log” 的所有者已更改为 root:mail\\n“test6/log2016.log” 的所有者已更改为 root:mail\\n“test6” 的所有者已更改为 root:mail\\n[root@localhost test]# ll\\ndrwxr-xr-x 2 root mail   4096 11-30 08:39 test6\\n[root@localhost test]# cd test6\\n[root@localhost test6]# ll\\n总计 604\\n---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log\\n---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log\\n-rw-r--r-- 1 root mail     61 11-30 08:39 log2013.log\\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2014.log\\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2015.log\\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2016.log\\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2017.log\\n```\\n\\t\\n说明：\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-10-09 13:20:26\n---\n\nchown将指定文件的拥有者改为指定的用户或组，用户可以是用户名或者用户ID；组可以是组名或者组ID；文件是以空格分开的要改变权限的文件列表，支持通配符。系统管理员经常使用chown命令，在将文件拷贝到另一个用户的名录下之后，让用户拥有使用该文件的权限。 \n\n<!-- more -->\n\n1. 命令格式：\n\n\t**chown [选项]... [所有者][:[组]] 文件...**\n\n2. 命令功能：\n\n\t通过chown改变文件的拥有者和群组。在更改文件的所有者或所属群组时，可以使用用户名称和用户识别码设置。普通用户不能将自己的文件改变成其他的拥有者。其操作权限一般为管理员。\n\n3. 命令参数：\n\n\t必要参数:\n\n　　　　-c 显示更改的部分的信息\n\n　　　　-f 忽略错误信息\n\n　　　　-h 修复符号链接\n\n　　　　**-R 处理指定目录以及其子目录下的所有文件**\n\n　　　　**-v 显示详细的处理信息**\n\n　　　　-deference 作用于符号链接的指向，而不是链接文件本身\n\n　　选择参数:\n\n　　　　--reference=<目录或文件> 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组\n\n　　　　--from=<当前用户：当前群组> 只有当前用户和群组跟指定的用户和群组相同时才进行改变\n\n　　　　--help 显示帮助信息\n\n　　　　--version 显示版本信息\n\n4．使用实例：\n\n　　**实例1：改变拥有者和群组**\n\n　　命令：\n\n　　chown mail:mail log2012.log\n\t\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root users 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown mail:mail log2012.log \n[root@localhost test6]# ll\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例2：改变文件拥有者和群组**\n\n　　命令：\n\n　　　　chown root: log2012.log\n\n　　输出：　　　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 mail mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown root: log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]#\n```\n说明：\n\n　　**实例3：改变文件群组**\n\n　　命令：\n\n　　　　chown :mail log2012.log\n\n　　输出：　　\n\n```\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root root  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n[root@localhost test6]# chown :mail log2012.log \n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root users 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail  302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root users     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root users      0 11-30 08:39 log2017.log\n```\n说明：\n\n　　**实例4：改变指定目录以及其子目录下的所有文件的拥有者和群组 **\n\n　　命令：\n\n　　　　**chown -R *-v* root:mail test6**\n\n　　输出：　　\n\n```\n[root@localhost test]# ll\ndrwxr-xr-x 2 root users   4096 11-30 08:39 test6\n[root@localhost test]# chown -R -v root:mail test6\n“test6/log2014.log” 的所有者已更改为 root:mail\n“test6/linklog.log” 的所有者已更改为 root:mail\n“test6/log2015.log” 的所有者已更改为 root:mail\n“test6/log2013.log” 的所有者已更改为 root:mail\n“test6/log2012.log” 的所有者已保留为 root:mail\n“test6/log2017.log” 的所有者已更改为 root:mail\n“test6/log2016.log” 的所有者已更改为 root:mail\n“test6” 的所有者已更改为 root:mail\n[root@localhost test]# ll\ndrwxr-xr-x 2 root mail   4096 11-30 08:39 test6\n[root@localhost test]# cd test6\n[root@localhost test6]# ll\n总计 604\n---xr--r-- 1 root mail 302108 11-30 08:39 linklog.log\n---xr--r-- 1 root mail 302108 11-30 08:39 log2012.log\n-rw-r--r-- 1 root mail     61 11-30 08:39 log2013.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2014.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2015.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2016.log\n-rw-r--r-- 1 root mail      0 11-30 08:39 log2017.log\n```\n\t\n说明：","slug":"chown命令","published":1,"updated":"2019-03-23T10:38:30.902Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eij001hgyavene3dgre"},{"title":"free命令","originContent":"free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。\n\n## 语法\n\n```\nfree(选项)\n```\n\n<!-- more -->\n\n## 选项\n\n```\n-b：以Byte为单位显示内存使用情况；\n-k：以KB为单位显示内存使用情况；\n-m：以MB为单位显示内存使用情况；\n-o：不显示缓冲区调节列；\n-s<间隔秒数>：持续观察内存使用状况；\n-t：显示内存总和列；\n-V：显示版本信息。\n```\n\n## 实例\n\n```\nfree -m\n             total       used       free     shared    buffers     cached\nMem:          2016       1973         42          0        163       1497\n-/+ buffers/cache:        312       1703\nSwap:         4094          0       4094\n```\n\n### 第一部分Mem行解释：\n```\ntotal：内存总数；\nused：已经使用的内存数；\nfree：空闲的内存数；\nshared：当前已经废弃不用；\nbuffers Buffer：缓存内存数；\ncached Page：缓存内存数。\n```\n\n关系：total = used + free\n\n### 第二部分(-/+ buffers/cache)解释:\n\n```\n(-buffers/cache) used内存数：第一部分Mem行中的 used – buffers – cached\n(+buffers/cache) free内存数: 第一部分Mem行中的 free + buffers + cached\n```\n\n可见-buffers/cache反映的是被程序实实在在吃掉的内存，而+buffers/cache反映的是可以挪用的内存总数。\n\n第三部分是指交换分区。","toc":false,"date":"2018-01-24T03:03:06.000Z","_content":"\nfree命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。\n\n## 语法\n\n```\nfree(选项)\n```\n\n<!-- more -->\n\n## 选项\n\n```\n-b：以Byte为单位显示内存使用情况；\n-k：以KB为单位显示内存使用情况；\n-m：以MB为单位显示内存使用情况；\n-o：不显示缓冲区调节列；\n-s<间隔秒数>：持续观察内存使用状况；\n-t：显示内存总和列；\n-V：显示版本信息。\n```\n\n## 实例\n\n```\nfree -m\n             total       used       free     shared    buffers     cached\nMem:          2016       1973         42          0        163       1497\n-/+ buffers/cache:        312       1703\nSwap:         4094          0       4094\n```\n\n### 第一部分Mem行解释：\n```\ntotal：内存总数；\nused：已经使用的内存数；\nfree：空闲的内存数；\nshared：当前已经废弃不用；\nbuffers Buffer：缓存内存数；\ncached Page：缓存内存数。\n```\n\n关系：total = used + free\n\n### 第二部分(-/+ buffers/cache)解释:\n\n```\n(-buffers/cache) used内存数：第一部分Mem行中的 used – buffers – cached\n(+buffers/cache) free内存数: 第一部分Mem行中的 free + buffers + cached\n```\n\n可见-buffers/cache反映的是被程序实实在在吃掉的内存，而+buffers/cache反映的是可以挪用的内存总数。\n\n第三部分是指交换分区。","source":"_posts/free命令.md","raw":"---\ntitle: free命令\ntags:\n  - linux\noriginContent: |-\n  free命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。\n\n  ## 语法\n\n  ```\n  free(选项)\n  ```\n\n  <!-- more -->\n\n  ## 选项\n\n  ```\n  -b：以Byte为单位显示内存使用情况；\n  -k：以KB为单位显示内存使用情况；\n  -m：以MB为单位显示内存使用情况；\n  -o：不显示缓冲区调节列；\n  -s<间隔秒数>：持续观察内存使用状况；\n  -t：显示内存总和列；\n  -V：显示版本信息。\n  ```\n\n  ## 实例\n\n  ```\n  free -m\n               total       used       free     shared    buffers     cached\n  Mem:          2016       1973         42          0        163       1497\n  -/+ buffers/cache:        312       1703\n  Swap:         4094          0       4094\n  ```\n\n  ### 第一部分Mem行解释：\n  ```\n  total：内存总数；\n  used：已经使用的内存数；\n  free：空闲的内存数；\n  shared：当前已经废弃不用；\n  buffers Buffer：缓存内存数；\n  cached Page：缓存内存数。\n  ```\n\n  关系：total = used + free\n\n  ### 第二部分(-/+ buffers/cache)解释:\n\n  ```\n  (-buffers/cache) used内存数：第一部分Mem行中的 used – buffers – cached\n  (+buffers/cache) free内存数: 第一部分Mem行中的 free + buffers + cached\n  ```\n\n  可见-buffers/cache反映的是被程序实实在在吃掉的内存，而+buffers/cache反映的是可以挪用的内存总数。\n\n  第三部分是指交换分区。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-24 11:03:06\n---\n\nfree命令可以显示当前系统未使用的和已使用的内存数目，还可以显示被内核使用的内存缓冲区。\n\n## 语法\n\n```\nfree(选项)\n```\n\n<!-- more -->\n\n## 选项\n\n```\n-b：以Byte为单位显示内存使用情况；\n-k：以KB为单位显示内存使用情况；\n-m：以MB为单位显示内存使用情况；\n-o：不显示缓冲区调节列；\n-s<间隔秒数>：持续观察内存使用状况；\n-t：显示内存总和列；\n-V：显示版本信息。\n```\n\n## 实例\n\n```\nfree -m\n             total       used       free     shared    buffers     cached\nMem:          2016       1973         42          0        163       1497\n-/+ buffers/cache:        312       1703\nSwap:         4094          0       4094\n```\n\n### 第一部分Mem行解释：\n```\ntotal：内存总数；\nused：已经使用的内存数；\nfree：空闲的内存数；\nshared：当前已经废弃不用；\nbuffers Buffer：缓存内存数；\ncached Page：缓存内存数。\n```\n\n关系：total = used + free\n\n### 第二部分(-/+ buffers/cache)解释:\n\n```\n(-buffers/cache) used内存数：第一部分Mem行中的 used – buffers – cached\n(+buffers/cache) free内存数: 第一部分Mem行中的 free + buffers + cached\n```\n\n可见-buffers/cache反映的是被程序实实在在吃掉的内存，而+buffers/cache反映的是可以挪用的内存总数。\n\n第三部分是指交换分区。","slug":"free命令","published":1,"updated":"2019-03-23T10:23:22.903Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eio001lgyavwr7ydlkb"},{"title":"dnsmasq (简体中文)","originContent":"Dnsmasq 提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq 可以用于为局域网电脑分配内网ip地址和提供路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于个人用户或少于50台主机的网络。此外它还自带了一个 PXE 服务器。\n<!-- more -->\n## 安装\n从官方仓库中安装 dnsmasq。\n## 配置\n编辑 dnsmasq 的配置文件 /etc/dnsmasq.conf 。这个文件包含大量的选项注释。\n\n```\n警告: dnsmasq 默认启用其 DNS 服务器。如果不需要，必须明确地将其 DNS 端口设置为 0 禁用它：\n----\n/etc/dnsmasq.conf\n----\nport=0\n```\n\n```\n提示： 查看配置文件语法是否正确，可执行下列命令：\n$ dnsmasq --test\n```\n## DNS 缓存设置\n要在单台电脑上以守护进程方式启动dnsmasq做DNS缓存服务器，编辑/etc/dnsmasq.conf，添加监听地址：\n\n```\nlisten-address=127.0.0.1\n```\n\n如果用此主机为局域网提供默认 DNS，请用为该主机绑定固定 IP 地址，设置：\n\n```\nlisten-address=192.168.x.x\n```\n这种情况建议配置静态IP\n\n多个ip地址设置:\n\n```\nlisten-address=127.0.0.1,192.168.x.x \n```\n\n### DNS 地址文件\n在配置好dnsmasq后，你需要编辑/etc/resolv.conf让DHCP客户端首先将本地地址(localhost)加入 DNS 文件(/etc/resolv.conf)，然后再通过其他DNS服务器解析地址。配置好DHCP客户端后需要重新启动网络来使设置生效\n\n#### resolv.conf\n一种选择是一个纯粹的 resolv.conf 配置。要做到这一点，才使第一个域名服务器在/etc/resolv.conf 中指向localhost：\n\n```\n/etc/resolv.conf\n\nnameserver 127.0.0.1\n# External nameservers\n...\n```\n\n现在，DNS查询将首先解析dnsmasq，只检查外部的服务器如果DNSMasq无法解析查询. dhcpcd, 不幸的是，往往默认覆盖 /etc/resolv.conf, 所以如果你使用DHCP，这里有一个好主意来保护 /etc/resolv.conf,要做到这一点，追加 nohook resolv.conf到dhcpcd的配置文件：\n\n```\n/etc/dhcpcd.conf\n...\nnohook resolv.conf\n```\n\n也可以保护您的resolv.conf不被修改：\n\n```\n# chattr +i /etc/resolv.conf\n```\n\n##### 三个以上域名服务器\nLinux 处理 DNS 请求时有个限制，在 resolv.conf 中最多只能配置三个域名服务器（nameserver）。作为一种变通方法,可以在 resolv.conf 文件中只保留 localhost 作为域名服务器，然后为外部域名服务器另外创建 resolv-file 文件。首先，为 dnsmasq 新建一个域名解析文件：\n\n```\n/etc/resolv.dnsmasq.conf\n# Google's nameservers, for example\nnameserver 8.8.8.8\nnameserver 8.8.4.4\n```\n然后编辑 /etc/dnsmasq.conf 让 dnsmasq 使用新创建的域名解析文件：\n\n```\n/etc/dnsmasq.conf\n...\nresolv-file=/etc/resolv.dnsmasq.conf\n...\n```\n\n#### 使用dhcpcd\ndhcpcd 可以是通过创建（或编辑）/etc/resolv.conf.head文件或 /etc/resolv.conf.tail文件来指定dns服务器，使/etc/resolv.conf不会被每次都被dhcpcd重写\n\n```\necho \"nameserver 127.0.0.1\" > /etc/resolv.conf.head #设置dns服务器为127.0.0.1\n```\n\n#### 使用dhclient\n要使用 dhclient， 取消 /etc/dhclient.conf 文件中如下行的注释：\n\n```\nprepend domain-name-servers 127.0.0.1;\n```\n\n### 使用NetworkManager\nNetworkManager 可以靠自身配置文件的设置项启动 dnsmasq 。在 NetworkManager.conf 文件的 [main] 节段添加 dns=dnsmasq 配置语句，然后禁用由 systemd 启动的 dnsmasq.service:\n\n```\n/etc/NetworkManager/NetworkManager.conf\n[main]\nplugins=keyfile\ndns=dnsmasq\n```\n\n可以在 /etc/NetworkManager/dnsmasq.d/ 目录下为 dnsmasq 创建自定义配置文件。例如，调整 DNS 缓存大小（保存在内存中）：\n\n```\n/etc/NetworkManager/dnsmasq.d/cache\ncache-size=1000\n```\n\ndnsmasq 被 NetworkManager 启动后，此目录下配置文件中的配置将取代默认配置。\n\n```\n提示： 这种方法可以让你启用特定域名的自定义DNS设置。例如: \nserver=/example1.com/exemple2.com/xx.xxx.xxx.x \n改变第一个DNS地址，浏览以下网站example1.com, example2.com\n使用xx.xxx.xxx.xx。\nThis method is preferred to a global DNS configuration \nwhen using particular DNS nameservers which lack of speed, \nstability, privacy and security.\n```\n#### IPv6\n启用 dnsmasq 在 NetworkManager 可能会中断仅持IPv6的DNS查询 (例如 dig -6 [hostname]) 否则将工作。 为了解决这个问题，创建以下文件将配置 dnsmasq 总是监听IPv6的loopback：\n\n```\n/etc/NetworkManager/dnsmasq.d/ipv6_listen.conf\nlisten-address=::1\n```\n\n此外， dnsmasq不优先考虑上游IPv6的DNS。不幸的是NetworkManager已不这样做 (Ubuntu Bug)。 一种解决方法是将禁用IPv4 DNS的NetworkManager的配置，假设存在。\n#### 其他方式\n另一种选择是在NetworkManagers“设置（通常通过右键单击小程序）和手动输入设置。设置将取决于前端中使用的类型;这个过程通常涉及右击小程序，编辑（或创建）一个配置文件，然后选择DHCP类型为“自动（指定地址）。”DNS地址将需要输入，通常以这种形式：127.0.0.1, DNS-server-one, ....\n\n## DHCP 服务器设置\ndnsmasq默认关闭DHCP功能，如果该主机需要为局域网中的其他设备提供IP和路由，应该对dnsmasq 配置文件(/etc/dnsmasq.conf)必要的配置如下：\n\n```\n# Only listen to routers' LAN NIC.  Doing so opens up tcp/udp port 53 to\n# localhost and udp port 67 to world:\ninterface=<LAN-NIC>\n\n# dnsmasq will open tcp/udp port 53 and udp port 67 to world to help with\n# dynamic interfaces (assigning dynamic ips). Dnsmasq will discard world\n# requests to them, but the paranoid might like to close them and let the \n# kernel handle them:\nbind-interfaces\n\n# Dynamic range of IPs to make available to LAN pc\ndhcp-range=192.168.111.50,192.168.111.100,12h\n\n# If you’d like to have dnsmasq assign static IPs, bind the LAN computer's\n# NIC MAC address:\ndhcp-host=aa:bb:cc:dd:ee:ff,192.168.111.50\n```\n## 启动守护进程\n设置为开机启动：\n\n```\n# systemctl enable dnsmasq\n```\n\n立即启动 dnsmashq：\n\n```\n# systemctl start dnsmasq\n```\n\n查看dnsmasq是否启动正常，查看系统日志：\n\n```\n# journalctl -u dnsmasq\n```\n需要重启网络服务以使 DHCP 客户端重建一个新的 /etc/resolv.conf。\n## 测试\n### DNS 缓存\n要测试查询速度，请访问一个 dnsmasq 启动后没有访问过的网站，执行 (dig (位于 dnsutils[broken link: replaced by bind-tools] 软件包):\n\n```\n$ dig archlinux.org | grep \"Query time\"\n```\n再次运行命令，因为使用了缓存，查询时间应该大大缩短。\n### DHCP 服务器\n从一个连接到使用了 dnsmasq 的计算机的计算机，配置它使用 DHCP 自动获取 IP 地址，然后尝试连接到你平时使用的网络。\n## 小技巧\n### 避免OpenDNS重定向Google请求\n要避免 OpenDNS 重定向所有 Google 请求到他们自己的搜索服务器，添加以下内容到 /etc/dnsmasq.conf：\n\n```\nserver=/www.google.com/X.X.X.X\n```\n\n用你的 ISP 的 DNS 服务器/路由器的 IP 替代 X.X.X.X 。\n\n### 查看租约\n```\ncat /var/lib/misc/dnsmasq.leases\n```\n### 添加自定义域\n它可以将一个自定义域添加到主机中的（本地）网络：\n\n```\nlocal=/home.lan/\ndomain=home.lan\n```\n\n在这个例子中可以ping主机/设备 (例如:您的主机文件中的定义) hostname.home.lan.\n\n取消扩展主机添加自定义域的主机条目：存在\n\n```\nexpand-hosts\n```\n\n如果没有这个设置，你必须域添加到/etc/hosts中的条目。","toc":false,"date":"2018-01-06T22:17:10.000Z","_content":"\nDnsmasq 提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq 可以用于为局域网电脑分配内网ip地址和提供路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于个人用户或少于50台主机的网络。此外它还自带了一个 PXE 服务器。\n<!-- more -->\n## 安装\n从官方仓库中安装 dnsmasq。\n## 配置\n编辑 dnsmasq 的配置文件 /etc/dnsmasq.conf 。这个文件包含大量的选项注释。\n\n```\n警告: dnsmasq 默认启用其 DNS 服务器。如果不需要，必须明确地将其 DNS 端口设置为 0 禁用它：\n----\n/etc/dnsmasq.conf\n----\nport=0\n```\n\n```\n提示： 查看配置文件语法是否正确，可执行下列命令：\n$ dnsmasq --test\n```\n## DNS 缓存设置\n要在单台电脑上以守护进程方式启动dnsmasq做DNS缓存服务器，编辑/etc/dnsmasq.conf，添加监听地址：\n\n```\nlisten-address=127.0.0.1\n```\n\n如果用此主机为局域网提供默认 DNS，请用为该主机绑定固定 IP 地址，设置：\n\n```\nlisten-address=192.168.x.x\n```\n这种情况建议配置静态IP\n\n多个ip地址设置:\n\n```\nlisten-address=127.0.0.1,192.168.x.x \n```\n\n### DNS 地址文件\n在配置好dnsmasq后，你需要编辑/etc/resolv.conf让DHCP客户端首先将本地地址(localhost)加入 DNS 文件(/etc/resolv.conf)，然后再通过其他DNS服务器解析地址。配置好DHCP客户端后需要重新启动网络来使设置生效\n\n#### resolv.conf\n一种选择是一个纯粹的 resolv.conf 配置。要做到这一点，才使第一个域名服务器在/etc/resolv.conf 中指向localhost：\n\n```\n/etc/resolv.conf\n\nnameserver 127.0.0.1\n# External nameservers\n...\n```\n\n现在，DNS查询将首先解析dnsmasq，只检查外部的服务器如果DNSMasq无法解析查询. dhcpcd, 不幸的是，往往默认覆盖 /etc/resolv.conf, 所以如果你使用DHCP，这里有一个好主意来保护 /etc/resolv.conf,要做到这一点，追加 nohook resolv.conf到dhcpcd的配置文件：\n\n```\n/etc/dhcpcd.conf\n...\nnohook resolv.conf\n```\n\n也可以保护您的resolv.conf不被修改：\n\n```\n# chattr +i /etc/resolv.conf\n```\n\n##### 三个以上域名服务器\nLinux 处理 DNS 请求时有个限制，在 resolv.conf 中最多只能配置三个域名服务器（nameserver）。作为一种变通方法,可以在 resolv.conf 文件中只保留 localhost 作为域名服务器，然后为外部域名服务器另外创建 resolv-file 文件。首先，为 dnsmasq 新建一个域名解析文件：\n\n```\n/etc/resolv.dnsmasq.conf\n# Google's nameservers, for example\nnameserver 8.8.8.8\nnameserver 8.8.4.4\n```\n然后编辑 /etc/dnsmasq.conf 让 dnsmasq 使用新创建的域名解析文件：\n\n```\n/etc/dnsmasq.conf\n...\nresolv-file=/etc/resolv.dnsmasq.conf\n...\n```\n\n#### 使用dhcpcd\ndhcpcd 可以是通过创建（或编辑）/etc/resolv.conf.head文件或 /etc/resolv.conf.tail文件来指定dns服务器，使/etc/resolv.conf不会被每次都被dhcpcd重写\n\n```\necho \"nameserver 127.0.0.1\" > /etc/resolv.conf.head #设置dns服务器为127.0.0.1\n```\n\n#### 使用dhclient\n要使用 dhclient， 取消 /etc/dhclient.conf 文件中如下行的注释：\n\n```\nprepend domain-name-servers 127.0.0.1;\n```\n\n### 使用NetworkManager\nNetworkManager 可以靠自身配置文件的设置项启动 dnsmasq 。在 NetworkManager.conf 文件的 [main] 节段添加 dns=dnsmasq 配置语句，然后禁用由 systemd 启动的 dnsmasq.service:\n\n```\n/etc/NetworkManager/NetworkManager.conf\n[main]\nplugins=keyfile\ndns=dnsmasq\n```\n\n可以在 /etc/NetworkManager/dnsmasq.d/ 目录下为 dnsmasq 创建自定义配置文件。例如，调整 DNS 缓存大小（保存在内存中）：\n\n```\n/etc/NetworkManager/dnsmasq.d/cache\ncache-size=1000\n```\n\ndnsmasq 被 NetworkManager 启动后，此目录下配置文件中的配置将取代默认配置。\n\n```\n提示： 这种方法可以让你启用特定域名的自定义DNS设置。例如: \nserver=/example1.com/exemple2.com/xx.xxx.xxx.x \n改变第一个DNS地址，浏览以下网站example1.com, example2.com\n使用xx.xxx.xxx.xx。\nThis method is preferred to a global DNS configuration \nwhen using particular DNS nameservers which lack of speed, \nstability, privacy and security.\n```\n#### IPv6\n启用 dnsmasq 在 NetworkManager 可能会中断仅持IPv6的DNS查询 (例如 dig -6 [hostname]) 否则将工作。 为了解决这个问题，创建以下文件将配置 dnsmasq 总是监听IPv6的loopback：\n\n```\n/etc/NetworkManager/dnsmasq.d/ipv6_listen.conf\nlisten-address=::1\n```\n\n此外， dnsmasq不优先考虑上游IPv6的DNS。不幸的是NetworkManager已不这样做 (Ubuntu Bug)。 一种解决方法是将禁用IPv4 DNS的NetworkManager的配置，假设存在。\n#### 其他方式\n另一种选择是在NetworkManagers“设置（通常通过右键单击小程序）和手动输入设置。设置将取决于前端中使用的类型;这个过程通常涉及右击小程序，编辑（或创建）一个配置文件，然后选择DHCP类型为“自动（指定地址）。”DNS地址将需要输入，通常以这种形式：127.0.0.1, DNS-server-one, ....\n\n## DHCP 服务器设置\ndnsmasq默认关闭DHCP功能，如果该主机需要为局域网中的其他设备提供IP和路由，应该对dnsmasq 配置文件(/etc/dnsmasq.conf)必要的配置如下：\n\n```\n# Only listen to routers' LAN NIC.  Doing so opens up tcp/udp port 53 to\n# localhost and udp port 67 to world:\ninterface=<LAN-NIC>\n\n# dnsmasq will open tcp/udp port 53 and udp port 67 to world to help with\n# dynamic interfaces (assigning dynamic ips). Dnsmasq will discard world\n# requests to them, but the paranoid might like to close them and let the \n# kernel handle them:\nbind-interfaces\n\n# Dynamic range of IPs to make available to LAN pc\ndhcp-range=192.168.111.50,192.168.111.100,12h\n\n# If you’d like to have dnsmasq assign static IPs, bind the LAN computer's\n# NIC MAC address:\ndhcp-host=aa:bb:cc:dd:ee:ff,192.168.111.50\n```\n## 启动守护进程\n设置为开机启动：\n\n```\n# systemctl enable dnsmasq\n```\n\n立即启动 dnsmashq：\n\n```\n# systemctl start dnsmasq\n```\n\n查看dnsmasq是否启动正常，查看系统日志：\n\n```\n# journalctl -u dnsmasq\n```\n需要重启网络服务以使 DHCP 客户端重建一个新的 /etc/resolv.conf。\n## 测试\n### DNS 缓存\n要测试查询速度，请访问一个 dnsmasq 启动后没有访问过的网站，执行 (dig (位于 dnsutils[broken link: replaced by bind-tools] 软件包):\n\n```\n$ dig archlinux.org | grep \"Query time\"\n```\n再次运行命令，因为使用了缓存，查询时间应该大大缩短。\n### DHCP 服务器\n从一个连接到使用了 dnsmasq 的计算机的计算机，配置它使用 DHCP 自动获取 IP 地址，然后尝试连接到你平时使用的网络。\n## 小技巧\n### 避免OpenDNS重定向Google请求\n要避免 OpenDNS 重定向所有 Google 请求到他们自己的搜索服务器，添加以下内容到 /etc/dnsmasq.conf：\n\n```\nserver=/www.google.com/X.X.X.X\n```\n\n用你的 ISP 的 DNS 服务器/路由器的 IP 替代 X.X.X.X 。\n\n### 查看租约\n```\ncat /var/lib/misc/dnsmasq.leases\n```\n### 添加自定义域\n它可以将一个自定义域添加到主机中的（本地）网络：\n\n```\nlocal=/home.lan/\ndomain=home.lan\n```\n\n在这个例子中可以ping主机/设备 (例如:您的主机文件中的定义) hostname.home.lan.\n\n取消扩展主机添加自定义域的主机条目：存在\n\n```\nexpand-hosts\n```\n\n如果没有这个设置，你必须域添加到/etc/hosts中的条目。","source":"_posts/dnsmasq官方文档.md","raw":"---\ntitle: dnsmasq (简体中文)\ntags:\n  - 运维\noriginContent: >-\n  Dnsmasq 提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS\n  请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq\n  可以用于为局域网电脑分配内网ip地址和提供路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于个人用户或少于50台主机的网络。此外它还自带了一个\n  PXE 服务器。\n\n  <!-- more -->\n\n  ## 安装\n\n  从官方仓库中安装 dnsmasq。\n\n  ## 配置\n\n  编辑 dnsmasq 的配置文件 /etc/dnsmasq.conf 。这个文件包含大量的选项注释。\n\n\n  ```\n\n  警告: dnsmasq 默认启用其 DNS 服务器。如果不需要，必须明确地将其 DNS 端口设置为 0 禁用它：\n\n  ----\n\n  /etc/dnsmasq.conf\n\n  ----\n\n  port=0\n\n  ```\n\n\n  ```\n\n  提示： 查看配置文件语法是否正确，可执行下列命令：\n\n  $ dnsmasq --test\n\n  ```\n\n  ## DNS 缓存设置\n\n  要在单台电脑上以守护进程方式启动dnsmasq做DNS缓存服务器，编辑/etc/dnsmasq.conf，添加监听地址：\n\n\n  ```\n\n  listen-address=127.0.0.1\n\n  ```\n\n\n  如果用此主机为局域网提供默认 DNS，请用为该主机绑定固定 IP 地址，设置：\n\n\n  ```\n\n  listen-address=192.168.x.x\n\n  ```\n\n  这种情况建议配置静态IP\n\n\n  多个ip地址设置:\n\n\n  ```\n\n  listen-address=127.0.0.1,192.168.x.x \n\n  ```\n\n\n  ### DNS 地址文件\n\n  在配置好dnsmasq后，你需要编辑/etc/resolv.conf让DHCP客户端首先将本地地址(localhost)加入 DNS\n  文件(/etc/resolv.conf)，然后再通过其他DNS服务器解析地址。配置好DHCP客户端后需要重新启动网络来使设置生效\n\n\n  #### resolv.conf\n\n  一种选择是一个纯粹的 resolv.conf 配置。要做到这一点，才使第一个域名服务器在/etc/resolv.conf 中指向localhost：\n\n\n  ```\n\n  /etc/resolv.conf\n\n\n  nameserver 127.0.0.1\n\n  # External nameservers\n\n  ...\n\n  ```\n\n\n  现在，DNS查询将首先解析dnsmasq，只检查外部的服务器如果DNSMasq无法解析查询. dhcpcd, 不幸的是，往往默认覆盖\n  /etc/resolv.conf, 所以如果你使用DHCP，这里有一个好主意来保护 /etc/resolv.conf,要做到这一点，追加 nohook\n  resolv.conf到dhcpcd的配置文件：\n\n\n  ```\n\n  /etc/dhcpcd.conf\n\n  ...\n\n  nohook resolv.conf\n\n  ```\n\n\n  也可以保护您的resolv.conf不被修改：\n\n\n  ```\n\n  # chattr +i /etc/resolv.conf\n\n  ```\n\n\n  ##### 三个以上域名服务器\n\n  Linux 处理 DNS 请求时有个限制，在 resolv.conf 中最多只能配置三个域名服务器（nameserver）。作为一种变通方法,可以在\n  resolv.conf 文件中只保留 localhost 作为域名服务器，然后为外部域名服务器另外创建 resolv-file 文件。首先，为\n  dnsmasq 新建一个域名解析文件：\n\n\n  ```\n\n  /etc/resolv.dnsmasq.conf\n\n  # Google's nameservers, for example\n\n  nameserver 8.8.8.8\n\n  nameserver 8.8.4.4\n\n  ```\n\n  然后编辑 /etc/dnsmasq.conf 让 dnsmasq 使用新创建的域名解析文件：\n\n\n  ```\n\n  /etc/dnsmasq.conf\n\n  ...\n\n  resolv-file=/etc/resolv.dnsmasq.conf\n\n  ...\n\n  ```\n\n\n  #### 使用dhcpcd\n\n  dhcpcd 可以是通过创建（或编辑）/etc/resolv.conf.head文件或\n  /etc/resolv.conf.tail文件来指定dns服务器，使/etc/resolv.conf不会被每次都被dhcpcd重写\n\n\n  ```\n\n  echo \"nameserver 127.0.0.1\" > /etc/resolv.conf.head #设置dns服务器为127.0.0.1\n\n  ```\n\n\n  #### 使用dhclient\n\n  要使用 dhclient， 取消 /etc/dhclient.conf 文件中如下行的注释：\n\n\n  ```\n\n  prepend domain-name-servers 127.0.0.1;\n\n  ```\n\n\n  ### 使用NetworkManager\n\n  NetworkManager 可以靠自身配置文件的设置项启动 dnsmasq 。在 NetworkManager.conf 文件的 [main] 节段添加\n  dns=dnsmasq 配置语句，然后禁用由 systemd 启动的 dnsmasq.service:\n\n\n  ```\n\n  /etc/NetworkManager/NetworkManager.conf\n\n  [main]\n\n  plugins=keyfile\n\n  dns=dnsmasq\n\n  ```\n\n\n  可以在 /etc/NetworkManager/dnsmasq.d/ 目录下为 dnsmasq 创建自定义配置文件。例如，调整 DNS\n  缓存大小（保存在内存中）：\n\n\n  ```\n\n  /etc/NetworkManager/dnsmasq.d/cache\n\n  cache-size=1000\n\n  ```\n\n\n  dnsmasq 被 NetworkManager 启动后，此目录下配置文件中的配置将取代默认配置。\n\n\n  ```\n\n  提示： 这种方法可以让你启用特定域名的自定义DNS设置。例如: \n\n  server=/example1.com/exemple2.com/xx.xxx.xxx.x \n\n  改变第一个DNS地址，浏览以下网站example1.com, example2.com\n\n  使用xx.xxx.xxx.xx。\n\n  This method is preferred to a global DNS configuration \n\n  when using particular DNS nameservers which lack of speed, \n\n  stability, privacy and security.\n\n  ```\n\n  #### IPv6\n\n  启用 dnsmasq 在 NetworkManager 可能会中断仅持IPv6的DNS查询 (例如 dig -6 [hostname]) 否则将工作。\n  为了解决这个问题，创建以下文件将配置 dnsmasq 总是监听IPv6的loopback：\n\n\n  ```\n\n  /etc/NetworkManager/dnsmasq.d/ipv6_listen.conf\n\n  listen-address=::1\n\n  ```\n\n\n  此外， dnsmasq不优先考虑上游IPv6的DNS。不幸的是NetworkManager已不这样做 (Ubuntu Bug)。\n  一种解决方法是将禁用IPv4 DNS的NetworkManager的配置，假设存在。\n\n  #### 其他方式\n\n  另一种选择是在NetworkManagers“设置（通常通过右键单击小程序）和手动输入设置。设置将取决于前端中使用的类型;这个过程通常涉及右击小程序，编辑（或创建）一个配置文件，然后选择DHCP类型为“自动（指定地址）。”DNS地址将需要输入，通常以这种形式：127.0.0.1,\n  DNS-server-one, ....\n\n\n  ## DHCP 服务器设置\n\n  dnsmasq默认关闭DHCP功能，如果该主机需要为局域网中的其他设备提供IP和路由，应该对dnsmasq\n  配置文件(/etc/dnsmasq.conf)必要的配置如下：\n\n\n  ```\n\n  # Only listen to routers' LAN NIC.  Doing so opens up tcp/udp port 53 to\n\n  # localhost and udp port 67 to world:\n\n  interface=<LAN-NIC>\n\n\n  # dnsmasq will open tcp/udp port 53 and udp port 67 to world to help with\n\n  # dynamic interfaces (assigning dynamic ips). Dnsmasq will discard world\n\n  # requests to them, but the paranoid might like to close them and let the \n\n  # kernel handle them:\n\n  bind-interfaces\n\n\n  # Dynamic range of IPs to make available to LAN pc\n\n  dhcp-range=192.168.111.50,192.168.111.100,12h\n\n\n  # If you’d like to have dnsmasq assign static IPs, bind the LAN computer's\n\n  # NIC MAC address:\n\n  dhcp-host=aa:bb:cc:dd:ee:ff,192.168.111.50\n\n  ```\n\n  ## 启动守护进程\n\n  设置为开机启动：\n\n\n  ```\n\n  # systemctl enable dnsmasq\n\n  ```\n\n\n  立即启动 dnsmashq：\n\n\n  ```\n\n  # systemctl start dnsmasq\n\n  ```\n\n\n  查看dnsmasq是否启动正常，查看系统日志：\n\n\n  ```\n\n  # journalctl -u dnsmasq\n\n  ```\n\n  需要重启网络服务以使 DHCP 客户端重建一个新的 /etc/resolv.conf。\n\n  ## 测试\n\n  ### DNS 缓存\n\n  要测试查询速度，请访问一个 dnsmasq 启动后没有访问过的网站，执行 (dig (位于 dnsutils[broken link: replaced\n  by bind-tools] 软件包):\n\n\n  ```\n\n  $ dig archlinux.org | grep \"Query time\"\n\n  ```\n\n  再次运行命令，因为使用了缓存，查询时间应该大大缩短。\n\n  ### DHCP 服务器\n\n  从一个连接到使用了 dnsmasq 的计算机的计算机，配置它使用 DHCP 自动获取 IP 地址，然后尝试连接到你平时使用的网络。\n\n  ## 小技巧\n\n  ### 避免OpenDNS重定向Google请求\n\n  要避免 OpenDNS 重定向所有 Google 请求到他们自己的搜索服务器，添加以下内容到 /etc/dnsmasq.conf：\n\n\n  ```\n\n  server=/www.google.com/X.X.X.X\n\n  ```\n\n\n  用你的 ISP 的 DNS 服务器/路由器的 IP 替代 X.X.X.X 。\n\n\n  ### 查看租约\n\n  ```\n\n  cat /var/lib/misc/dnsmasq.leases\n\n  ```\n\n  ### 添加自定义域\n\n  它可以将一个自定义域添加到主机中的（本地）网络：\n\n\n  ```\n\n  local=/home.lan/\n\n  domain=home.lan\n\n  ```\n\n\n  在这个例子中可以ping主机/设备 (例如:您的主机文件中的定义) hostname.home.lan.\n\n\n  取消扩展主机添加自定义域的主机条目：存在\n\n\n  ```\n\n  expand-hosts\n\n  ```\n\n\n  如果没有这个设置，你必须域添加到/etc/hosts中的条目。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-07 06:17:10\n---\n\nDnsmasq 提供 DNS 缓存和 DHCP 服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，dnsmasq 可以用于为局域网电脑分配内网ip地址和提供路由。DNS和DHCP两个功能可以同时或分别单独实现。dnsmasq轻量且易配置，适用于个人用户或少于50台主机的网络。此外它还自带了一个 PXE 服务器。\n<!-- more -->\n## 安装\n从官方仓库中安装 dnsmasq。\n## 配置\n编辑 dnsmasq 的配置文件 /etc/dnsmasq.conf 。这个文件包含大量的选项注释。\n\n```\n警告: dnsmasq 默认启用其 DNS 服务器。如果不需要，必须明确地将其 DNS 端口设置为 0 禁用它：\n----\n/etc/dnsmasq.conf\n----\nport=0\n```\n\n```\n提示： 查看配置文件语法是否正确，可执行下列命令：\n$ dnsmasq --test\n```\n## DNS 缓存设置\n要在单台电脑上以守护进程方式启动dnsmasq做DNS缓存服务器，编辑/etc/dnsmasq.conf，添加监听地址：\n\n```\nlisten-address=127.0.0.1\n```\n\n如果用此主机为局域网提供默认 DNS，请用为该主机绑定固定 IP 地址，设置：\n\n```\nlisten-address=192.168.x.x\n```\n这种情况建议配置静态IP\n\n多个ip地址设置:\n\n```\nlisten-address=127.0.0.1,192.168.x.x \n```\n\n### DNS 地址文件\n在配置好dnsmasq后，你需要编辑/etc/resolv.conf让DHCP客户端首先将本地地址(localhost)加入 DNS 文件(/etc/resolv.conf)，然后再通过其他DNS服务器解析地址。配置好DHCP客户端后需要重新启动网络来使设置生效\n\n#### resolv.conf\n一种选择是一个纯粹的 resolv.conf 配置。要做到这一点，才使第一个域名服务器在/etc/resolv.conf 中指向localhost：\n\n```\n/etc/resolv.conf\n\nnameserver 127.0.0.1\n# External nameservers\n...\n```\n\n现在，DNS查询将首先解析dnsmasq，只检查外部的服务器如果DNSMasq无法解析查询. dhcpcd, 不幸的是，往往默认覆盖 /etc/resolv.conf, 所以如果你使用DHCP，这里有一个好主意来保护 /etc/resolv.conf,要做到这一点，追加 nohook resolv.conf到dhcpcd的配置文件：\n\n```\n/etc/dhcpcd.conf\n...\nnohook resolv.conf\n```\n\n也可以保护您的resolv.conf不被修改：\n\n```\n# chattr +i /etc/resolv.conf\n```\n\n##### 三个以上域名服务器\nLinux 处理 DNS 请求时有个限制，在 resolv.conf 中最多只能配置三个域名服务器（nameserver）。作为一种变通方法,可以在 resolv.conf 文件中只保留 localhost 作为域名服务器，然后为外部域名服务器另外创建 resolv-file 文件。首先，为 dnsmasq 新建一个域名解析文件：\n\n```\n/etc/resolv.dnsmasq.conf\n# Google's nameservers, for example\nnameserver 8.8.8.8\nnameserver 8.8.4.4\n```\n然后编辑 /etc/dnsmasq.conf 让 dnsmasq 使用新创建的域名解析文件：\n\n```\n/etc/dnsmasq.conf\n...\nresolv-file=/etc/resolv.dnsmasq.conf\n...\n```\n\n#### 使用dhcpcd\ndhcpcd 可以是通过创建（或编辑）/etc/resolv.conf.head文件或 /etc/resolv.conf.tail文件来指定dns服务器，使/etc/resolv.conf不会被每次都被dhcpcd重写\n\n```\necho \"nameserver 127.0.0.1\" > /etc/resolv.conf.head #设置dns服务器为127.0.0.1\n```\n\n#### 使用dhclient\n要使用 dhclient， 取消 /etc/dhclient.conf 文件中如下行的注释：\n\n```\nprepend domain-name-servers 127.0.0.1;\n```\n\n### 使用NetworkManager\nNetworkManager 可以靠自身配置文件的设置项启动 dnsmasq 。在 NetworkManager.conf 文件的 [main] 节段添加 dns=dnsmasq 配置语句，然后禁用由 systemd 启动的 dnsmasq.service:\n\n```\n/etc/NetworkManager/NetworkManager.conf\n[main]\nplugins=keyfile\ndns=dnsmasq\n```\n\n可以在 /etc/NetworkManager/dnsmasq.d/ 目录下为 dnsmasq 创建自定义配置文件。例如，调整 DNS 缓存大小（保存在内存中）：\n\n```\n/etc/NetworkManager/dnsmasq.d/cache\ncache-size=1000\n```\n\ndnsmasq 被 NetworkManager 启动后，此目录下配置文件中的配置将取代默认配置。\n\n```\n提示： 这种方法可以让你启用特定域名的自定义DNS设置。例如: \nserver=/example1.com/exemple2.com/xx.xxx.xxx.x \n改变第一个DNS地址，浏览以下网站example1.com, example2.com\n使用xx.xxx.xxx.xx。\nThis method is preferred to a global DNS configuration \nwhen using particular DNS nameservers which lack of speed, \nstability, privacy and security.\n```\n#### IPv6\n启用 dnsmasq 在 NetworkManager 可能会中断仅持IPv6的DNS查询 (例如 dig -6 [hostname]) 否则将工作。 为了解决这个问题，创建以下文件将配置 dnsmasq 总是监听IPv6的loopback：\n\n```\n/etc/NetworkManager/dnsmasq.d/ipv6_listen.conf\nlisten-address=::1\n```\n\n此外， dnsmasq不优先考虑上游IPv6的DNS。不幸的是NetworkManager已不这样做 (Ubuntu Bug)。 一种解决方法是将禁用IPv4 DNS的NetworkManager的配置，假设存在。\n#### 其他方式\n另一种选择是在NetworkManagers“设置（通常通过右键单击小程序）和手动输入设置。设置将取决于前端中使用的类型;这个过程通常涉及右击小程序，编辑（或创建）一个配置文件，然后选择DHCP类型为“自动（指定地址）。”DNS地址将需要输入，通常以这种形式：127.0.0.1, DNS-server-one, ....\n\n## DHCP 服务器设置\ndnsmasq默认关闭DHCP功能，如果该主机需要为局域网中的其他设备提供IP和路由，应该对dnsmasq 配置文件(/etc/dnsmasq.conf)必要的配置如下：\n\n```\n# Only listen to routers' LAN NIC.  Doing so opens up tcp/udp port 53 to\n# localhost and udp port 67 to world:\ninterface=<LAN-NIC>\n\n# dnsmasq will open tcp/udp port 53 and udp port 67 to world to help with\n# dynamic interfaces (assigning dynamic ips). Dnsmasq will discard world\n# requests to them, but the paranoid might like to close them and let the \n# kernel handle them:\nbind-interfaces\n\n# Dynamic range of IPs to make available to LAN pc\ndhcp-range=192.168.111.50,192.168.111.100,12h\n\n# If you’d like to have dnsmasq assign static IPs, bind the LAN computer's\n# NIC MAC address:\ndhcp-host=aa:bb:cc:dd:ee:ff,192.168.111.50\n```\n## 启动守护进程\n设置为开机启动：\n\n```\n# systemctl enable dnsmasq\n```\n\n立即启动 dnsmashq：\n\n```\n# systemctl start dnsmasq\n```\n\n查看dnsmasq是否启动正常，查看系统日志：\n\n```\n# journalctl -u dnsmasq\n```\n需要重启网络服务以使 DHCP 客户端重建一个新的 /etc/resolv.conf。\n## 测试\n### DNS 缓存\n要测试查询速度，请访问一个 dnsmasq 启动后没有访问过的网站，执行 (dig (位于 dnsutils[broken link: replaced by bind-tools] 软件包):\n\n```\n$ dig archlinux.org | grep \"Query time\"\n```\n再次运行命令，因为使用了缓存，查询时间应该大大缩短。\n### DHCP 服务器\n从一个连接到使用了 dnsmasq 的计算机的计算机，配置它使用 DHCP 自动获取 IP 地址，然后尝试连接到你平时使用的网络。\n## 小技巧\n### 避免OpenDNS重定向Google请求\n要避免 OpenDNS 重定向所有 Google 请求到他们自己的搜索服务器，添加以下内容到 /etc/dnsmasq.conf：\n\n```\nserver=/www.google.com/X.X.X.X\n```\n\n用你的 ISP 的 DNS 服务器/路由器的 IP 替代 X.X.X.X 。\n\n### 查看租约\n```\ncat /var/lib/misc/dnsmasq.leases\n```\n### 添加自定义域\n它可以将一个自定义域添加到主机中的（本地）网络：\n\n```\nlocal=/home.lan/\ndomain=home.lan\n```\n\n在这个例子中可以ping主机/设备 (例如:您的主机文件中的定义) hostname.home.lan.\n\n取消扩展主机添加自定义域的主机条目：存在\n\n```\nexpand-hosts\n```\n\n如果没有这个设置，你必须域添加到/etc/hosts中的条目。","slug":"dnsmasq官方文档","published":1,"updated":"2019-03-23T10:26:23.332Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eit001ogyav0f0q3crf"},{"title":"curl命令","originContent":"curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\n\n## 语法\n\n```\ncurl(选项)(参数)\n```\n<!-- more -->\n\n## 选项\n|             选项               |              含义             |\n|-------------------------------|-------------------------------|\n| -a/--append\t                   | 上传文件时，附加到目标文件        |\n|-A/--user-agent \\<string>\t     | 设置用户代理发送给服务器           |\n|-anyauth\t                      |  可以使用“任何”身份验证方法       |\n|-b/--cookie \\<name=string/file> |       cookie字符串或文件读取位置  |\n|    --basic                    |          使用HTTP基本验         |\n|-B/--use-ascii\t               |      使用ASCII /文本传输        |\n|-c/--cookie-jar \\<file>\t     |  操作结束后把cookie写入到这个文件中 |\n|-C/--continue-at \\<offset>|断点续转|\n|-d/--data \\<data>|HTTP POST方式传送数据|\n| --data-ascii \\<data>|以ascii的方式post数据|\n|--data-binary \\<data>|以二进制的方式post数据|\n| --negotiate|使用HTTP身份验证|\n|--digest|使用数字身份验证|\n| --disable-eprt|禁止使用EPRT或LPRT|\n|--disable-epsv|禁止使用EPSV|\n|-D/--dump-header \\<file>|把header信息写入到该文件中|\n|--egd-file \\<file>|为随机数据(SSL)设置EGD socket路径|\n|--tcp-nodelay|使用TCP_NODELAY选项|\n|-e/--referer|来源网址|\n|-E/--cert \\<cert[:passwd]>|客户端证书文件和密码 (SSL)|\n|--cert-type \\<type>|证书文件类型 (DER/PEM/ENG) (SSL)|\n| --key \\<key>|私钥文件名 (SSL)|\n| --key-type \\<type>|私钥文件类型 (DER/PEM/ENG) (SSL)|\n|--pass \\<pass>|私钥密码 (SSL)|\n| --engine \\<eng>|加密引擎使用 (SSL). \"--engine list\" for list|\n| --cacert \\<file>|CA证书 (SSL)|\n| --capath \\<directory>|CA目录 (made using c_rehash) to verify peer against (SSL)|\n|--ciphers \\<list>|SSL密码|\n|--compressed|要求返回是压缩的形势 (using deflate or gzip)|\n|--connect-timeout \\<seconds>|设置最大请求时间|\n|--create-dirs|建立本地目录的目录层次结构|\n|--crlf|上传是把LF转变成CRLF|\n|-f/--fail|连接失败时不显示http错误|\n|--ftp-create-dirs|如果远程目录不存在，创建远程目录|\n|--ftp-method [multicwd/nocwd/singlecwd]|控制CWD的使用|\n| --ftp-pasv|使用 PASV/EPSV 代替端口|\n|--ftp-skip-pasv-ip|使用PASV的时候,忽略该IP地址|\n|--ftp-ssl|尝试用 SSL/TLS 来进行ftp数据传输|\n|--ftp-ssl-reqd|要求用 SSL/TLS 来进行ftp数据传输|\n|-F/--form \\<name=content>|模拟http表单提交数据|\n|--form-string \\<name=string>|模拟http表单提交数据|\n|-g/--globoff|禁用网址序列和范围使用{}和[]|\n|-G/--get|以get的方式来发送数据|\n|-H/--header \\<line>|自定义头信息传递给服务器|\n|--ignore-content-length|忽略的HTTP头信息的长度|\n|-i/--include|输出时包括protocol头信息|\n|-I/--head|只显示请求头信息|\n|-j/--junk-session-cookies|读取文件进忽略session cookie|\n|--interface \\<interface>|使用指定网络接口/地址|\n|--krb4 \\<level>|使用指定安全级别的krb4|\n|-k/--insecure|允许不使用证书到SSL站点|\n|-K/--config|指定的配置文件读取|\n|-l/--list-only|列出ftp目录下的文件名称|\n|--limit-rate \\<rate>|设置传输速度|\n|--local-port\\<NUM>|强制使用本地端口号|\n|-m/--max-time \\<seconds>|设置最大传输时间|\n| --max-redirs \\<num>|设置最大读取的目录数|\n|--max-filesize \\<bytes>|设置最大下载的文件总量|\n|-M/--manual|显示全手动|\n|-n/--netrc|从netrc文件中读取用户名和密码|\n|--netrc-optional|使用 .netrc 或者 URL来覆盖-n|\n|--ntlm|使用 HTTP NTLM 身份验证|\n|-N/--no-buffer|禁用缓冲输出|\n|-o/--output|把输出写到该文件中|\n|-O/--remote-name|把输出写到该文件中，保留远程文件的文件名|\n|-p/--proxytunnel|使用HTTP代理|\n|--proxy-anyauth|选择任一代理身份验证方法|\n|--proxy-basic|在代理上使用基本身份验证|\n|--proxy-digest|在代理上使用数字身份验证|\n|--proxy-ntlm|在代理上使用ntlm身份验证|\n|-P/--ftp-port \\<address>|使用端口地址，而不是使用PASV|\n|-q|作为第一个参数，关闭 .curlrc|\n|-Q/--quote \\<cmd>|文件传输前，发送命令到服务器|\n|-r/--range \\<range>|检索来自HTTP/1.1或FTP服务器字节范围|\n|--range-file|读取（SSL）的随机文件|\n|-R/--remote-time|在本地生成文件时，保留远程文件时间|\n|--retry \\<num>|传输出现问题时，重试的次数|\n|--retry-delay \\<seconds>|传输出现问题时，设置重试间隔时间|\n|--retry-max-time \\<seconds>\t|传输出现问题时，设置最大重试时间|\n|-s/--silent|静默模式。不输出任何东西|\n|-S/--show-error|显示错误|\n|--socks4 \\<host[:port]>|用socks4代理给定主机和端口|\n|--socks5 \\<host[:port]>|用socks5代理给定主机和端口|\n| --stderr \\<file>||\n|-t/--telnet-option \\<OPT=val>|Telnet选项设置|\n|--trace \\<file>|对指定文件进行debug|\n| --trace-ascii \\<file>|Like --跟踪但没有hex输出|\n|--trace-time|跟踪/详细输出时，添加时间戳|\n|-T/--upload-file \\<file>|上传文件|\n|--url \\<URL>|Spet URL to work with|\n|-u/--user \\<user[:password]>|设置服务器的用户和密码|\n|-U/--proxy-user \\<user[:password]>|设置代理用户名和密码|\n|-w/--write-out [format]|什么输出完成后|\n|-x/--proxy \\<host[:port]>|在给定的端口上使用HTTP代理|\n|-X/--request \\<command>|指定什么命令|\n|-y/--speed-time|放弃限速所要的时间，默认为30|\n|-Y/--speed-limit|停止传输速度的限制，速度时间|\n\n## 实例\n### 文件下载\ncurl命令可以用来执行下载、发送各种HTTP请求，指定HTTP头部等操作。如果系统没有curl可以使用`yum install curl`安装，也可以下载安装。curl是将下载文件输出到stdout，将进度信息输出到stderr，不显示进度信息使用`--silent`选项。\n\n```\ncurl URL --silent\n```\n\n这条命令是将下载文件输出到终端，所有下载的数据都被写入到stdout。\n\n使用选项`-O`将下载的数据写入到文件，必须使用文件的绝对地址：\n\n```\ncurl http://man.linuxde.net/text.iso --silent -O\n```\n\n选项`-o`将下载数据写入到指定名称的文件中，并使用`--progress`显示进度条：\n\n```\ncurl http://man.linuxde.net/test.iso -o filename.iso --progress\n######################################### 100.0%\n```\n\n### 断点续传\n\ncurl能够从特定的文件偏移处继续下载，它可以通过指定一个便宜量来下载部分文件：\n\n```\ncurl URL/File -C 偏移量\n\n#偏移量是以字节为单位的整数，如果让curl自动推断出正确的续传位置使用-C -：\ncurl -C -URL\n```\n\n### 使用curl设置参照页字符串\n参照页是位于HTTP头部中的一个字符串，用来表示用户是从哪个页面到达当前页面的，如果用户点击网页A中的某个连接，那么用户就会跳转到B网页，网页B头部的参照页字符串就包含网页A的URL。\n\n使用`--referer`选项指定参照页字符串：\n\t\t\t\n```\ncurl --referer http://www.google.com http://man.linuxde.net\n```\n\n### 用curl设置cookies\n\n使用`--cookie \"COKKIES\"`选项来指定cookie，多个cookie使用分号分隔：\n\n```\ncurl http://man.linuxde.net --cookie \"user=root;pass=123456\"\n```\n\n将cookie另存为一个文件，使用`--cookie-jar`选项：\n\n```\ncurl URL --cookie-jar cookie_file\n```\n\n### 用curl设置用户代理字符串\n有些网站访问会提示只能使用IE浏览器来访问，这是因为这些网站设置了检查用户代理，可以使用curl把用户代理设置为IE，这样就可以访问了。使用`--user-agent`或者`-A`选项：\n\n```\ncurl URL --user-agent \"Mozilla/5.0\"\ncurl URL -A \"Mozilla/5.0\"\n```\n\n其他HTTP头部信息也可以使用curl来发送，使用`-H`\"头部信息\" 传递多个头部信息，例如：\n\n```\ncurl -H \"Host:man.linuxde.net\" -H \"accept-language:zh-cn\" URL\n```\n\n### curl的带宽控制和下载配额\n使用`--limit-rate`限制curl的下载速度：\n\n```\ncurl URL --limit-rate 50k\n```\n\n命令中用k（千字节）和m（兆字节）指定下载速度限制。\n\n使用`--max-filesize`指定可下载的最大文件大小：\n\n```\ncurl URL --max-filesize bytes\n```\n\n如果文件大小超出限制，命令则返回一个非0退出码，如果命令正常则返回0。\n\n### 用curl进行认证\n\n使用curl选项 -u 可以完成HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\n\n```\ncurl -u user:pwd http://man.linuxde.net\ncurl -u user http://man.linuxde.net\n```\n\n### 只打印响应头部信息\n\n通过`-I`或者`-head`可以只打印出HTTP头部信息：\n\n```\n[root@localhost text]# curl -I http://man.linuxde.net\nHTTP/1.1 200 OK\nServer: nginx/1.2.5\ndate: Mon, 10 Dec 2012 09:24:34 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: keep-alive\nVary: Accept-Encoding\nX-Pingback: http://man.linuxde.net/xmlrpc.php\n```\n\n[原文地址](http://man.linuxde.net/curl)","toc":false,"date":"2018-01-18T02:10:07.000Z","_content":"\ncurl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\n\n## 语法\n\n```\ncurl(选项)(参数)\n```\n<!-- more -->\n\n## 选项\n|             选项               |              含义             |\n|-------------------------------|-------------------------------|\n| -a/--append\t                   | 上传文件时，附加到目标文件        |\n|-A/--user-agent \\<string>\t     | 设置用户代理发送给服务器           |\n|-anyauth\t                      |  可以使用“任何”身份验证方法       |\n|-b/--cookie \\<name=string/file> |       cookie字符串或文件读取位置  |\n|    --basic                    |          使用HTTP基本验         |\n|-B/--use-ascii\t               |      使用ASCII /文本传输        |\n|-c/--cookie-jar \\<file>\t     |  操作结束后把cookie写入到这个文件中 |\n|-C/--continue-at \\<offset>|断点续转|\n|-d/--data \\<data>|HTTP POST方式传送数据|\n| --data-ascii \\<data>|以ascii的方式post数据|\n|--data-binary \\<data>|以二进制的方式post数据|\n| --negotiate|使用HTTP身份验证|\n|--digest|使用数字身份验证|\n| --disable-eprt|禁止使用EPRT或LPRT|\n|--disable-epsv|禁止使用EPSV|\n|-D/--dump-header \\<file>|把header信息写入到该文件中|\n|--egd-file \\<file>|为随机数据(SSL)设置EGD socket路径|\n|--tcp-nodelay|使用TCP_NODELAY选项|\n|-e/--referer|来源网址|\n|-E/--cert \\<cert[:passwd]>|客户端证书文件和密码 (SSL)|\n|--cert-type \\<type>|证书文件类型 (DER/PEM/ENG) (SSL)|\n| --key \\<key>|私钥文件名 (SSL)|\n| --key-type \\<type>|私钥文件类型 (DER/PEM/ENG) (SSL)|\n|--pass \\<pass>|私钥密码 (SSL)|\n| --engine \\<eng>|加密引擎使用 (SSL). \"--engine list\" for list|\n| --cacert \\<file>|CA证书 (SSL)|\n| --capath \\<directory>|CA目录 (made using c_rehash) to verify peer against (SSL)|\n|--ciphers \\<list>|SSL密码|\n|--compressed|要求返回是压缩的形势 (using deflate or gzip)|\n|--connect-timeout \\<seconds>|设置最大请求时间|\n|--create-dirs|建立本地目录的目录层次结构|\n|--crlf|上传是把LF转变成CRLF|\n|-f/--fail|连接失败时不显示http错误|\n|--ftp-create-dirs|如果远程目录不存在，创建远程目录|\n|--ftp-method [multicwd/nocwd/singlecwd]|控制CWD的使用|\n| --ftp-pasv|使用 PASV/EPSV 代替端口|\n|--ftp-skip-pasv-ip|使用PASV的时候,忽略该IP地址|\n|--ftp-ssl|尝试用 SSL/TLS 来进行ftp数据传输|\n|--ftp-ssl-reqd|要求用 SSL/TLS 来进行ftp数据传输|\n|-F/--form \\<name=content>|模拟http表单提交数据|\n|--form-string \\<name=string>|模拟http表单提交数据|\n|-g/--globoff|禁用网址序列和范围使用{}和[]|\n|-G/--get|以get的方式来发送数据|\n|-H/--header \\<line>|自定义头信息传递给服务器|\n|--ignore-content-length|忽略的HTTP头信息的长度|\n|-i/--include|输出时包括protocol头信息|\n|-I/--head|只显示请求头信息|\n|-j/--junk-session-cookies|读取文件进忽略session cookie|\n|--interface \\<interface>|使用指定网络接口/地址|\n|--krb4 \\<level>|使用指定安全级别的krb4|\n|-k/--insecure|允许不使用证书到SSL站点|\n|-K/--config|指定的配置文件读取|\n|-l/--list-only|列出ftp目录下的文件名称|\n|--limit-rate \\<rate>|设置传输速度|\n|--local-port\\<NUM>|强制使用本地端口号|\n|-m/--max-time \\<seconds>|设置最大传输时间|\n| --max-redirs \\<num>|设置最大读取的目录数|\n|--max-filesize \\<bytes>|设置最大下载的文件总量|\n|-M/--manual|显示全手动|\n|-n/--netrc|从netrc文件中读取用户名和密码|\n|--netrc-optional|使用 .netrc 或者 URL来覆盖-n|\n|--ntlm|使用 HTTP NTLM 身份验证|\n|-N/--no-buffer|禁用缓冲输出|\n|-o/--output|把输出写到该文件中|\n|-O/--remote-name|把输出写到该文件中，保留远程文件的文件名|\n|-p/--proxytunnel|使用HTTP代理|\n|--proxy-anyauth|选择任一代理身份验证方法|\n|--proxy-basic|在代理上使用基本身份验证|\n|--proxy-digest|在代理上使用数字身份验证|\n|--proxy-ntlm|在代理上使用ntlm身份验证|\n|-P/--ftp-port \\<address>|使用端口地址，而不是使用PASV|\n|-q|作为第一个参数，关闭 .curlrc|\n|-Q/--quote \\<cmd>|文件传输前，发送命令到服务器|\n|-r/--range \\<range>|检索来自HTTP/1.1或FTP服务器字节范围|\n|--range-file|读取（SSL）的随机文件|\n|-R/--remote-time|在本地生成文件时，保留远程文件时间|\n|--retry \\<num>|传输出现问题时，重试的次数|\n|--retry-delay \\<seconds>|传输出现问题时，设置重试间隔时间|\n|--retry-max-time \\<seconds>\t|传输出现问题时，设置最大重试时间|\n|-s/--silent|静默模式。不输出任何东西|\n|-S/--show-error|显示错误|\n|--socks4 \\<host[:port]>|用socks4代理给定主机和端口|\n|--socks5 \\<host[:port]>|用socks5代理给定主机和端口|\n| --stderr \\<file>||\n|-t/--telnet-option \\<OPT=val>|Telnet选项设置|\n|--trace \\<file>|对指定文件进行debug|\n| --trace-ascii \\<file>|Like --跟踪但没有hex输出|\n|--trace-time|跟踪/详细输出时，添加时间戳|\n|-T/--upload-file \\<file>|上传文件|\n|--url \\<URL>|Spet URL to work with|\n|-u/--user \\<user[:password]>|设置服务器的用户和密码|\n|-U/--proxy-user \\<user[:password]>|设置代理用户名和密码|\n|-w/--write-out [format]|什么输出完成后|\n|-x/--proxy \\<host[:port]>|在给定的端口上使用HTTP代理|\n|-X/--request \\<command>|指定什么命令|\n|-y/--speed-time|放弃限速所要的时间，默认为30|\n|-Y/--speed-limit|停止传输速度的限制，速度时间|\n\n## 实例\n### 文件下载\ncurl命令可以用来执行下载、发送各种HTTP请求，指定HTTP头部等操作。如果系统没有curl可以使用`yum install curl`安装，也可以下载安装。curl是将下载文件输出到stdout，将进度信息输出到stderr，不显示进度信息使用`--silent`选项。\n\n```\ncurl URL --silent\n```\n\n这条命令是将下载文件输出到终端，所有下载的数据都被写入到stdout。\n\n使用选项`-O`将下载的数据写入到文件，必须使用文件的绝对地址：\n\n```\ncurl http://man.linuxde.net/text.iso --silent -O\n```\n\n选项`-o`将下载数据写入到指定名称的文件中，并使用`--progress`显示进度条：\n\n```\ncurl http://man.linuxde.net/test.iso -o filename.iso --progress\n######################################### 100.0%\n```\n\n### 断点续传\n\ncurl能够从特定的文件偏移处继续下载，它可以通过指定一个便宜量来下载部分文件：\n\n```\ncurl URL/File -C 偏移量\n\n#偏移量是以字节为单位的整数，如果让curl自动推断出正确的续传位置使用-C -：\ncurl -C -URL\n```\n\n### 使用curl设置参照页字符串\n参照页是位于HTTP头部中的一个字符串，用来表示用户是从哪个页面到达当前页面的，如果用户点击网页A中的某个连接，那么用户就会跳转到B网页，网页B头部的参照页字符串就包含网页A的URL。\n\n使用`--referer`选项指定参照页字符串：\n\t\t\t\n```\ncurl --referer http://www.google.com http://man.linuxde.net\n```\n\n### 用curl设置cookies\n\n使用`--cookie \"COKKIES\"`选项来指定cookie，多个cookie使用分号分隔：\n\n```\ncurl http://man.linuxde.net --cookie \"user=root;pass=123456\"\n```\n\n将cookie另存为一个文件，使用`--cookie-jar`选项：\n\n```\ncurl URL --cookie-jar cookie_file\n```\n\n### 用curl设置用户代理字符串\n有些网站访问会提示只能使用IE浏览器来访问，这是因为这些网站设置了检查用户代理，可以使用curl把用户代理设置为IE，这样就可以访问了。使用`--user-agent`或者`-A`选项：\n\n```\ncurl URL --user-agent \"Mozilla/5.0\"\ncurl URL -A \"Mozilla/5.0\"\n```\n\n其他HTTP头部信息也可以使用curl来发送，使用`-H`\"头部信息\" 传递多个头部信息，例如：\n\n```\ncurl -H \"Host:man.linuxde.net\" -H \"accept-language:zh-cn\" URL\n```\n\n### curl的带宽控制和下载配额\n使用`--limit-rate`限制curl的下载速度：\n\n```\ncurl URL --limit-rate 50k\n```\n\n命令中用k（千字节）和m（兆字节）指定下载速度限制。\n\n使用`--max-filesize`指定可下载的最大文件大小：\n\n```\ncurl URL --max-filesize bytes\n```\n\n如果文件大小超出限制，命令则返回一个非0退出码，如果命令正常则返回0。\n\n### 用curl进行认证\n\n使用curl选项 -u 可以完成HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\n\n```\ncurl -u user:pwd http://man.linuxde.net\ncurl -u user http://man.linuxde.net\n```\n\n### 只打印响应头部信息\n\n通过`-I`或者`-head`可以只打印出HTTP头部信息：\n\n```\n[root@localhost text]# curl -I http://man.linuxde.net\nHTTP/1.1 200 OK\nServer: nginx/1.2.5\ndate: Mon, 10 Dec 2012 09:24:34 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: keep-alive\nVary: Accept-Encoding\nX-Pingback: http://man.linuxde.net/xmlrpc.php\n```\n\n[原文地址](http://man.linuxde.net/curl)","source":"_posts/curl命令.md","raw":"---\ntitle: curl命令\ntags:\n  - linux\noriginContent: \"curl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\\n\\n## 语法\\n\\n```\\ncurl(选项)(参数)\\n```\\n<!-- more -->\\n\\n## 选项\\n|             选项               |              含义             |\\n|-------------------------------|-------------------------------|\\n| -a/--append\\t                   | 上传文件时，附加到目标文件        |\\n|-A/--user-agent \\\\<string>\\t     | 设置用户代理发送给服务器           |\\n|-anyauth\\t                      |  可以使用“任何”身份验证方法       |\\n|-b/--cookie \\\\<name=string/file> |       cookie字符串或文件读取位置  |\\n|    --basic                    |          使用HTTP基本验         |\\n|-B/--use-ascii\\t               |      使用ASCII /文本传输        |\\n|-c/--cookie-jar \\\\<file>\\t     |  操作结束后把cookie写入到这个文件中 |\\n|-C/--continue-at \\\\<offset>|断点续转|\\n|-d/--data \\\\<data>|HTTP POST方式传送数据|\\n| --data-ascii \\\\<data>|以ascii的方式post数据|\\n|--data-binary \\\\<data>|以二进制的方式post数据|\\n| --negotiate|使用HTTP身份验证|\\n|--digest|使用数字身份验证|\\n| --disable-eprt|禁止使用EPRT或LPRT|\\n|--disable-epsv|禁止使用EPSV|\\n|-D/--dump-header \\\\<file>|把header信息写入到该文件中|\\n|--egd-file \\\\<file>|为随机数据(SSL)设置EGD socket路径|\\n|--tcp-nodelay|使用TCP_NODELAY选项|\\n|-e/--referer|来源网址|\\n|-E/--cert \\\\<cert[:passwd]>|客户端证书文件和密码 (SSL)|\\n|--cert-type \\\\<type>|证书文件类型 (DER/PEM/ENG) (SSL)|\\n| --key \\\\<key>|私钥文件名 (SSL)|\\n| --key-type \\\\<type>|私钥文件类型 (DER/PEM/ENG) (SSL)|\\n|--pass \\\\<pass>|私钥密码 (SSL)|\\n| --engine \\\\<eng>|加密引擎使用 (SSL). \\\"--engine list\\\" for list|\\n| --cacert \\\\<file>|CA证书 (SSL)|\\n| --capath \\\\<directory>|CA目录 (made using c_rehash) to verify peer against (SSL)|\\n|--ciphers \\\\<list>|SSL密码|\\n|--compressed|要求返回是压缩的形势 (using deflate or gzip)|\\n|--connect-timeout \\\\<seconds>|设置最大请求时间|\\n|--create-dirs|建立本地目录的目录层次结构|\\n|--crlf|上传是把LF转变成CRLF|\\n|-f/--fail|连接失败时不显示http错误|\\n|--ftp-create-dirs|如果远程目录不存在，创建远程目录|\\n|--ftp-method [multicwd/nocwd/singlecwd]|控制CWD的使用|\\n| --ftp-pasv|使用 PASV/EPSV 代替端口|\\n|--ftp-skip-pasv-ip|使用PASV的时候,忽略该IP地址|\\n|--ftp-ssl|尝试用 SSL/TLS 来进行ftp数据传输|\\n|--ftp-ssl-reqd|要求用 SSL/TLS 来进行ftp数据传输|\\n|-F/--form \\\\<name=content>|模拟http表单提交数据|\\n|--form-string \\\\<name=string>|模拟http表单提交数据|\\n|-g/--globoff|禁用网址序列和范围使用{}和[]|\\n|-G/--get|以get的方式来发送数据|\\n|-H/--header \\\\<line>|自定义头信息传递给服务器|\\n|--ignore-content-length|忽略的HTTP头信息的长度|\\n|-i/--include|输出时包括protocol头信息|\\n|-I/--head|只显示请求头信息|\\n|-j/--junk-session-cookies|读取文件进忽略session cookie|\\n|--interface \\\\<interface>|使用指定网络接口/地址|\\n|--krb4 \\\\<level>|使用指定安全级别的krb4|\\n|-k/--insecure|允许不使用证书到SSL站点|\\n|-K/--config|指定的配置文件读取|\\n|-l/--list-only|列出ftp目录下的文件名称|\\n|--limit-rate \\\\<rate>|设置传输速度|\\n|--local-port\\\\<NUM>|强制使用本地端口号|\\n|-m/--max-time \\\\<seconds>|设置最大传输时间|\\n| --max-redirs \\\\<num>|设置最大读取的目录数|\\n|--max-filesize \\\\<bytes>|设置最大下载的文件总量|\\n|-M/--manual|显示全手动|\\n|-n/--netrc|从netrc文件中读取用户名和密码|\\n|--netrc-optional|使用 .netrc 或者 URL来覆盖-n|\\n|--ntlm|使用 HTTP NTLM 身份验证|\\n|-N/--no-buffer|禁用缓冲输出|\\n|-o/--output|把输出写到该文件中|\\n|-O/--remote-name|把输出写到该文件中，保留远程文件的文件名|\\n|-p/--proxytunnel|使用HTTP代理|\\n|--proxy-anyauth|选择任一代理身份验证方法|\\n|--proxy-basic|在代理上使用基本身份验证|\\n|--proxy-digest|在代理上使用数字身份验证|\\n|--proxy-ntlm|在代理上使用ntlm身份验证|\\n|-P/--ftp-port \\\\<address>|使用端口地址，而不是使用PASV|\\n|-q|作为第一个参数，关闭 .curlrc|\\n|-Q/--quote \\\\<cmd>|文件传输前，发送命令到服务器|\\n|-r/--range \\\\<range>|检索来自HTTP/1.1或FTP服务器字节范围|\\n|--range-file|读取（SSL）的随机文件|\\n|-R/--remote-time|在本地生成文件时，保留远程文件时间|\\n|--retry \\\\<num>|传输出现问题时，重试的次数|\\n|--retry-delay \\\\<seconds>|传输出现问题时，设置重试间隔时间|\\n|--retry-max-time \\\\<seconds>\\t|传输出现问题时，设置最大重试时间|\\n|-s/--silent|静默模式。不输出任何东西|\\n|-S/--show-error|显示错误|\\n|--socks4 \\\\<host[:port]>|用socks4代理给定主机和端口|\\n|--socks5 \\\\<host[:port]>|用socks5代理给定主机和端口|\\n| --stderr \\\\<file>||\\n|-t/--telnet-option \\\\<OPT=val>|Telnet选项设置|\\n|--trace \\\\<file>|对指定文件进行debug|\\n| --trace-ascii \\\\<file>|Like --跟踪但没有hex输出|\\n|--trace-time|跟踪/详细输出时，添加时间戳|\\n|-T/--upload-file \\\\<file>|上传文件|\\n|--url \\\\<URL>|Spet URL to work with|\\n|-u/--user \\\\<user[:password]>|设置服务器的用户和密码|\\n|-U/--proxy-user \\\\<user[:password]>|设置代理用户名和密码|\\n|-w/--write-out [format]|什么输出完成后|\\n|-x/--proxy \\\\<host[:port]>|在给定的端口上使用HTTP代理|\\n|-X/--request \\\\<command>|指定什么命令|\\n|-y/--speed-time|放弃限速所要的时间，默认为30|\\n|-Y/--speed-limit|停止传输速度的限制，速度时间|\\n\\n## 实例\\n### 文件下载\\ncurl命令可以用来执行下载、发送各种HTTP请求，指定HTTP头部等操作。如果系统没有curl可以使用`yum install curl`安装，也可以下载安装。curl是将下载文件输出到stdout，将进度信息输出到stderr，不显示进度信息使用`--silent`选项。\\n\\n```\\ncurl URL --silent\\n```\\n\\n这条命令是将下载文件输出到终端，所有下载的数据都被写入到stdout。\\n\\n使用选项`-O`将下载的数据写入到文件，必须使用文件的绝对地址：\\n\\n```\\ncurl http://man.linuxde.net/text.iso --silent -O\\n```\\n\\n选项`-o`将下载数据写入到指定名称的文件中，并使用`--progress`显示进度条：\\n\\n```\\ncurl http://man.linuxde.net/test.iso -o filename.iso --progress\\n######################################### 100.0%\\n```\\n\\n### 断点续传\\n\\ncurl能够从特定的文件偏移处继续下载，它可以通过指定一个便宜量来下载部分文件：\\n\\n```\\ncurl URL/File -C 偏移量\\n\\n#偏移量是以字节为单位的整数，如果让curl自动推断出正确的续传位置使用-C -：\\ncurl -C -URL\\n```\\n\\n### 使用curl设置参照页字符串\\n参照页是位于HTTP头部中的一个字符串，用来表示用户是从哪个页面到达当前页面的，如果用户点击网页A中的某个连接，那么用户就会跳转到B网页，网页B头部的参照页字符串就包含网页A的URL。\\n\\n使用`--referer`选项指定参照页字符串：\\n\\t\\t\\t\\n```\\ncurl --referer http://www.google.com http://man.linuxde.net\\n```\\n\\n### 用curl设置cookies\\n\\n使用`--cookie \\\"COKKIES\\\"`选项来指定cookie，多个cookie使用分号分隔：\\n\\n```\\ncurl http://man.linuxde.net --cookie \\\"user=root;pass=123456\\\"\\n```\\n\\n将cookie另存为一个文件，使用`--cookie-jar`选项：\\n\\n```\\ncurl URL --cookie-jar cookie_file\\n```\\n\\n### 用curl设置用户代理字符串\\n有些网站访问会提示只能使用IE浏览器来访问，这是因为这些网站设置了检查用户代理，可以使用curl把用户代理设置为IE，这样就可以访问了。使用`--user-agent`或者`-A`选项：\\n\\n```\\ncurl URL --user-agent \\\"Mozilla/5.0\\\"\\ncurl URL -A \\\"Mozilla/5.0\\\"\\n```\\n\\n其他HTTP头部信息也可以使用curl来发送，使用`-H`\\\"头部信息\\\" 传递多个头部信息，例如：\\n\\n```\\ncurl -H \\\"Host:man.linuxde.net\\\" -H \\\"accept-language:zh-cn\\\" URL\\n```\\n\\n### curl的带宽控制和下载配额\\n使用`--limit-rate`限制curl的下载速度：\\n\\n```\\ncurl URL --limit-rate 50k\\n```\\n\\n命令中用k（千字节）和m（兆字节）指定下载速度限制。\\n\\n使用`--max-filesize`指定可下载的最大文件大小：\\n\\n```\\ncurl URL --max-filesize bytes\\n```\\n\\n如果文件大小超出限制，命令则返回一个非0退出码，如果命令正常则返回0。\\n\\n### 用curl进行认证\\n\\n使用curl选项 -u 可以完成HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\\n\\n```\\ncurl -u user:pwd http://man.linuxde.net\\ncurl -u user http://man.linuxde.net\\n```\\n\\n### 只打印响应头部信息\\n\\n通过`-I`或者`-head`可以只打印出HTTP头部信息：\\n\\n```\\n[root@localhost text]# curl -I http://man.linuxde.net\\nHTTP/1.1 200 OK\\nServer: nginx/1.2.5\\ndate: Mon, 10 Dec 2012 09:24:34 GMT\\nContent-Type: text/html; charset=UTF-8\\nConnection: keep-alive\\nVary: Accept-Encoding\\nX-Pingback: http://man.linuxde.net/xmlrpc.php\\n```\\n\\n[原文地址](http://man.linuxde.net/curl)\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-18 10:10:07\n---\n\ncurl命令是一个利用URL规则在命令行下工作的文件传输工具。它支持文件的上传和下载，所以是综合传输工具，但按传统，习惯称curl为下载工具。作为一款强力工具，curl支持包括HTTP、HTTPS、ftp等众多协议，还支持POST、cookies、认证、从指定偏移处下载部分文件、用户代理字符串、限速、文件大小、进度条等特征。做网页处理流程和数据检索自动化，curl可以祝一臂之力。\n\n## 语法\n\n```\ncurl(选项)(参数)\n```\n<!-- more -->\n\n## 选项\n|             选项               |              含义             |\n|-------------------------------|-------------------------------|\n| -a/--append\t                   | 上传文件时，附加到目标文件        |\n|-A/--user-agent \\<string>\t     | 设置用户代理发送给服务器           |\n|-anyauth\t                      |  可以使用“任何”身份验证方法       |\n|-b/--cookie \\<name=string/file> |       cookie字符串或文件读取位置  |\n|    --basic                    |          使用HTTP基本验         |\n|-B/--use-ascii\t               |      使用ASCII /文本传输        |\n|-c/--cookie-jar \\<file>\t     |  操作结束后把cookie写入到这个文件中 |\n|-C/--continue-at \\<offset>|断点续转|\n|-d/--data \\<data>|HTTP POST方式传送数据|\n| --data-ascii \\<data>|以ascii的方式post数据|\n|--data-binary \\<data>|以二进制的方式post数据|\n| --negotiate|使用HTTP身份验证|\n|--digest|使用数字身份验证|\n| --disable-eprt|禁止使用EPRT或LPRT|\n|--disable-epsv|禁止使用EPSV|\n|-D/--dump-header \\<file>|把header信息写入到该文件中|\n|--egd-file \\<file>|为随机数据(SSL)设置EGD socket路径|\n|--tcp-nodelay|使用TCP_NODELAY选项|\n|-e/--referer|来源网址|\n|-E/--cert \\<cert[:passwd]>|客户端证书文件和密码 (SSL)|\n|--cert-type \\<type>|证书文件类型 (DER/PEM/ENG) (SSL)|\n| --key \\<key>|私钥文件名 (SSL)|\n| --key-type \\<type>|私钥文件类型 (DER/PEM/ENG) (SSL)|\n|--pass \\<pass>|私钥密码 (SSL)|\n| --engine \\<eng>|加密引擎使用 (SSL). \"--engine list\" for list|\n| --cacert \\<file>|CA证书 (SSL)|\n| --capath \\<directory>|CA目录 (made using c_rehash) to verify peer against (SSL)|\n|--ciphers \\<list>|SSL密码|\n|--compressed|要求返回是压缩的形势 (using deflate or gzip)|\n|--connect-timeout \\<seconds>|设置最大请求时间|\n|--create-dirs|建立本地目录的目录层次结构|\n|--crlf|上传是把LF转变成CRLF|\n|-f/--fail|连接失败时不显示http错误|\n|--ftp-create-dirs|如果远程目录不存在，创建远程目录|\n|--ftp-method [multicwd/nocwd/singlecwd]|控制CWD的使用|\n| --ftp-pasv|使用 PASV/EPSV 代替端口|\n|--ftp-skip-pasv-ip|使用PASV的时候,忽略该IP地址|\n|--ftp-ssl|尝试用 SSL/TLS 来进行ftp数据传输|\n|--ftp-ssl-reqd|要求用 SSL/TLS 来进行ftp数据传输|\n|-F/--form \\<name=content>|模拟http表单提交数据|\n|--form-string \\<name=string>|模拟http表单提交数据|\n|-g/--globoff|禁用网址序列和范围使用{}和[]|\n|-G/--get|以get的方式来发送数据|\n|-H/--header \\<line>|自定义头信息传递给服务器|\n|--ignore-content-length|忽略的HTTP头信息的长度|\n|-i/--include|输出时包括protocol头信息|\n|-I/--head|只显示请求头信息|\n|-j/--junk-session-cookies|读取文件进忽略session cookie|\n|--interface \\<interface>|使用指定网络接口/地址|\n|--krb4 \\<level>|使用指定安全级别的krb4|\n|-k/--insecure|允许不使用证书到SSL站点|\n|-K/--config|指定的配置文件读取|\n|-l/--list-only|列出ftp目录下的文件名称|\n|--limit-rate \\<rate>|设置传输速度|\n|--local-port\\<NUM>|强制使用本地端口号|\n|-m/--max-time \\<seconds>|设置最大传输时间|\n| --max-redirs \\<num>|设置最大读取的目录数|\n|--max-filesize \\<bytes>|设置最大下载的文件总量|\n|-M/--manual|显示全手动|\n|-n/--netrc|从netrc文件中读取用户名和密码|\n|--netrc-optional|使用 .netrc 或者 URL来覆盖-n|\n|--ntlm|使用 HTTP NTLM 身份验证|\n|-N/--no-buffer|禁用缓冲输出|\n|-o/--output|把输出写到该文件中|\n|-O/--remote-name|把输出写到该文件中，保留远程文件的文件名|\n|-p/--proxytunnel|使用HTTP代理|\n|--proxy-anyauth|选择任一代理身份验证方法|\n|--proxy-basic|在代理上使用基本身份验证|\n|--proxy-digest|在代理上使用数字身份验证|\n|--proxy-ntlm|在代理上使用ntlm身份验证|\n|-P/--ftp-port \\<address>|使用端口地址，而不是使用PASV|\n|-q|作为第一个参数，关闭 .curlrc|\n|-Q/--quote \\<cmd>|文件传输前，发送命令到服务器|\n|-r/--range \\<range>|检索来自HTTP/1.1或FTP服务器字节范围|\n|--range-file|读取（SSL）的随机文件|\n|-R/--remote-time|在本地生成文件时，保留远程文件时间|\n|--retry \\<num>|传输出现问题时，重试的次数|\n|--retry-delay \\<seconds>|传输出现问题时，设置重试间隔时间|\n|--retry-max-time \\<seconds>\t|传输出现问题时，设置最大重试时间|\n|-s/--silent|静默模式。不输出任何东西|\n|-S/--show-error|显示错误|\n|--socks4 \\<host[:port]>|用socks4代理给定主机和端口|\n|--socks5 \\<host[:port]>|用socks5代理给定主机和端口|\n| --stderr \\<file>||\n|-t/--telnet-option \\<OPT=val>|Telnet选项设置|\n|--trace \\<file>|对指定文件进行debug|\n| --trace-ascii \\<file>|Like --跟踪但没有hex输出|\n|--trace-time|跟踪/详细输出时，添加时间戳|\n|-T/--upload-file \\<file>|上传文件|\n|--url \\<URL>|Spet URL to work with|\n|-u/--user \\<user[:password]>|设置服务器的用户和密码|\n|-U/--proxy-user \\<user[:password]>|设置代理用户名和密码|\n|-w/--write-out [format]|什么输出完成后|\n|-x/--proxy \\<host[:port]>|在给定的端口上使用HTTP代理|\n|-X/--request \\<command>|指定什么命令|\n|-y/--speed-time|放弃限速所要的时间，默认为30|\n|-Y/--speed-limit|停止传输速度的限制，速度时间|\n\n## 实例\n### 文件下载\ncurl命令可以用来执行下载、发送各种HTTP请求，指定HTTP头部等操作。如果系统没有curl可以使用`yum install curl`安装，也可以下载安装。curl是将下载文件输出到stdout，将进度信息输出到stderr，不显示进度信息使用`--silent`选项。\n\n```\ncurl URL --silent\n```\n\n这条命令是将下载文件输出到终端，所有下载的数据都被写入到stdout。\n\n使用选项`-O`将下载的数据写入到文件，必须使用文件的绝对地址：\n\n```\ncurl http://man.linuxde.net/text.iso --silent -O\n```\n\n选项`-o`将下载数据写入到指定名称的文件中，并使用`--progress`显示进度条：\n\n```\ncurl http://man.linuxde.net/test.iso -o filename.iso --progress\n######################################### 100.0%\n```\n\n### 断点续传\n\ncurl能够从特定的文件偏移处继续下载，它可以通过指定一个便宜量来下载部分文件：\n\n```\ncurl URL/File -C 偏移量\n\n#偏移量是以字节为单位的整数，如果让curl自动推断出正确的续传位置使用-C -：\ncurl -C -URL\n```\n\n### 使用curl设置参照页字符串\n参照页是位于HTTP头部中的一个字符串，用来表示用户是从哪个页面到达当前页面的，如果用户点击网页A中的某个连接，那么用户就会跳转到B网页，网页B头部的参照页字符串就包含网页A的URL。\n\n使用`--referer`选项指定参照页字符串：\n\t\t\t\n```\ncurl --referer http://www.google.com http://man.linuxde.net\n```\n\n### 用curl设置cookies\n\n使用`--cookie \"COKKIES\"`选项来指定cookie，多个cookie使用分号分隔：\n\n```\ncurl http://man.linuxde.net --cookie \"user=root;pass=123456\"\n```\n\n将cookie另存为一个文件，使用`--cookie-jar`选项：\n\n```\ncurl URL --cookie-jar cookie_file\n```\n\n### 用curl设置用户代理字符串\n有些网站访问会提示只能使用IE浏览器来访问，这是因为这些网站设置了检查用户代理，可以使用curl把用户代理设置为IE，这样就可以访问了。使用`--user-agent`或者`-A`选项：\n\n```\ncurl URL --user-agent \"Mozilla/5.0\"\ncurl URL -A \"Mozilla/5.0\"\n```\n\n其他HTTP头部信息也可以使用curl来发送，使用`-H`\"头部信息\" 传递多个头部信息，例如：\n\n```\ncurl -H \"Host:man.linuxde.net\" -H \"accept-language:zh-cn\" URL\n```\n\n### curl的带宽控制和下载配额\n使用`--limit-rate`限制curl的下载速度：\n\n```\ncurl URL --limit-rate 50k\n```\n\n命令中用k（千字节）和m（兆字节）指定下载速度限制。\n\n使用`--max-filesize`指定可下载的最大文件大小：\n\n```\ncurl URL --max-filesize bytes\n```\n\n如果文件大小超出限制，命令则返回一个非0退出码，如果命令正常则返回0。\n\n### 用curl进行认证\n\n使用curl选项 -u 可以完成HTTP或者FTP的认证，可以指定密码，也可以不指定密码在后续操作中输入密码：\n\n```\ncurl -u user:pwd http://man.linuxde.net\ncurl -u user http://man.linuxde.net\n```\n\n### 只打印响应头部信息\n\n通过`-I`或者`-head`可以只打印出HTTP头部信息：\n\n```\n[root@localhost text]# curl -I http://man.linuxde.net\nHTTP/1.1 200 OK\nServer: nginx/1.2.5\ndate: Mon, 10 Dec 2012 09:24:34 GMT\nContent-Type: text/html; charset=UTF-8\nConnection: keep-alive\nVary: Accept-Encoding\nX-Pingback: http://man.linuxde.net/xmlrpc.php\n```\n\n[原文地址](http://man.linuxde.net/curl)","slug":"curl命令","published":1,"updated":"2019-03-23T10:23:55.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eix001sgyav8lvhy8yg"},{"title":"dnsmasq.conf 配置","originContent":"这个文档里说的比较详细：\n<!-- more -->\n```\n##############################################################################\n#\n#        DNS 选项\n#\n##############################################################################\n# 不加载本地的 /etc/hosts 文件\n#no-hosts\n# 添加读取额外的 hosts 文件路径，可以多次指定。如果指定为目录，则读取目录中的所有文件。\n#addn-hosts=/etc/hosts\n# 读取目录中的所有文件，文件更新将自动读取\n#hostsdir=<path>\n# 例如，/etc/hosts中的os01将扩展成os01.example.com\n#expand-hosts\n \n##############################################################################\n# 缓存时间设置，一般不需要设置\n# 本地 hosts 文件的缓存时间，通常不要求缓存本地，这样更改hosts文件后就即时生效。\n#local-ttl=3600\n# 同 local-ttl 仅影响 DHCP 租约\n#dhcp-ttl=<time>\n# 对于上游返回的值没有ttl时，dnsmasq给一个默认的ttl，一般不需要设置，\n#neg-ttl=<time>\n# 指定返回给客户端的ttl时间，一般不需要设置\n#max-ttl=<time>\n# 设置在缓存中的条目的最大 TTL。\n#max-cache-ttl=<time>\n# 不需要设置，除非你知道你在做什么。\n#min-cache-ttl=<time>\n# 一般不需要设置\n#auth-ttl=<time>\n \n##############################################################################\n# 记录dns查询日志\n#log-queries\n# 设置日志记录器，‘-‘ 为 stderr，也可以是文件路径。默认为：DAEMON，调试时使用 LOCAL0。\n#log-facility=<facility>\n#log-facility=/var/log/dnsmasq/dnsmasq.log\n# 异步log，缓解阻塞，提高性能。默认为5，最大100。\n#log-async[=<lines>]\n#log-async=50\n \n##############################################################################\n# 指定用户和组\n#user=nobody\n#group=nobody\n \n##############################################################################\n# 指定DNS的端口，默认53，设置 port=0 将完全禁用 DNS 功能，仅使用 DHCP/TFTP\n#port=53\n# 指定 EDNS.0 UDP 包的最大尺寸，默认为 RFC5625 推荐的 edns-packet-max=4096\n#edns-packet-max=<size>\n# 指定向上游查询的 UDP 端口，默认是随机端口，指定后降低安全性、加快速度、减少资源消耗。\n# 设置为 0 有操作系统分配。\nquery-port=53535\n# 指定向上游查询的 UDP 端口范围，方便防火墙设置。\n#min-port=<port>\n#max-port=<port>\n# 指定接口，指定后同时附加 lo 接口，可以使用‘*‘通配符\n#interface=wlp2s0\n# 指定排除的接口，排除高优先级，可以使用‘*‘通配符\n#except-interface=\n# 启用 DNS 验证模式\n#auth-server=<domain>,<interface>|<ip-address>\n# 仅接收同一子网的 DNS 请求，仅在未指定 interface、except-interface、listen-address \n# 或者 auth-server 时有效。\n#local-service\n# 指定不提供 DHCP 或 TFTP 服务的接口，仅提供 DNS 服务\n#no-dhcp-interface=enp3s0\n# 指定IP地址，可以多次指定。下面两行跟指定接口的作用类似。\n#listen-address=192.168.10.254\n#listen-address=127.0.0.1\n# 绑定接口，开启此项将仅监听指定的接口。\n#bind-interfaces\n# 对于新添加的接口也进行绑定。\n#bind-dynamic\n \n##############################################################################\n# 如果 hosts 中的主机有多个 IP 地址，仅返回对应子网的 IP 地址。\n#localise-queries\n# 如果反向查找的是私有地址例如192.168.X.X，仅从 hosts 文件查找，不再转发到上游服务器\n#bogus-priv\n# 对于任何被解析到此IP的域名，使其解析失效，可以多次指定\n#bogus-nxdomain=64.94.110.11\n# 忽略指定的 DNS 响应服务器地址，例如 1.1.1.1 为伪造的 dns 服务器并且响应速度非常快，\n# 指定 ignore-address=1.1.1.1 可以忽略它的响应信息，从而等待正确的响应结果。\n#ignore-address=<ipaddr>\n#filterwin2k\n \n##############################################################################\n# 指定 resolv-file 文件路径，默认/etc/resolv.conf\n#resolv-file=/etc/resolv.conf\n# 不读取 resolv-file 来确定上游服务器\n#no-resolv\n# 在编译时需要启用 DBus 支持。\n#enable-dbus[=<service-name>]\n# 严格按照resolv.conf中的顺序进行查找\n#strict-order\n# 向所有上有服务器发送查询，而不是一个。\n#all-servers\n#dns-loop-detect\n \n##############################################################################\n# 这项安全设置是拒绝解析包含私有 IP 地址的域名，\n# 这些IP地址包括如下私有地址范围：10.0.0.0/8、172.16.0.0/12、192.168.0.0/16。\n# 其初衷是要防止类似上游DNS服务器故意将某些域名解析成特定私有内网IP而劫持用户这样的安全攻击。\n# 直接在配置文件中注销 stop-dns-rebind 配置项从而禁用该功能。\n# 这个方法确实可以一劳永逸的解决解析内网 IP 地址的问题，但是我们也失去了这项安全保护的特性，\n# 所以在这里我不推荐这个办法。\n# 使用 rebind-domain-ok 进行特定配置，顾名思义该配置项可以有选择的忽略域名的 rebind 行为\n#stop-dns-rebind\n#rebind-localhost-ok\n#rebind-domain-ok=[<domain>]|[[/<domain>/[<domain>/]\n#rebind-domain-ok=/.dinghuangjie.com/.dhj.com/.harlinsu.com/.example.com/.test.com/.esderive.com/\n \n##############################################################################\n# 也不要检测 /etc/resolv.conf 的变化\n#no-poll\n# 重启后清空缓存\n#clear-on-reload\n# 完整的域名才向上游服务器查找，如果仅仅是主机名仅查找hosts文件\n#domain-needed\n \n##############################################################################\n# IP地址转换\n#alias=[<old-ip>]|[<start-ip>-<end-ip>],<new-ip>[,<mask>]\n##############################################################################\n#local=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=/example.com/192.168.10.252\n#rev-server=<ip-address>/<prefix-len>,<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n \n# 将任何属于 <domain> 域名解析成指定的 <ipaddr> 地址。\n# 也就是将 <domain> 及其所有子域名解析成指定的 <ipaddr> IPv4 或者 IPv6 地址，\n# 通常用于屏蔽特定的域名。\n# 一次只能指定一个 IPv4 或者 IPv6 地址，\n# 要同时返回 IPv4 和IPv6 地址，请多次指定 address= 选项。\n# 注意： /etc/hosts 以及 DHCP 租约将覆盖此项设置。\n#address=/<domain>/[domain/][<ipaddr>]\n \n#ipset=/<domain>/[domain/]<ipset>[,<ipset>]\n#mx-host=<mx name>[[,<hostname>],<preference>]\n#mx-target=<hostname>\n \n# SRV 记录\n#srv-host=<_service>.<_prot>.[<domain>],[<target>[,<port>[,<priority>[,<weight>]]]]\n \n# A, AAAA 和 PTR 记录 \n#host-record=<name>[,<name>....],[<IPv4-address>],[<IPv6-address>][,<TTL>]\n \n# TXT 记录\n#txt-record=<name>[[,<text>],<text>]\n \n# PTR 记录 \n#ptr-record=<name>[,<target>]\n \n#naptr-record=<name>,<order>,<preference>,<flags>,<service>,<regexp>[,<replacement>]\n \n# CNAME 别名记录\n#cname=<cname>,<target>[,<TTL>]\n \n \n#dns-rr=<name>,<RR-number>,[<hex data>]\n#interface-name=<name>,<interface>[/4|/6]\n#synth-domain=<domain>,<address range>[,<prefix>]\n#add-mac[=base64|text]\n#add-cpe-id=<string>\n#add-subnet[[=[<IPv4 address>/]<IPv4 prefix length>][,[<IPv6 address>/]<IPv6 prefix length>]]\n##############################################################################\n \n##############################################################################\n# 缓存条数，默认为150条，cache-size=0 禁用缓存。\ncache-size=1000\n# 不缓存未知域名缓存，默认情况下dnsmasq缓存未知域名并直接返回为客户端。\n#no-negcache\n# 指定DNS同属查询转发数量\ndns-forward-max=1000\n \n# 启用连接跟踪，读取 Linux 入栈 DNS 查询请求的连接跟踪标记，\n# 并且将上游返回的响应信息设置同样的标记。\n# 用于带宽控制和防火墙部署。\n# 此选项必须在编译时启用 conntrack 支持，并且内核正确配置并加载 conntrack。\n# 此选项不能与 query-port 同时使用。\n#conntrack\n \n \n##############################################################################\n#\n#        DHCP 选项\n#\n##############################################################################\n# 设置 DHCP 地址池，同时启用 DHCP 功能。\n# IPv4 <mode> 可指定为 static|proxy ，当 <mode> 指定为 static 时，\n# 需用 dhcp-host 手动分配地址池中的 IP 地址。\n# 当 <mode> 指定为 proxy 时，为指定的地址池提供 DHCP 代理。\n#dhcp-range=[tag:<tag>[,tag:<tag>],][set:<tag>,]<start-addr>[,<end-addr>][,<mode>][,<netmask>[,<broadcast>]][,<lease time>]\n#dhcp-range=172.16.0.2,172.16.0.250,255.255.255.0,1h\n#dhcp-range=192.168.10.150,192.168.10.180,static,255.255.255.0,1h\n \n# 根据 MAC 地址或 id 固定分配客户端的 IP 地址、主机名、租期。\n# IPv4 下指定 id:* 将忽略 DHCP 客户端的 ID ，仅根据 MAC 来进行 IP 地址分配。\n# 在读取 /etc/hosts 的情况，也可以根据 /etc/hosts 中的主机名分配对应 IP 地址。\n# 指定 ignore 将忽略指定客户端得 DHCP 请求。\n#dhcp-host=[<hwaddr>][,id:<client_id>|*][,set:<tag>][,<ipaddr>][,<hostname>][,<lease_time>][,ignore]\n#dhcp-hostsfile=<path>\n#dhcp-hostsdir=<path>\n# 读取 /etc/ethers 文件 与使用 dhcp-host 的作用相同。IPv6 无效。\n#read-ethers\n \n# 指定给 DHCP 客户端的选项信息，\n# 默认情况下 dnsmasq 将发送：子网掩码、广播地址、DNS 服务器地址、网关地址、域等信息。\n# 指定此选项也可覆盖这些默认值并且设置其他选项值。\n# 重要：可以使用 option:<option-name>或者 option号 来指定。\n# <option-name> 和 option号的对应关系可使用命令：\n# dnsmasq --help dhcp 以及 dnsmasq --help dhcp6 查看，这点很重要。\n# 例如设置网关参数，既可以使用 dhcp-option=3,192.168.4.4 也可以使用 dhcp-option = option:router,192.168.4.4。\n# 0.0.0.0 意味着当前运行 dnsmasq 的主机地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# [encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],] 有待继续研究。\n#dhcp-option=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],][<opt>|option:<opt-name>|option6:<opt>|option6:<opt-name>],[<value>[,<value>]]\n#dhcp-option-force=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],]<opt>,[<value>[,<value>]]\n#dhcp-optsfile=<path>\n#dhcp-optsdir=<path>\n#dhcp-option=3,1.2.3.4\n#dhcp-option=option:router,1.2.3.4\n#dhcp-option=option:router,192.168.10.254\n#dhcp-option=option:dns-server,192.168.10.254,221.12.1.227,221.12.33.227\n \n##############################################################################\n# (IPv4 only) 禁用重用服务器名称和文件字段作为额外的 dhcp-option 选项。\n# 一般情况下 dnsmasq 从 dhcp-boot 移出启动服务器和文件信息到 dhcp-option 选项中。\n# 这使得在 dhcp-option 选项封包中有额外的选项空间可用，但是会使老的客户端混淆。\n# 此选项将强制使用简单并安全的方式来避免此类情况。可以认为是一个兼容性选项。\n#dhcp-no-override\n \n##############################################################################\n# 配置 DHCP 中继。\n# <local address> 是运行 dnsmasq 的接口的 IP 地址。\n# 所有在 <local address> 接口上接收到的 DHCP 请求将中继到 <server address> 指定的远程 DHCP 服务器。\n# 可以多次配置此选项，使用同一个 <local address> 转发到多个不同的 <server address> 指定的远程 DHCP 服务器。\n# <server address> 仅允许使用 IP 地址，不能使用域名等其他格式。\n# 如果是 DHCPv6，<server address> 可以是 ALL_SERVERS 的多播地址 ff05::1:3 。\n# 在这种情况下必须指定接口 <interface> ，不能使用通配符，用于直接多播到对应的 DHCP 服务器所在的接口。\n# <interface> 指定了仅允许接收从 <interface> 接口的 DHCP 服务器相应信息。\n#dhcp-relay=<local address>,<server address>[,<interface>]\n \n##############################################################################\n# 设置标签\n#dhcp-vendorclass=set:<tag>,[enterprise:<IANA-enterprise number>,]<vendor-class>\n#dhcp-userclass=set:<tag>,<user-class>\n#dhcp-mac=set:<tag>,<MAC address>\n#dhcp-circuitid=set:<tag>,<circuit-id>\n#dhcp-remoteid=set:<tag>,<remote-id>\n#dhcp-subscrid=set:<tag>,<subscriber-id>\n#dhcp-match=set:<tag>,<option number>|option:<option name>|vi-encap:<enterprise>[,<value>]\n#tag-if=set:<tag>[,set:<tag>[,tag:<tag>[,tag:<tag>]]]\n \n#dhcp-proxy[=<ip addr>]......\n \n##############################################################################\n# 不分配匹配这些 tag:<tag> 的 DHCP 请求。\n#dhcp-ignore=tag:<tag>[,tag:<tag>]\n#dhcp-ignore-names[=tag:<tag>[,tag:<tag>]]\n#dhcp-generate-names=tag:<tag>[,tag:<tag>]\n# IPv4 only 使用广播与匹配 tag:<tag> 的客户端通信。一般用于兼容老的 BOOT 客户端。\n#dhcp-broadcast[=tag:<tag>[,tag:<tag>]] \n \n##############################################################################\n# IPv4 only 设置 DHCP 服务器返回的 BOOTP 选项，\n# <servername> <server address> 可选，\n# 如果未设置服务器名称将设为空，服务器地址设为 dnsmasq 的 IP 地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# 如果指定 <tftp_servername> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#dhcp-boot=[tag:<tag>,]<filename>,[<servername>[,<server address>|<tftp_servername>]]\n# 根据不同的类型使用不同的选项。\n# 使用示例：\n#        dhcp-match=set:EFI_x86-64,option:client-arch,9\n#        dhcp-boot=tag:EFI_x86-64,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Xscale,option:client-arch,8\n#        #dhcp-boot=tag:EFI_Xscale,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_BC,option:client-arch,7\n#        #dhcp-boot=tag:EFI_BC,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_IA32,option:client-arch,6\n#        #dhcp-boot=tag:EFI_IA32,uefi/grubx64.efi\n#        #dhcp-match=set:Intel_Lean_Client,option:client-arch,5\n#        #dhcp-boot=tag:Intel_Lean_Client,uefi/grubx64.efi\n#        #dhcp-match=set:Arc_x86,option:client-arch,4\n#        #dhcp-boot=tag:Arc_x86,uefi/grubx64.efi\n#        #dhcp-match=set:DEC_Alpha,option:client-arch,3\n#        #dhcp-boot=tag:DEC_Alpha,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Itanium,option:client-arch,2\n#        #dhcp-boot=tag:EFI_Itanium,uefi/grubx64.efi\n#        #dhcp-match=set:NEC/PC98,option:client-arch,1\n#        #dhcp-boot=tag:NEC/PC98,uefi/grubx64.efi\n#        dhcp-match=set:Intel_x86PC,option:client-arch,0\n#        dhcp-boot=tag:Intel_x86PC,pxelinux.0\n \n##############################################################################\n# DHCP 使用客户端的 MAC 地址的哈希值为客户端分配 IP 地址，\n# 通常情况下即使客户端使自己的租约到期，客户端的 IP 地址仍将长期保持稳定。\n# 在默认模式下，IP 地址是随机分配的。\n# 启用 dhcp-sequential-ip 选项将按顺序分配 IP 地址。\n# 在顺序分配模式下，客户端使租约到期更像是仅仅移动一下 IP 地址。\n# 在通常情况下不建议使用这种方式。\n#dhcp-sequential-ip\n \n##############################################################################\n# 多数情况下我们使用 PXE，只是简单的允许 PXE 客户端获取 IP 地址，\n# 然后 PXE 客户端下载 dhcp-boot 选项指定的文件并执行，也就是 BOOTP 的方式。\n# 然而在有适当配置的 DHCP 服务器支持的情况下，PXE 系统能够实现更复杂的功能。\n# pxe-service 选项可指定 PXE 环境的启动菜单。\n# 为不同的类型系统设定不同的启动菜单，并且覆盖 dhcp-boot 选项。\n# <CSA> 为客户端系统类型：x86PC, PC98, IA64_EFI, Alpha, Arc_x86, Intel_Lean_Client, \n# IA32_EFI, X86-64_EFI, Xscale_EFI, BC_EFI, ARM32_EFI 和 ARM64_EFI，其他类型可能为一个整数。\n# <basename> 引导 PXE 客户端使用 tftp 从 <server address> 或者 <server_name> 下载文件。\n#     注意：\"layer\" 后缀 (通常是 \".0\") 由 PXE 提供，也就是 PXE 客户端默认在文件名附加 .0 后缀。\n#     示例：pxe-service=x86PC, \"Install Linux\", pxelinux         （读取 pxelinux.0 文件并执行）\n#           pxe-service=x86PC, \"Install Linux\", pxelinux, 1.2.3.4（不适用于老的PXE）\n#     <bootservicetype> 整数，PXE 客户端将通过广播或者通过 <server address> \n#           或者 <server_name> 搜索对应类型的适合的启动服务。。\n#     示例：pxe-service=x86PC, \"Install windows from RIS server\", 1\n#           pxe-service=x86PC, \"Install windows from RIS server\", 1, 1.2.3.4\n#     未指定 <basename>、<bootservicetype> 或者 <bootservicetype> 为 “0”，将从本地启动。\n#     示例：pxe-service=x86PC, \"Boot from local disk\"\n#           pxe-service=x86PC, \"Boot from local disk\", 0\n# 如果指定 <server_name> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#pxe-service=[tag:<tag>,]<CSA>,<menu text>[,<basename>|<bootservicetype>][,<server address>|<server_name>]\n# 在 PXE 启动后弹出提示，<prompt> 为提示内容，<timeout> 为超时时间，为 0 则立即执行。\n# 如果未指定此选项，在有多个启动选项的情况下等待用户选择，不会超时。\n#pxe-prompt=[tag:<tag>,]<prompt>[,<timeout>]\n# 根据不同的类型使用不同的菜单，使用示例：\n#        #pxe-prompt=\"What system shall I netboot?\", 120\n#        # or with timeout before first available action is taken:\n#        pxe-prompt=\"Press F8 or Enter key for menu.\", 60\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode), boot from local\", 0\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode)\", pxelinux\n#        pxe-service=PC98, \"Now in PC98 mode\", PC98\n#        pxe-service=IA64_EFI, \"Now in IA64_EFI mode\", IA64_EFI\n#        pxe-service=Alpha, \"Now in Alpha mode\", Alpha\n#        pxe-service=Arc_x86, \"Now in Arc_x86 mode\", Arc_x86\n#        pxe-service=Intel_Lean_Client, \"Now in Intel_Lean_Client mode\", Intel_Lean_Client\n#        pxe-service=IA32_EFI, \"Now in IA32_EFI mode\", IA32_EFI\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode), boot from local\", 0\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode)\", grub/grub-x86_64.efi\n#        pxe-service=Xscale_EFI, \"Now in Xscale_EFI mode\", Xscale_EFI\n#        pxe-service=BC_EFI, \"Now in BC_EFI mode\", BC_EFI\n#        # CentOS7 系统不支持下列两个选项\n#        #pxe-service=ARM32_EFI,\"Now in ARM32_EFI mode\",ARM32_EFI\n#        #pxe-service=ARM64_EFI,\"Now in ARM64_EFI mode\",ARM64_EFI\n \n##############################################################################\n# 默认为150，即最多分配150个ip地址出去，最大1000个ip\n#dhcp-lease-max=150\n# (IPv4 only) 指定DHCP端口，默认为67和68。如果不指定则为1067和1068，单指定一个，第二个加1\n#dhcp-alternate-port[=<server port>[,<client port>]]\n# 谨慎使用此选项，避免 IP 地址浪费。(IPv4 only) 允许动态分配 IP 地址给 BOOTP 客户端。\n# 注意：BOOTP 客户端获取的 IP 地址是永久的，将无法再次分配给其他客户端。\n#bootp-dynamic[=<network-id>[,<network-id>]]\n# 谨慎使用此选项。\n# 默认情况下 DHCP 服务器使用 ping 的方式进行确保 IP 未被使用的情况下将 IP 地址分配出去。\n# 启用此选项将不使用 ping 进行确认。\n#no-ping\n \n##############################################################################\n# 记录额外的 dhcp 日志，记录所有发送给 DHCP 客户端的选项（option）以及标签（tag）信息\n#log-dhcp\n# 禁止记录日常操作日志，错误日志仍然记录。启用 log-dhcp 将覆盖下列选项。\n#quiet-dhcp\n#quiet-dhcp6\n#quiet-ra\n \n# 修改 DHCP 默认租约文件路径，默认情况下无需修改\n#dhcp-leasefile=/var/lib/dnsmasq/dnsmasq.leases\n# (IPv6 only)\n#dhcp-duid=<enterprise-id>,<uid>\n \n##############################################################################\n#dhcp-script=<path>\n#dhcp-luascript=<path>\n#dhcp-scriptuser=root\n#script-arp\n#leasefile-ro\n \n#bridge-interface=<interface>,<alias>[,<alias>]\n \n##############################################################################\n# 给 DHCP 服务器指定 domain 域名信息，也可以给对应的 IP 地址池指定域名。\n#     直接指定域名\n#     示例：domain=thekelleys.org.uk\n#     子网对应的域名\n#     示例：domain=wireless.thekelleys.org.uk,192.168.2.0/24\n#     ip范围对应的域名\n#     示例：domain=reserved.thekelleys.org.uk,192.68.3.100,192.168.3.200\n#domain=<domain>[,<address range>[,local]]\n# 在默认情况下 dnsmasq 插入普通的客户端主机名到 DNS 中。\n# 在这种情况下主机名必须唯一，即使两个客户端具有不同的域名后缀。\n# 如果第二个客户端使用了相同的主机名，DNS 查询将自动更新为第二个客户端的 IP 地址。\n# 如果设置了 dhcp-fqdn 选项，普通的主机名将不再插入到 DNS 中去，\n# 仅允许合格的具有域名后缀的主机名插入到 DNS 服务器中。\n# 指定此选项需同时指定不含 <address range> 地址范围的 domain 选项。\n#dhcp-fqdn\n# 通常情况下分配 DHCP 租约后，dnsmasq 设置 FQDN 选项告诉客户端不要尝试 DDNS 更新主机名与 IP 地址。\n# 这是因为  name-IP 已自动添加到 dnsmasq 的 DNS 视图中的。\n# 设置此选项将允许客户端 DDNS 更新，\n# 在 windows 下允许客户端更新 windows AD 服务器是非常有用的。\n# 参看  RFC 4702 。\n#dhcp-client-update\n \n#enable-ra\n#ra-param=<interface>,[high|low],[[<ra-interval>],<router lifetime>]\n \n \n##############################################################################\n#\n#        TFTP 选项\n#\n##############################################################################\n# 对于绝大多数的配置，仅需指定 enable-tftp 和 tftp-root 选项即可。\n# 是否启用内置的 tftp 服务器，可以指定多个逗号分隔的网络接口\n#enable-tftp[=<interface>[,<interface>]]\n#enable-tftp\n#enable-tftp=enp3s0,lo\n# 指定 tftp 的根目录，也就是寻找传输文件时使用的相对路径，可以附加接口，\n#tftp-root=<directory>[,<interface>]\n#tftp-root=/var/lib/tftpboot/\n# 如果取消注释，那么即使指定的 tftp-root 无法访问，仍然启动 tftp 服务。\n#tftp-no-fail\n# 附加客户端的 IP 地址作为文件路径。此选项仅在正确设置了 tftp-root 的情况下可用，\n# 示例：如果 tftp-root=/tftp，客户端为 192.168.1.15 请求 myfile.txt 文件时，\n# 将优先请求 /tftp/192.168.1.15/myfile.txt 文件， 其次是 /tftp/myfile.txt 文件。\n# 感觉没什么用。\n#tftp-unique-root\n# 启用安全模式，启用此选项，仅允许 tftp 进程访问属主为自己的文件。\n# 不启用此选项，允许访问所有 tftp 进程属主可读取的文件。\n# 如果 dnsmasq 是以 root 用户运行，tftp-secure 选项将允许访问全局可读的文件。\n# 一般情况下不推荐以 root 用户运行 dnsmasq。\n# 在指定了 tftp-root 的情况下并不是很重要。\n#tftp-secure\n# 将所有文件请求转换为小写。对于 Windows 客户端来说非常有用，建议开启此项。\n# 注意：dnsmasq 的 TFTP 服务器总是将文件路径中的“\\”转换为“/”。\n#tftp-lowercase\n# 允许最大的连接数，默认为 50 。\n# 如果将连接数设置的很大，需注意每个进程的最大文件描述符限制，详见文档手册。\n#tftp-max=<connections>\n#tftp-max=50\n# 设置传输时的 MTU 值，建议不设置或按需设置。\n# 如果设定的值大于网络接口的 MTU 值，将按照网络接口的 MTU 值自动分片传输（不推荐）。\n#tftp-mtu=<mtu size>\n# 停止 tftp 服务器与客户端协商 \"blocksize\" 选项。启用后，防止一些古怪的客户端出问题。\n#tftp-no-blocksize\n# 指定 tftp 的连接端口的范围，方便防火墙部署。\n# tftp 侦听在 69/udp ，连接端口默认是由系统自动分配的，\n# 非 root 用户运行时指定的连接端口号需大于 1025 最大 65535。\n#tftp-port-range=<start>,<end>\n###############################################################################\n#conf-dir=<directory>[,<file-extension>......]\n#conf-file=/etc/dnsmasq.more.conf\nconf-dir=/etc/dnsmasq.d\n#servers-file=<file>\n```","toc":false,"date":"2018-01-10T10:17:10.000Z","_content":"\n这个文档里说的比较详细：\n<!-- more -->\n```\n##############################################################################\n#\n#        DNS 选项\n#\n##############################################################################\n# 不加载本地的 /etc/hosts 文件\n#no-hosts\n# 添加读取额外的 hosts 文件路径，可以多次指定。如果指定为目录，则读取目录中的所有文件。\n#addn-hosts=/etc/hosts\n# 读取目录中的所有文件，文件更新将自动读取\n#hostsdir=<path>\n# 例如，/etc/hosts中的os01将扩展成os01.example.com\n#expand-hosts\n \n##############################################################################\n# 缓存时间设置，一般不需要设置\n# 本地 hosts 文件的缓存时间，通常不要求缓存本地，这样更改hosts文件后就即时生效。\n#local-ttl=3600\n# 同 local-ttl 仅影响 DHCP 租约\n#dhcp-ttl=<time>\n# 对于上游返回的值没有ttl时，dnsmasq给一个默认的ttl，一般不需要设置，\n#neg-ttl=<time>\n# 指定返回给客户端的ttl时间，一般不需要设置\n#max-ttl=<time>\n# 设置在缓存中的条目的最大 TTL。\n#max-cache-ttl=<time>\n# 不需要设置，除非你知道你在做什么。\n#min-cache-ttl=<time>\n# 一般不需要设置\n#auth-ttl=<time>\n \n##############################################################################\n# 记录dns查询日志\n#log-queries\n# 设置日志记录器，‘-‘ 为 stderr，也可以是文件路径。默认为：DAEMON，调试时使用 LOCAL0。\n#log-facility=<facility>\n#log-facility=/var/log/dnsmasq/dnsmasq.log\n# 异步log，缓解阻塞，提高性能。默认为5，最大100。\n#log-async[=<lines>]\n#log-async=50\n \n##############################################################################\n# 指定用户和组\n#user=nobody\n#group=nobody\n \n##############################################################################\n# 指定DNS的端口，默认53，设置 port=0 将完全禁用 DNS 功能，仅使用 DHCP/TFTP\n#port=53\n# 指定 EDNS.0 UDP 包的最大尺寸，默认为 RFC5625 推荐的 edns-packet-max=4096\n#edns-packet-max=<size>\n# 指定向上游查询的 UDP 端口，默认是随机端口，指定后降低安全性、加快速度、减少资源消耗。\n# 设置为 0 有操作系统分配。\nquery-port=53535\n# 指定向上游查询的 UDP 端口范围，方便防火墙设置。\n#min-port=<port>\n#max-port=<port>\n# 指定接口，指定后同时附加 lo 接口，可以使用‘*‘通配符\n#interface=wlp2s0\n# 指定排除的接口，排除高优先级，可以使用‘*‘通配符\n#except-interface=\n# 启用 DNS 验证模式\n#auth-server=<domain>,<interface>|<ip-address>\n# 仅接收同一子网的 DNS 请求，仅在未指定 interface、except-interface、listen-address \n# 或者 auth-server 时有效。\n#local-service\n# 指定不提供 DHCP 或 TFTP 服务的接口，仅提供 DNS 服务\n#no-dhcp-interface=enp3s0\n# 指定IP地址，可以多次指定。下面两行跟指定接口的作用类似。\n#listen-address=192.168.10.254\n#listen-address=127.0.0.1\n# 绑定接口，开启此项将仅监听指定的接口。\n#bind-interfaces\n# 对于新添加的接口也进行绑定。\n#bind-dynamic\n \n##############################################################################\n# 如果 hosts 中的主机有多个 IP 地址，仅返回对应子网的 IP 地址。\n#localise-queries\n# 如果反向查找的是私有地址例如192.168.X.X，仅从 hosts 文件查找，不再转发到上游服务器\n#bogus-priv\n# 对于任何被解析到此IP的域名，使其解析失效，可以多次指定\n#bogus-nxdomain=64.94.110.11\n# 忽略指定的 DNS 响应服务器地址，例如 1.1.1.1 为伪造的 dns 服务器并且响应速度非常快，\n# 指定 ignore-address=1.1.1.1 可以忽略它的响应信息，从而等待正确的响应结果。\n#ignore-address=<ipaddr>\n#filterwin2k\n \n##############################################################################\n# 指定 resolv-file 文件路径，默认/etc/resolv.conf\n#resolv-file=/etc/resolv.conf\n# 不读取 resolv-file 来确定上游服务器\n#no-resolv\n# 在编译时需要启用 DBus 支持。\n#enable-dbus[=<service-name>]\n# 严格按照resolv.conf中的顺序进行查找\n#strict-order\n# 向所有上有服务器发送查询，而不是一个。\n#all-servers\n#dns-loop-detect\n \n##############################################################################\n# 这项安全设置是拒绝解析包含私有 IP 地址的域名，\n# 这些IP地址包括如下私有地址范围：10.0.0.0/8、172.16.0.0/12、192.168.0.0/16。\n# 其初衷是要防止类似上游DNS服务器故意将某些域名解析成特定私有内网IP而劫持用户这样的安全攻击。\n# 直接在配置文件中注销 stop-dns-rebind 配置项从而禁用该功能。\n# 这个方法确实可以一劳永逸的解决解析内网 IP 地址的问题，但是我们也失去了这项安全保护的特性，\n# 所以在这里我不推荐这个办法。\n# 使用 rebind-domain-ok 进行特定配置，顾名思义该配置项可以有选择的忽略域名的 rebind 行为\n#stop-dns-rebind\n#rebind-localhost-ok\n#rebind-domain-ok=[<domain>]|[[/<domain>/[<domain>/]\n#rebind-domain-ok=/.dinghuangjie.com/.dhj.com/.harlinsu.com/.example.com/.test.com/.esderive.com/\n \n##############################################################################\n# 也不要检测 /etc/resolv.conf 的变化\n#no-poll\n# 重启后清空缓存\n#clear-on-reload\n# 完整的域名才向上游服务器查找，如果仅仅是主机名仅查找hosts文件\n#domain-needed\n \n##############################################################################\n# IP地址转换\n#alias=[<old-ip>]|[<start-ip>-<end-ip>],<new-ip>[,<mask>]\n##############################################################################\n#local=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=/example.com/192.168.10.252\n#rev-server=<ip-address>/<prefix-len>,<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n \n# 将任何属于 <domain> 域名解析成指定的 <ipaddr> 地址。\n# 也就是将 <domain> 及其所有子域名解析成指定的 <ipaddr> IPv4 或者 IPv6 地址，\n# 通常用于屏蔽特定的域名。\n# 一次只能指定一个 IPv4 或者 IPv6 地址，\n# 要同时返回 IPv4 和IPv6 地址，请多次指定 address= 选项。\n# 注意： /etc/hosts 以及 DHCP 租约将覆盖此项设置。\n#address=/<domain>/[domain/][<ipaddr>]\n \n#ipset=/<domain>/[domain/]<ipset>[,<ipset>]\n#mx-host=<mx name>[[,<hostname>],<preference>]\n#mx-target=<hostname>\n \n# SRV 记录\n#srv-host=<_service>.<_prot>.[<domain>],[<target>[,<port>[,<priority>[,<weight>]]]]\n \n# A, AAAA 和 PTR 记录 \n#host-record=<name>[,<name>....],[<IPv4-address>],[<IPv6-address>][,<TTL>]\n \n# TXT 记录\n#txt-record=<name>[[,<text>],<text>]\n \n# PTR 记录 \n#ptr-record=<name>[,<target>]\n \n#naptr-record=<name>,<order>,<preference>,<flags>,<service>,<regexp>[,<replacement>]\n \n# CNAME 别名记录\n#cname=<cname>,<target>[,<TTL>]\n \n \n#dns-rr=<name>,<RR-number>,[<hex data>]\n#interface-name=<name>,<interface>[/4|/6]\n#synth-domain=<domain>,<address range>[,<prefix>]\n#add-mac[=base64|text]\n#add-cpe-id=<string>\n#add-subnet[[=[<IPv4 address>/]<IPv4 prefix length>][,[<IPv6 address>/]<IPv6 prefix length>]]\n##############################################################################\n \n##############################################################################\n# 缓存条数，默认为150条，cache-size=0 禁用缓存。\ncache-size=1000\n# 不缓存未知域名缓存，默认情况下dnsmasq缓存未知域名并直接返回为客户端。\n#no-negcache\n# 指定DNS同属查询转发数量\ndns-forward-max=1000\n \n# 启用连接跟踪，读取 Linux 入栈 DNS 查询请求的连接跟踪标记，\n# 并且将上游返回的响应信息设置同样的标记。\n# 用于带宽控制和防火墙部署。\n# 此选项必须在编译时启用 conntrack 支持，并且内核正确配置并加载 conntrack。\n# 此选项不能与 query-port 同时使用。\n#conntrack\n \n \n##############################################################################\n#\n#        DHCP 选项\n#\n##############################################################################\n# 设置 DHCP 地址池，同时启用 DHCP 功能。\n# IPv4 <mode> 可指定为 static|proxy ，当 <mode> 指定为 static 时，\n# 需用 dhcp-host 手动分配地址池中的 IP 地址。\n# 当 <mode> 指定为 proxy 时，为指定的地址池提供 DHCP 代理。\n#dhcp-range=[tag:<tag>[,tag:<tag>],][set:<tag>,]<start-addr>[,<end-addr>][,<mode>][,<netmask>[,<broadcast>]][,<lease time>]\n#dhcp-range=172.16.0.2,172.16.0.250,255.255.255.0,1h\n#dhcp-range=192.168.10.150,192.168.10.180,static,255.255.255.0,1h\n \n# 根据 MAC 地址或 id 固定分配客户端的 IP 地址、主机名、租期。\n# IPv4 下指定 id:* 将忽略 DHCP 客户端的 ID ，仅根据 MAC 来进行 IP 地址分配。\n# 在读取 /etc/hosts 的情况，也可以根据 /etc/hosts 中的主机名分配对应 IP 地址。\n# 指定 ignore 将忽略指定客户端得 DHCP 请求。\n#dhcp-host=[<hwaddr>][,id:<client_id>|*][,set:<tag>][,<ipaddr>][,<hostname>][,<lease_time>][,ignore]\n#dhcp-hostsfile=<path>\n#dhcp-hostsdir=<path>\n# 读取 /etc/ethers 文件 与使用 dhcp-host 的作用相同。IPv6 无效。\n#read-ethers\n \n# 指定给 DHCP 客户端的选项信息，\n# 默认情况下 dnsmasq 将发送：子网掩码、广播地址、DNS 服务器地址、网关地址、域等信息。\n# 指定此选项也可覆盖这些默认值并且设置其他选项值。\n# 重要：可以使用 option:<option-name>或者 option号 来指定。\n# <option-name> 和 option号的对应关系可使用命令：\n# dnsmasq --help dhcp 以及 dnsmasq --help dhcp6 查看，这点很重要。\n# 例如设置网关参数，既可以使用 dhcp-option=3,192.168.4.4 也可以使用 dhcp-option = option:router,192.168.4.4。\n# 0.0.0.0 意味着当前运行 dnsmasq 的主机地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# [encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],] 有待继续研究。\n#dhcp-option=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],][<opt>|option:<opt-name>|option6:<opt>|option6:<opt-name>],[<value>[,<value>]]\n#dhcp-option-force=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],]<opt>,[<value>[,<value>]]\n#dhcp-optsfile=<path>\n#dhcp-optsdir=<path>\n#dhcp-option=3,1.2.3.4\n#dhcp-option=option:router,1.2.3.4\n#dhcp-option=option:router,192.168.10.254\n#dhcp-option=option:dns-server,192.168.10.254,221.12.1.227,221.12.33.227\n \n##############################################################################\n# (IPv4 only) 禁用重用服务器名称和文件字段作为额外的 dhcp-option 选项。\n# 一般情况下 dnsmasq 从 dhcp-boot 移出启动服务器和文件信息到 dhcp-option 选项中。\n# 这使得在 dhcp-option 选项封包中有额外的选项空间可用，但是会使老的客户端混淆。\n# 此选项将强制使用简单并安全的方式来避免此类情况。可以认为是一个兼容性选项。\n#dhcp-no-override\n \n##############################################################################\n# 配置 DHCP 中继。\n# <local address> 是运行 dnsmasq 的接口的 IP 地址。\n# 所有在 <local address> 接口上接收到的 DHCP 请求将中继到 <server address> 指定的远程 DHCP 服务器。\n# 可以多次配置此选项，使用同一个 <local address> 转发到多个不同的 <server address> 指定的远程 DHCP 服务器。\n# <server address> 仅允许使用 IP 地址，不能使用域名等其他格式。\n# 如果是 DHCPv6，<server address> 可以是 ALL_SERVERS 的多播地址 ff05::1:3 。\n# 在这种情况下必须指定接口 <interface> ，不能使用通配符，用于直接多播到对应的 DHCP 服务器所在的接口。\n# <interface> 指定了仅允许接收从 <interface> 接口的 DHCP 服务器相应信息。\n#dhcp-relay=<local address>,<server address>[,<interface>]\n \n##############################################################################\n# 设置标签\n#dhcp-vendorclass=set:<tag>,[enterprise:<IANA-enterprise number>,]<vendor-class>\n#dhcp-userclass=set:<tag>,<user-class>\n#dhcp-mac=set:<tag>,<MAC address>\n#dhcp-circuitid=set:<tag>,<circuit-id>\n#dhcp-remoteid=set:<tag>,<remote-id>\n#dhcp-subscrid=set:<tag>,<subscriber-id>\n#dhcp-match=set:<tag>,<option number>|option:<option name>|vi-encap:<enterprise>[,<value>]\n#tag-if=set:<tag>[,set:<tag>[,tag:<tag>[,tag:<tag>]]]\n \n#dhcp-proxy[=<ip addr>]......\n \n##############################################################################\n# 不分配匹配这些 tag:<tag> 的 DHCP 请求。\n#dhcp-ignore=tag:<tag>[,tag:<tag>]\n#dhcp-ignore-names[=tag:<tag>[,tag:<tag>]]\n#dhcp-generate-names=tag:<tag>[,tag:<tag>]\n# IPv4 only 使用广播与匹配 tag:<tag> 的客户端通信。一般用于兼容老的 BOOT 客户端。\n#dhcp-broadcast[=tag:<tag>[,tag:<tag>]] \n \n##############################################################################\n# IPv4 only 设置 DHCP 服务器返回的 BOOTP 选项，\n# <servername> <server address> 可选，\n# 如果未设置服务器名称将设为空，服务器地址设为 dnsmasq 的 IP 地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# 如果指定 <tftp_servername> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#dhcp-boot=[tag:<tag>,]<filename>,[<servername>[,<server address>|<tftp_servername>]]\n# 根据不同的类型使用不同的选项。\n# 使用示例：\n#        dhcp-match=set:EFI_x86-64,option:client-arch,9\n#        dhcp-boot=tag:EFI_x86-64,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Xscale,option:client-arch,8\n#        #dhcp-boot=tag:EFI_Xscale,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_BC,option:client-arch,7\n#        #dhcp-boot=tag:EFI_BC,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_IA32,option:client-arch,6\n#        #dhcp-boot=tag:EFI_IA32,uefi/grubx64.efi\n#        #dhcp-match=set:Intel_Lean_Client,option:client-arch,5\n#        #dhcp-boot=tag:Intel_Lean_Client,uefi/grubx64.efi\n#        #dhcp-match=set:Arc_x86,option:client-arch,4\n#        #dhcp-boot=tag:Arc_x86,uefi/grubx64.efi\n#        #dhcp-match=set:DEC_Alpha,option:client-arch,3\n#        #dhcp-boot=tag:DEC_Alpha,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Itanium,option:client-arch,2\n#        #dhcp-boot=tag:EFI_Itanium,uefi/grubx64.efi\n#        #dhcp-match=set:NEC/PC98,option:client-arch,1\n#        #dhcp-boot=tag:NEC/PC98,uefi/grubx64.efi\n#        dhcp-match=set:Intel_x86PC,option:client-arch,0\n#        dhcp-boot=tag:Intel_x86PC,pxelinux.0\n \n##############################################################################\n# DHCP 使用客户端的 MAC 地址的哈希值为客户端分配 IP 地址，\n# 通常情况下即使客户端使自己的租约到期，客户端的 IP 地址仍将长期保持稳定。\n# 在默认模式下，IP 地址是随机分配的。\n# 启用 dhcp-sequential-ip 选项将按顺序分配 IP 地址。\n# 在顺序分配模式下，客户端使租约到期更像是仅仅移动一下 IP 地址。\n# 在通常情况下不建议使用这种方式。\n#dhcp-sequential-ip\n \n##############################################################################\n# 多数情况下我们使用 PXE，只是简单的允许 PXE 客户端获取 IP 地址，\n# 然后 PXE 客户端下载 dhcp-boot 选项指定的文件并执行，也就是 BOOTP 的方式。\n# 然而在有适当配置的 DHCP 服务器支持的情况下，PXE 系统能够实现更复杂的功能。\n# pxe-service 选项可指定 PXE 环境的启动菜单。\n# 为不同的类型系统设定不同的启动菜单，并且覆盖 dhcp-boot 选项。\n# <CSA> 为客户端系统类型：x86PC, PC98, IA64_EFI, Alpha, Arc_x86, Intel_Lean_Client, \n# IA32_EFI, X86-64_EFI, Xscale_EFI, BC_EFI, ARM32_EFI 和 ARM64_EFI，其他类型可能为一个整数。\n# <basename> 引导 PXE 客户端使用 tftp 从 <server address> 或者 <server_name> 下载文件。\n#     注意：\"layer\" 后缀 (通常是 \".0\") 由 PXE 提供，也就是 PXE 客户端默认在文件名附加 .0 后缀。\n#     示例：pxe-service=x86PC, \"Install Linux\", pxelinux         （读取 pxelinux.0 文件并执行）\n#           pxe-service=x86PC, \"Install Linux\", pxelinux, 1.2.3.4（不适用于老的PXE）\n#     <bootservicetype> 整数，PXE 客户端将通过广播或者通过 <server address> \n#           或者 <server_name> 搜索对应类型的适合的启动服务。。\n#     示例：pxe-service=x86PC, \"Install windows from RIS server\", 1\n#           pxe-service=x86PC, \"Install windows from RIS server\", 1, 1.2.3.4\n#     未指定 <basename>、<bootservicetype> 或者 <bootservicetype> 为 “0”，将从本地启动。\n#     示例：pxe-service=x86PC, \"Boot from local disk\"\n#           pxe-service=x86PC, \"Boot from local disk\", 0\n# 如果指定 <server_name> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#pxe-service=[tag:<tag>,]<CSA>,<menu text>[,<basename>|<bootservicetype>][,<server address>|<server_name>]\n# 在 PXE 启动后弹出提示，<prompt> 为提示内容，<timeout> 为超时时间，为 0 则立即执行。\n# 如果未指定此选项，在有多个启动选项的情况下等待用户选择，不会超时。\n#pxe-prompt=[tag:<tag>,]<prompt>[,<timeout>]\n# 根据不同的类型使用不同的菜单，使用示例：\n#        #pxe-prompt=\"What system shall I netboot?\", 120\n#        # or with timeout before first available action is taken:\n#        pxe-prompt=\"Press F8 or Enter key for menu.\", 60\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode), boot from local\", 0\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode)\", pxelinux\n#        pxe-service=PC98, \"Now in PC98 mode\", PC98\n#        pxe-service=IA64_EFI, \"Now in IA64_EFI mode\", IA64_EFI\n#        pxe-service=Alpha, \"Now in Alpha mode\", Alpha\n#        pxe-service=Arc_x86, \"Now in Arc_x86 mode\", Arc_x86\n#        pxe-service=Intel_Lean_Client, \"Now in Intel_Lean_Client mode\", Intel_Lean_Client\n#        pxe-service=IA32_EFI, \"Now in IA32_EFI mode\", IA32_EFI\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode), boot from local\", 0\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode)\", grub/grub-x86_64.efi\n#        pxe-service=Xscale_EFI, \"Now in Xscale_EFI mode\", Xscale_EFI\n#        pxe-service=BC_EFI, \"Now in BC_EFI mode\", BC_EFI\n#        # CentOS7 系统不支持下列两个选项\n#        #pxe-service=ARM32_EFI,\"Now in ARM32_EFI mode\",ARM32_EFI\n#        #pxe-service=ARM64_EFI,\"Now in ARM64_EFI mode\",ARM64_EFI\n \n##############################################################################\n# 默认为150，即最多分配150个ip地址出去，最大1000个ip\n#dhcp-lease-max=150\n# (IPv4 only) 指定DHCP端口，默认为67和68。如果不指定则为1067和1068，单指定一个，第二个加1\n#dhcp-alternate-port[=<server port>[,<client port>]]\n# 谨慎使用此选项，避免 IP 地址浪费。(IPv4 only) 允许动态分配 IP 地址给 BOOTP 客户端。\n# 注意：BOOTP 客户端获取的 IP 地址是永久的，将无法再次分配给其他客户端。\n#bootp-dynamic[=<network-id>[,<network-id>]]\n# 谨慎使用此选项。\n# 默认情况下 DHCP 服务器使用 ping 的方式进行确保 IP 未被使用的情况下将 IP 地址分配出去。\n# 启用此选项将不使用 ping 进行确认。\n#no-ping\n \n##############################################################################\n# 记录额外的 dhcp 日志，记录所有发送给 DHCP 客户端的选项（option）以及标签（tag）信息\n#log-dhcp\n# 禁止记录日常操作日志，错误日志仍然记录。启用 log-dhcp 将覆盖下列选项。\n#quiet-dhcp\n#quiet-dhcp6\n#quiet-ra\n \n# 修改 DHCP 默认租约文件路径，默认情况下无需修改\n#dhcp-leasefile=/var/lib/dnsmasq/dnsmasq.leases\n# (IPv6 only)\n#dhcp-duid=<enterprise-id>,<uid>\n \n##############################################################################\n#dhcp-script=<path>\n#dhcp-luascript=<path>\n#dhcp-scriptuser=root\n#script-arp\n#leasefile-ro\n \n#bridge-interface=<interface>,<alias>[,<alias>]\n \n##############################################################################\n# 给 DHCP 服务器指定 domain 域名信息，也可以给对应的 IP 地址池指定域名。\n#     直接指定域名\n#     示例：domain=thekelleys.org.uk\n#     子网对应的域名\n#     示例：domain=wireless.thekelleys.org.uk,192.168.2.0/24\n#     ip范围对应的域名\n#     示例：domain=reserved.thekelleys.org.uk,192.68.3.100,192.168.3.200\n#domain=<domain>[,<address range>[,local]]\n# 在默认情况下 dnsmasq 插入普通的客户端主机名到 DNS 中。\n# 在这种情况下主机名必须唯一，即使两个客户端具有不同的域名后缀。\n# 如果第二个客户端使用了相同的主机名，DNS 查询将自动更新为第二个客户端的 IP 地址。\n# 如果设置了 dhcp-fqdn 选项，普通的主机名将不再插入到 DNS 中去，\n# 仅允许合格的具有域名后缀的主机名插入到 DNS 服务器中。\n# 指定此选项需同时指定不含 <address range> 地址范围的 domain 选项。\n#dhcp-fqdn\n# 通常情况下分配 DHCP 租约后，dnsmasq 设置 FQDN 选项告诉客户端不要尝试 DDNS 更新主机名与 IP 地址。\n# 这是因为  name-IP 已自动添加到 dnsmasq 的 DNS 视图中的。\n# 设置此选项将允许客户端 DDNS 更新，\n# 在 windows 下允许客户端更新 windows AD 服务器是非常有用的。\n# 参看  RFC 4702 。\n#dhcp-client-update\n \n#enable-ra\n#ra-param=<interface>,[high|low],[[<ra-interval>],<router lifetime>]\n \n \n##############################################################################\n#\n#        TFTP 选项\n#\n##############################################################################\n# 对于绝大多数的配置，仅需指定 enable-tftp 和 tftp-root 选项即可。\n# 是否启用内置的 tftp 服务器，可以指定多个逗号分隔的网络接口\n#enable-tftp[=<interface>[,<interface>]]\n#enable-tftp\n#enable-tftp=enp3s0,lo\n# 指定 tftp 的根目录，也就是寻找传输文件时使用的相对路径，可以附加接口，\n#tftp-root=<directory>[,<interface>]\n#tftp-root=/var/lib/tftpboot/\n# 如果取消注释，那么即使指定的 tftp-root 无法访问，仍然启动 tftp 服务。\n#tftp-no-fail\n# 附加客户端的 IP 地址作为文件路径。此选项仅在正确设置了 tftp-root 的情况下可用，\n# 示例：如果 tftp-root=/tftp，客户端为 192.168.1.15 请求 myfile.txt 文件时，\n# 将优先请求 /tftp/192.168.1.15/myfile.txt 文件， 其次是 /tftp/myfile.txt 文件。\n# 感觉没什么用。\n#tftp-unique-root\n# 启用安全模式，启用此选项，仅允许 tftp 进程访问属主为自己的文件。\n# 不启用此选项，允许访问所有 tftp 进程属主可读取的文件。\n# 如果 dnsmasq 是以 root 用户运行，tftp-secure 选项将允许访问全局可读的文件。\n# 一般情况下不推荐以 root 用户运行 dnsmasq。\n# 在指定了 tftp-root 的情况下并不是很重要。\n#tftp-secure\n# 将所有文件请求转换为小写。对于 Windows 客户端来说非常有用，建议开启此项。\n# 注意：dnsmasq 的 TFTP 服务器总是将文件路径中的“\\”转换为“/”。\n#tftp-lowercase\n# 允许最大的连接数，默认为 50 。\n# 如果将连接数设置的很大，需注意每个进程的最大文件描述符限制，详见文档手册。\n#tftp-max=<connections>\n#tftp-max=50\n# 设置传输时的 MTU 值，建议不设置或按需设置。\n# 如果设定的值大于网络接口的 MTU 值，将按照网络接口的 MTU 值自动分片传输（不推荐）。\n#tftp-mtu=<mtu size>\n# 停止 tftp 服务器与客户端协商 \"blocksize\" 选项。启用后，防止一些古怪的客户端出问题。\n#tftp-no-blocksize\n# 指定 tftp 的连接端口的范围，方便防火墙部署。\n# tftp 侦听在 69/udp ，连接端口默认是由系统自动分配的，\n# 非 root 用户运行时指定的连接端口号需大于 1025 最大 65535。\n#tftp-port-range=<start>,<end>\n###############################################################################\n#conf-dir=<directory>[,<file-extension>......]\n#conf-file=/etc/dnsmasq.more.conf\nconf-dir=/etc/dnsmasq.d\n#servers-file=<file>\n```","source":"_posts/dnsmasq.conf 配置.md","raw":"---\ntitle: dnsmasq.conf 配置\ntags:\n  - 运维\noriginContent: >-\n  这个文档里说的比较详细：\n\n  <!-- more -->\n\n  ```\n\n  ##############################################################################\n\n  #\n\n  #        DNS 选项\n\n  #\n\n  ##############################################################################\n\n  # 不加载本地的 /etc/hosts 文件\n\n  #no-hosts\n\n  # 添加读取额外的 hosts 文件路径，可以多次指定。如果指定为目录，则读取目录中的所有文件。\n\n  #addn-hosts=/etc/hosts\n\n  # 读取目录中的所有文件，文件更新将自动读取\n\n  #hostsdir=<path>\n\n  # 例如，/etc/hosts中的os01将扩展成os01.example.com\n\n  #expand-hosts\n   \n  ##############################################################################\n\n  # 缓存时间设置，一般不需要设置\n\n  # 本地 hosts 文件的缓存时间，通常不要求缓存本地，这样更改hosts文件后就即时生效。\n\n  #local-ttl=3600\n\n  # 同 local-ttl 仅影响 DHCP 租约\n\n  #dhcp-ttl=<time>\n\n  # 对于上游返回的值没有ttl时，dnsmasq给一个默认的ttl，一般不需要设置，\n\n  #neg-ttl=<time>\n\n  # 指定返回给客户端的ttl时间，一般不需要设置\n\n  #max-ttl=<time>\n\n  # 设置在缓存中的条目的最大 TTL。\n\n  #max-cache-ttl=<time>\n\n  # 不需要设置，除非你知道你在做什么。\n\n  #min-cache-ttl=<time>\n\n  # 一般不需要设置\n\n  #auth-ttl=<time>\n   \n  ##############################################################################\n\n  # 记录dns查询日志\n\n  #log-queries\n\n  # 设置日志记录器，‘-‘ 为 stderr，也可以是文件路径。默认为：DAEMON，调试时使用 LOCAL0。\n\n  #log-facility=<facility>\n\n  #log-facility=/var/log/dnsmasq/dnsmasq.log\n\n  # 异步log，缓解阻塞，提高性能。默认为5，最大100。\n\n  #log-async[=<lines>]\n\n  #log-async=50\n   \n  ##############################################################################\n\n  # 指定用户和组\n\n  #user=nobody\n\n  #group=nobody\n   \n  ##############################################################################\n\n  # 指定DNS的端口，默认53，设置 port=0 将完全禁用 DNS 功能，仅使用 DHCP/TFTP\n\n  #port=53\n\n  # 指定 EDNS.0 UDP 包的最大尺寸，默认为 RFC5625 推荐的 edns-packet-max=4096\n\n  #edns-packet-max=<size>\n\n  # 指定向上游查询的 UDP 端口，默认是随机端口，指定后降低安全性、加快速度、减少资源消耗。\n\n  # 设置为 0 有操作系统分配。\n\n  query-port=53535\n\n  # 指定向上游查询的 UDP 端口范围，方便防火墙设置。\n\n  #min-port=<port>\n\n  #max-port=<port>\n\n  # 指定接口，指定后同时附加 lo 接口，可以使用‘*‘通配符\n\n  #interface=wlp2s0\n\n  # 指定排除的接口，排除高优先级，可以使用‘*‘通配符\n\n  #except-interface=\n\n  # 启用 DNS 验证模式\n\n  #auth-server=<domain>,<interface>|<ip-address>\n\n  # 仅接收同一子网的 DNS 请求，仅在未指定 interface、except-interface、listen-address \n\n  # 或者 auth-server 时有效。\n\n  #local-service\n\n  # 指定不提供 DHCP 或 TFTP 服务的接口，仅提供 DNS 服务\n\n  #no-dhcp-interface=enp3s0\n\n  # 指定IP地址，可以多次指定。下面两行跟指定接口的作用类似。\n\n  #listen-address=192.168.10.254\n\n  #listen-address=127.0.0.1\n\n  # 绑定接口，开启此项将仅监听指定的接口。\n\n  #bind-interfaces\n\n  # 对于新添加的接口也进行绑定。\n\n  #bind-dynamic\n   \n  ##############################################################################\n\n  # 如果 hosts 中的主机有多个 IP 地址，仅返回对应子网的 IP 地址。\n\n  #localise-queries\n\n  # 如果反向查找的是私有地址例如192.168.X.X，仅从 hosts 文件查找，不再转发到上游服务器\n\n  #bogus-priv\n\n  # 对于任何被解析到此IP的域名，使其解析失效，可以多次指定\n\n  #bogus-nxdomain=64.94.110.11\n\n  # 忽略指定的 DNS 响应服务器地址，例如 1.1.1.1 为伪造的 dns 服务器并且响应速度非常快，\n\n  # 指定 ignore-address=1.1.1.1 可以忽略它的响应信息，从而等待正确的响应结果。\n\n  #ignore-address=<ipaddr>\n\n  #filterwin2k\n   \n  ##############################################################################\n\n  # 指定 resolv-file 文件路径，默认/etc/resolv.conf\n\n  #resolv-file=/etc/resolv.conf\n\n  # 不读取 resolv-file 来确定上游服务器\n\n  #no-resolv\n\n  # 在编译时需要启用 DBus 支持。\n\n  #enable-dbus[=<service-name>]\n\n  # 严格按照resolv.conf中的顺序进行查找\n\n  #strict-order\n\n  # 向所有上有服务器发送查询，而不是一个。\n\n  #all-servers\n\n  #dns-loop-detect\n   \n  ##############################################################################\n\n  # 这项安全设置是拒绝解析包含私有 IP 地址的域名，\n\n  # 这些IP地址包括如下私有地址范围：10.0.0.0/8、172.16.0.0/12、192.168.0.0/16。\n\n  # 其初衷是要防止类似上游DNS服务器故意将某些域名解析成特定私有内网IP而劫持用户这样的安全攻击。\n\n  # 直接在配置文件中注销 stop-dns-rebind 配置项从而禁用该功能。\n\n  # 这个方法确实可以一劳永逸的解决解析内网 IP 地址的问题，但是我们也失去了这项安全保护的特性，\n\n  # 所以在这里我不推荐这个办法。\n\n  # 使用 rebind-domain-ok 进行特定配置，顾名思义该配置项可以有选择的忽略域名的 rebind 行为\n\n  #stop-dns-rebind\n\n  #rebind-localhost-ok\n\n  #rebind-domain-ok=[<domain>]|[[/<domain>/[<domain>/]\n\n  #rebind-domain-ok=/.dinghuangjie.com/.dhj.com/.harlinsu.com/.example.com/.test.com/.esderive.com/\n   \n  ##############################################################################\n\n  # 也不要检测 /etc/resolv.conf 的变化\n\n  #no-poll\n\n  # 重启后清空缓存\n\n  #clear-on-reload\n\n  # 完整的域名才向上游服务器查找，如果仅仅是主机名仅查找hosts文件\n\n  #domain-needed\n   \n  ##############################################################################\n\n  # IP地址转换\n\n  #alias=[<old-ip>]|[<start-ip>-<end-ip>],<new-ip>[,<mask>]\n\n  ##############################################################################\n\n  #local=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n\n  #server=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n\n  #server=/example.com/192.168.10.252\n\n  #rev-server=<ip-address>/<prefix-len>,<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n   \n  # 将任何属于 <domain> 域名解析成指定的 <ipaddr> 地址。\n\n  # 也就是将 <domain> 及其所有子域名解析成指定的 <ipaddr> IPv4 或者 IPv6 地址，\n\n  # 通常用于屏蔽特定的域名。\n\n  # 一次只能指定一个 IPv4 或者 IPv6 地址，\n\n  # 要同时返回 IPv4 和IPv6 地址，请多次指定 address= 选项。\n\n  # 注意： /etc/hosts 以及 DHCP 租约将覆盖此项设置。\n\n  #address=/<domain>/[domain/][<ipaddr>]\n   \n  #ipset=/<domain>/[domain/]<ipset>[,<ipset>]\n\n  #mx-host=<mx name>[[,<hostname>],<preference>]\n\n  #mx-target=<hostname>\n   \n  # SRV 记录\n\n  #srv-host=<_service>.<_prot>.[<domain>],[<target>[,<port>[,<priority>[,<weight>]]]]\n   \n  # A, AAAA 和 PTR 记录 \n\n  #host-record=<name>[,<name>....],[<IPv4-address>],[<IPv6-address>][,<TTL>]\n   \n  # TXT 记录\n\n  #txt-record=<name>[[,<text>],<text>]\n   \n  # PTR 记录 \n\n  #ptr-record=<name>[,<target>]\n   \n  #naptr-record=<name>,<order>,<preference>,<flags>,<service>,<regexp>[,<replacement>]\n   \n  # CNAME 别名记录\n\n  #cname=<cname>,<target>[,<TTL>]\n   \n   \n  #dns-rr=<name>,<RR-number>,[<hex data>]\n\n  #interface-name=<name>,<interface>[/4|/6]\n\n  #synth-domain=<domain>,<address range>[,<prefix>]\n\n  #add-mac[=base64|text]\n\n  #add-cpe-id=<string>\n\n  #add-subnet[[=[<IPv4 address>/]<IPv4 prefix length>][,[<IPv6 address>/]<IPv6\n  prefix length>]]\n\n  ##############################################################################\n   \n  ##############################################################################\n\n  # 缓存条数，默认为150条，cache-size=0 禁用缓存。\n\n  cache-size=1000\n\n  # 不缓存未知域名缓存，默认情况下dnsmasq缓存未知域名并直接返回为客户端。\n\n  #no-negcache\n\n  # 指定DNS同属查询转发数量\n\n  dns-forward-max=1000\n   \n  # 启用连接跟踪，读取 Linux 入栈 DNS 查询请求的连接跟踪标记，\n\n  # 并且将上游返回的响应信息设置同样的标记。\n\n  # 用于带宽控制和防火墙部署。\n\n  # 此选项必须在编译时启用 conntrack 支持，并且内核正确配置并加载 conntrack。\n\n  # 此选项不能与 query-port 同时使用。\n\n  #conntrack\n   \n   \n  ##############################################################################\n\n  #\n\n  #        DHCP 选项\n\n  #\n\n  ##############################################################################\n\n  # 设置 DHCP 地址池，同时启用 DHCP 功能。\n\n  # IPv4 <mode> 可指定为 static|proxy ，当 <mode> 指定为 static 时，\n\n  # 需用 dhcp-host 手动分配地址池中的 IP 地址。\n\n  # 当 <mode> 指定为 proxy 时，为指定的地址池提供 DHCP 代理。\n\n  #dhcp-range=[tag:<tag>[,tag:<tag>],][set:<tag>,]<start-addr>[,<end-addr>][,<mode>][,<netmask>[,<broadcast>]][,<lease\n  time>]\n\n  #dhcp-range=172.16.0.2,172.16.0.250,255.255.255.0,1h\n\n  #dhcp-range=192.168.10.150,192.168.10.180,static,255.255.255.0,1h\n   \n  # 根据 MAC 地址或 id 固定分配客户端的 IP 地址、主机名、租期。\n\n  # IPv4 下指定 id:* 将忽略 DHCP 客户端的 ID ，仅根据 MAC 来进行 IP 地址分配。\n\n  # 在读取 /etc/hosts 的情况，也可以根据 /etc/hosts 中的主机名分配对应 IP 地址。\n\n  # 指定 ignore 将忽略指定客户端得 DHCP 请求。\n\n  #dhcp-host=[<hwaddr>][,id:<client_id>|*][,set:<tag>][,<ipaddr>][,<hostname>][,<lease_time>][,ignore]\n\n  #dhcp-hostsfile=<path>\n\n  #dhcp-hostsdir=<path>\n\n  # 读取 /etc/ethers 文件 与使用 dhcp-host 的作用相同。IPv6 无效。\n\n  #read-ethers\n   \n  # 指定给 DHCP 客户端的选项信息，\n\n  # 默认情况下 dnsmasq 将发送：子网掩码、广播地址、DNS 服务器地址、网关地址、域等信息。\n\n  # 指定此选项也可覆盖这些默认值并且设置其他选项值。\n\n  # 重要：可以使用 option:<option-name>或者 option号 来指定。\n\n  # <option-name> 和 option号的对应关系可使用命令：\n\n  # dnsmasq --help dhcp 以及 dnsmasq --help dhcp6 查看，这点很重要。\n\n  # 例如设置网关参数，既可以使用 dhcp-option=3,192.168.4.4 也可以使用 dhcp-option =\n  option:router,192.168.4.4。\n\n  # 0.0.0.0 意味着当前运行 dnsmasq 的主机地址。\n\n  # 如果指定了多个 tag:<tag> 必须同时匹配才行。\n\n  # [encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],] 有待继续研究。\n\n  #dhcp-option=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],][<opt>|option:<opt-name>|option6:<opt>|option6:<opt-name>],[<value>[,<value>]]\n\n  #dhcp-option-force=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],]<opt>,[<value>[,<value>]]\n\n  #dhcp-optsfile=<path>\n\n  #dhcp-optsdir=<path>\n\n  #dhcp-option=3,1.2.3.4\n\n  #dhcp-option=option:router,1.2.3.4\n\n  #dhcp-option=option:router,192.168.10.254\n\n  #dhcp-option=option:dns-server,192.168.10.254,221.12.1.227,221.12.33.227\n   \n  ##############################################################################\n\n  # (IPv4 only) 禁用重用服务器名称和文件字段作为额外的 dhcp-option 选项。\n\n  # 一般情况下 dnsmasq 从 dhcp-boot 移出启动服务器和文件信息到 dhcp-option 选项中。\n\n  # 这使得在 dhcp-option 选项封包中有额外的选项空间可用，但是会使老的客户端混淆。\n\n  # 此选项将强制使用简单并安全的方式来避免此类情况。可以认为是一个兼容性选项。\n\n  #dhcp-no-override\n   \n  ##############################################################################\n\n  # 配置 DHCP 中继。\n\n  # <local address> 是运行 dnsmasq 的接口的 IP 地址。\n\n  # 所有在 <local address> 接口上接收到的 DHCP 请求将中继到 <server address> 指定的远程 DHCP 服务器。\n\n  # 可以多次配置此选项，使用同一个 <local address> 转发到多个不同的 <server address> 指定的远程 DHCP 服务器。\n\n  # <server address> 仅允许使用 IP 地址，不能使用域名等其他格式。\n\n  # 如果是 DHCPv6，<server address> 可以是 ALL_SERVERS 的多播地址 ff05::1:3 。\n\n  # 在这种情况下必须指定接口 <interface> ，不能使用通配符，用于直接多播到对应的 DHCP 服务器所在的接口。\n\n  # <interface> 指定了仅允许接收从 <interface> 接口的 DHCP 服务器相应信息。\n\n  #dhcp-relay=<local address>,<server address>[,<interface>]\n   \n  ##############################################################################\n\n  # 设置标签\n\n  #dhcp-vendorclass=set:<tag>,[enterprise:<IANA-enterprise\n  number>,]<vendor-class>\n\n  #dhcp-userclass=set:<tag>,<user-class>\n\n  #dhcp-mac=set:<tag>,<MAC address>\n\n  #dhcp-circuitid=set:<tag>,<circuit-id>\n\n  #dhcp-remoteid=set:<tag>,<remote-id>\n\n  #dhcp-subscrid=set:<tag>,<subscriber-id>\n\n  #dhcp-match=set:<tag>,<option number>|option:<option\n  name>|vi-encap:<enterprise>[,<value>]\n\n  #tag-if=set:<tag>[,set:<tag>[,tag:<tag>[,tag:<tag>]]]\n   \n  #dhcp-proxy[=<ip addr>]......\n   \n  ##############################################################################\n\n  # 不分配匹配这些 tag:<tag> 的 DHCP 请求。\n\n  #dhcp-ignore=tag:<tag>[,tag:<tag>]\n\n  #dhcp-ignore-names[=tag:<tag>[,tag:<tag>]]\n\n  #dhcp-generate-names=tag:<tag>[,tag:<tag>]\n\n  # IPv4 only 使用广播与匹配 tag:<tag> 的客户端通信。一般用于兼容老的 BOOT 客户端。\n\n  #dhcp-broadcast[=tag:<tag>[,tag:<tag>]] \n   \n  ##############################################################################\n\n  # IPv4 only 设置 DHCP 服务器返回的 BOOTP 选项，\n\n  # <servername> <server address> 可选，\n\n  # 如果未设置服务器名称将设为空，服务器地址设为 dnsmasq 的 IP 地址。\n\n  # 如果指定了多个 tag:<tag> 必须同时匹配才行。\n\n  # 如果指定 <tftp_servername> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n\n  #dhcp-boot=[tag:<tag>,]<filename>,[<servername>[,<server\n  address>|<tftp_servername>]]\n\n  # 根据不同的类型使用不同的选项。\n\n  # 使用示例：\n\n  #        dhcp-match=set:EFI_x86-64,option:client-arch,9\n\n  #        dhcp-boot=tag:EFI_x86-64,uefi/grubx64.efi\n\n  #        #dhcp-match=set:EFI_Xscale,option:client-arch,8\n\n  #        #dhcp-boot=tag:EFI_Xscale,uefi/grubx64.efi\n\n  #        #dhcp-match=set:EFI_BC,option:client-arch,7\n\n  #        #dhcp-boot=tag:EFI_BC,uefi/grubx64.efi\n\n  #        #dhcp-match=set:EFI_IA32,option:client-arch,6\n\n  #        #dhcp-boot=tag:EFI_IA32,uefi/grubx64.efi\n\n  #        #dhcp-match=set:Intel_Lean_Client,option:client-arch,5\n\n  #        #dhcp-boot=tag:Intel_Lean_Client,uefi/grubx64.efi\n\n  #        #dhcp-match=set:Arc_x86,option:client-arch,4\n\n  #        #dhcp-boot=tag:Arc_x86,uefi/grubx64.efi\n\n  #        #dhcp-match=set:DEC_Alpha,option:client-arch,3\n\n  #        #dhcp-boot=tag:DEC_Alpha,uefi/grubx64.efi\n\n  #        #dhcp-match=set:EFI_Itanium,option:client-arch,2\n\n  #        #dhcp-boot=tag:EFI_Itanium,uefi/grubx64.efi\n\n  #        #dhcp-match=set:NEC/PC98,option:client-arch,1\n\n  #        #dhcp-boot=tag:NEC/PC98,uefi/grubx64.efi\n\n  #        dhcp-match=set:Intel_x86PC,option:client-arch,0\n\n  #        dhcp-boot=tag:Intel_x86PC,pxelinux.0\n   \n  ##############################################################################\n\n  # DHCP 使用客户端的 MAC 地址的哈希值为客户端分配 IP 地址，\n\n  # 通常情况下即使客户端使自己的租约到期，客户端的 IP 地址仍将长期保持稳定。\n\n  # 在默认模式下，IP 地址是随机分配的。\n\n  # 启用 dhcp-sequential-ip 选项将按顺序分配 IP 地址。\n\n  # 在顺序分配模式下，客户端使租约到期更像是仅仅移动一下 IP 地址。\n\n  # 在通常情况下不建议使用这种方式。\n\n  #dhcp-sequential-ip\n   \n  ##############################################################################\n\n  # 多数情况下我们使用 PXE，只是简单的允许 PXE 客户端获取 IP 地址，\n\n  # 然后 PXE 客户端下载 dhcp-boot 选项指定的文件并执行，也就是 BOOTP 的方式。\n\n  # 然而在有适当配置的 DHCP 服务器支持的情况下，PXE 系统能够实现更复杂的功能。\n\n  # pxe-service 选项可指定 PXE 环境的启动菜单。\n\n  # 为不同的类型系统设定不同的启动菜单，并且覆盖 dhcp-boot 选项。\n\n  # <CSA> 为客户端系统类型：x86PC, PC98, IA64_EFI, Alpha, Arc_x86, Intel_Lean_Client, \n\n  # IA32_EFI, X86-64_EFI, Xscale_EFI, BC_EFI, ARM32_EFI 和 ARM64_EFI，其他类型可能为一个整数。\n\n  # <basename> 引导 PXE 客户端使用 tftp 从 <server address> 或者 <server_name> 下载文件。\n\n  #     注意：\"layer\" 后缀 (通常是 \".0\") 由 PXE 提供，也就是 PXE 客户端默认在文件名附加 .0 后缀。\n\n  #     示例：pxe-service=x86PC, \"Install Linux\", pxelinux         （读取 pxelinux.0\n  文件并执行）\n\n  #           pxe-service=x86PC, \"Install Linux\", pxelinux, 1.2.3.4（不适用于老的PXE）\n\n  #     <bootservicetype> 整数，PXE 客户端将通过广播或者通过 <server address> \n\n  #           或者 <server_name> 搜索对应类型的适合的启动服务。。\n\n  #     示例：pxe-service=x86PC, \"Install windows from RIS server\", 1\n\n  #           pxe-service=x86PC, \"Install windows from RIS server\", 1, 1.2.3.4\n\n  #     未指定 <basename>、<bootservicetype> 或者 <bootservicetype> 为 “0”，将从本地启动。\n\n  #     示例：pxe-service=x86PC, \"Boot from local disk\"\n\n  #           pxe-service=x86PC, \"Boot from local disk\", 0\n\n  # 如果指定 <server_name> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n\n  #pxe-service=[tag:<tag>,]<CSA>,<menu\n  text>[,<basename>|<bootservicetype>][,<server address>|<server_name>]\n\n  # 在 PXE 启动后弹出提示，<prompt> 为提示内容，<timeout> 为超时时间，为 0 则立即执行。\n\n  # 如果未指定此选项，在有多个启动选项的情况下等待用户选择，不会超时。\n\n  #pxe-prompt=[tag:<tag>,]<prompt>[,<timeout>]\n\n  # 根据不同的类型使用不同的菜单，使用示例：\n\n  #        #pxe-prompt=\"What system shall I netboot?\", 120\n\n  #        # or with timeout before first available action is taken:\n\n  #        pxe-prompt=\"Press F8 or Enter key for menu.\", 60\n\n  #        pxe-service=x86PC, \"Now in x86PC (BIOS mode), boot from local\", 0\n\n  #        pxe-service=x86PC, \"Now in x86PC (BIOS mode)\", pxelinux\n\n  #        pxe-service=PC98, \"Now in PC98 mode\", PC98\n\n  #        pxe-service=IA64_EFI, \"Now in IA64_EFI mode\", IA64_EFI\n\n  #        pxe-service=Alpha, \"Now in Alpha mode\", Alpha\n\n  #        pxe-service=Arc_x86, \"Now in Arc_x86 mode\", Arc_x86\n\n  #        pxe-service=Intel_Lean_Client, \"Now in Intel_Lean_Client mode\",\n  Intel_Lean_Client\n\n  #        pxe-service=IA32_EFI, \"Now in IA32_EFI mode\", IA32_EFI\n\n  #        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode), boot from\n  local\", 0\n\n  #        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode)\",\n  grub/grub-x86_64.efi\n\n  #        pxe-service=Xscale_EFI, \"Now in Xscale_EFI mode\", Xscale_EFI\n\n  #        pxe-service=BC_EFI, \"Now in BC_EFI mode\", BC_EFI\n\n  #        # CentOS7 系统不支持下列两个选项\n\n  #        #pxe-service=ARM32_EFI,\"Now in ARM32_EFI mode\",ARM32_EFI\n\n  #        #pxe-service=ARM64_EFI,\"Now in ARM64_EFI mode\",ARM64_EFI\n   \n  ##############################################################################\n\n  # 默认为150，即最多分配150个ip地址出去，最大1000个ip\n\n  #dhcp-lease-max=150\n\n  # (IPv4 only) 指定DHCP端口，默认为67和68。如果不指定则为1067和1068，单指定一个，第二个加1\n\n  #dhcp-alternate-port[=<server port>[,<client port>]]\n\n  # 谨慎使用此选项，避免 IP 地址浪费。(IPv4 only) 允许动态分配 IP 地址给 BOOTP 客户端。\n\n  # 注意：BOOTP 客户端获取的 IP 地址是永久的，将无法再次分配给其他客户端。\n\n  #bootp-dynamic[=<network-id>[,<network-id>]]\n\n  # 谨慎使用此选项。\n\n  # 默认情况下 DHCP 服务器使用 ping 的方式进行确保 IP 未被使用的情况下将 IP 地址分配出去。\n\n  # 启用此选项将不使用 ping 进行确认。\n\n  #no-ping\n   \n  ##############################################################################\n\n  # 记录额外的 dhcp 日志，记录所有发送给 DHCP 客户端的选项（option）以及标签（tag）信息\n\n  #log-dhcp\n\n  # 禁止记录日常操作日志，错误日志仍然记录。启用 log-dhcp 将覆盖下列选项。\n\n  #quiet-dhcp\n\n  #quiet-dhcp6\n\n  #quiet-ra\n   \n  # 修改 DHCP 默认租约文件路径，默认情况下无需修改\n\n  #dhcp-leasefile=/var/lib/dnsmasq/dnsmasq.leases\n\n  # (IPv6 only)\n\n  #dhcp-duid=<enterprise-id>,<uid>\n   \n  ##############################################################################\n\n  #dhcp-script=<path>\n\n  #dhcp-luascript=<path>\n\n  #dhcp-scriptuser=root\n\n  #script-arp\n\n  #leasefile-ro\n   \n  #bridge-interface=<interface>,<alias>[,<alias>]\n   \n  ##############################################################################\n\n  # 给 DHCP 服务器指定 domain 域名信息，也可以给对应的 IP 地址池指定域名。\n\n  #     直接指定域名\n\n  #     示例：domain=thekelleys.org.uk\n\n  #     子网对应的域名\n\n  #     示例：domain=wireless.thekelleys.org.uk,192.168.2.0/24\n\n  #     ip范围对应的域名\n\n  #     示例：domain=reserved.thekelleys.org.uk,192.68.3.100,192.168.3.200\n\n  #domain=<domain>[,<address range>[,local]]\n\n  # 在默认情况下 dnsmasq 插入普通的客户端主机名到 DNS 中。\n\n  # 在这种情况下主机名必须唯一，即使两个客户端具有不同的域名后缀。\n\n  # 如果第二个客户端使用了相同的主机名，DNS 查询将自动更新为第二个客户端的 IP 地址。\n\n  # 如果设置了 dhcp-fqdn 选项，普通的主机名将不再插入到 DNS 中去，\n\n  # 仅允许合格的具有域名后缀的主机名插入到 DNS 服务器中。\n\n  # 指定此选项需同时指定不含 <address range> 地址范围的 domain 选项。\n\n  #dhcp-fqdn\n\n  # 通常情况下分配 DHCP 租约后，dnsmasq 设置 FQDN 选项告诉客户端不要尝试 DDNS 更新主机名与 IP 地址。\n\n  # 这是因为  name-IP 已自动添加到 dnsmasq 的 DNS 视图中的。\n\n  # 设置此选项将允许客户端 DDNS 更新，\n\n  # 在 windows 下允许客户端更新 windows AD 服务器是非常有用的。\n\n  # 参看  RFC 4702 。\n\n  #dhcp-client-update\n   \n  #enable-ra\n\n  #ra-param=<interface>,[high|low],[[<ra-interval>],<router lifetime>]\n   \n   \n  ##############################################################################\n\n  #\n\n  #        TFTP 选项\n\n  #\n\n  ##############################################################################\n\n  # 对于绝大多数的配置，仅需指定 enable-tftp 和 tftp-root 选项即可。\n\n  # 是否启用内置的 tftp 服务器，可以指定多个逗号分隔的网络接口\n\n  #enable-tftp[=<interface>[,<interface>]]\n\n  #enable-tftp\n\n  #enable-tftp=enp3s0,lo\n\n  # 指定 tftp 的根目录，也就是寻找传输文件时使用的相对路径，可以附加接口，\n\n  #tftp-root=<directory>[,<interface>]\n\n  #tftp-root=/var/lib/tftpboot/\n\n  # 如果取消注释，那么即使指定的 tftp-root 无法访问，仍然启动 tftp 服务。\n\n  #tftp-no-fail\n\n  # 附加客户端的 IP 地址作为文件路径。此选项仅在正确设置了 tftp-root 的情况下可用，\n\n  # 示例：如果 tftp-root=/tftp，客户端为 192.168.1.15 请求 myfile.txt 文件时，\n\n  # 将优先请求 /tftp/192.168.1.15/myfile.txt 文件， 其次是 /tftp/myfile.txt 文件。\n\n  # 感觉没什么用。\n\n  #tftp-unique-root\n\n  # 启用安全模式，启用此选项，仅允许 tftp 进程访问属主为自己的文件。\n\n  # 不启用此选项，允许访问所有 tftp 进程属主可读取的文件。\n\n  # 如果 dnsmasq 是以 root 用户运行，tftp-secure 选项将允许访问全局可读的文件。\n\n  # 一般情况下不推荐以 root 用户运行 dnsmasq。\n\n  # 在指定了 tftp-root 的情况下并不是很重要。\n\n  #tftp-secure\n\n  # 将所有文件请求转换为小写。对于 Windows 客户端来说非常有用，建议开启此项。\n\n  # 注意：dnsmasq 的 TFTP 服务器总是将文件路径中的“\\”转换为“/”。\n\n  #tftp-lowercase\n\n  # 允许最大的连接数，默认为 50 。\n\n  # 如果将连接数设置的很大，需注意每个进程的最大文件描述符限制，详见文档手册。\n\n  #tftp-max=<connections>\n\n  #tftp-max=50\n\n  # 设置传输时的 MTU 值，建议不设置或按需设置。\n\n  # 如果设定的值大于网络接口的 MTU 值，将按照网络接口的 MTU 值自动分片传输（不推荐）。\n\n  #tftp-mtu=<mtu size>\n\n  # 停止 tftp 服务器与客户端协商 \"blocksize\" 选项。启用后，防止一些古怪的客户端出问题。\n\n  #tftp-no-blocksize\n\n  # 指定 tftp 的连接端口的范围，方便防火墙部署。\n\n  # tftp 侦听在 69/udp ，连接端口默认是由系统自动分配的，\n\n  # 非 root 用户运行时指定的连接端口号需大于 1025 最大 65535。\n\n  #tftp-port-range=<start>,<end>\n\n  ###############################################################################\n\n  #conf-dir=<directory>[,<file-extension>......]\n\n  #conf-file=/etc/dnsmasq.more.conf\n\n  conf-dir=/etc/dnsmasq.d\n\n  #servers-file=<file>\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-10 18:17:10\n---\n\n这个文档里说的比较详细：\n<!-- more -->\n```\n##############################################################################\n#\n#        DNS 选项\n#\n##############################################################################\n# 不加载本地的 /etc/hosts 文件\n#no-hosts\n# 添加读取额外的 hosts 文件路径，可以多次指定。如果指定为目录，则读取目录中的所有文件。\n#addn-hosts=/etc/hosts\n# 读取目录中的所有文件，文件更新将自动读取\n#hostsdir=<path>\n# 例如，/etc/hosts中的os01将扩展成os01.example.com\n#expand-hosts\n \n##############################################################################\n# 缓存时间设置，一般不需要设置\n# 本地 hosts 文件的缓存时间，通常不要求缓存本地，这样更改hosts文件后就即时生效。\n#local-ttl=3600\n# 同 local-ttl 仅影响 DHCP 租约\n#dhcp-ttl=<time>\n# 对于上游返回的值没有ttl时，dnsmasq给一个默认的ttl，一般不需要设置，\n#neg-ttl=<time>\n# 指定返回给客户端的ttl时间，一般不需要设置\n#max-ttl=<time>\n# 设置在缓存中的条目的最大 TTL。\n#max-cache-ttl=<time>\n# 不需要设置，除非你知道你在做什么。\n#min-cache-ttl=<time>\n# 一般不需要设置\n#auth-ttl=<time>\n \n##############################################################################\n# 记录dns查询日志\n#log-queries\n# 设置日志记录器，‘-‘ 为 stderr，也可以是文件路径。默认为：DAEMON，调试时使用 LOCAL0。\n#log-facility=<facility>\n#log-facility=/var/log/dnsmasq/dnsmasq.log\n# 异步log，缓解阻塞，提高性能。默认为5，最大100。\n#log-async[=<lines>]\n#log-async=50\n \n##############################################################################\n# 指定用户和组\n#user=nobody\n#group=nobody\n \n##############################################################################\n# 指定DNS的端口，默认53，设置 port=0 将完全禁用 DNS 功能，仅使用 DHCP/TFTP\n#port=53\n# 指定 EDNS.0 UDP 包的最大尺寸，默认为 RFC5625 推荐的 edns-packet-max=4096\n#edns-packet-max=<size>\n# 指定向上游查询的 UDP 端口，默认是随机端口，指定后降低安全性、加快速度、减少资源消耗。\n# 设置为 0 有操作系统分配。\nquery-port=53535\n# 指定向上游查询的 UDP 端口范围，方便防火墙设置。\n#min-port=<port>\n#max-port=<port>\n# 指定接口，指定后同时附加 lo 接口，可以使用‘*‘通配符\n#interface=wlp2s0\n# 指定排除的接口，排除高优先级，可以使用‘*‘通配符\n#except-interface=\n# 启用 DNS 验证模式\n#auth-server=<domain>,<interface>|<ip-address>\n# 仅接收同一子网的 DNS 请求，仅在未指定 interface、except-interface、listen-address \n# 或者 auth-server 时有效。\n#local-service\n# 指定不提供 DHCP 或 TFTP 服务的接口，仅提供 DNS 服务\n#no-dhcp-interface=enp3s0\n# 指定IP地址，可以多次指定。下面两行跟指定接口的作用类似。\n#listen-address=192.168.10.254\n#listen-address=127.0.0.1\n# 绑定接口，开启此项将仅监听指定的接口。\n#bind-interfaces\n# 对于新添加的接口也进行绑定。\n#bind-dynamic\n \n##############################################################################\n# 如果 hosts 中的主机有多个 IP 地址，仅返回对应子网的 IP 地址。\n#localise-queries\n# 如果反向查找的是私有地址例如192.168.X.X，仅从 hosts 文件查找，不再转发到上游服务器\n#bogus-priv\n# 对于任何被解析到此IP的域名，使其解析失效，可以多次指定\n#bogus-nxdomain=64.94.110.11\n# 忽略指定的 DNS 响应服务器地址，例如 1.1.1.1 为伪造的 dns 服务器并且响应速度非常快，\n# 指定 ignore-address=1.1.1.1 可以忽略它的响应信息，从而等待正确的响应结果。\n#ignore-address=<ipaddr>\n#filterwin2k\n \n##############################################################################\n# 指定 resolv-file 文件路径，默认/etc/resolv.conf\n#resolv-file=/etc/resolv.conf\n# 不读取 resolv-file 来确定上游服务器\n#no-resolv\n# 在编译时需要启用 DBus 支持。\n#enable-dbus[=<service-name>]\n# 严格按照resolv.conf中的顺序进行查找\n#strict-order\n# 向所有上有服务器发送查询，而不是一个。\n#all-servers\n#dns-loop-detect\n \n##############################################################################\n# 这项安全设置是拒绝解析包含私有 IP 地址的域名，\n# 这些IP地址包括如下私有地址范围：10.0.0.0/8、172.16.0.0/12、192.168.0.0/16。\n# 其初衷是要防止类似上游DNS服务器故意将某些域名解析成特定私有内网IP而劫持用户这样的安全攻击。\n# 直接在配置文件中注销 stop-dns-rebind 配置项从而禁用该功能。\n# 这个方法确实可以一劳永逸的解决解析内网 IP 地址的问题，但是我们也失去了这项安全保护的特性，\n# 所以在这里我不推荐这个办法。\n# 使用 rebind-domain-ok 进行特定配置，顾名思义该配置项可以有选择的忽略域名的 rebind 行为\n#stop-dns-rebind\n#rebind-localhost-ok\n#rebind-domain-ok=[<domain>]|[[/<domain>/[<domain>/]\n#rebind-domain-ok=/.dinghuangjie.com/.dhj.com/.harlinsu.com/.example.com/.test.com/.esderive.com/\n \n##############################################################################\n# 也不要检测 /etc/resolv.conf 的变化\n#no-poll\n# 重启后清空缓存\n#clear-on-reload\n# 完整的域名才向上游服务器查找，如果仅仅是主机名仅查找hosts文件\n#domain-needed\n \n##############################################################################\n# IP地址转换\n#alias=[<old-ip>]|[<start-ip>-<end-ip>],<new-ip>[,<mask>]\n##############################################################################\n#local=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=[/[<domain>]/[domain/]][<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n#server=/example.com/192.168.10.252\n#rev-server=<ip-address>/<prefix-len>,<ipaddr>[#<port>][@<source-ip>|<interface>[#<port>]]\n \n# 将任何属于 <domain> 域名解析成指定的 <ipaddr> 地址。\n# 也就是将 <domain> 及其所有子域名解析成指定的 <ipaddr> IPv4 或者 IPv6 地址，\n# 通常用于屏蔽特定的域名。\n# 一次只能指定一个 IPv4 或者 IPv6 地址，\n# 要同时返回 IPv4 和IPv6 地址，请多次指定 address= 选项。\n# 注意： /etc/hosts 以及 DHCP 租约将覆盖此项设置。\n#address=/<domain>/[domain/][<ipaddr>]\n \n#ipset=/<domain>/[domain/]<ipset>[,<ipset>]\n#mx-host=<mx name>[[,<hostname>],<preference>]\n#mx-target=<hostname>\n \n# SRV 记录\n#srv-host=<_service>.<_prot>.[<domain>],[<target>[,<port>[,<priority>[,<weight>]]]]\n \n# A, AAAA 和 PTR 记录 \n#host-record=<name>[,<name>....],[<IPv4-address>],[<IPv6-address>][,<TTL>]\n \n# TXT 记录\n#txt-record=<name>[[,<text>],<text>]\n \n# PTR 记录 \n#ptr-record=<name>[,<target>]\n \n#naptr-record=<name>,<order>,<preference>,<flags>,<service>,<regexp>[,<replacement>]\n \n# CNAME 别名记录\n#cname=<cname>,<target>[,<TTL>]\n \n \n#dns-rr=<name>,<RR-number>,[<hex data>]\n#interface-name=<name>,<interface>[/4|/6]\n#synth-domain=<domain>,<address range>[,<prefix>]\n#add-mac[=base64|text]\n#add-cpe-id=<string>\n#add-subnet[[=[<IPv4 address>/]<IPv4 prefix length>][,[<IPv6 address>/]<IPv6 prefix length>]]\n##############################################################################\n \n##############################################################################\n# 缓存条数，默认为150条，cache-size=0 禁用缓存。\ncache-size=1000\n# 不缓存未知域名缓存，默认情况下dnsmasq缓存未知域名并直接返回为客户端。\n#no-negcache\n# 指定DNS同属查询转发数量\ndns-forward-max=1000\n \n# 启用连接跟踪，读取 Linux 入栈 DNS 查询请求的连接跟踪标记，\n# 并且将上游返回的响应信息设置同样的标记。\n# 用于带宽控制和防火墙部署。\n# 此选项必须在编译时启用 conntrack 支持，并且内核正确配置并加载 conntrack。\n# 此选项不能与 query-port 同时使用。\n#conntrack\n \n \n##############################################################################\n#\n#        DHCP 选项\n#\n##############################################################################\n# 设置 DHCP 地址池，同时启用 DHCP 功能。\n# IPv4 <mode> 可指定为 static|proxy ，当 <mode> 指定为 static 时，\n# 需用 dhcp-host 手动分配地址池中的 IP 地址。\n# 当 <mode> 指定为 proxy 时，为指定的地址池提供 DHCP 代理。\n#dhcp-range=[tag:<tag>[,tag:<tag>],][set:<tag>,]<start-addr>[,<end-addr>][,<mode>][,<netmask>[,<broadcast>]][,<lease time>]\n#dhcp-range=172.16.0.2,172.16.0.250,255.255.255.0,1h\n#dhcp-range=192.168.10.150,192.168.10.180,static,255.255.255.0,1h\n \n# 根据 MAC 地址或 id 固定分配客户端的 IP 地址、主机名、租期。\n# IPv4 下指定 id:* 将忽略 DHCP 客户端的 ID ，仅根据 MAC 来进行 IP 地址分配。\n# 在读取 /etc/hosts 的情况，也可以根据 /etc/hosts 中的主机名分配对应 IP 地址。\n# 指定 ignore 将忽略指定客户端得 DHCP 请求。\n#dhcp-host=[<hwaddr>][,id:<client_id>|*][,set:<tag>][,<ipaddr>][,<hostname>][,<lease_time>][,ignore]\n#dhcp-hostsfile=<path>\n#dhcp-hostsdir=<path>\n# 读取 /etc/ethers 文件 与使用 dhcp-host 的作用相同。IPv6 无效。\n#read-ethers\n \n# 指定给 DHCP 客户端的选项信息，\n# 默认情况下 dnsmasq 将发送：子网掩码、广播地址、DNS 服务器地址、网关地址、域等信息。\n# 指定此选项也可覆盖这些默认值并且设置其他选项值。\n# 重要：可以使用 option:<option-name>或者 option号 来指定。\n# <option-name> 和 option号的对应关系可使用命令：\n# dnsmasq --help dhcp 以及 dnsmasq --help dhcp6 查看，这点很重要。\n# 例如设置网关参数，既可以使用 dhcp-option=3,192.168.4.4 也可以使用 dhcp-option = option:router,192.168.4.4。\n# 0.0.0.0 意味着当前运行 dnsmasq 的主机地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# [encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],] 有待继续研究。\n#dhcp-option=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],][<opt>|option:<opt-name>|option6:<opt>|option6:<opt-name>],[<value>[,<value>]]\n#dhcp-option-force=[tag:<tag>,[tag:<tag>,]][encap:<opt>,][vi-encap:<enterprise>,][vendor:[<vendor-class>],]<opt>,[<value>[,<value>]]\n#dhcp-optsfile=<path>\n#dhcp-optsdir=<path>\n#dhcp-option=3,1.2.3.4\n#dhcp-option=option:router,1.2.3.4\n#dhcp-option=option:router,192.168.10.254\n#dhcp-option=option:dns-server,192.168.10.254,221.12.1.227,221.12.33.227\n \n##############################################################################\n# (IPv4 only) 禁用重用服务器名称和文件字段作为额外的 dhcp-option 选项。\n# 一般情况下 dnsmasq 从 dhcp-boot 移出启动服务器和文件信息到 dhcp-option 选项中。\n# 这使得在 dhcp-option 选项封包中有额外的选项空间可用，但是会使老的客户端混淆。\n# 此选项将强制使用简单并安全的方式来避免此类情况。可以认为是一个兼容性选项。\n#dhcp-no-override\n \n##############################################################################\n# 配置 DHCP 中继。\n# <local address> 是运行 dnsmasq 的接口的 IP 地址。\n# 所有在 <local address> 接口上接收到的 DHCP 请求将中继到 <server address> 指定的远程 DHCP 服务器。\n# 可以多次配置此选项，使用同一个 <local address> 转发到多个不同的 <server address> 指定的远程 DHCP 服务器。\n# <server address> 仅允许使用 IP 地址，不能使用域名等其他格式。\n# 如果是 DHCPv6，<server address> 可以是 ALL_SERVERS 的多播地址 ff05::1:3 。\n# 在这种情况下必须指定接口 <interface> ，不能使用通配符，用于直接多播到对应的 DHCP 服务器所在的接口。\n# <interface> 指定了仅允许接收从 <interface> 接口的 DHCP 服务器相应信息。\n#dhcp-relay=<local address>,<server address>[,<interface>]\n \n##############################################################################\n# 设置标签\n#dhcp-vendorclass=set:<tag>,[enterprise:<IANA-enterprise number>,]<vendor-class>\n#dhcp-userclass=set:<tag>,<user-class>\n#dhcp-mac=set:<tag>,<MAC address>\n#dhcp-circuitid=set:<tag>,<circuit-id>\n#dhcp-remoteid=set:<tag>,<remote-id>\n#dhcp-subscrid=set:<tag>,<subscriber-id>\n#dhcp-match=set:<tag>,<option number>|option:<option name>|vi-encap:<enterprise>[,<value>]\n#tag-if=set:<tag>[,set:<tag>[,tag:<tag>[,tag:<tag>]]]\n \n#dhcp-proxy[=<ip addr>]......\n \n##############################################################################\n# 不分配匹配这些 tag:<tag> 的 DHCP 请求。\n#dhcp-ignore=tag:<tag>[,tag:<tag>]\n#dhcp-ignore-names[=tag:<tag>[,tag:<tag>]]\n#dhcp-generate-names=tag:<tag>[,tag:<tag>]\n# IPv4 only 使用广播与匹配 tag:<tag> 的客户端通信。一般用于兼容老的 BOOT 客户端。\n#dhcp-broadcast[=tag:<tag>[,tag:<tag>]] \n \n##############################################################################\n# IPv4 only 设置 DHCP 服务器返回的 BOOTP 选项，\n# <servername> <server address> 可选，\n# 如果未设置服务器名称将设为空，服务器地址设为 dnsmasq 的 IP 地址。\n# 如果指定了多个 tag:<tag> 必须同时匹配才行。\n# 如果指定 <tftp_servername> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#dhcp-boot=[tag:<tag>,]<filename>,[<servername>[,<server address>|<tftp_servername>]]\n# 根据不同的类型使用不同的选项。\n# 使用示例：\n#        dhcp-match=set:EFI_x86-64,option:client-arch,9\n#        dhcp-boot=tag:EFI_x86-64,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Xscale,option:client-arch,8\n#        #dhcp-boot=tag:EFI_Xscale,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_BC,option:client-arch,7\n#        #dhcp-boot=tag:EFI_BC,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_IA32,option:client-arch,6\n#        #dhcp-boot=tag:EFI_IA32,uefi/grubx64.efi\n#        #dhcp-match=set:Intel_Lean_Client,option:client-arch,5\n#        #dhcp-boot=tag:Intel_Lean_Client,uefi/grubx64.efi\n#        #dhcp-match=set:Arc_x86,option:client-arch,4\n#        #dhcp-boot=tag:Arc_x86,uefi/grubx64.efi\n#        #dhcp-match=set:DEC_Alpha,option:client-arch,3\n#        #dhcp-boot=tag:DEC_Alpha,uefi/grubx64.efi\n#        #dhcp-match=set:EFI_Itanium,option:client-arch,2\n#        #dhcp-boot=tag:EFI_Itanium,uefi/grubx64.efi\n#        #dhcp-match=set:NEC/PC98,option:client-arch,1\n#        #dhcp-boot=tag:NEC/PC98,uefi/grubx64.efi\n#        dhcp-match=set:Intel_x86PC,option:client-arch,0\n#        dhcp-boot=tag:Intel_x86PC,pxelinux.0\n \n##############################################################################\n# DHCP 使用客户端的 MAC 地址的哈希值为客户端分配 IP 地址，\n# 通常情况下即使客户端使自己的租约到期，客户端的 IP 地址仍将长期保持稳定。\n# 在默认模式下，IP 地址是随机分配的。\n# 启用 dhcp-sequential-ip 选项将按顺序分配 IP 地址。\n# 在顺序分配模式下，客户端使租约到期更像是仅仅移动一下 IP 地址。\n# 在通常情况下不建议使用这种方式。\n#dhcp-sequential-ip\n \n##############################################################################\n# 多数情况下我们使用 PXE，只是简单的允许 PXE 客户端获取 IP 地址，\n# 然后 PXE 客户端下载 dhcp-boot 选项指定的文件并执行，也就是 BOOTP 的方式。\n# 然而在有适当配置的 DHCP 服务器支持的情况下，PXE 系统能够实现更复杂的功能。\n# pxe-service 选项可指定 PXE 环境的启动菜单。\n# 为不同的类型系统设定不同的启动菜单，并且覆盖 dhcp-boot 选项。\n# <CSA> 为客户端系统类型：x86PC, PC98, IA64_EFI, Alpha, Arc_x86, Intel_Lean_Client, \n# IA32_EFI, X86-64_EFI, Xscale_EFI, BC_EFI, ARM32_EFI 和 ARM64_EFI，其他类型可能为一个整数。\n# <basename> 引导 PXE 客户端使用 tftp 从 <server address> 或者 <server_name> 下载文件。\n#     注意：\"layer\" 后缀 (通常是 \".0\") 由 PXE 提供，也就是 PXE 客户端默认在文件名附加 .0 后缀。\n#     示例：pxe-service=x86PC, \"Install Linux\", pxelinux         （读取 pxelinux.0 文件并执行）\n#           pxe-service=x86PC, \"Install Linux\", pxelinux, 1.2.3.4（不适用于老的PXE）\n#     <bootservicetype> 整数，PXE 客户端将通过广播或者通过 <server address> \n#           或者 <server_name> 搜索对应类型的适合的启动服务。。\n#     示例：pxe-service=x86PC, \"Install windows from RIS server\", 1\n#           pxe-service=x86PC, \"Install windows from RIS server\", 1, 1.2.3.4\n#     未指定 <basename>、<bootservicetype> 或者 <bootservicetype> 为 “0”，将从本地启动。\n#     示例：pxe-service=x86PC, \"Boot from local disk\"\n#           pxe-service=x86PC, \"Boot from local disk\", 0\n# 如果指定 <server_name> 将按照 /etc/hosts 中对应的 IP 地址进行轮询负载均衡。  \n#pxe-service=[tag:<tag>,]<CSA>,<menu text>[,<basename>|<bootservicetype>][,<server address>|<server_name>]\n# 在 PXE 启动后弹出提示，<prompt> 为提示内容，<timeout> 为超时时间，为 0 则立即执行。\n# 如果未指定此选项，在有多个启动选项的情况下等待用户选择，不会超时。\n#pxe-prompt=[tag:<tag>,]<prompt>[,<timeout>]\n# 根据不同的类型使用不同的菜单，使用示例：\n#        #pxe-prompt=\"What system shall I netboot?\", 120\n#        # or with timeout before first available action is taken:\n#        pxe-prompt=\"Press F8 or Enter key for menu.\", 60\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode), boot from local\", 0\n#        pxe-service=x86PC, \"Now in x86PC (BIOS mode)\", pxelinux\n#        pxe-service=PC98, \"Now in PC98 mode\", PC98\n#        pxe-service=IA64_EFI, \"Now in IA64_EFI mode\", IA64_EFI\n#        pxe-service=Alpha, \"Now in Alpha mode\", Alpha\n#        pxe-service=Arc_x86, \"Now in Arc_x86 mode\", Arc_x86\n#        pxe-service=Intel_Lean_Client, \"Now in Intel_Lean_Client mode\", Intel_Lean_Client\n#        pxe-service=IA32_EFI, \"Now in IA32_EFI mode\", IA32_EFI\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode), boot from local\", 0\n#        pxe-service=X86-64_EFI, \"Now in X86-64_EFI (UEFI mode)\", grub/grub-x86_64.efi\n#        pxe-service=Xscale_EFI, \"Now in Xscale_EFI mode\", Xscale_EFI\n#        pxe-service=BC_EFI, \"Now in BC_EFI mode\", BC_EFI\n#        # CentOS7 系统不支持下列两个选项\n#        #pxe-service=ARM32_EFI,\"Now in ARM32_EFI mode\",ARM32_EFI\n#        #pxe-service=ARM64_EFI,\"Now in ARM64_EFI mode\",ARM64_EFI\n \n##############################################################################\n# 默认为150，即最多分配150个ip地址出去，最大1000个ip\n#dhcp-lease-max=150\n# (IPv4 only) 指定DHCP端口，默认为67和68。如果不指定则为1067和1068，单指定一个，第二个加1\n#dhcp-alternate-port[=<server port>[,<client port>]]\n# 谨慎使用此选项，避免 IP 地址浪费。(IPv4 only) 允许动态分配 IP 地址给 BOOTP 客户端。\n# 注意：BOOTP 客户端获取的 IP 地址是永久的，将无法再次分配给其他客户端。\n#bootp-dynamic[=<network-id>[,<network-id>]]\n# 谨慎使用此选项。\n# 默认情况下 DHCP 服务器使用 ping 的方式进行确保 IP 未被使用的情况下将 IP 地址分配出去。\n# 启用此选项将不使用 ping 进行确认。\n#no-ping\n \n##############################################################################\n# 记录额外的 dhcp 日志，记录所有发送给 DHCP 客户端的选项（option）以及标签（tag）信息\n#log-dhcp\n# 禁止记录日常操作日志，错误日志仍然记录。启用 log-dhcp 将覆盖下列选项。\n#quiet-dhcp\n#quiet-dhcp6\n#quiet-ra\n \n# 修改 DHCP 默认租约文件路径，默认情况下无需修改\n#dhcp-leasefile=/var/lib/dnsmasq/dnsmasq.leases\n# (IPv6 only)\n#dhcp-duid=<enterprise-id>,<uid>\n \n##############################################################################\n#dhcp-script=<path>\n#dhcp-luascript=<path>\n#dhcp-scriptuser=root\n#script-arp\n#leasefile-ro\n \n#bridge-interface=<interface>,<alias>[,<alias>]\n \n##############################################################################\n# 给 DHCP 服务器指定 domain 域名信息，也可以给对应的 IP 地址池指定域名。\n#     直接指定域名\n#     示例：domain=thekelleys.org.uk\n#     子网对应的域名\n#     示例：domain=wireless.thekelleys.org.uk,192.168.2.0/24\n#     ip范围对应的域名\n#     示例：domain=reserved.thekelleys.org.uk,192.68.3.100,192.168.3.200\n#domain=<domain>[,<address range>[,local]]\n# 在默认情况下 dnsmasq 插入普通的客户端主机名到 DNS 中。\n# 在这种情况下主机名必须唯一，即使两个客户端具有不同的域名后缀。\n# 如果第二个客户端使用了相同的主机名，DNS 查询将自动更新为第二个客户端的 IP 地址。\n# 如果设置了 dhcp-fqdn 选项，普通的主机名将不再插入到 DNS 中去，\n# 仅允许合格的具有域名后缀的主机名插入到 DNS 服务器中。\n# 指定此选项需同时指定不含 <address range> 地址范围的 domain 选项。\n#dhcp-fqdn\n# 通常情况下分配 DHCP 租约后，dnsmasq 设置 FQDN 选项告诉客户端不要尝试 DDNS 更新主机名与 IP 地址。\n# 这是因为  name-IP 已自动添加到 dnsmasq 的 DNS 视图中的。\n# 设置此选项将允许客户端 DDNS 更新，\n# 在 windows 下允许客户端更新 windows AD 服务器是非常有用的。\n# 参看  RFC 4702 。\n#dhcp-client-update\n \n#enable-ra\n#ra-param=<interface>,[high|low],[[<ra-interval>],<router lifetime>]\n \n \n##############################################################################\n#\n#        TFTP 选项\n#\n##############################################################################\n# 对于绝大多数的配置，仅需指定 enable-tftp 和 tftp-root 选项即可。\n# 是否启用内置的 tftp 服务器，可以指定多个逗号分隔的网络接口\n#enable-tftp[=<interface>[,<interface>]]\n#enable-tftp\n#enable-tftp=enp3s0,lo\n# 指定 tftp 的根目录，也就是寻找传输文件时使用的相对路径，可以附加接口，\n#tftp-root=<directory>[,<interface>]\n#tftp-root=/var/lib/tftpboot/\n# 如果取消注释，那么即使指定的 tftp-root 无法访问，仍然启动 tftp 服务。\n#tftp-no-fail\n# 附加客户端的 IP 地址作为文件路径。此选项仅在正确设置了 tftp-root 的情况下可用，\n# 示例：如果 tftp-root=/tftp，客户端为 192.168.1.15 请求 myfile.txt 文件时，\n# 将优先请求 /tftp/192.168.1.15/myfile.txt 文件， 其次是 /tftp/myfile.txt 文件。\n# 感觉没什么用。\n#tftp-unique-root\n# 启用安全模式，启用此选项，仅允许 tftp 进程访问属主为自己的文件。\n# 不启用此选项，允许访问所有 tftp 进程属主可读取的文件。\n# 如果 dnsmasq 是以 root 用户运行，tftp-secure 选项将允许访问全局可读的文件。\n# 一般情况下不推荐以 root 用户运行 dnsmasq。\n# 在指定了 tftp-root 的情况下并不是很重要。\n#tftp-secure\n# 将所有文件请求转换为小写。对于 Windows 客户端来说非常有用，建议开启此项。\n# 注意：dnsmasq 的 TFTP 服务器总是将文件路径中的“\\”转换为“/”。\n#tftp-lowercase\n# 允许最大的连接数，默认为 50 。\n# 如果将连接数设置的很大，需注意每个进程的最大文件描述符限制，详见文档手册。\n#tftp-max=<connections>\n#tftp-max=50\n# 设置传输时的 MTU 值，建议不设置或按需设置。\n# 如果设定的值大于网络接口的 MTU 值，将按照网络接口的 MTU 值自动分片传输（不推荐）。\n#tftp-mtu=<mtu size>\n# 停止 tftp 服务器与客户端协商 \"blocksize\" 选项。启用后，防止一些古怪的客户端出问题。\n#tftp-no-blocksize\n# 指定 tftp 的连接端口的范围，方便防火墙部署。\n# tftp 侦听在 69/udp ，连接端口默认是由系统自动分配的，\n# 非 root 用户运行时指定的连接端口号需大于 1025 最大 65535。\n#tftp-port-range=<start>,<end>\n###############################################################################\n#conf-dir=<directory>[,<file-extension>......]\n#conf-file=/etc/dnsmasq.more.conf\nconf-dir=/etc/dnsmasq.d\n#servers-file=<file>\n```","slug":"dnsmasq.conf 配置","published":1,"updated":"2019-03-23T10:25:59.776Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ej1001vgyavv5lhll4c"},{"title":"linux查看端口占用情况","originContent":"1. 查看5150端口占用的命令行如下：\n\n```\nlsof -i:5150\n```\n\n不识别lsof，则执行`yum install lsof -y`\n\n结果如下:\n\n```\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnode    6055 root   19u  IPv6  29137      0t0  TCP *:atmp (LISTEN)\nnode    6055 root   21u  IPv6  29139      0t0  TCP localhost.localdomain:atmp->192.168.34.11:59258 (ESTABLISHED)\n```\n\n2. 如果想杀掉node进程则使用\n\n```\nsudo kill 6055\n```","toc":false,"date":"2018-04-08T07:25:10.000Z","_content":"\n1. 查看5150端口占用的命令行如下：\n\n```\nlsof -i:5150\n```\n\n不识别lsof，则执行`yum install lsof -y`\n\n结果如下:\n\n```\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnode    6055 root   19u  IPv6  29137      0t0  TCP *:atmp (LISTEN)\nnode    6055 root   21u  IPv6  29139      0t0  TCP localhost.localdomain:atmp->192.168.34.11:59258 (ESTABLISHED)\n```\n\n2. 如果想杀掉node进程则使用\n\n```\nsudo kill 6055\n```","source":"_posts/linux查看端口占用情况.md","raw":"---\ntitle: linux查看端口占用情况\ntags:\n  - linux\noriginContent: >-\n  1. 查看5150端口占用的命令行如下：\n\n\n  ```\n\n  lsof -i:5150\n\n  ```\n\n\n  不识别lsof，则执行`yum install lsof -y`\n\n\n  结果如下:\n\n\n  ```\n\n  COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n\n  node    6055 root   19u  IPv6  29137      0t0  TCP *:atmp (LISTEN)\n\n  node    6055 root   21u  IPv6  29139      0t0  TCP\n  localhost.localdomain:atmp->192.168.34.11:59258 (ESTABLISHED)\n\n  ```\n\n\n  2. 如果想杀掉node进程则使用\n\n\n  ```\n\n  sudo kill 6055\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-04-08 15:25:10\n---\n\n1. 查看5150端口占用的命令行如下：\n\n```\nlsof -i:5150\n```\n\n不识别lsof，则执行`yum install lsof -y`\n\n结果如下:\n\n```\nCOMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\nnode    6055 root   19u  IPv6  29137      0t0  TCP *:atmp (LISTEN)\nnode    6055 root   21u  IPv6  29139      0t0  TCP localhost.localdomain:atmp->192.168.34.11:59258 (ESTABLISHED)\n```\n\n2. 如果想杀掉node进程则使用\n\n```\nsudo kill 6055\n```","slug":"linux查看端口占用情况","published":1,"updated":"2019-03-23T10:19:26.081Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ej5001zgyavpxq8u2mo"},{"title":"koajs框架下创建二维码生成服务","originContent":"通过node-qrcode项目能够快速搭建一个生成二维码的服务器，但是在各种框架下如何使用呢，比如我们用的koajs，同时希望这是一个动态生成图片的服务，也就是返回的就是图片信息，而不是通过一次get请求得到图片url，然后再把url放到图片src中，这种方式一来会增加客户端的复杂程度，二来生成的图片需要服务器资源存储\n\n<!-- more -->\n\n这时候我们就需要一个类似服务的链接，将需要二维码展示的字符串编码后传给后端则能得到一个需要的图片，代码如下：\n\n```\n\n/**\n * 获取二维码接口\n *\n * txt 参数为二维码展示内容，如果不存在或者为空默认生成乐视网地址\n *\n * 接口地址：http://myhost/service/getQrCode/encodeuricomponentStr\n *\n */\n\nvar QRCode = require('qrcode');\n\n/**\n * 通过包装方法，能够使用yield同步获取得到结果\n * @param text\n * @returns {Function}\n */\nvar getQRCode = function(text) {\n    return function (done) {\n        QRCode.toDataURL(text, {\n            margin: 1\n        }, function (err, dataUrl) {\n            done(null, dataUrl);\n        });\n    }\n}\n\n/**\n *\n * 经过一番尝试这样处理方式比较合理，不用操作文件\n * 尝试1：QRCode.toFile生成图片存到本地，通过fs读文件，返回浏览器，可以使用但是占用磁盘资源，维护成本相对较大\n * 尝试2：QRCode.toDataURL得到图片的base64格式，删除掉前边的固定图片标识，将base64转成buffer通过koajs输出\n * 尝试2的做法比较优雅，不会产生文件，更不会存在文件读写操作，只要服务器是稳定的，图片就一定能够出来\n * \n * 缺点就是当服务失效后，所有二维码将不再存在。\n * \n * 由于我们的参数传递是放在路径里，当然也能放在查询字符串里，这里用的是路径\n * 好处就是能够使用cdn缓存，如果服务挂了，访问过的链接二维码图片在cdn还能缓存一段时间\n * 同时能减少一部分服务器压力\n */\nexports.init = function* () {\n    var txt = decodeURIComponent(this.params.txt || 'http:myhost');\n    var dataUrl = yield getQRCode(txt);\n    // 去掉生成dataUrl里边的固定标识，剩下的就是base64字符\n    var base64 = dataUrl.replace(/^data:image\\/\\w+;base64,/, \"\")\n    var dataBuffer = new Buffer(base64, 'base64');\n    this.set('content-type', 'image/png');\n    this.status = 200;\n    this.body = dataBuffer;\n};\n\n```\n\n最后验证CDN是否生效的方法也很简单，监听特定请求的二维码请求，第一次能够打到服务器上，之后的请求不再走服务器即可\n```\n tail -f /var/logs/nginx/access.log | grep \"service/getQrCode/myuniquestr\"\n```","toc":false,"date":"2017-11-01T09:50:10.000Z","_content":"\n通过node-qrcode项目能够快速搭建一个生成二维码的服务器，但是在各种框架下如何使用呢，比如我们用的koajs，同时希望这是一个动态生成图片的服务，也就是返回的就是图片信息，而不是通过一次get请求得到图片url，然后再把url放到图片src中，这种方式一来会增加客户端的复杂程度，二来生成的图片需要服务器资源存储\n\n<!-- more -->\n\n这时候我们就需要一个类似服务的链接，将需要二维码展示的字符串编码后传给后端则能得到一个需要的图片，代码如下：\n\n```\n\n/**\n * 获取二维码接口\n *\n * txt 参数为二维码展示内容，如果不存在或者为空默认生成乐视网地址\n *\n * 接口地址：http://myhost/service/getQrCode/encodeuricomponentStr\n *\n */\n\nvar QRCode = require('qrcode');\n\n/**\n * 通过包装方法，能够使用yield同步获取得到结果\n * @param text\n * @returns {Function}\n */\nvar getQRCode = function(text) {\n    return function (done) {\n        QRCode.toDataURL(text, {\n            margin: 1\n        }, function (err, dataUrl) {\n            done(null, dataUrl);\n        });\n    }\n}\n\n/**\n *\n * 经过一番尝试这样处理方式比较合理，不用操作文件\n * 尝试1：QRCode.toFile生成图片存到本地，通过fs读文件，返回浏览器，可以使用但是占用磁盘资源，维护成本相对较大\n * 尝试2：QRCode.toDataURL得到图片的base64格式，删除掉前边的固定图片标识，将base64转成buffer通过koajs输出\n * 尝试2的做法比较优雅，不会产生文件，更不会存在文件读写操作，只要服务器是稳定的，图片就一定能够出来\n * \n * 缺点就是当服务失效后，所有二维码将不再存在。\n * \n * 由于我们的参数传递是放在路径里，当然也能放在查询字符串里，这里用的是路径\n * 好处就是能够使用cdn缓存，如果服务挂了，访问过的链接二维码图片在cdn还能缓存一段时间\n * 同时能减少一部分服务器压力\n */\nexports.init = function* () {\n    var txt = decodeURIComponent(this.params.txt || 'http:myhost');\n    var dataUrl = yield getQRCode(txt);\n    // 去掉生成dataUrl里边的固定标识，剩下的就是base64字符\n    var base64 = dataUrl.replace(/^data:image\\/\\w+;base64,/, \"\")\n    var dataBuffer = new Buffer(base64, 'base64');\n    this.set('content-type', 'image/png');\n    this.status = 200;\n    this.body = dataBuffer;\n};\n\n```\n\n最后验证CDN是否生效的方法也很简单，监听特定请求的二维码请求，第一次能够打到服务器上，之后的请求不再走服务器即可\n```\n tail -f /var/logs/nginx/access.log | grep \"service/getQrCode/myuniquestr\"\n```","source":"_posts/koajs框架下创建二维码生成服务.md","raw":"---\ntitle: koajs框架下创建二维码生成服务\ntags:\n  - koajs\noriginContent: >-\n  通过node-qrcode项目能够快速搭建一个生成二维码的服务器，但是在各种框架下如何使用呢，比如我们用的koajs，同时希望这是一个动态生成图片的服务，也就是返回的就是图片信息，而不是通过一次get请求得到图片url，然后再把url放到图片src中，这种方式一来会增加客户端的复杂程度，二来生成的图片需要服务器资源存储\n\n\n  <!-- more -->\n\n\n  这时候我们就需要一个类似服务的链接，将需要二维码展示的字符串编码后传给后端则能得到一个需要的图片，代码如下：\n\n\n  ```\n\n\n  /**\n   * 获取二维码接口\n   *\n   * txt 参数为二维码展示内容，如果不存在或者为空默认生成乐视网地址\n   *\n   * 接口地址：http://myhost/service/getQrCode/encodeuricomponentStr\n   *\n   */\n\n  var QRCode = require('qrcode');\n\n\n  /**\n   * 通过包装方法，能够使用yield同步获取得到结果\n   * @param text\n   * @returns {Function}\n   */\n  var getQRCode = function(text) {\n      return function (done) {\n          QRCode.toDataURL(text, {\n              margin: 1\n          }, function (err, dataUrl) {\n              done(null, dataUrl);\n          });\n      }\n  }\n\n\n  /**\n   *\n   * 经过一番尝试这样处理方式比较合理，不用操作文件\n   * 尝试1：QRCode.toFile生成图片存到本地，通过fs读文件，返回浏览器，可以使用但是占用磁盘资源，维护成本相对较大\n   * 尝试2：QRCode.toDataURL得到图片的base64格式，删除掉前边的固定图片标识，将base64转成buffer通过koajs输出\n   * 尝试2的做法比较优雅，不会产生文件，更不会存在文件读写操作，只要服务器是稳定的，图片就一定能够出来\n   * \n   * 缺点就是当服务失效后，所有二维码将不再存在。\n   * \n   * 由于我们的参数传递是放在路径里，当然也能放在查询字符串里，这里用的是路径\n   * 好处就是能够使用cdn缓存，如果服务挂了，访问过的链接二维码图片在cdn还能缓存一段时间\n   * 同时能减少一部分服务器压力\n   */\n  exports.init = function* () {\n      var txt = decodeURIComponent(this.params.txt || 'http:myhost');\n      var dataUrl = yield getQRCode(txt);\n      // 去掉生成dataUrl里边的固定标识，剩下的就是base64字符\n      var base64 = dataUrl.replace(/^data:image\\/\\w+;base64,/, \"\")\n      var dataBuffer = new Buffer(base64, 'base64');\n      this.set('content-type', 'image/png');\n      this.status = 200;\n      this.body = dataBuffer;\n  };\n\n\n  ```\n\n\n  最后验证CDN是否生效的方法也很简单，监听特定请求的二维码请求，第一次能够打到服务器上，之后的请求不再走服务器即可\n\n  ```\n   tail -f /var/logs/nginx/access.log | grep \"service/getQrCode/myuniquestr\"\n  ```\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-11-01 17:50:10\n---\n\n通过node-qrcode项目能够快速搭建一个生成二维码的服务器，但是在各种框架下如何使用呢，比如我们用的koajs，同时希望这是一个动态生成图片的服务，也就是返回的就是图片信息，而不是通过一次get请求得到图片url，然后再把url放到图片src中，这种方式一来会增加客户端的复杂程度，二来生成的图片需要服务器资源存储\n\n<!-- more -->\n\n这时候我们就需要一个类似服务的链接，将需要二维码展示的字符串编码后传给后端则能得到一个需要的图片，代码如下：\n\n```\n\n/**\n * 获取二维码接口\n *\n * txt 参数为二维码展示内容，如果不存在或者为空默认生成乐视网地址\n *\n * 接口地址：http://myhost/service/getQrCode/encodeuricomponentStr\n *\n */\n\nvar QRCode = require('qrcode');\n\n/**\n * 通过包装方法，能够使用yield同步获取得到结果\n * @param text\n * @returns {Function}\n */\nvar getQRCode = function(text) {\n    return function (done) {\n        QRCode.toDataURL(text, {\n            margin: 1\n        }, function (err, dataUrl) {\n            done(null, dataUrl);\n        });\n    }\n}\n\n/**\n *\n * 经过一番尝试这样处理方式比较合理，不用操作文件\n * 尝试1：QRCode.toFile生成图片存到本地，通过fs读文件，返回浏览器，可以使用但是占用磁盘资源，维护成本相对较大\n * 尝试2：QRCode.toDataURL得到图片的base64格式，删除掉前边的固定图片标识，将base64转成buffer通过koajs输出\n * 尝试2的做法比较优雅，不会产生文件，更不会存在文件读写操作，只要服务器是稳定的，图片就一定能够出来\n * \n * 缺点就是当服务失效后，所有二维码将不再存在。\n * \n * 由于我们的参数传递是放在路径里，当然也能放在查询字符串里，这里用的是路径\n * 好处就是能够使用cdn缓存，如果服务挂了，访问过的链接二维码图片在cdn还能缓存一段时间\n * 同时能减少一部分服务器压力\n */\nexports.init = function* () {\n    var txt = decodeURIComponent(this.params.txt || 'http:myhost');\n    var dataUrl = yield getQRCode(txt);\n    // 去掉生成dataUrl里边的固定标识，剩下的就是base64字符\n    var base64 = dataUrl.replace(/^data:image\\/\\w+;base64,/, \"\")\n    var dataBuffer = new Buffer(base64, 'base64');\n    this.set('content-type', 'image/png');\n    this.status = 200;\n    this.body = dataBuffer;\n};\n\n```\n\n最后验证CDN是否生效的方法也很简单，监听特定请求的二维码请求，第一次能够打到服务器上，之后的请求不再走服务器即可\n```\n tail -f /var/logs/nginx/access.log | grep \"service/getQrCode/myuniquestr\"\n```","slug":"koajs框架下创建二维码生成服务","published":1,"updated":"2019-03-23T10:32:05.692Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ej80022gyavzj3p6vv7"},{"title":"nginx单页应用基本配置","originContent":"我们经常会用到nginx单页应用，同时我们部署的时候需要注意一点就是单页应用的所有页面入口都是相同的, nginx上怎么配置呢\n\n<!-- more -->\n如下：\n\n```\nserver {\n    listen 80;\n    charset utf-8;\n    root /your/root;\n    index index.html index.htm;\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n}\n```","toc":false,"date":"2018-03-25T02:10:09.000Z","_content":"\n我们经常会用到nginx单页应用，同时我们部署的时候需要注意一点就是单页应用的所有页面入口都是相同的, nginx上怎么配置呢\n\n<!-- more -->\n如下：\n\n```\nserver {\n    listen 80;\n    charset utf-8;\n    root /your/root;\n    index index.html index.htm;\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n}\n```","source":"_posts/nginx单页应用基本配置.md","raw":"---\ntitle: nginx单页应用基本配置\ntags:\n  - nginx\noriginContent: |-\n  我们经常会用到nginx单页应用，同时我们部署的时候需要注意一点就是单页应用的所有页面入口都是相同的, nginx上怎么配置呢\n\n  <!-- more -->\n  如下：\n\n  ```\n  server {\n      listen 80;\n      charset utf-8;\n      root /your/root;\n      index index.html index.htm;\n      location / {\n          try_files $uri $uri/ /index.html;\n      }\n  }\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-03-25 10:10:09\n---\n\n我们经常会用到nginx单页应用，同时我们部署的时候需要注意一点就是单页应用的所有页面入口都是相同的, nginx上怎么配置呢\n\n<!-- more -->\n如下：\n\n```\nserver {\n    listen 80;\n    charset utf-8;\n    root /your/root;\n    index index.html index.htm;\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n}\n```","slug":"nginx单页应用基本配置","published":1,"updated":"2019-03-23T10:21:00.263Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejc0026gyavpqwggnlm"},{"title":"mkdir 用法","originContent":"这次主要想记录的是\n\n```\nmkdir -p folder1/folder2/folder3  # 没有文件夹则创建文件夹\n```\n\n帮助文档可以看下边：\n\n```\n用法：mkdir [选项]... 目录...\nCreate the DIRECTORY(ies), if they do not already exist.\n\nMandatory arguments to long options are mandatory for short options too.\n  -m, --mode=MODE   set file mode (as in chmod), not a=rwx - umask\n  -p, --parents     no error if existing, make parent directories as needed\n  -v, --verbose     print a message for each created directory\n  -Z                   set SELinux security context of each created directory\n                         to the default type\n      --context[=CTX]  like -Z, or if CTX is specified then set the SELinux\n                         or SMACK security context to CTX\n      --help\t\t显示此帮助信息并退出\n      --version\t\t显示版本信息并退出\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n请向<http://translationproject.org/team/zh_CN.html> 报告mkdir 的翻译错误\n要获取完整文档，请运行：info coreutils 'mkdir invocation'\n\n```","toc":false,"date":"2018-01-02T06:41:08.000Z","_content":"\n这次主要想记录的是\n\n```\nmkdir -p folder1/folder2/folder3  # 没有文件夹则创建文件夹\n```\n\n帮助文档可以看下边：\n\n```\n用法：mkdir [选项]... 目录...\nCreate the DIRECTORY(ies), if they do not already exist.\n\nMandatory arguments to long options are mandatory for short options too.\n  -m, --mode=MODE   set file mode (as in chmod), not a=rwx - umask\n  -p, --parents     no error if existing, make parent directories as needed\n  -v, --verbose     print a message for each created directory\n  -Z                   set SELinux security context of each created directory\n                         to the default type\n      --context[=CTX]  like -Z, or if CTX is specified then set the SELinux\n                         or SMACK security context to CTX\n      --help\t\t显示此帮助信息并退出\n      --version\t\t显示版本信息并退出\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n请向<http://translationproject.org/team/zh_CN.html> 报告mkdir 的翻译错误\n要获取完整文档，请运行：info coreutils 'mkdir invocation'\n\n```","source":"_posts/mkdir-用法.md","raw":"---\ntitle: mkdir 用法\ntags:\n  - linux\noriginContent: \"这次主要想记录的是\\n\\n```\\nmkdir -p folder1/folder2/folder3  # 没有文件夹则创建文件夹\\n```\\n\\n帮助文档可以看下边：\\n\\n```\\n用法：mkdir [选项]... 目录...\\nCreate the DIRECTORY(ies), if they do not already exist.\\n\\nMandatory arguments to long options are mandatory for short options too.\\n  -m, --mode=MODE   set file mode (as in chmod), not a=rwx - umask\\n  -p, --parents     no error if existing, make parent directories as needed\\n  -v, --verbose     print a message for each created directory\\n  -Z                   set SELinux security context of each created directory\\n                         to the default type\\n      --context[=CTX]  like -Z, or if CTX is specified then set the SELinux\\n                         or SMACK security context to CTX\\n      --help\\t\\t显示此帮助信息并退出\\n      --version\\t\\t显示版本信息并退出\\n\\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\\n请向<http://translationproject.org/team/zh_CN.html> 报告mkdir 的翻译错误\\n要获取完整文档，请运行：info coreutils 'mkdir invocation'\\n\\n```\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-02 14:41:08\n---\n\n这次主要想记录的是\n\n```\nmkdir -p folder1/folder2/folder3  # 没有文件夹则创建文件夹\n```\n\n帮助文档可以看下边：\n\n```\n用法：mkdir [选项]... 目录...\nCreate the DIRECTORY(ies), if they do not already exist.\n\nMandatory arguments to long options are mandatory for short options too.\n  -m, --mode=MODE   set file mode (as in chmod), not a=rwx - umask\n  -p, --parents     no error if existing, make parent directories as needed\n  -v, --verbose     print a message for each created directory\n  -Z                   set SELinux security context of each created directory\n                         to the default type\n      --context[=CTX]  like -Z, or if CTX is specified then set the SELinux\n                         or SMACK security context to CTX\n      --help\t\t显示此帮助信息并退出\n      --version\t\t显示版本信息并退出\n\nGNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n请向<http://translationproject.org/team/zh_CN.html> 报告mkdir 的翻译错误\n要获取完整文档，请运行：info coreutils 'mkdir invocation'\n\n```","slug":"mkdir-用法","published":1,"updated":"2019-03-23T10:27:56.648Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejf0029gyavxyw0u61e"},{"title":"nginx设置cookie点滴感悟","originContent":"公司有一个简单需求：利用nginx的ngx_http_auth_request_module模块设计一个鉴权接口，将鉴权接口返回的字符串赋值给$trueValue，设置到cookie的Value中。\n\n面对这个简单需求，首先，去百度搜索nginx、cookie等相关的关键字，有价值的内容不多，而且写的不够详细，令自己踩了不少坑，所以萌生了写作本文的想法。\n\n搜索后，我首先利用百度知道 https://zhidao.baidu.com/question/519658630466299605.html 这篇文章，能成功设置cookie。本地浏览器向nginx发送一个get/post请求，利用chrome开发者工具查看应答报文的头部已包含set_cookie字段，同时，在Resources标签可见已写入库，如下图1所示。但是，仅仅按照这文章这么做的话，Domain、Expires字段均为默认值，显然这不符合最终要求。\n\n接下来，继续搜索找到 http://www.iteye.com/problems/60159 这篇文章，文中在上篇文章的基础上，设置了自定义的domain、expires等字段。但是，这文章写得太简略了，根本没讲清楚使用原则是什么，无法让人彻底明白每个key应该如何设置，这为我的使用埋下一个坑。当我使用时，原封不动粘贴上面这个链接的add_header指令内容到自己nginx.conf中。经测试，在应答报文中的确包含了set-cookie字段（我们知道，浏览器获知了应答报文的set-cookie字段的信息，即可在本地保留cookie），但是没有入库(即在图1中查询不到任何信息)。\n\n所以就继续搜索，想解决没有入库的问题。此时，我这边思路出现了问题，错误地做出了如下判断：\n\n1. 认为使用add_header指令时，我的字段格式有问题，希望通过将如下指令的双引号换成单引号、增加或者删除空格、更改时间格式等方式让cookie入库，结果折腾好长时间宣告失败。\n\n```\nadd_header \"Set-Cookie\" \"rec_id=$rec_id;domain=.test1.com;path=/;expires=Mon, 29-Jun-2015 06:11:17 GMT\";\n```\n\n2. 认为本地chrome浏览器的设置有问题，遂尝试换成IE、Firefox等其他浏览器，看一下能否正常入库，经实验后，均无法正常入库。\n3. 认为add_header指令本身的问题，遂尝试ngx_http_userid_module这个专门用于设置cookie的nginx模块。\n\nngx_http_userid_module模块有专门的语句设置path、expires、domain等字段。但是，我通篇阅读了有关这个模块的nginx官网( http://nginx.org/en/docs/http/ngx_http_userid_module.html )文档后，竟然没有找到设置cookie Value的方式。以前也遇到过这种官方文档写作不明确的情况，比如：post_action指令在nginx官方文档找不到任何说明，但是实际上是可以使用的。没办法，只能自己尝试。我感觉既然userid_name指令是用来设置cookie name的，那么如果我用userid_name uid=\"myCookieValue\"这样，能不能成功呢？实验后，发现的确可以将cookie name设置成uid，cookie Value设置成\"myCookieValue\"。\n\n本以为这样就能完成任务了，坑爹的事儿又来了。如果这么用的话，竟然不支持nginx变量！比如，我设置userid_name uid=$trueValue，其中的$trueValue在nginx.conf中已赋值，但浏览器访问nginx后获取的Value值，竟然是$trueValue，而不是$trueValue中存储的值！这就尴尬了，这条路又走不通了。\n\n走了这么多弯路后，又开始大量搜索相关资料。终于 https://segmentfault.com/q/1010000006116583 中给出了\"同源原则\"，这简单的四字提示。我突然想到我的add_header指令中的domain字段设置的是.test1.com，而nginx的虚拟主机配置的域名是www.abc.com，这两者是不一致的，很有可能根据同源原则，只有这两者一致后，cookie才能设置成功。最后，经过实验，证明了我的判断是正确的。\n\n好了，文章抄到这里作为备忘，自己的设置如下：\n\n```\nserver {\n        listen                  80;\n        server_name             xxx.xx.com;\n        charset                 utf-8;\n        add_header Set-Cookie   'client_ip=$proxy_add_x_forwarded_for;domain=xxx.xx.com;path=/;';\n\n        index index.html;\n        root  /letv/www;\n}\n```","toc":false,"date":"2018-04-11T05:54:55.000Z","_content":"\n公司有一个简单需求：利用nginx的ngx_http_auth_request_module模块设计一个鉴权接口，将鉴权接口返回的字符串赋值给$trueValue，设置到cookie的Value中。\n\n面对这个简单需求，首先，去百度搜索nginx、cookie等相关的关键字，有价值的内容不多，而且写的不够详细，令自己踩了不少坑，所以萌生了写作本文的想法。\n\n搜索后，我首先利用百度知道 https://zhidao.baidu.com/question/519658630466299605.html 这篇文章，能成功设置cookie。本地浏览器向nginx发送一个get/post请求，利用chrome开发者工具查看应答报文的头部已包含set_cookie字段，同时，在Resources标签可见已写入库，如下图1所示。但是，仅仅按照这文章这么做的话，Domain、Expires字段均为默认值，显然这不符合最终要求。\n\n接下来，继续搜索找到 http://www.iteye.com/problems/60159 这篇文章，文中在上篇文章的基础上，设置了自定义的domain、expires等字段。但是，这文章写得太简略了，根本没讲清楚使用原则是什么，无法让人彻底明白每个key应该如何设置，这为我的使用埋下一个坑。当我使用时，原封不动粘贴上面这个链接的add_header指令内容到自己nginx.conf中。经测试，在应答报文中的确包含了set-cookie字段（我们知道，浏览器获知了应答报文的set-cookie字段的信息，即可在本地保留cookie），但是没有入库(即在图1中查询不到任何信息)。\n\n所以就继续搜索，想解决没有入库的问题。此时，我这边思路出现了问题，错误地做出了如下判断：\n\n1. 认为使用add_header指令时，我的字段格式有问题，希望通过将如下指令的双引号换成单引号、增加或者删除空格、更改时间格式等方式让cookie入库，结果折腾好长时间宣告失败。\n\n```\nadd_header \"Set-Cookie\" \"rec_id=$rec_id;domain=.test1.com;path=/;expires=Mon, 29-Jun-2015 06:11:17 GMT\";\n```\n\n2. 认为本地chrome浏览器的设置有问题，遂尝试换成IE、Firefox等其他浏览器，看一下能否正常入库，经实验后，均无法正常入库。\n3. 认为add_header指令本身的问题，遂尝试ngx_http_userid_module这个专门用于设置cookie的nginx模块。\n\nngx_http_userid_module模块有专门的语句设置path、expires、domain等字段。但是，我通篇阅读了有关这个模块的nginx官网( http://nginx.org/en/docs/http/ngx_http_userid_module.html )文档后，竟然没有找到设置cookie Value的方式。以前也遇到过这种官方文档写作不明确的情况，比如：post_action指令在nginx官方文档找不到任何说明，但是实际上是可以使用的。没办法，只能自己尝试。我感觉既然userid_name指令是用来设置cookie name的，那么如果我用userid_name uid=\"myCookieValue\"这样，能不能成功呢？实验后，发现的确可以将cookie name设置成uid，cookie Value设置成\"myCookieValue\"。\n\n本以为这样就能完成任务了，坑爹的事儿又来了。如果这么用的话，竟然不支持nginx变量！比如，我设置userid_name uid=$trueValue，其中的$trueValue在nginx.conf中已赋值，但浏览器访问nginx后获取的Value值，竟然是$trueValue，而不是$trueValue中存储的值！这就尴尬了，这条路又走不通了。\n\n走了这么多弯路后，又开始大量搜索相关资料。终于 https://segmentfault.com/q/1010000006116583 中给出了\"同源原则\"，这简单的四字提示。我突然想到我的add_header指令中的domain字段设置的是.test1.com，而nginx的虚拟主机配置的域名是www.abc.com，这两者是不一致的，很有可能根据同源原则，只有这两者一致后，cookie才能设置成功。最后，经过实验，证明了我的判断是正确的。\n\n好了，文章抄到这里作为备忘，自己的设置如下：\n\n```\nserver {\n        listen                  80;\n        server_name             xxx.xx.com;\n        charset                 utf-8;\n        add_header Set-Cookie   'client_ip=$proxy_add_x_forwarded_for;domain=xxx.xx.com;path=/;';\n\n        index index.html;\n        root  /letv/www;\n}\n```","source":"_posts/nginx设置cookie点滴感悟.md","raw":"---\ntitle: nginx设置cookie点滴感悟\ntags:\n  - nginx\noriginContent: >-\n  公司有一个简单需求：利用nginx的ngx_http_auth_request_module模块设计一个鉴权接口，将鉴权接口返回的字符串赋值给$trueValue，设置到cookie的Value中。\n\n\n  面对这个简单需求，首先，去百度搜索nginx、cookie等相关的关键字，有价值的内容不多，而且写的不够详细，令自己踩了不少坑，所以萌生了写作本文的想法。\n\n\n  搜索后，我首先利用百度知道 https://zhidao.baidu.com/question/519658630466299605.html\n  这篇文章，能成功设置cookie。本地浏览器向nginx发送一个get/post请求，利用chrome开发者工具查看应答报文的头部已包含set_cookie字段，同时，在Resources标签可见已写入库，如下图1所示。但是，仅仅按照这文章这么做的话，Domain、Expires字段均为默认值，显然这不符合最终要求。\n\n\n  接下来，继续搜索找到 http://www.iteye.com/problems/60159\n  这篇文章，文中在上篇文章的基础上，设置了自定义的domain、expires等字段。但是，这文章写得太简略了，根本没讲清楚使用原则是什么，无法让人彻底明白每个key应该如何设置，这为我的使用埋下一个坑。当我使用时，原封不动粘贴上面这个链接的add_header指令内容到自己nginx.conf中。经测试，在应答报文中的确包含了set-cookie字段（我们知道，浏览器获知了应答报文的set-cookie字段的信息，即可在本地保留cookie），但是没有入库(即在图1中查询不到任何信息)。\n\n\n  所以就继续搜索，想解决没有入库的问题。此时，我这边思路出现了问题，错误地做出了如下判断：\n\n\n  1.\n  认为使用add_header指令时，我的字段格式有问题，希望通过将如下指令的双引号换成单引号、增加或者删除空格、更改时间格式等方式让cookie入库，结果折腾好长时间宣告失败。\n\n\n  ```\n\n  add_header \"Set-Cookie\" \"rec_id=$rec_id;domain=.test1.com;path=/;expires=Mon,\n  29-Jun-2015 06:11:17 GMT\";\n\n  ```\n\n\n  2. 认为本地chrome浏览器的设置有问题，遂尝试换成IE、Firefox等其他浏览器，看一下能否正常入库，经实验后，均无法正常入库。\n\n  3. 认为add_header指令本身的问题，遂尝试ngx_http_userid_module这个专门用于设置cookie的nginx模块。\n\n\n  ngx_http_userid_module模块有专门的语句设置path、expires、domain等字段。但是，我通篇阅读了有关这个模块的nginx官网(\n  http://nginx.org/en/docs/http/ngx_http_userid_module.html )文档后，竟然没有找到设置cookie\n  Value的方式。以前也遇到过这种官方文档写作不明确的情况，比如：post_action指令在nginx官方文档找不到任何说明，但是实际上是可以使用的。没办法，只能自己尝试。我感觉既然userid_name指令是用来设置cookie\n  name的，那么如果我用userid_name uid=\"myCookieValue\"这样，能不能成功呢？实验后，发现的确可以将cookie\n  name设置成uid，cookie Value设置成\"myCookieValue\"。\n\n\n  本以为这样就能完成任务了，坑爹的事儿又来了。如果这么用的话，竟然不支持nginx变量！比如，我设置userid_name\n  uid=$trueValue，其中的$trueValue在nginx.conf中已赋值，但浏览器访问nginx后获取的Value值，竟然是$trueValue，而不是$trueValue中存储的值！这就尴尬了，这条路又走不通了。\n\n\n  走了这么多弯路后，又开始大量搜索相关资料。终于 https://segmentfault.com/q/1010000006116583\n  中给出了\"同源原则\"，这简单的四字提示。我突然想到我的add_header指令中的domain字段设置的是.test1.com，而nginx的虚拟主机配置的域名是www.abc.com，这两者是不一致的，很有可能根据同源原则，只有这两者一致后，cookie才能设置成功。最后，经过实验，证明了我的判断是正确的。\n\n\n  好了，文章抄到这里作为备忘，自己的设置如下：\n\n\n  ```\n\n  server {\n          listen                  80;\n          server_name             xxx.xx.com;\n          charset                 utf-8;\n          add_header Set-Cookie   'client_ip=$proxy_add_x_forwarded_for;domain=xxx.xx.com;path=/;';\n\n          index index.html;\n          root  /letv/www;\n  }\n\n  ```\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-04-11 13:54:55\n---\n\n公司有一个简单需求：利用nginx的ngx_http_auth_request_module模块设计一个鉴权接口，将鉴权接口返回的字符串赋值给$trueValue，设置到cookie的Value中。\n\n面对这个简单需求，首先，去百度搜索nginx、cookie等相关的关键字，有价值的内容不多，而且写的不够详细，令自己踩了不少坑，所以萌生了写作本文的想法。\n\n搜索后，我首先利用百度知道 https://zhidao.baidu.com/question/519658630466299605.html 这篇文章，能成功设置cookie。本地浏览器向nginx发送一个get/post请求，利用chrome开发者工具查看应答报文的头部已包含set_cookie字段，同时，在Resources标签可见已写入库，如下图1所示。但是，仅仅按照这文章这么做的话，Domain、Expires字段均为默认值，显然这不符合最终要求。\n\n接下来，继续搜索找到 http://www.iteye.com/problems/60159 这篇文章，文中在上篇文章的基础上，设置了自定义的domain、expires等字段。但是，这文章写得太简略了，根本没讲清楚使用原则是什么，无法让人彻底明白每个key应该如何设置，这为我的使用埋下一个坑。当我使用时，原封不动粘贴上面这个链接的add_header指令内容到自己nginx.conf中。经测试，在应答报文中的确包含了set-cookie字段（我们知道，浏览器获知了应答报文的set-cookie字段的信息，即可在本地保留cookie），但是没有入库(即在图1中查询不到任何信息)。\n\n所以就继续搜索，想解决没有入库的问题。此时，我这边思路出现了问题，错误地做出了如下判断：\n\n1. 认为使用add_header指令时，我的字段格式有问题，希望通过将如下指令的双引号换成单引号、增加或者删除空格、更改时间格式等方式让cookie入库，结果折腾好长时间宣告失败。\n\n```\nadd_header \"Set-Cookie\" \"rec_id=$rec_id;domain=.test1.com;path=/;expires=Mon, 29-Jun-2015 06:11:17 GMT\";\n```\n\n2. 认为本地chrome浏览器的设置有问题，遂尝试换成IE、Firefox等其他浏览器，看一下能否正常入库，经实验后，均无法正常入库。\n3. 认为add_header指令本身的问题，遂尝试ngx_http_userid_module这个专门用于设置cookie的nginx模块。\n\nngx_http_userid_module模块有专门的语句设置path、expires、domain等字段。但是，我通篇阅读了有关这个模块的nginx官网( http://nginx.org/en/docs/http/ngx_http_userid_module.html )文档后，竟然没有找到设置cookie Value的方式。以前也遇到过这种官方文档写作不明确的情况，比如：post_action指令在nginx官方文档找不到任何说明，但是实际上是可以使用的。没办法，只能自己尝试。我感觉既然userid_name指令是用来设置cookie name的，那么如果我用userid_name uid=\"myCookieValue\"这样，能不能成功呢？实验后，发现的确可以将cookie name设置成uid，cookie Value设置成\"myCookieValue\"。\n\n本以为这样就能完成任务了，坑爹的事儿又来了。如果这么用的话，竟然不支持nginx变量！比如，我设置userid_name uid=$trueValue，其中的$trueValue在nginx.conf中已赋值，但浏览器访问nginx后获取的Value值，竟然是$trueValue，而不是$trueValue中存储的值！这就尴尬了，这条路又走不通了。\n\n走了这么多弯路后，又开始大量搜索相关资料。终于 https://segmentfault.com/q/1010000006116583 中给出了\"同源原则\"，这简单的四字提示。我突然想到我的add_header指令中的domain字段设置的是.test1.com，而nginx的虚拟主机配置的域名是www.abc.com，这两者是不一致的，很有可能根据同源原则，只有这两者一致后，cookie才能设置成功。最后，经过实验，证明了我的判断是正确的。\n\n好了，文章抄到这里作为备忘，自己的设置如下：\n\n```\nserver {\n        listen                  80;\n        server_name             xxx.xx.com;\n        charset                 utf-8;\n        add_header Set-Cookie   'client_ip=$proxy_add_x_forwarded_for;domain=xxx.xx.com;path=/;';\n\n        index index.html;\n        root  /letv/www;\n}\n```","slug":"nginx设置cookie点滴感悟","published":1,"updated":"2019-03-23T10:18:16.434Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejk002dgyavwmg4s1i4"},{"title":"nodejs项目缓存策略","originContent":"项目中一定会用到缓存，能够最大程度的减少服务器压力，但有时候不同业务场景对缓存的使用方式也有所不同，比如我们项目服务端使用的memcached缓存，但当页面大于1M的时候缓存就无法保存，这样缓存的功能就无效了。\n\n之前的逻辑就是缓存失效后逻辑代码组装","toc":false,"date":"2018-01-10T11:17:10.000Z","_content":"\n项目中一定会用到缓存，能够最大程度的减少服务器压力，但有时候不同业务场景对缓存的使用方式也有所不同，比如我们项目服务端使用的memcached缓存，但当页面大于1M的时候缓存就无法保存，这样缓存的功能就无效了。\n\n之前的逻辑就是缓存失效后逻辑代码组装","source":"_posts/nodejs项目缓存策略.md","raw":"---\ntitle: nodejs项目缓存策略\ntags:\n  - nodejs\noriginContent: >-\n  项目中一定会用到缓存，能够最大程度的减少服务器压力，但有时候不同业务场景对缓存的使用方式也有所不同，比如我们项目服务端使用的memcached缓存，但当页面大于1M的时候缓存就无法保存，这样缓存的功能就无效了。\n\n\n  之前的逻辑就是缓存失效后逻辑代码组装\ncategories:\n  - NodeJS\ntoc: false\ndate: 2018-01-10 19:17:10\n---\n\n项目中一定会用到缓存，能够最大程度的减少服务器压力，但有时候不同业务场景对缓存的使用方式也有所不同，比如我们项目服务端使用的memcached缓存，但当页面大于1M的时候缓存就无法保存，这样缓存的功能就无效了。\n\n之前的逻辑就是缓存失效后逻辑代码组装","slug":"nodejs项目缓存策略","published":1,"updated":"2019-03-23T10:25:46.847Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejn002ggyav186x3j93"},{"title":"nodejs+redis应用","originContent":"1. 什么是Redis\n\n\tRedis是一个基于BSD开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API.\n\n\t<!-- more -->\n\t\n\t1. Redis存储的是一个个的键值对\n\t2. 通常用Redis做缓存数据库\n\t3. Redis的五种数据类型(字符串，哈希，链表，无序集合，有序集合)\n\n2. Redis安装\n\n\tRedis官方不支持windows安装，所以我们这里以centos7 为例：\n\t\n\t```\n\t$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\t$ rpm -Uvh https://centos7.iuscommunity.org/ius-release.rpm\n\t$ yum install redis -y\n\t$ systemctl start redis\n\t$ systemctl enable redis\n\t$ systemctl status redis\n\t```\n\n3. Redis运行\n\tRedis服务器默认使用6379端口\n\t\n\t> resis-server\n\t\n\t也可以自己指定端口\n\t\n\t> redis-server --port 6380\n\t\n\t客户端通过\n\t\n\t> redis-cli\n\t\n\t来连接数据库服务器\n\t\n\t也可以指定服务器地址和端口\n\t\n\t> redis-cli -h 127.0.0.1 -p 6380\n\t\n\t测试客户端和服务器是否连通\n\t\n\t> PING\n\t\n\t返回PONG说明连通了\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140354.png)\n\n4. Redis的基本使用\n\n\t4.1 字符串\n\t\n\tset key value 设置key的value\n\t\n\tget key 得到key的value\n\t\n\tincr key key如果是整型自增1\n\t\n\tkeys * 得到所有key\n\t\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140737.png)\n\n\t4.2 哈希\n\t\n\thset key filed value 设置key对象的field属性的value\n\t\n\thget key filed 得到key对象的field属性的value\n\t\n\thgetall key 得到key对象的所有的属性和值\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141134.png)\n\n\t4.3 链表\n\t\n\t适合存储社交网站的新鲜事\n\t\n\tlpush key value [value ...] 向链表key左边添加元素\n\t\n\trpush key value [value...] 向链表key右边添加元素\n\t\n\tlpop key 移除key链表左边第一个元素\n\t\n\trpop key 移除key链表右边第一元素\n\t\n\tlrange key start stop 获取链表中某一段，包含最大值，-1表示最后一个元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141515.png)\n\n\t4.4 集合类型\n\t\n\t适合存储文章的标签，因为是唯一的\n\t\n\tsadd key member [member ...] 向集合key中添加元素，如果元素已经存在则忽略\n\t\n\tsrem key member [member ...] 从集合key中删除元素\n\t\n\tsmembers key 返回集合key中所有的元素\n\t\n\tsinter key [key ...] 多个集合执行交集运算\n\t\n\tsdiff key [key ...] 多个集合执行差集运算\n\t\n\tsunion key [key ...] 多个集合执行并集运算\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141834.png)\n\n\t4.5 有序集合\n\t\n\t适用于通过文章访问量排序\n\t\n\tzadd key score member [score member ...] 向有序集合key中加入一个或多个元素和分数，如果元素已经存在，则替换分数\n\t\n\tzrem key member [member ...] 删除集合中一个或多个元素\n\t\n\tzrange key start stop [withscores] 按元素分数从小到大顺序返回元素，如需获得对应元素的分数，在尾部加上withscores\n\t\n\tzrevrange key start stop [withscores] 按元素分数从大到小顺序返回元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-142158.png)\n\n5.Redis 数据库桌面管理工具\n\n下载地址:http://redisdesktop.com/download\n\n可以很方便的管理Redis数据库里的键值对\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-150845@2x.png)\n\n6.Redis 数据库其他说明\nRedis默认支持16个数据库，编号0~15，每个数据库是独立的不能相互访问，可以通过\n\n> SELECT 数据库编号\n\n来更换数据库\n\nRedis不支持自定义数据库名字\n\nRedis不支持每个数据库设置不同的密码\n\n我们可以通过配置参数database修改支持的数据库个数，当选择的数据库编号超过最大数据库编号，默认使用最大数据库编号的数据库\n\n清空当前数据库的所有内容\n\n> flushdb\n\n清空所有数据库的所有内容\n\n> flushall\n\n随机返回当前数据库的一个键\n\n> randomkey\n\n删除一个或多个key\n\n> del key\n\n返回给定哈希表中所有键的值\n\n> hvals key\n\n**如果需要将redis用作缓存，可以设置生存时间，这样就不会持久化存储**\n\n设置某个键的生存时间\n\n1.(以秒为单位)\n\n> expire key time\n\n2.(以毫秒为单位)\n\n> pexpire key time\n\n以秒为单位返回给定key的剩余生存时间，没有设置生存时间则返回-1\n\n> ttl key\n\n下面我们来看一下怎么样在nodejs中使用redis\n\n1. 安装redis模块\n\n\t> npm install redis\n\n\t通过redis.createClient(port,host,options)来连接redis服务器\n\n```\nvar redis = require(\"redis\"),\n    client = redis.createClient(6380,\"117.121.25.228\",{});\n\nexports.throw = function(bottle,callback){\n    bottle.time = bottle.time || Date.now();\n    var bottleId = Math.random().toString(16);\n    var type = {male:0,female:1};\n    console.log(type[bottle.type]);\n    /*client.SELECT选择数据库编号*/\n    client.SELECT(type[bottle.type],function(){\n        /*client.HMSET 保存哈希键值*/\n        client.HMSET(bottleId,bottle,function(err,result){\n            if(err){\n                return callback({code:0,msg:\"过会儿再来试试吧！\"});\n            }\n            callback({code:1,msg:result});\n            /*设置过期时间为1天*/\n            client.EXPIRE(bottleId,86400);\n        });\n    });\n}\nexports.pick = function(info,callback){\n    var type = {all:Math.round(Math.random()),male:0,female:1};\n    info.type = info.type || 'all';\n    client.SELECT(type[info.type],function(){\n        /*随机返回当前数据库的一个键*/\n        client.RANDOMKEY(function(err,bottleId){\n            if(!bottleId){\n                return callback({code:0,msg:\"大海空空如也...\"});\n            }\n            /*根据key返回哈希对象*/\n            client.HGETALL(bottleId,function(err,bottle){\n                if(err){\n                    return callback({code:0,msg:\"漂流瓶破损了...\"});\n                }\n                callback({code:1,msg:bottle});\n                /*根据key删除键值*/\n                client.DEL(bottleId);\n            });\n        });\n    });\n}\n```\n\n作者：隔壁陈叔叔\n\n链接：[http://www.jianshu.com/p/dbc1da93eae5](http://www.jianshu.com/p/dbc1da93eae5)\n\n來源：简书\n\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","toc":false,"date":"2017-10-10T03:20:26.000Z","_content":"\n1. 什么是Redis\n\n\tRedis是一个基于BSD开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API.\n\n\t<!-- more -->\n\t\n\t1. Redis存储的是一个个的键值对\n\t2. 通常用Redis做缓存数据库\n\t3. Redis的五种数据类型(字符串，哈希，链表，无序集合，有序集合)\n\n2. Redis安装\n\n\tRedis官方不支持windows安装，所以我们这里以centos7 为例：\n\t\n\t```\n\t$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\t$ rpm -Uvh https://centos7.iuscommunity.org/ius-release.rpm\n\t$ yum install redis -y\n\t$ systemctl start redis\n\t$ systemctl enable redis\n\t$ systemctl status redis\n\t```\n\n3. Redis运行\n\tRedis服务器默认使用6379端口\n\t\n\t> resis-server\n\t\n\t也可以自己指定端口\n\t\n\t> redis-server --port 6380\n\t\n\t客户端通过\n\t\n\t> redis-cli\n\t\n\t来连接数据库服务器\n\t\n\t也可以指定服务器地址和端口\n\t\n\t> redis-cli -h 127.0.0.1 -p 6380\n\t\n\t测试客户端和服务器是否连通\n\t\n\t> PING\n\t\n\t返回PONG说明连通了\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140354.png)\n\n4. Redis的基本使用\n\n\t4.1 字符串\n\t\n\tset key value 设置key的value\n\t\n\tget key 得到key的value\n\t\n\tincr key key如果是整型自增1\n\t\n\tkeys * 得到所有key\n\t\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140737.png)\n\n\t4.2 哈希\n\t\n\thset key filed value 设置key对象的field属性的value\n\t\n\thget key filed 得到key对象的field属性的value\n\t\n\thgetall key 得到key对象的所有的属性和值\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141134.png)\n\n\t4.3 链表\n\t\n\t适合存储社交网站的新鲜事\n\t\n\tlpush key value [value ...] 向链表key左边添加元素\n\t\n\trpush key value [value...] 向链表key右边添加元素\n\t\n\tlpop key 移除key链表左边第一个元素\n\t\n\trpop key 移除key链表右边第一元素\n\t\n\tlrange key start stop 获取链表中某一段，包含最大值，-1表示最后一个元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141515.png)\n\n\t4.4 集合类型\n\t\n\t适合存储文章的标签，因为是唯一的\n\t\n\tsadd key member [member ...] 向集合key中添加元素，如果元素已经存在则忽略\n\t\n\tsrem key member [member ...] 从集合key中删除元素\n\t\n\tsmembers key 返回集合key中所有的元素\n\t\n\tsinter key [key ...] 多个集合执行交集运算\n\t\n\tsdiff key [key ...] 多个集合执行差集运算\n\t\n\tsunion key [key ...] 多个集合执行并集运算\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141834.png)\n\n\t4.5 有序集合\n\t\n\t适用于通过文章访问量排序\n\t\n\tzadd key score member [score member ...] 向有序集合key中加入一个或多个元素和分数，如果元素已经存在，则替换分数\n\t\n\tzrem key member [member ...] 删除集合中一个或多个元素\n\t\n\tzrange key start stop [withscores] 按元素分数从小到大顺序返回元素，如需获得对应元素的分数，在尾部加上withscores\n\t\n\tzrevrange key start stop [withscores] 按元素分数从大到小顺序返回元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-142158.png)\n\n5.Redis 数据库桌面管理工具\n\n下载地址:http://redisdesktop.com/download\n\n可以很方便的管理Redis数据库里的键值对\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-150845@2x.png)\n\n6.Redis 数据库其他说明\nRedis默认支持16个数据库，编号0~15，每个数据库是独立的不能相互访问，可以通过\n\n> SELECT 数据库编号\n\n来更换数据库\n\nRedis不支持自定义数据库名字\n\nRedis不支持每个数据库设置不同的密码\n\n我们可以通过配置参数database修改支持的数据库个数，当选择的数据库编号超过最大数据库编号，默认使用最大数据库编号的数据库\n\n清空当前数据库的所有内容\n\n> flushdb\n\n清空所有数据库的所有内容\n\n> flushall\n\n随机返回当前数据库的一个键\n\n> randomkey\n\n删除一个或多个key\n\n> del key\n\n返回给定哈希表中所有键的值\n\n> hvals key\n\n**如果需要将redis用作缓存，可以设置生存时间，这样就不会持久化存储**\n\n设置某个键的生存时间\n\n1.(以秒为单位)\n\n> expire key time\n\n2.(以毫秒为单位)\n\n> pexpire key time\n\n以秒为单位返回给定key的剩余生存时间，没有设置生存时间则返回-1\n\n> ttl key\n\n下面我们来看一下怎么样在nodejs中使用redis\n\n1. 安装redis模块\n\n\t> npm install redis\n\n\t通过redis.createClient(port,host,options)来连接redis服务器\n\n```\nvar redis = require(\"redis\"),\n    client = redis.createClient(6380,\"117.121.25.228\",{});\n\nexports.throw = function(bottle,callback){\n    bottle.time = bottle.time || Date.now();\n    var bottleId = Math.random().toString(16);\n    var type = {male:0,female:1};\n    console.log(type[bottle.type]);\n    /*client.SELECT选择数据库编号*/\n    client.SELECT(type[bottle.type],function(){\n        /*client.HMSET 保存哈希键值*/\n        client.HMSET(bottleId,bottle,function(err,result){\n            if(err){\n                return callback({code:0,msg:\"过会儿再来试试吧！\"});\n            }\n            callback({code:1,msg:result});\n            /*设置过期时间为1天*/\n            client.EXPIRE(bottleId,86400);\n        });\n    });\n}\nexports.pick = function(info,callback){\n    var type = {all:Math.round(Math.random()),male:0,female:1};\n    info.type = info.type || 'all';\n    client.SELECT(type[info.type],function(){\n        /*随机返回当前数据库的一个键*/\n        client.RANDOMKEY(function(err,bottleId){\n            if(!bottleId){\n                return callback({code:0,msg:\"大海空空如也...\"});\n            }\n            /*根据key返回哈希对象*/\n            client.HGETALL(bottleId,function(err,bottle){\n                if(err){\n                    return callback({code:0,msg:\"漂流瓶破损了...\"});\n                }\n                callback({code:1,msg:bottle});\n                /*根据key删除键值*/\n                client.DEL(bottleId);\n            });\n        });\n    });\n}\n```\n\n作者：隔壁陈叔叔\n\n链接：[http://www.jianshu.com/p/dbc1da93eae5](http://www.jianshu.com/p/dbc1da93eae5)\n\n來源：简书\n\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","source":"_posts/nodejs+redis应用.md","raw":"---\ntitle: nodejs+redis应用\ntags:\n  - redis\noriginContent: \"1. 什么是Redis\\n\\n\\tRedis是一个基于BSD开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API.\\n\\n\\t<!-- more -->\\n\\t\\n\\t1. Redis存储的是一个个的键值对\\n\\t2. 通常用Redis做缓存数据库\\n\\t3. Redis的五种数据类型(字符串，哈希，链表，无序集合，有序集合)\\n\\n2. Redis安装\\n\\n\\tRedis官方不支持windows安装，所以我们这里以centos7 为例：\\n\\t\\n\\t```\\n\\t$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\\n\\t$ rpm -Uvh https://centos7.iuscommunity.org/ius-release.rpm\\n\\t$ yum install redis -y\\n\\t$ systemctl start redis\\n\\t$ systemctl enable redis\\n\\t$ systemctl status redis\\n\\t```\\n\\n3. Redis运行\\n\\tRedis服务器默认使用6379端口\\n\\t\\n\\t> resis-server\\n\\t\\n\\t也可以自己指定端口\\n\\t\\n\\t> redis-server --port 6380\\n\\t\\n\\t客户端通过\\n\\t\\n\\t> redis-cli\\n\\t\\n\\t来连接数据库服务器\\n\\t\\n\\t也可以指定服务器地址和端口\\n\\t\\n\\t> redis-cli -h 127.0.0.1 -p 6380\\n\\t\\n\\t测试客户端和服务器是否连通\\n\\t\\n\\t> PING\\n\\t\\n\\t返回PONG说明连通了\\n\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140354.png)\\n\\n4. Redis的基本使用\\n\\n\\t4.1 字符串\\n\\t\\n\\tset key value 设置key的value\\n\\t\\n\\tget key 得到key的value\\n\\t\\n\\tincr key key如果是整型自增1\\n\\t\\n\\tkeys * 得到所有key\\n\\t\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140737.png)\\n\\n\\t4.2 哈希\\n\\t\\n\\thset key filed value 设置key对象的field属性的value\\n\\t\\n\\thget key filed 得到key对象的field属性的value\\n\\t\\n\\thgetall key 得到key对象的所有的属性和值\\n\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141134.png)\\n\\n\\t4.3 链表\\n\\t\\n\\t适合存储社交网站的新鲜事\\n\\t\\n\\tlpush key value [value ...] 向链表key左边添加元素\\n\\t\\n\\trpush key value [value...] 向链表key右边添加元素\\n\\t\\n\\tlpop key 移除key链表左边第一个元素\\n\\t\\n\\trpop key 移除key链表右边第一元素\\n\\t\\n\\tlrange key start stop 获取链表中某一段，包含最大值，-1表示最后一个元素\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141515.png)\\n\\n\\t4.4 集合类型\\n\\t\\n\\t适合存储文章的标签，因为是唯一的\\n\\t\\n\\tsadd key member [member ...] 向集合key中添加元素，如果元素已经存在则忽略\\n\\t\\n\\tsrem key member [member ...] 从集合key中删除元素\\n\\t\\n\\tsmembers key 返回集合key中所有的元素\\n\\t\\n\\tsinter key [key ...] 多个集合执行交集运算\\n\\t\\n\\tsdiff key [key ...] 多个集合执行差集运算\\n\\t\\n\\tsunion key [key ...] 多个集合执行并集运算\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141834.png)\\n\\n\\t4.5 有序集合\\n\\t\\n\\t适用于通过文章访问量排序\\n\\t\\n\\tzadd key score member [score member ...] 向有序集合key中加入一个或多个元素和分数，如果元素已经存在，则替换分数\\n\\t\\n\\tzrem key member [member ...] 删除集合中一个或多个元素\\n\\t\\n\\tzrange key start stop [withscores] 按元素分数从小到大顺序返回元素，如需获得对应元素的分数，在尾部加上withscores\\n\\t\\n\\tzrevrange key start stop [withscores] 按元素分数从大到小顺序返回元素\\n\\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-142158.png)\\n\\n5.Redis 数据库桌面管理工具\\n\\n下载地址:http://redisdesktop.com/download\\n\\n可以很方便的管理Redis数据库里的键值对\\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-150845@2x.png)\\n\\n6.Redis 数据库其他说明\\nRedis默认支持16个数据库，编号0~15，每个数据库是独立的不能相互访问，可以通过\\n\\n> SELECT 数据库编号\\n\\n来更换数据库\\n\\nRedis不支持自定义数据库名字\\n\\nRedis不支持每个数据库设置不同的密码\\n\\n我们可以通过配置参数database修改支持的数据库个数，当选择的数据库编号超过最大数据库编号，默认使用最大数据库编号的数据库\\n\\n清空当前数据库的所有内容\\n\\n> flushdb\\n\\n清空所有数据库的所有内容\\n\\n> flushall\\n\\n随机返回当前数据库的一个键\\n\\n> randomkey\\n\\n删除一个或多个key\\n\\n> del key\\n\\n返回给定哈希表中所有键的值\\n\\n> hvals key\\n\\n**如果需要将redis用作缓存，可以设置生存时间，这样就不会持久化存储**\\n\\n设置某个键的生存时间\\n\\n1.(以秒为单位)\\n\\n> expire key time\\n\\n2.(以毫秒为单位)\\n\\n> pexpire key time\\n\\n以秒为单位返回给定key的剩余生存时间，没有设置生存时间则返回-1\\n\\n> ttl key\\n\\n下面我们来看一下怎么样在nodejs中使用redis\\n\\n1. 安装redis模块\\n\\n\\t> npm install redis\\n\\n\\t通过redis.createClient(port,host,options)来连接redis服务器\\n\\n```\\nvar redis = require(\\\"redis\\\"),\\n    client = redis.createClient(6380,\\\"117.121.25.228\\\",{});\\n\\nexports.throw = function(bottle,callback){\\n    bottle.time = bottle.time || Date.now();\\n    var bottleId = Math.random().toString(16);\\n    var type = {male:0,female:1};\\n    console.log(type[bottle.type]);\\n    /*client.SELECT选择数据库编号*/\\n    client.SELECT(type[bottle.type],function(){\\n        /*client.HMSET 保存哈希键值*/\\n        client.HMSET(bottleId,bottle,function(err,result){\\n            if(err){\\n                return callback({code:0,msg:\\\"过会儿再来试试吧！\\\"});\\n            }\\n            callback({code:1,msg:result});\\n            /*设置过期时间为1天*/\\n            client.EXPIRE(bottleId,86400);\\n        });\\n    });\\n}\\nexports.pick = function(info,callback){\\n    var type = {all:Math.round(Math.random()),male:0,female:1};\\n    info.type = info.type || 'all';\\n    client.SELECT(type[info.type],function(){\\n        /*随机返回当前数据库的一个键*/\\n        client.RANDOMKEY(function(err,bottleId){\\n            if(!bottleId){\\n                return callback({code:0,msg:\\\"大海空空如也...\\\"});\\n            }\\n            /*根据key返回哈希对象*/\\n            client.HGETALL(bottleId,function(err,bottle){\\n                if(err){\\n                    return callback({code:0,msg:\\\"漂流瓶破损了...\\\"});\\n                }\\n                callback({code:1,msg:bottle});\\n                /*根据key删除键值*/\\n                client.DEL(bottleId);\\n            });\\n        });\\n    });\\n}\\n```\\n\\n作者：隔壁陈叔叔\\n\\n链接：[http://www.jianshu.com/p/dbc1da93eae5](http://www.jianshu.com/p/dbc1da93eae5)\\n\\n來源：简书\\n\\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\"\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-10-10 11:20:26\n---\n\n1. 什么是Redis\n\n\tRedis是一个基于BSD开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API.\n\n\t<!-- more -->\n\t\n\t1. Redis存储的是一个个的键值对\n\t2. 通常用Redis做缓存数据库\n\t3. Redis的五种数据类型(字符串，哈希，链表，无序集合，有序集合)\n\n2. Redis安装\n\n\tRedis官方不支持windows安装，所以我们这里以centos7 为例：\n\t\n\t```\n\t$ rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\t$ rpm -Uvh https://centos7.iuscommunity.org/ius-release.rpm\n\t$ yum install redis -y\n\t$ systemctl start redis\n\t$ systemctl enable redis\n\t$ systemctl status redis\n\t```\n\n3. Redis运行\n\tRedis服务器默认使用6379端口\n\t\n\t> resis-server\n\t\n\t也可以自己指定端口\n\t\n\t> redis-server --port 6380\n\t\n\t客户端通过\n\t\n\t> redis-cli\n\t\n\t来连接数据库服务器\n\t\n\t也可以指定服务器地址和端口\n\t\n\t> redis-cli -h 127.0.0.1 -p 6380\n\t\n\t测试客户端和服务器是否连通\n\t\n\t> PING\n\t\n\t返回PONG说明连通了\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140354.png)\n\n4. Redis的基本使用\n\n\t4.1 字符串\n\t\n\tset key value 设置key的value\n\t\n\tget key 得到key的value\n\t\n\tincr key key如果是整型自增1\n\t\n\tkeys * 得到所有key\n\t\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171010-140737.png)\n\n\t4.2 哈希\n\t\n\thset key filed value 设置key对象的field属性的value\n\t\n\thget key filed 得到key对象的field属性的value\n\t\n\thgetall key 得到key对象的所有的属性和值\n\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141134.png)\n\n\t4.3 链表\n\t\n\t适合存储社交网站的新鲜事\n\t\n\tlpush key value [value ...] 向链表key左边添加元素\n\t\n\trpush key value [value...] 向链表key右边添加元素\n\t\n\tlpop key 移除key链表左边第一个元素\n\t\n\trpop key 移除key链表右边第一元素\n\t\n\tlrange key start stop 获取链表中某一段，包含最大值，-1表示最后一个元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141515.png)\n\n\t4.4 集合类型\n\t\n\t适合存储文章的标签，因为是唯一的\n\t\n\tsadd key member [member ...] 向集合key中添加元素，如果元素已经存在则忽略\n\t\n\tsrem key member [member ...] 从集合key中删除元素\n\t\n\tsmembers key 返回集合key中所有的元素\n\t\n\tsinter key [key ...] 多个集合执行交集运算\n\t\n\tsdiff key [key ...] 多个集合执行差集运算\n\t\n\tsunion key [key ...] 多个集合执行并集运算\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-141834.png)\n\n\t4.5 有序集合\n\t\n\t适用于通过文章访问量排序\n\t\n\tzadd key score member [score member ...] 向有序集合key中加入一个或多个元素和分数，如果元素已经存在，则替换分数\n\t\n\tzrem key member [member ...] 删除集合中一个或多个元素\n\t\n\tzrange key start stop [withscores] 按元素分数从小到大顺序返回元素，如需获得对应元素的分数，在尾部加上withscores\n\t\n\tzrevrange key start stop [withscores] 按元素分数从大到小顺序返回元素\n\t![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-142158.png)\n\n5.Redis 数据库桌面管理工具\n\n下载地址:http://redisdesktop.com/download\n\n可以很方便的管理Redis数据库里的键值对\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/QQ20171010-150845@2x.png)\n\n6.Redis 数据库其他说明\nRedis默认支持16个数据库，编号0~15，每个数据库是独立的不能相互访问，可以通过\n\n> SELECT 数据库编号\n\n来更换数据库\n\nRedis不支持自定义数据库名字\n\nRedis不支持每个数据库设置不同的密码\n\n我们可以通过配置参数database修改支持的数据库个数，当选择的数据库编号超过最大数据库编号，默认使用最大数据库编号的数据库\n\n清空当前数据库的所有内容\n\n> flushdb\n\n清空所有数据库的所有内容\n\n> flushall\n\n随机返回当前数据库的一个键\n\n> randomkey\n\n删除一个或多个key\n\n> del key\n\n返回给定哈希表中所有键的值\n\n> hvals key\n\n**如果需要将redis用作缓存，可以设置生存时间，这样就不会持久化存储**\n\n设置某个键的生存时间\n\n1.(以秒为单位)\n\n> expire key time\n\n2.(以毫秒为单位)\n\n> pexpire key time\n\n以秒为单位返回给定key的剩余生存时间，没有设置生存时间则返回-1\n\n> ttl key\n\n下面我们来看一下怎么样在nodejs中使用redis\n\n1. 安装redis模块\n\n\t> npm install redis\n\n\t通过redis.createClient(port,host,options)来连接redis服务器\n\n```\nvar redis = require(\"redis\"),\n    client = redis.createClient(6380,\"117.121.25.228\",{});\n\nexports.throw = function(bottle,callback){\n    bottle.time = bottle.time || Date.now();\n    var bottleId = Math.random().toString(16);\n    var type = {male:0,female:1};\n    console.log(type[bottle.type]);\n    /*client.SELECT选择数据库编号*/\n    client.SELECT(type[bottle.type],function(){\n        /*client.HMSET 保存哈希键值*/\n        client.HMSET(bottleId,bottle,function(err,result){\n            if(err){\n                return callback({code:0,msg:\"过会儿再来试试吧！\"});\n            }\n            callback({code:1,msg:result});\n            /*设置过期时间为1天*/\n            client.EXPIRE(bottleId,86400);\n        });\n    });\n}\nexports.pick = function(info,callback){\n    var type = {all:Math.round(Math.random()),male:0,female:1};\n    info.type = info.type || 'all';\n    client.SELECT(type[info.type],function(){\n        /*随机返回当前数据库的一个键*/\n        client.RANDOMKEY(function(err,bottleId){\n            if(!bottleId){\n                return callback({code:0,msg:\"大海空空如也...\"});\n            }\n            /*根据key返回哈希对象*/\n            client.HGETALL(bottleId,function(err,bottle){\n                if(err){\n                    return callback({code:0,msg:\"漂流瓶破损了...\"});\n                }\n                callback({code:1,msg:bottle});\n                /*根据key删除键值*/\n                client.DEL(bottleId);\n            });\n        });\n    });\n}\n```\n\n作者：隔壁陈叔叔\n\n链接：[http://www.jianshu.com/p/dbc1da93eae5](http://www.jianshu.com/p/dbc1da93eae5)\n\n來源：简书\n\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","slug":"nodejs+redis应用","published":1,"updated":"2019-03-23T10:37:25.459Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejr002kgyav17bcf8r4"},{"title":"npm使用淘宝镜像","originContent":"> 淘宝的npm镜像地址为：[https://registry.npm.taobao.org](https://registry.npm.taobao.org) \n\n<!-- more -->\n\n# 临时使用\n```\nnpm --registry https://registry.npm.taobao.org install xxx\n```\n\n# 永久使用\n```\nnpm config set registry https://registry.npm.taobao.org\n```\n\n配置后使用npm config get registry来看是否已经发生变化\n\n还有一种方式是通过使用cnpm，但是这种方式会有一个问题，通过cnpm安装的组件很多会在目录前边带有版本号，个人认为这个效果很差，由于它是一个软连接的方式进行的引用，在windows系统甚至会报错，所以在无法翻墙的情况下，使用永久的用法还是不错的。","toc":false,"date":"2017-09-22T10:21:51.000Z","_content":"\n> 淘宝的npm镜像地址为：[https://registry.npm.taobao.org](https://registry.npm.taobao.org) \n\n<!-- more -->\n\n# 临时使用\n```\nnpm --registry https://registry.npm.taobao.org install xxx\n```\n\n# 永久使用\n```\nnpm config set registry https://registry.npm.taobao.org\n```\n\n配置后使用npm config get registry来看是否已经发生变化\n\n还有一种方式是通过使用cnpm，但是这种方式会有一个问题，通过cnpm安装的组件很多会在目录前边带有版本号，个人认为这个效果很差，由于它是一个软连接的方式进行的引用，在windows系统甚至会报错，所以在无法翻墙的情况下，使用永久的用法还是不错的。","source":"_posts/npm使用淘宝镜像.md","raw":"---\ntitle: npm使用淘宝镜像\ntags:\n  - nodejs\noriginContent: >-\n  >\n  淘宝的npm镜像地址为：[https://registry.npm.taobao.org](https://registry.npm.taobao.org) \n\n\n  <!-- more -->\n\n\n  # 临时使用\n\n  ```\n\n  npm --registry https://registry.npm.taobao.org install xxx\n\n  ```\n\n\n  # 永久使用\n\n  ```\n\n  npm config set registry https://registry.npm.taobao.org\n\n  ```\n\n\n  配置后使用npm config get registry来看是否已经发生变化\n\n\n  还有一种方式是通过使用cnpm，但是这种方式会有一个问题，通过cnpm安装的组件很多会在目录前边带有版本号，个人认为这个效果很差，由于它是一个软连接的方式进行的引用，在windows系统甚至会报错，所以在无法翻墙的情况下，使用永久的用法还是不错的。\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-09-22 18:21:51\n---\n\n> 淘宝的npm镜像地址为：[https://registry.npm.taobao.org](https://registry.npm.taobao.org) \n\n<!-- more -->\n\n# 临时使用\n```\nnpm --registry https://registry.npm.taobao.org install xxx\n```\n\n# 永久使用\n```\nnpm config set registry https://registry.npm.taobao.org\n```\n\n配置后使用npm config get registry来看是否已经发生变化\n\n还有一种方式是通过使用cnpm，但是这种方式会有一个问题，通过cnpm安装的组件很多会在目录前边带有版本号，个人认为这个效果很差，由于它是一个软连接的方式进行的引用，在windows系统甚至会报错，所以在无法翻墙的情况下，使用永久的用法还是不错的。","slug":"npm使用淘宝镜像","published":1,"updated":"2019-03-23T10:46:02.525Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eju002ngyav4n4jovvc"},{"title":"nvm永久切换node版本","originContent":"一行命令而已：\n\n```\nnvm alias default 7.6.0\n```\n\n通过 `nvm use 7.6.0` 只能在当前控制台临时修改版本，为了避免麻烦，可以使用上边的命令修改。","toc":false,"date":"2017-12-26T07:30:23.000Z","_content":"\n一行命令而已：\n\n```\nnvm alias default 7.6.0\n```\n\n通过 `nvm use 7.6.0` 只能在当前控制台临时修改版本，为了避免麻烦，可以使用上边的命令修改。","source":"_posts/nvm-切换node版本.md","raw":"---\ntitle: nvm永久切换node版本\ntags:\n  - nodejs\noriginContent: |-\n  一行命令而已：\n\n  ```\n  nvm alias default 7.6.0\n  ```\n\n  通过 `nvm use 7.6.0` 只能在当前控制台临时修改版本，为了避免麻烦，可以使用上边的命令修改。\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-12-26 15:30:23\n---\n\n一行命令而已：\n\n```\nnvm alias default 7.6.0\n```\n\n通过 `nvm use 7.6.0` 只能在当前控制台临时修改版本，为了避免麻烦，可以使用上边的命令修改。","slug":"nvm-切换node版本","published":1,"updated":"2019-03-23T10:45:09.030Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ejy002rgyaviwr7h5a8"},{"title":"pm2启动npm下服务的命令","originContent":"有时候我们的项目只有npm命令执行启动，这时候还想用pm2来管理该怎么做呢：\n\n```\n# 其中run start就是npm指令 npm run start\npm2 start npm --name 'yourprojectname' -- run start\n```","toc":false,"date":"2018-03-27T06:40:07.000Z","_content":"\n有时候我们的项目只有npm命令执行启动，这时候还想用pm2来管理该怎么做呢：\n\n```\n# 其中run start就是npm指令 npm run start\npm2 start npm --name 'yourprojectname' -- run start\n```","source":"_posts/pm2启动npm下服务的命令.md","raw":"---\ntitle: pm2启动npm下服务的命令\ntags:\n  - nodejs\noriginContent: |-\n  有时候我们的项目只有npm命令执行启动，这时候还想用pm2来管理该怎么做呢：\n\n  ```\n  # 其中run start就是npm指令 npm run start\n  pm2 start npm --name 'yourprojectname' -- run start\n  ```\ncategories:\n  - NodeJS\ntoc: false\ndate: 2018-03-27 14:40:07\n---\n\n有时候我们的项目只有npm命令执行启动，这时候还想用pm2来管理该怎么做呢：\n\n```\n# 其中run start就是npm指令 npm run start\npm2 start npm --name 'yourprojectname' -- run start\n```","slug":"pm2启动npm下服务的命令","published":1,"updated":"2019-03-23T10:45:49.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ek4002ugyaviteh738l"},{"title":"pomelo之rpc坑","originContent":"在使用pomelo的RPC功能时，由于不清楚它的尿性，最后的回调没有传入，导致一个问题\n\n服务器上总是有\n\n```\nrpc request timeout\nrpc callback timeout\n```\n\n的错误输出。但是却不影响业务，于是去代码里面搜索\n\n在mailbox那个文件中有这个输出\n\n原因是在每个rpc调用的时候会设置一个callback的timeout。\n\n若是在这个timeout内没有调用callback，则会产生如上输出\n\n后来果断在rpc中将callback传入，整个世界清静了。\n\n另外说一句，官方的chat示例中就有这个错误的示例。它在调用kick的时候callback传入的Null，不出意外的，一会以后它的输出也是rpc timeout….\n\n[原文地址](http://blog.csdn.net/nynyvkhhiiii/article/details/49757095)","toc":false,"date":"2018-03-12T08:15:05.000Z","_content":"\n在使用pomelo的RPC功能时，由于不清楚它的尿性，最后的回调没有传入，导致一个问题\n\n服务器上总是有\n\n```\nrpc request timeout\nrpc callback timeout\n```\n\n的错误输出。但是却不影响业务，于是去代码里面搜索\n\n在mailbox那个文件中有这个输出\n\n原因是在每个rpc调用的时候会设置一个callback的timeout。\n\n若是在这个timeout内没有调用callback，则会产生如上输出\n\n后来果断在rpc中将callback传入，整个世界清静了。\n\n另外说一句，官方的chat示例中就有这个错误的示例。它在调用kick的时候callback传入的Null，不出意外的，一会以后它的输出也是rpc timeout….\n\n[原文地址](http://blog.csdn.net/nynyvkhhiiii/article/details/49757095)","source":"_posts/pomelo之rpc坑.md","raw":"---\ntitle: pomelo之rpc坑\ntags:\n  - pomelo\noriginContent: >-\n  在使用pomelo的RPC功能时，由于不清楚它的尿性，最后的回调没有传入，导致一个问题\n\n\n  服务器上总是有\n\n\n  ```\n\n  rpc request timeout\n\n  rpc callback timeout\n\n  ```\n\n\n  的错误输出。但是却不影响业务，于是去代码里面搜索\n\n\n  在mailbox那个文件中有这个输出\n\n\n  原因是在每个rpc调用的时候会设置一个callback的timeout。\n\n\n  若是在这个timeout内没有调用callback，则会产生如上输出\n\n\n  后来果断在rpc中将callback传入，整个世界清静了。\n\n\n  另外说一句，官方的chat示例中就有这个错误的示例。它在调用kick的时候callback传入的Null，不出意外的，一会以后它的输出也是rpc\n  timeout….\n\n\n  [原文地址](http://blog.csdn.net/nynyvkhhiiii/article/details/49757095)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-03-12 16:15:05\n---\n\n在使用pomelo的RPC功能时，由于不清楚它的尿性，最后的回调没有传入，导致一个问题\n\n服务器上总是有\n\n```\nrpc request timeout\nrpc callback timeout\n```\n\n的错误输出。但是却不影响业务，于是去代码里面搜索\n\n在mailbox那个文件中有这个输出\n\n原因是在每个rpc调用的时候会设置一个callback的timeout。\n\n若是在这个timeout内没有调用callback，则会产生如上输出\n\n后来果断在rpc中将callback传入，整个世界清静了。\n\n另外说一句，官方的chat示例中就有这个错误的示例。它在调用kick的时候callback传入的Null，不出意外的，一会以后它的输出也是rpc timeout….\n\n[原文地址](http://blog.csdn.net/nynyvkhhiiii/article/details/49757095)","slug":"pomelo之rpc坑","published":1,"updated":"2019-03-23T10:21:12.966Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ek7002ygyav684hmmnv"},{"title":"pomelo的HelloWorld","originContent":"老传统，让我们也先从HelloWorld这个例子开始吧。\n\n## 新建项目\n\n使用pomelo的命令行工具可以**快速创建一个项目**，命令如下：\n\n```\npomelo init ./HelloWorld 或 pomelo init HelloWorld\n```\n\n或者你也可以使用下面的三个命令：\n\n```\nmkdir HelloWorld\ncd HelloWorld\npomelo init\n```\n\n这两种创建方式是等价的，更多关于pomelo命令行使用的文档，请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。在初始化项目的时候，用户需要选择其底层使用的通信协议，分为socket.io和websocket，**选择1或2回车即可**。\n\n<!-- more -->\n\n然后，进入到HelloWorld文件夹，安装依赖包：\n\n```\nsh npm-install.sh\n```\n\nwindows用户，可以直接运行 `npm-install.bat`\n\n## 项目目录结构\n让我们来看看一个pomelo项目的大致结构\n\n新建立的项目结构如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/HelloWorldFolder.png)\n\n该目录结构很清楚地展示了游戏项目的前后端分层结构，分别在各个目录下填写相关代码，即可快速开发游戏。下面对各个目录进行简要分析：\n\n### game-server\n**game-server是用pomelo框架搭建的游戏服务器**，以文件app.js作为入口，运行游戏的所有逻辑和功能。在接下来的开发中，**所有游戏逻辑、功能、配置等都在该目录下进行**。\n\n* app子目录\n\n这个目录下放置所有的**游戏服务器代码**的地方，用户在**这里实现不同类型的服务器**，添加对应的Handler，Remote等等。\n\n* config子目录\n\n**game-server下config包括了游戏服务器的所有配置信息**。配置信息以JSON文件的格式进行定义，包含有日志、master、server等服务器的配置信息。该目录还可以进行扩展，对数据库配置信息、地图信息和数值表等信息进行定义。总而言之，**这里是放着所有游戏服务器相关的配置信息的地方**。\n\n* logs子目录\n\n日志是项目中不可或缺的，可以对项目的运行情况进行很好的备份，也是系统运维的参考数据之一，**logs存放了游戏服务器所有的日志信息**。\n\n### shared\n\n**shared存放一些前后端、game-server与web-server共用代码**，由于都是javascript代码，那么对于一些工具或者算法代码，就可以前后端共用，极大地提高了代码重用性。\n\n### web-server\n\nweb-server是用express 3.x框架搭建的web服务器，以文件app.js作为入口，当然开发者可以选择Nginx等其他web服务器。如果游戏的客户端不是web的话，如Android平台的话，这个目录就不是必须的了。当然，**在这个例子中，我们的客户端是web，所以web服务器还是必须的**。\n\n## 启动项目\n对于我们这个例子来说，由于客户端是web，所以必须启动game-server(游戏服务器)和web-server(web服务器)\n\n启动game-server服务器：\n\n```\ncd game-server\npomelo start\n```\n\n启动web-server服务器：\n\n```\ncd web-server\nnode app \n```\n\n在启动过程中可能会有端口号冲突导致启动不成功，只需在config里面修改使用的端口号即可。如果上面的启动都没有问题的话，我们就可以对我们的HelloWorld进行测试了。用浏览器(推荐使用chrome)访问 http://localhost:3001或者 http://127.0.0.1:3001 即可, 点击Test Game Server，提示 game server is ok 说明运行成功，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/helloworld_test_snapshot.png)\n\n## 查看服务器\n可以使用`pomelo list`查看已经启动的服务器，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/list_snapshot.png)\n\n服务器状态可以查看5种状态信息：\n\n* serverId：服务器的serverId，同config配置表中的id。\n* serverType：服务器的serverType，同config配置表中的type。\n* pid：服务器对应的进程pid。\n* heapUsed：该服务器已经使用的堆大小（单位：兆）。\n* uptime：该服务器启动时长（单位：分钟）。\n\n## 关闭项目\n\n可以使用以下两种方式关闭项目：\n\n```\ncd game-server\npomelo stop\n```\n\n或者\n\n```\ncd game-server\npomelo kill\n```\n\n其中`pomelo stop`比较优雅，`pomelo kill`比较粗暴，安全性低，开发环境下可以使用，产品环境慎用，更详细的pomelo命令行用法请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。\n\n## 小结\n到这里为止，我们已经成功安装了pomelo，并成功运行了HelloWorld。接下来，建议你看一下pomelo整体的一个较详细的概述。 如果你已经迫不及待地想写代码，可以去pomelo例子教程, 那里以一个chat应用为例，一步一步地向你展示如何来使用pomelo进行一个实际应用的开发，以及pomelo的一些API的使用方式等。","toc":false,"date":"2018-02-28T04:04:05.000Z","_content":"\n老传统，让我们也先从HelloWorld这个例子开始吧。\n\n## 新建项目\n\n使用pomelo的命令行工具可以**快速创建一个项目**，命令如下：\n\n```\npomelo init ./HelloWorld 或 pomelo init HelloWorld\n```\n\n或者你也可以使用下面的三个命令：\n\n```\nmkdir HelloWorld\ncd HelloWorld\npomelo init\n```\n\n这两种创建方式是等价的，更多关于pomelo命令行使用的文档，请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。在初始化项目的时候，用户需要选择其底层使用的通信协议，分为socket.io和websocket，**选择1或2回车即可**。\n\n<!-- more -->\n\n然后，进入到HelloWorld文件夹，安装依赖包：\n\n```\nsh npm-install.sh\n```\n\nwindows用户，可以直接运行 `npm-install.bat`\n\n## 项目目录结构\n让我们来看看一个pomelo项目的大致结构\n\n新建立的项目结构如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/HelloWorldFolder.png)\n\n该目录结构很清楚地展示了游戏项目的前后端分层结构，分别在各个目录下填写相关代码，即可快速开发游戏。下面对各个目录进行简要分析：\n\n### game-server\n**game-server是用pomelo框架搭建的游戏服务器**，以文件app.js作为入口，运行游戏的所有逻辑和功能。在接下来的开发中，**所有游戏逻辑、功能、配置等都在该目录下进行**。\n\n* app子目录\n\n这个目录下放置所有的**游戏服务器代码**的地方，用户在**这里实现不同类型的服务器**，添加对应的Handler，Remote等等。\n\n* config子目录\n\n**game-server下config包括了游戏服务器的所有配置信息**。配置信息以JSON文件的格式进行定义，包含有日志、master、server等服务器的配置信息。该目录还可以进行扩展，对数据库配置信息、地图信息和数值表等信息进行定义。总而言之，**这里是放着所有游戏服务器相关的配置信息的地方**。\n\n* logs子目录\n\n日志是项目中不可或缺的，可以对项目的运行情况进行很好的备份，也是系统运维的参考数据之一，**logs存放了游戏服务器所有的日志信息**。\n\n### shared\n\n**shared存放一些前后端、game-server与web-server共用代码**，由于都是javascript代码，那么对于一些工具或者算法代码，就可以前后端共用，极大地提高了代码重用性。\n\n### web-server\n\nweb-server是用express 3.x框架搭建的web服务器，以文件app.js作为入口，当然开发者可以选择Nginx等其他web服务器。如果游戏的客户端不是web的话，如Android平台的话，这个目录就不是必须的了。当然，**在这个例子中，我们的客户端是web，所以web服务器还是必须的**。\n\n## 启动项目\n对于我们这个例子来说，由于客户端是web，所以必须启动game-server(游戏服务器)和web-server(web服务器)\n\n启动game-server服务器：\n\n```\ncd game-server\npomelo start\n```\n\n启动web-server服务器：\n\n```\ncd web-server\nnode app \n```\n\n在启动过程中可能会有端口号冲突导致启动不成功，只需在config里面修改使用的端口号即可。如果上面的启动都没有问题的话，我们就可以对我们的HelloWorld进行测试了。用浏览器(推荐使用chrome)访问 http://localhost:3001或者 http://127.0.0.1:3001 即可, 点击Test Game Server，提示 game server is ok 说明运行成功，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/helloworld_test_snapshot.png)\n\n## 查看服务器\n可以使用`pomelo list`查看已经启动的服务器，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/list_snapshot.png)\n\n服务器状态可以查看5种状态信息：\n\n* serverId：服务器的serverId，同config配置表中的id。\n* serverType：服务器的serverType，同config配置表中的type。\n* pid：服务器对应的进程pid。\n* heapUsed：该服务器已经使用的堆大小（单位：兆）。\n* uptime：该服务器启动时长（单位：分钟）。\n\n## 关闭项目\n\n可以使用以下两种方式关闭项目：\n\n```\ncd game-server\npomelo stop\n```\n\n或者\n\n```\ncd game-server\npomelo kill\n```\n\n其中`pomelo stop`比较优雅，`pomelo kill`比较粗暴，安全性低，开发环境下可以使用，产品环境慎用，更详细的pomelo命令行用法请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。\n\n## 小结\n到这里为止，我们已经成功安装了pomelo，并成功运行了HelloWorld。接下来，建议你看一下pomelo整体的一个较详细的概述。 如果你已经迫不及待地想写代码，可以去pomelo例子教程, 那里以一个chat应用为例，一步一步地向你展示如何来使用pomelo进行一个实际应用的开发，以及pomelo的一些API的使用方式等。","source":"_posts/pomelo的HelloWorld.md","raw":"---\ntitle: pomelo的HelloWorld\ntags:\n  - pomelo\noriginContent: >-\n  老传统，让我们也先从HelloWorld这个例子开始吧。\n\n\n  ## 新建项目\n\n\n  使用pomelo的命令行工具可以**快速创建一个项目**，命令如下：\n\n\n  ```\n\n  pomelo init ./HelloWorld 或 pomelo init HelloWorld\n\n  ```\n\n\n  或者你也可以使用下面的三个命令：\n\n\n  ```\n\n  mkdir HelloWorld\n\n  cd HelloWorld\n\n  pomelo init\n\n  ```\n\n\n  这两种创建方式是等价的，更多关于pomelo命令行使用的文档，请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。在初始化项目的时候，用户需要选择其底层使用的通信协议，分为socket.io和websocket，**选择1或2回车即可**。\n\n\n  <!-- more -->\n\n\n  然后，进入到HelloWorld文件夹，安装依赖包：\n\n\n  ```\n\n  sh npm-install.sh\n\n  ```\n\n\n  windows用户，可以直接运行 `npm-install.bat`\n\n\n  ## 项目目录结构\n\n  让我们来看看一个pomelo项目的大致结构\n\n\n  新建立的项目结构如下图所示：\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/HelloWorldFolder.png)\n\n\n  该目录结构很清楚地展示了游戏项目的前后端分层结构，分别在各个目录下填写相关代码，即可快速开发游戏。下面对各个目录进行简要分析：\n\n\n  ### game-server\n\n  **game-server是用pomelo框架搭建的游戏服务器**，以文件app.js作为入口，运行游戏的所有逻辑和功能。在接下来的开发中，**所有游戏逻辑、功能、配置等都在该目录下进行**。\n\n\n  * app子目录\n\n\n  这个目录下放置所有的**游戏服务器代码**的地方，用户在**这里实现不同类型的服务器**，添加对应的Handler，Remote等等。\n\n\n  * config子目录\n\n\n  **game-server下config包括了游戏服务器的所有配置信息**。配置信息以JSON文件的格式进行定义，包含有日志、master、server等服务器的配置信息。该目录还可以进行扩展，对数据库配置信息、地图信息和数值表等信息进行定义。总而言之，**这里是放着所有游戏服务器相关的配置信息的地方**。\n\n\n  * logs子目录\n\n\n  日志是项目中不可或缺的，可以对项目的运行情况进行很好的备份，也是系统运维的参考数据之一，**logs存放了游戏服务器所有的日志信息**。\n\n\n  ### shared\n\n\n  **shared存放一些前后端、game-server与web-server共用代码**，由于都是javascript代码，那么对于一些工具或者算法代码，就可以前后端共用，极大地提高了代码重用性。\n\n\n  ### web-server\n\n\n  web-server是用express\n  3.x框架搭建的web服务器，以文件app.js作为入口，当然开发者可以选择Nginx等其他web服务器。如果游戏的客户端不是web的话，如Android平台的话，这个目录就不是必须的了。当然，**在这个例子中，我们的客户端是web，所以web服务器还是必须的**。\n\n\n  ## 启动项目\n\n  对于我们这个例子来说，由于客户端是web，所以必须启动game-server(游戏服务器)和web-server(web服务器)\n\n\n  启动game-server服务器：\n\n\n  ```\n\n  cd game-server\n\n  pomelo start\n\n  ```\n\n\n  启动web-server服务器：\n\n\n  ```\n\n  cd web-server\n\n  node app \n\n  ```\n\n\n  在启动过程中可能会有端口号冲突导致启动不成功，只需在config里面修改使用的端口号即可。如果上面的启动都没有问题的话，我们就可以对我们的HelloWorld进行测试了。用浏览器(推荐使用chrome)访问\n  http://localhost:3001或者 http://127.0.0.1:3001 即可, 点击Test Game Server，提示 game\n  server is ok 说明运行成功，如下图所示：\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/helloworld_test_snapshot.png)\n\n\n  ## 查看服务器\n\n  可以使用`pomelo list`查看已经启动的服务器，如下图所示：\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/list_snapshot.png)\n\n\n  服务器状态可以查看5种状态信息：\n\n\n  * serverId：服务器的serverId，同config配置表中的id。\n\n  * serverType：服务器的serverType，同config配置表中的type。\n\n  * pid：服务器对应的进程pid。\n\n  * heapUsed：该服务器已经使用的堆大小（单位：兆）。\n\n  * uptime：该服务器启动时长（单位：分钟）。\n\n\n  ## 关闭项目\n\n\n  可以使用以下两种方式关闭项目：\n\n\n  ```\n\n  cd game-server\n\n  pomelo stop\n\n  ```\n\n\n  或者\n\n\n  ```\n\n  cd game-server\n\n  pomelo kill\n\n  ```\n\n\n  其中`pomelo stop`比较优雅，`pomelo\n  kill`比较粗暴，安全性低，开发环境下可以使用，产品环境慎用，更详细的pomelo命令行用法请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。\n\n\n  ## 小结\n\n  到这里为止，我们已经成功安装了pomelo，并成功运行了HelloWorld。接下来，建议你看一下pomelo整体的一个较详细的概述。\n  如果你已经迫不及待地想写代码，可以去pomelo例子教程,\n  那里以一个chat应用为例，一步一步地向你展示如何来使用pomelo进行一个实际应用的开发，以及pomelo的一些API的使用方式等。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-02-28 12:04:05\n---\n\n老传统，让我们也先从HelloWorld这个例子开始吧。\n\n## 新建项目\n\n使用pomelo的命令行工具可以**快速创建一个项目**，命令如下：\n\n```\npomelo init ./HelloWorld 或 pomelo init HelloWorld\n```\n\n或者你也可以使用下面的三个命令：\n\n```\nmkdir HelloWorld\ncd HelloWorld\npomelo init\n```\n\n这两种创建方式是等价的，更多关于pomelo命令行使用的文档，请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。在初始化项目的时候，用户需要选择其底层使用的通信协议，分为socket.io和websocket，**选择1或2回车即可**。\n\n<!-- more -->\n\n然后，进入到HelloWorld文件夹，安装依赖包：\n\n```\nsh npm-install.sh\n```\n\nwindows用户，可以直接运行 `npm-install.bat`\n\n## 项目目录结构\n让我们来看看一个pomelo项目的大致结构\n\n新建立的项目结构如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/HelloWorldFolder.png)\n\n该目录结构很清楚地展示了游戏项目的前后端分层结构，分别在各个目录下填写相关代码，即可快速开发游戏。下面对各个目录进行简要分析：\n\n### game-server\n**game-server是用pomelo框架搭建的游戏服务器**，以文件app.js作为入口，运行游戏的所有逻辑和功能。在接下来的开发中，**所有游戏逻辑、功能、配置等都在该目录下进行**。\n\n* app子目录\n\n这个目录下放置所有的**游戏服务器代码**的地方，用户在**这里实现不同类型的服务器**，添加对应的Handler，Remote等等。\n\n* config子目录\n\n**game-server下config包括了游戏服务器的所有配置信息**。配置信息以JSON文件的格式进行定义，包含有日志、master、server等服务器的配置信息。该目录还可以进行扩展，对数据库配置信息、地图信息和数值表等信息进行定义。总而言之，**这里是放着所有游戏服务器相关的配置信息的地方**。\n\n* logs子目录\n\n日志是项目中不可或缺的，可以对项目的运行情况进行很好的备份，也是系统运维的参考数据之一，**logs存放了游戏服务器所有的日志信息**。\n\n### shared\n\n**shared存放一些前后端、game-server与web-server共用代码**，由于都是javascript代码，那么对于一些工具或者算法代码，就可以前后端共用，极大地提高了代码重用性。\n\n### web-server\n\nweb-server是用express 3.x框架搭建的web服务器，以文件app.js作为入口，当然开发者可以选择Nginx等其他web服务器。如果游戏的客户端不是web的话，如Android平台的话，这个目录就不是必须的了。当然，**在这个例子中，我们的客户端是web，所以web服务器还是必须的**。\n\n## 启动项目\n对于我们这个例子来说，由于客户端是web，所以必须启动game-server(游戏服务器)和web-server(web服务器)\n\n启动game-server服务器：\n\n```\ncd game-server\npomelo start\n```\n\n启动web-server服务器：\n\n```\ncd web-server\nnode app \n```\n\n在启动过程中可能会有端口号冲突导致启动不成功，只需在config里面修改使用的端口号即可。如果上面的启动都没有问题的话，我们就可以对我们的HelloWorld进行测试了。用浏览器(推荐使用chrome)访问 http://localhost:3001或者 http://127.0.0.1:3001 即可, 点击Test Game Server，提示 game server is ok 说明运行成功，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/helloworld_test_snapshot.png)\n\n## 查看服务器\n可以使用`pomelo list`查看已经启动的服务器，如下图所示：\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/pomelo/list_snapshot.png)\n\n服务器状态可以查看5种状态信息：\n\n* serverId：服务器的serverId，同config配置表中的id。\n* serverType：服务器的serverType，同config配置表中的type。\n* pid：服务器对应的进程pid。\n* heapUsed：该服务器已经使用的堆大小（单位：兆）。\n* uptime：该服务器启动时长（单位：分钟）。\n\n## 关闭项目\n\n可以使用以下两种方式关闭项目：\n\n```\ncd game-server\npomelo stop\n```\n\n或者\n\n```\ncd game-server\npomelo kill\n```\n\n其中`pomelo stop`比较优雅，`pomelo kill`比较粗暴，安全性低，开发环境下可以使用，产品环境慎用，更详细的pomelo命令行用法请参阅[pomelo命令行工具使用](https://github.com/NetEase/pomelo/wiki/pomelo%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8)。\n\n## 小结\n到这里为止，我们已经成功安装了pomelo，并成功运行了HelloWorld。接下来，建议你看一下pomelo整体的一个较详细的概述。 如果你已经迫不及待地想写代码，可以去pomelo例子教程, 那里以一个chat应用为例，一步一步地向你展示如何来使用pomelo进行一个实际应用的开发，以及pomelo的一些API的使用方式等。","slug":"pomelo的HelloWorld","published":1,"updated":"2019-03-23T10:21:40.513Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eka0031gyav8hxbouxf"},{"title":"vagrant ssh 本机连接方式","originContent":"vagrant 启动虚拟机以后想通过本机的命令行进行连接，这时候需要用到openssh\n\n1. 安装openssh\n\n```\nyum install openssh-* -y\n```\n\n2. 查看及启动sshd\n\n```\nsystemctl status sshd\nsystemctl restart sshd\n```\n\n3. 修改配置文件\n\n```\nvi /etc/ssh/sshd_config\n```\n\n4. 去掉两处注释\n\n```\nPort 22\nListenAddress 0.0.0.0\n```\n\n5. 修改一处配置\n\n```\nPasswordAuthentication yes\n```\n\n有了这些东西就可以在别的机器上ssh到这个机器了，同时可以使用linux-ssh远程不输入密码","toc":false,"date":"2018-04-08T12:27:02.000Z","_content":"\nvagrant 启动虚拟机以后想通过本机的命令行进行连接，这时候需要用到openssh\n\n1. 安装openssh\n\n```\nyum install openssh-* -y\n```\n\n2. 查看及启动sshd\n\n```\nsystemctl status sshd\nsystemctl restart sshd\n```\n\n3. 修改配置文件\n\n```\nvi /etc/ssh/sshd_config\n```\n\n4. 去掉两处注释\n\n```\nPort 22\nListenAddress 0.0.0.0\n```\n\n5. 修改一处配置\n\n```\nPasswordAuthentication yes\n```\n\n有了这些东西就可以在别的机器上ssh到这个机器了，同时可以使用linux-ssh远程不输入密码","source":"_posts/vagrant-ssh-本机连接方式.md","raw":"---\ntitle: vagrant ssh 本机连接方式\ntags:\n  - vagrant\noriginContent: |-\n  vagrant 启动虚拟机以后想通过本机的命令行进行连接，这时候需要用到openssh\n\n  1. 安装openssh\n\n  ```\n  yum install openssh-* -y\n  ```\n\n  2. 查看及启动sshd\n\n  ```\n  systemctl status sshd\n  systemctl restart sshd\n  ```\n\n  3. 修改配置文件\n\n  ```\n  vi /etc/ssh/sshd_config\n  ```\n\n  4. 去掉两处注释\n\n  ```\n  Port 22\n  ListenAddress 0.0.0.0\n  ```\n\n  5. 修改一处配置\n\n  ```\n  PasswordAuthentication yes\n  ```\n\n  有了这些东西就可以在别的机器上ssh到这个机器了，同时可以使用linux-ssh远程不输入密码\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-04-08 20:27:02\n---\n\nvagrant 启动虚拟机以后想通过本机的命令行进行连接，这时候需要用到openssh\n\n1. 安装openssh\n\n```\nyum install openssh-* -y\n```\n\n2. 查看及启动sshd\n\n```\nsystemctl status sshd\nsystemctl restart sshd\n```\n\n3. 修改配置文件\n\n```\nvi /etc/ssh/sshd_config\n```\n\n4. 去掉两处注释\n\n```\nPort 22\nListenAddress 0.0.0.0\n```\n\n5. 修改一处配置\n\n```\nPasswordAuthentication yes\n```\n\n有了这些东西就可以在别的机器上ssh到这个机器了，同时可以使用linux-ssh远程不输入密码","slug":"vagrant-ssh-本机连接方式","published":1,"updated":"2019-03-23T10:19:13.067Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ekg0034gyavlcvvrfj1"},{"title":"uptime命令","originContent":"uptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。\n\n## 语法\n\n```\nuptime(选项)\n```\n\n## 选项\n\n```\n-V：显示指令的版本信息。\n```\n\n## 实例\n\n使用uptime命令查看系统负载：\n\n```\n[root@LinServ-1 ~]# uptime -V    #显示uptime命令版本信息\nprocps version 3.2.7\n\n[root@LinServ-1 ~]# uptime\n 15:31:30 up 127 days,  3:00,  1 user,  load average: 0.00, 0.00, 0.00\n```\n\n<!-- more -->\n\n显示内容说明：\n\n```\n15:31:30             //系统当前时间\nup 127 days,  3:00   //主机已运行时间,时间越大，说明你的机器越稳定。\n1 user               //用户连接数，是总连接数而不是用户数\nload average: 0.00, 0.00, 0.00         // 系统平均负载，统计最近1，5，15分钟的系统平均负载\n```\n\n那么什么是系统平均负载呢？ 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。\n\n如果每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。\n\n如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了。\n\n[原文地址](http://man.linuxde.net/uptime)","toc":false,"date":"2018-01-24T02:48:47.000Z","_content":"\nuptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。\n\n## 语法\n\n```\nuptime(选项)\n```\n\n## 选项\n\n```\n-V：显示指令的版本信息。\n```\n\n## 实例\n\n使用uptime命令查看系统负载：\n\n```\n[root@LinServ-1 ~]# uptime -V    #显示uptime命令版本信息\nprocps version 3.2.7\n\n[root@LinServ-1 ~]# uptime\n 15:31:30 up 127 days,  3:00,  1 user,  load average: 0.00, 0.00, 0.00\n```\n\n<!-- more -->\n\n显示内容说明：\n\n```\n15:31:30             //系统当前时间\nup 127 days,  3:00   //主机已运行时间,时间越大，说明你的机器越稳定。\n1 user               //用户连接数，是总连接数而不是用户数\nload average: 0.00, 0.00, 0.00         // 系统平均负载，统计最近1，5，15分钟的系统平均负载\n```\n\n那么什么是系统平均负载呢？ 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。\n\n如果每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。\n\n如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了。\n\n[原文地址](http://man.linuxde.net/uptime)","source":"_posts/uptime命令.md","raw":"---\ntitle: uptime命令\ntags:\n  - linux\noriginContent: >-\n  uptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。\n\n\n  ## 语法\n\n\n  ```\n\n  uptime(选项)\n\n  ```\n\n\n  ## 选项\n\n\n  ```\n\n  -V：显示指令的版本信息。\n\n  ```\n\n\n  ## 实例\n\n\n  使用uptime命令查看系统负载：\n\n\n  ```\n\n  [root@LinServ-1 ~]# uptime -V    #显示uptime命令版本信息\n\n  procps version 3.2.7\n\n\n  [root@LinServ-1 ~]# uptime\n   15:31:30 up 127 days,  3:00,  1 user,  load average: 0.00, 0.00, 0.00\n  ```\n\n\n  <!-- more -->\n\n\n  显示内容说明：\n\n\n  ```\n\n  15:31:30             //系统当前时间\n\n  up 127 days,  3:00   //主机已运行时间,时间越大，说明你的机器越稳定。\n\n  1 user               //用户连接数，是总连接数而不是用户数\n\n  load average: 0.00, 0.00, 0.00         // 系统平均负载，统计最近1，5，15分钟的系统平均负载\n\n  ```\n\n\n  那么什么是系统平均负载呢？ 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。\n\n\n  如果每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。\n\n\n  如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了。\n\n\n  [原文地址](http://man.linuxde.net/uptime)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-24 10:48:47\n---\n\nuptime命令能够打印系统总共运行了多长时间和系统的平均负载。uptime命令可以显示的信息显示依次为：现在时间、系统已经运行了多长时间、目前有多少登陆用户、系统在过去的1分钟、5分钟和15分钟内的平均负载。\n\n## 语法\n\n```\nuptime(选项)\n```\n\n## 选项\n\n```\n-V：显示指令的版本信息。\n```\n\n## 实例\n\n使用uptime命令查看系统负载：\n\n```\n[root@LinServ-1 ~]# uptime -V    #显示uptime命令版本信息\nprocps version 3.2.7\n\n[root@LinServ-1 ~]# uptime\n 15:31:30 up 127 days,  3:00,  1 user,  load average: 0.00, 0.00, 0.00\n```\n\n<!-- more -->\n\n显示内容说明：\n\n```\n15:31:30             //系统当前时间\nup 127 days,  3:00   //主机已运行时间,时间越大，说明你的机器越稳定。\n1 user               //用户连接数，是总连接数而不是用户数\nload average: 0.00, 0.00, 0.00         // 系统平均负载，统计最近1，5，15分钟的系统平均负载\n```\n\n那么什么是系统平均负载呢？ 系统平均负载是指在特定时间间隔内运行队列中的平均进程数。\n\n如果每个CPU内核的当前活动进程数不大于3的话，那么系统的性能是良好的。如果每个CPU内核的任务数大于5，那么这台机器的性能有严重问题。\n\n如果你的linux主机是1个双核CPU的话，当Load Average 为6的时候说明机器已经被充分使用了。\n\n[原文地址](http://man.linuxde.net/uptime)","slug":"uptime命令","published":1,"updated":"2019-03-23T10:23:31.339Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ekm0038gyavuvp9skh3"},{"title":"wget命令","originContent":"wget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。\n\n## 语法\n\n```\nwget(选项)(参数)\n```\n<!-- more -->\n## 选项\n\n```\n-a<日志文件>：在指定的日志文件中记录资料的执行过程；\n-A<后缀名>：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；\n-b：进行后台的方式运行wget；\n-B<连接地址>：设置参考的连接地址的基地地址；\n-c：继续执行上次终端的任务；\n-C<标志>：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；\n-d：调试模式运行指令；\n-D<域名列表>：设置顺着的域名列表，域名之间用“，”分隔；\n-e<指令>：作为文件“.wgetrc”中的一部分执行指定的指令；\n-h：显示指令帮助信息；\n-i<文件>：从指定文件获取要下载的URL地址；\n-l<目录列表>：设置顺着的目录列表，多个目录用“，”分隔；\n-L：仅顺着关联的连接；\n-r：递归下载方式；\n-nc：文件存在时，下载文件不覆盖原有文件；\n-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；\n-q：不显示指令执行过程；\n-nh：不查询主机名称；\n-v：显示详细执行过程；\n-V：显示版本信息；\n--passive-ftp：使用被动模式PASV连接FTP服务器；\n--follow-ftp：从HTML文件中下载FTP连接文件。\n```\n\n## 参数\nURL：下载指定的URL地址。\n\n## 实例\n\n### 使用wget下载单个文件\n```\nwget http://www.linuxde.net/testfile.zip\n```\n以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。\n\n### 下载并以不同的文件名保存\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\nwget默认会以最后一个符合`/`的后面的字符来命令，对于动态链接的下载通常文件名会不正确。\n\n错误：下面的例子会下载一个文件并以名称`download.aspx?id=1080`保存:\n\n```\nwget http://www.linuxde.net/download?id=1\n```\n\n即使下载的文件是zip格式，它仍然以`download.php?id=1080`命令。\n\n正确：为了解决这个问题，我们可以使用参数`-O`来指定一个文件名：\n\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\n### wget限速下载\n```\nwget --limit-rate=300k http://www.linuxde.net/testfile.zip\n```\n\n当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。\n\n### 使用wget断点续传\n\n```\nwget -c http://www.linuxde.net/testfile.zip\n```\n\n使用`wget -c`重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用`-c`参数。\n\n### 使用wget后台下载\n```\nwget -b http://www.linuxde.net/testfile.zip\n\nContinuing in background, pid 1840.\nOutput will be written to `wget-log'.\n```\n\n对于下载非常大的文件的时候，我们可以使用参数`-b`进行后台下载，你可以使用以下命令来察看下载进度：\n\n```\ntail -f wget-log\n```\n\n### tail -f wget-log\n```\nwget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://www.linuxde.net/testfile.zip\n```\n\n有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过`--user-agent`参数伪装。\n\n### 测试下载链接\n当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加`--spider`参数进行检查。\n\n```\nwget --spider URL\n```\n\n如果下载链接正确，将会显示:\n\n```\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nRemote file exists and could contain further links,\nbut recursion is disabled -- not retrieving.\n```\n\n这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误:\n\n```\nwget --spider url\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 404 Not Found\nRemote file does not exist -- broken link!!!\n```\n\n你可以在以下几种情况下使用`--spider`参数：\n\n1. 定时下载之前进行检查\n2. 间隔检测网站是否可用\n3. 检查网站页面的死链接\n\n### 增加重试次数\n\n```\nwget --tries=40 URL\n```\n\n如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用--tries增加重试次数。\n\n### 下载多个文件\n\n```\nwget -i filelist.txt\n```\n\n首先，保存一份下载链接文件：\n\n```\ncat > filelist.txt\nurl1\nurl2\nurl3\nurl4\n```\n\n接着使用这个文件和参数`-i`下载。\n\n### 镜像网站\n\n```\nwget --mirror -p --convert-links -P ./LOCAL URL\n```\n\n下载整个网站到本地。\n\n* `--miror`开户镜像下载。\n* `-p`下载所有为了html页面显示正常的文件。\n* `--convert-links`下载后，转换成本地的链接。\n* `-P ./LOCAL`保存所有文件和目录到本地指定目录。\n\n### 过滤指定格式下载\n\n```\nwget --reject=gif URL\n```\n\n下载一个网站，但你不希望下载图片，可以使用这条命令。\n\n### 把下载信息存入日志文件\n\n```\nwget -o download.log URL\n```\n\n不希望下载信息直接显示在终端而是在一个日志文件，可以使用。\n\n### 限制总下载文件大小\n```\nwget -Q5m -i filelist.txt\n```\n当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。\n\n### 下载指定格式文件\n```\nwget -r -A.pdf url\n```\n\n可以在以下情况使用该功能：\n\n* 下载一个网站的所有图片。\n* 下载一个网站的所有视频。\n* 下载一个网站的所有PDF文件。\n\n### FTP下载\n```\nwget ftp-url\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n可以使用wget来完成ftp链接的下载。\n\n使用wget匿名ftp下载： \n\n```\nwget ftp-url\n```\n\n使用wget用户名和密码认证的ftp下载：\n\n```\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n\n[原文地址](http://man.linuxde.net/wget)","toc":false,"date":"2018-01-17T09:17:01.000Z","_content":"\nwget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。\n\n## 语法\n\n```\nwget(选项)(参数)\n```\n<!-- more -->\n## 选项\n\n```\n-a<日志文件>：在指定的日志文件中记录资料的执行过程；\n-A<后缀名>：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；\n-b：进行后台的方式运行wget；\n-B<连接地址>：设置参考的连接地址的基地地址；\n-c：继续执行上次终端的任务；\n-C<标志>：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；\n-d：调试模式运行指令；\n-D<域名列表>：设置顺着的域名列表，域名之间用“，”分隔；\n-e<指令>：作为文件“.wgetrc”中的一部分执行指定的指令；\n-h：显示指令帮助信息；\n-i<文件>：从指定文件获取要下载的URL地址；\n-l<目录列表>：设置顺着的目录列表，多个目录用“，”分隔；\n-L：仅顺着关联的连接；\n-r：递归下载方式；\n-nc：文件存在时，下载文件不覆盖原有文件；\n-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；\n-q：不显示指令执行过程；\n-nh：不查询主机名称；\n-v：显示详细执行过程；\n-V：显示版本信息；\n--passive-ftp：使用被动模式PASV连接FTP服务器；\n--follow-ftp：从HTML文件中下载FTP连接文件。\n```\n\n## 参数\nURL：下载指定的URL地址。\n\n## 实例\n\n### 使用wget下载单个文件\n```\nwget http://www.linuxde.net/testfile.zip\n```\n以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。\n\n### 下载并以不同的文件名保存\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\nwget默认会以最后一个符合`/`的后面的字符来命令，对于动态链接的下载通常文件名会不正确。\n\n错误：下面的例子会下载一个文件并以名称`download.aspx?id=1080`保存:\n\n```\nwget http://www.linuxde.net/download?id=1\n```\n\n即使下载的文件是zip格式，它仍然以`download.php?id=1080`命令。\n\n正确：为了解决这个问题，我们可以使用参数`-O`来指定一个文件名：\n\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\n### wget限速下载\n```\nwget --limit-rate=300k http://www.linuxde.net/testfile.zip\n```\n\n当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。\n\n### 使用wget断点续传\n\n```\nwget -c http://www.linuxde.net/testfile.zip\n```\n\n使用`wget -c`重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用`-c`参数。\n\n### 使用wget后台下载\n```\nwget -b http://www.linuxde.net/testfile.zip\n\nContinuing in background, pid 1840.\nOutput will be written to `wget-log'.\n```\n\n对于下载非常大的文件的时候，我们可以使用参数`-b`进行后台下载，你可以使用以下命令来察看下载进度：\n\n```\ntail -f wget-log\n```\n\n### tail -f wget-log\n```\nwget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://www.linuxde.net/testfile.zip\n```\n\n有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过`--user-agent`参数伪装。\n\n### 测试下载链接\n当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加`--spider`参数进行检查。\n\n```\nwget --spider URL\n```\n\n如果下载链接正确，将会显示:\n\n```\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nRemote file exists and could contain further links,\nbut recursion is disabled -- not retrieving.\n```\n\n这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误:\n\n```\nwget --spider url\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 404 Not Found\nRemote file does not exist -- broken link!!!\n```\n\n你可以在以下几种情况下使用`--spider`参数：\n\n1. 定时下载之前进行检查\n2. 间隔检测网站是否可用\n3. 检查网站页面的死链接\n\n### 增加重试次数\n\n```\nwget --tries=40 URL\n```\n\n如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用--tries增加重试次数。\n\n### 下载多个文件\n\n```\nwget -i filelist.txt\n```\n\n首先，保存一份下载链接文件：\n\n```\ncat > filelist.txt\nurl1\nurl2\nurl3\nurl4\n```\n\n接着使用这个文件和参数`-i`下载。\n\n### 镜像网站\n\n```\nwget --mirror -p --convert-links -P ./LOCAL URL\n```\n\n下载整个网站到本地。\n\n* `--miror`开户镜像下载。\n* `-p`下载所有为了html页面显示正常的文件。\n* `--convert-links`下载后，转换成本地的链接。\n* `-P ./LOCAL`保存所有文件和目录到本地指定目录。\n\n### 过滤指定格式下载\n\n```\nwget --reject=gif URL\n```\n\n下载一个网站，但你不希望下载图片，可以使用这条命令。\n\n### 把下载信息存入日志文件\n\n```\nwget -o download.log URL\n```\n\n不希望下载信息直接显示在终端而是在一个日志文件，可以使用。\n\n### 限制总下载文件大小\n```\nwget -Q5m -i filelist.txt\n```\n当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。\n\n### 下载指定格式文件\n```\nwget -r -A.pdf url\n```\n\n可以在以下情况使用该功能：\n\n* 下载一个网站的所有图片。\n* 下载一个网站的所有视频。\n* 下载一个网站的所有PDF文件。\n\n### FTP下载\n```\nwget ftp-url\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n可以使用wget来完成ftp链接的下载。\n\n使用wget匿名ftp下载： \n\n```\nwget ftp-url\n```\n\n使用wget用户名和密码认证的ftp下载：\n\n```\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n\n[原文地址](http://man.linuxde.net/wget)","source":"_posts/wget命令.md","raw":"---\ntitle: wget命令\ntags:\n  - linux\noriginContent: >-\n  wget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。\n\n\n  ## 语法\n\n\n  ```\n\n  wget(选项)(参数)\n\n  ```\n\n  <!-- more -->\n\n  ## 选项\n\n\n  ```\n\n  -a<日志文件>：在指定的日志文件中记录资料的执行过程；\n\n  -A<后缀名>：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；\n\n  -b：进行后台的方式运行wget；\n\n  -B<连接地址>：设置参考的连接地址的基地地址；\n\n  -c：继续执行上次终端的任务；\n\n  -C<标志>：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；\n\n  -d：调试模式运行指令；\n\n  -D<域名列表>：设置顺着的域名列表，域名之间用“，”分隔；\n\n  -e<指令>：作为文件“.wgetrc”中的一部分执行指定的指令；\n\n  -h：显示指令帮助信息；\n\n  -i<文件>：从指定文件获取要下载的URL地址；\n\n  -l<目录列表>：设置顺着的目录列表，多个目录用“，”分隔；\n\n  -L：仅顺着关联的连接；\n\n  -r：递归下载方式；\n\n  -nc：文件存在时，下载文件不覆盖原有文件；\n\n  -nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；\n\n  -q：不显示指令执行过程；\n\n  -nh：不查询主机名称；\n\n  -v：显示详细执行过程；\n\n  -V：显示版本信息；\n\n  --passive-ftp：使用被动模式PASV连接FTP服务器；\n\n  --follow-ftp：从HTML文件中下载FTP连接文件。\n\n  ```\n\n\n  ## 参数\n\n  URL：下载指定的URL地址。\n\n\n  ## 实例\n\n\n  ### 使用wget下载单个文件\n\n  ```\n\n  wget http://www.linuxde.net/testfile.zip\n\n  ```\n\n  以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。\n\n\n  ### 下载并以不同的文件名保存\n\n  ```\n\n  wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n\n  ```\n\n\n  wget默认会以最后一个符合`/`的后面的字符来命令，对于动态链接的下载通常文件名会不正确。\n\n\n  错误：下面的例子会下载一个文件并以名称`download.aspx?id=1080`保存:\n\n\n  ```\n\n  wget http://www.linuxde.net/download?id=1\n\n  ```\n\n\n  即使下载的文件是zip格式，它仍然以`download.php?id=1080`命令。\n\n\n  正确：为了解决这个问题，我们可以使用参数`-O`来指定一个文件名：\n\n\n  ```\n\n  wget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n\n  ```\n\n\n  ### wget限速下载\n\n  ```\n\n  wget --limit-rate=300k http://www.linuxde.net/testfile.zip\n\n  ```\n\n\n  当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。\n\n\n  ### 使用wget断点续传\n\n\n  ```\n\n  wget -c http://www.linuxde.net/testfile.zip\n\n  ```\n\n\n  使用`wget\n  -c`重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用`-c`参数。\n\n\n  ### 使用wget后台下载\n\n  ```\n\n  wget -b http://www.linuxde.net/testfile.zip\n\n\n  Continuing in background, pid 1840.\n\n  Output will be written to `wget-log'.\n\n  ```\n\n\n  对于下载非常大的文件的时候，我们可以使用参数`-b`进行后台下载，你可以使用以下命令来察看下载进度：\n\n\n  ```\n\n  tail -f wget-log\n\n  ```\n\n\n  ### tail -f wget-log\n\n  ```\n\n  wget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US)\n  AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\"\n  http://www.linuxde.net/testfile.zip\n\n  ```\n\n\n  有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过`--user-agent`参数伪装。\n\n\n  ### 测试下载链接\n\n  当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加`--spider`参数进行检查。\n\n\n  ```\n\n  wget --spider URL\n\n  ```\n\n\n  如果下载链接正确，将会显示:\n\n\n  ```\n\n  Spider mode enabled. Check if remote file exists.\n\n  HTTP request sent, awaiting response... 200 OK\n\n  Length: unspecified [text/html]\n\n  Remote file exists and could contain further links,\n\n  but recursion is disabled -- not retrieving.\n\n  ```\n\n\n  这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误:\n\n\n  ```\n\n  wget --spider url\n\n  Spider mode enabled. Check if remote file exists.\n\n  HTTP request sent, awaiting response... 404 Not Found\n\n  Remote file does not exist -- broken link!!!\n\n  ```\n\n\n  你可以在以下几种情况下使用`--spider`参数：\n\n\n  1. 定时下载之前进行检查\n\n  2. 间隔检测网站是否可用\n\n  3. 检查网站页面的死链接\n\n\n  ### 增加重试次数\n\n\n  ```\n\n  wget --tries=40 URL\n\n  ```\n\n\n  如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用--tries增加重试次数。\n\n\n  ### 下载多个文件\n\n\n  ```\n\n  wget -i filelist.txt\n\n  ```\n\n\n  首先，保存一份下载链接文件：\n\n\n  ```\n\n  cat > filelist.txt\n\n  url1\n\n  url2\n\n  url3\n\n  url4\n\n  ```\n\n\n  接着使用这个文件和参数`-i`下载。\n\n\n  ### 镜像网站\n\n\n  ```\n\n  wget --mirror -p --convert-links -P ./LOCAL URL\n\n  ```\n\n\n  下载整个网站到本地。\n\n\n  * `--miror`开户镜像下载。\n\n  * `-p`下载所有为了html页面显示正常的文件。\n\n  * `--convert-links`下载后，转换成本地的链接。\n\n  * `-P ./LOCAL`保存所有文件和目录到本地指定目录。\n\n\n  ### 过滤指定格式下载\n\n\n  ```\n\n  wget --reject=gif URL\n\n  ```\n\n\n  下载一个网站，但你不希望下载图片，可以使用这条命令。\n\n\n  ### 把下载信息存入日志文件\n\n\n  ```\n\n  wget -o download.log URL\n\n  ```\n\n\n  不希望下载信息直接显示在终端而是在一个日志文件，可以使用。\n\n\n  ### 限制总下载文件大小\n\n  ```\n\n  wget -Q5m -i filelist.txt\n\n  ```\n\n  当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。\n\n\n  ### 下载指定格式文件\n\n  ```\n\n  wget -r -A.pdf url\n\n  ```\n\n\n  可以在以下情况使用该功能：\n\n\n  * 下载一个网站的所有图片。\n\n  * 下载一个网站的所有视频。\n\n  * 下载一个网站的所有PDF文件。\n\n\n  ### FTP下载\n\n  ```\n\n  wget ftp-url\n\n  wget --ftp-user=USERNAME --ftp-password=PASSWORD url\n\n  ```\n\n  可以使用wget来完成ftp链接的下载。\n\n\n  使用wget匿名ftp下载： \n\n\n  ```\n\n  wget ftp-url\n\n  ```\n\n\n  使用wget用户名和密码认证的ftp下载：\n\n\n  ```\n\n  wget --ftp-user=USERNAME --ftp-password=PASSWORD url\n\n  ```\n\n\n  [原文地址](http://man.linuxde.net/wget)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-17 17:17:01\n---\n\nwget命令用来从指定的URL下载文件。wget非常稳定，它在带宽很窄的情况下和不稳定网络中有很强的适应性，如果是由于网络的原因下载失败，wget会不断的尝试，直到整个文件下载完毕。如果是服务器打断下载过程，它会再次联到服务器上从停止的地方继续下载。这对从那些限定了链接时间的服务器上下载大文件非常有用。\n\n## 语法\n\n```\nwget(选项)(参数)\n```\n<!-- more -->\n## 选项\n\n```\n-a<日志文件>：在指定的日志文件中记录资料的执行过程；\n-A<后缀名>：指定要下载文件的后缀名，多个后缀名之间使用逗号进行分隔；\n-b：进行后台的方式运行wget；\n-B<连接地址>：设置参考的连接地址的基地地址；\n-c：继续执行上次终端的任务；\n-C<标志>：设置服务器数据块功能标志on为激活，off为关闭，默认值为on；\n-d：调试模式运行指令；\n-D<域名列表>：设置顺着的域名列表，域名之间用“，”分隔；\n-e<指令>：作为文件“.wgetrc”中的一部分执行指定的指令；\n-h：显示指令帮助信息；\n-i<文件>：从指定文件获取要下载的URL地址；\n-l<目录列表>：设置顺着的目录列表，多个目录用“，”分隔；\n-L：仅顺着关联的连接；\n-r：递归下载方式；\n-nc：文件存在时，下载文件不覆盖原有文件；\n-nv：下载时只显示更新和出错信息，不显示指令的详细执行过程；\n-q：不显示指令执行过程；\n-nh：不查询主机名称；\n-v：显示详细执行过程；\n-V：显示版本信息；\n--passive-ftp：使用被动模式PASV连接FTP服务器；\n--follow-ftp：从HTML文件中下载FTP连接文件。\n```\n\n## 参数\nURL：下载指定的URL地址。\n\n## 实例\n\n### 使用wget下载单个文件\n```\nwget http://www.linuxde.net/testfile.zip\n```\n以下的例子是从网络下载一个文件并保存在当前目录，在下载的过程中会显示进度条，包含（下载完成百分比，已经下载的字节，当前下载速度，剩余下载时间）。\n\n### 下载并以不同的文件名保存\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\nwget默认会以最后一个符合`/`的后面的字符来命令，对于动态链接的下载通常文件名会不正确。\n\n错误：下面的例子会下载一个文件并以名称`download.aspx?id=1080`保存:\n\n```\nwget http://www.linuxde.net/download?id=1\n```\n\n即使下载的文件是zip格式，它仍然以`download.php?id=1080`命令。\n\n正确：为了解决这个问题，我们可以使用参数`-O`来指定一个文件名：\n\n```\nwget -O wordpress.zip http://www.linuxde.net/download.aspx?id=1080\n```\n\n### wget限速下载\n```\nwget --limit-rate=300k http://www.linuxde.net/testfile.zip\n```\n\n当你执行wget的时候，它默认会占用全部可能的宽带下载。但是当你准备下载一个大文件，而你还需要下载其它文件时就有必要限速了。\n\n### 使用wget断点续传\n\n```\nwget -c http://www.linuxde.net/testfile.zip\n```\n\n使用`wget -c`重新启动下载中断的文件，对于我们下载大文件时突然由于网络等原因中断非常有帮助，我们可以继续接着下载而不是重新下载一个文件。需要继续中断的下载时可以使用`-c`参数。\n\n### 使用wget后台下载\n```\nwget -b http://www.linuxde.net/testfile.zip\n\nContinuing in background, pid 1840.\nOutput will be written to `wget-log'.\n```\n\n对于下载非常大的文件的时候，我们可以使用参数`-b`进行后台下载，你可以使用以下命令来察看下载进度：\n\n```\ntail -f wget-log\n```\n\n### tail -f wget-log\n```\nwget --user-agent=\"Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.16 (KHTML, like Gecko) Chrome/10.0.648.204 Safari/534.16\" http://www.linuxde.net/testfile.zip\n```\n\n有些网站能通过根据判断代理名称不是浏览器而拒绝你的下载请求。不过你可以通过`--user-agent`参数伪装。\n\n### 测试下载链接\n当你打算进行定时下载，你应该在预定时间测试下载链接是否有效。我们可以增加`--spider`参数进行检查。\n\n```\nwget --spider URL\n```\n\n如果下载链接正确，将会显示:\n\n```\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [text/html]\nRemote file exists and could contain further links,\nbut recursion is disabled -- not retrieving.\n```\n\n这保证了下载能在预定的时间进行，但当你给错了一个链接，将会显示如下错误:\n\n```\nwget --spider url\nSpider mode enabled. Check if remote file exists.\nHTTP request sent, awaiting response... 404 Not Found\nRemote file does not exist -- broken link!!!\n```\n\n你可以在以下几种情况下使用`--spider`参数：\n\n1. 定时下载之前进行检查\n2. 间隔检测网站是否可用\n3. 检查网站页面的死链接\n\n### 增加重试次数\n\n```\nwget --tries=40 URL\n```\n\n如果网络有问题或下载一个大文件也有可能失败。wget默认重试20次连接下载文件。如果需要，你可以使用--tries增加重试次数。\n\n### 下载多个文件\n\n```\nwget -i filelist.txt\n```\n\n首先，保存一份下载链接文件：\n\n```\ncat > filelist.txt\nurl1\nurl2\nurl3\nurl4\n```\n\n接着使用这个文件和参数`-i`下载。\n\n### 镜像网站\n\n```\nwget --mirror -p --convert-links -P ./LOCAL URL\n```\n\n下载整个网站到本地。\n\n* `--miror`开户镜像下载。\n* `-p`下载所有为了html页面显示正常的文件。\n* `--convert-links`下载后，转换成本地的链接。\n* `-P ./LOCAL`保存所有文件和目录到本地指定目录。\n\n### 过滤指定格式下载\n\n```\nwget --reject=gif URL\n```\n\n下载一个网站，但你不希望下载图片，可以使用这条命令。\n\n### 把下载信息存入日志文件\n\n```\nwget -o download.log URL\n```\n\n不希望下载信息直接显示在终端而是在一个日志文件，可以使用。\n\n### 限制总下载文件大小\n```\nwget -Q5m -i filelist.txt\n```\n当你想要下载的文件超过5M而退出下载，你可以使用。注意：这个参数对单个文件下载不起作用，只能递归下载时才有效。\n\n### 下载指定格式文件\n```\nwget -r -A.pdf url\n```\n\n可以在以下情况使用该功能：\n\n* 下载一个网站的所有图片。\n* 下载一个网站的所有视频。\n* 下载一个网站的所有PDF文件。\n\n### FTP下载\n```\nwget ftp-url\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n可以使用wget来完成ftp链接的下载。\n\n使用wget匿名ftp下载： \n\n```\nwget ftp-url\n```\n\n使用wget用户名和密码认证的ftp下载：\n\n```\nwget --ftp-user=USERNAME --ftp-password=PASSWORD url\n```\n\n[原文地址](http://man.linuxde.net/wget)","slug":"wget命令","published":1,"updated":"2019-03-23T10:24:03.609Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ekq003bgyav2snmfcc6"},{"title":"vi命令","originContent":"vi命令是UNIX操作系统和类UNIX操作系统中最通用的全屏幕纯文本编辑器。Linux中的vi编辑器叫vim，它是vi的增强版（vi Improved），与vi编辑器完全兼容，而且实现了很多增强功能。\n\nvi编辑器支持编辑模式和命令模式，编辑模式下可以完成文本的编辑功能，命令模式下可以完成对文件的操作命令，要正确使用vi编辑器就必须熟练掌握着两种模式的切换。默认情况下，打开vi编辑器后自动进入命令模式。从编辑模式切换到命令模式使用“esc”键，从命令模式切换到编辑模式使用“A”、“a”、“O”、“o”、“I”、“i”键。\n\nvi编辑器提供了丰富的内置命令，有些内置命令使用键盘组合键即可完成，有些内置命令则需要以冒号“：”开头输入。常用内置命令如下：\n\n<!-- more -->\n\n```\nCtrl+u：向文件首翻半屏；\nCtrl+d：向文件尾翻半屏；\nCtrl+f：向文件尾翻一屏；\nCtrl+b：向文件首翻一屏；\nEsc：从编辑模式切换到命令模式；\nZZ：命令模式下保存当前文件所做的修改后退出vi；\n:行号：光标跳转到指定行的行首；\n:$：光标跳转到最后一行的行首；\nx或X：删除一个字符，x删除光标后的，而X删除光标前的；\nD：删除从当前光标到光标所在行尾的全部字符；\ndd：删除光标行正行内容；\nndd：删除当前行及其后n-1行；\nnyy：将当前行及其下n行的内容保存到寄存器？中，其中？为一个字母，n为一个数字；\np：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的下方；\nP：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的上方；\n/字符串：文本查找操作，用于从当前光标所在位置开始向文件尾部查找指定字符串的内容，查找的字符串会被加亮显示；\n？name：文本查找操作，用于从当前光标所在位置开始向文件头部查找指定字符串的内容，查找的字符串会被加亮显示；\na，bs/F/T：替换文本操作，用于在第a行到第b行之间，将F字符串换成T字符串。其中，“s/”表示进行替换操作；\na：在当前字符后添加文本；\nA：在行末添加文本；\ni：在当前字符前插入文本；\nI：在行首插入文本；\no：在当前行后面插入一空行；\nO：在当前行前面插入一空行；\n:wq：在命令模式下，执行存盘退出操作；\n:w：在命令模式下，执行存盘操作；\n:w！：在命令模式下，执行强制存盘操作；\n:q：在命令模式下，执行退出vi操作；\n:q！：在命令模式下，执行强制退出vi操作；\n:e文件名：在命令模式下，打开并编辑指定名称的文件；\n:n：在命令模式下，如果同时打开多个文件，则继续编辑下一个文件；\n:f：在命令模式下，用于显示当前的文件名、光标所在行的行号以及显示比例；\n:set number：在命令模式下，用于在最左端显示行号；\n:set nonumber：在命令模式下，用于在最左端不显示行号；\n```\n\n## 语法\n\n```\nvi(选项)(参数)\n```\n\n## 选项\n\n```\n+<行号>：从指定行号的行开始先是文本内容；\n-b：以二进制模式打开文件，用于编辑二进制文件和可执行文件；\n-c<指令>：在完成对第一个文件编辑任务后，执行给出的指令；\n-d：以diff模式打开文件，当多个文件编辑时，显示文件差异部分；\n-l：使用lisp模式，打开“lisp”和“showmatch”；\n-m：取消写文件功能，重设“write”选项；\n-M：关闭修改功能；\n-n：不实用缓存功能；\n-o<文件数目>：指定同时打开指定数目的文件；\n-R：以只读方式打开文件；\n-s：安静模式，不现实指令的任何错误信息。\n```\n\n## 参数\n\n```\n文件列表：指定要编辑的文件列表。多个文件之间使用空格分隔开。\n```\n\n## 知识扩展\n\nvi编辑器有三种工作方式：命令方式、输入方式和ex转义方式。通过相应的命令或操作，在这三种工作方式之间可以进行转换。\n\n### 命令方式\n\n在Shell提示符后输入命令vi，进入vi编辑器，并处于vi的命令方式。此时，从键盘上输入的任何字符都被作为编辑命令来解释，例如，a(append）表示附加命令，i(insert）表示插入命令，x表示删除字符命令等。如果输入的字符不是vi的合法命令，则机器发出“报警声”，光标不移动。另外，在命令方式下输入的字符（即vi命令）并不在屏幕上显示出来，例如，输入i，屏幕上并无变化，但通过执行i命令，编辑器的工作方式却发生变化：由命令方式变为输入方式。\n\n### 输入方式\n\n通过输入vi的插入命令（i）、附加命令（a）、打开命令（o）、替换命令（s）、修改命令(c）或取代命令（r）可以从命令方式进入输入方式。在输入方式下，从键盘上输入的所有字符都被插入到正在编辑的缓冲区中，被当做该文件的正文。进入输入方式后，输入的可见字符都在屏幕上显示出来，而编辑命令不再起作用，仅作为普通字母出现。例如，在命令方式下输入字母i，进到输入方式，然后再输入i，就在屏幕上相应光标处添加一个字母i。\n\n由输入方式回到命令方式的办法是按下Esc键。如果已在命令方式下，那么按下Esc键就会发出“嘟嘟”声。为了确保用户想执行的vi命令是在命令方式下输入的，不妨多按几下Esc键，听到嘟声后再输入命令。\n\n### ex转义方式\n\nvi和ex编辑器的功能是相同的，二者的主要区别是用户界面。在vi中，命令通常是单个字母，如a,x,r等。而在ex中，命令是以Enter；键结束的命令行。vi有一个专门的“转义”命令，可访问很多面向行的ex命令。为使用ex转义方式，可输入一个冒号（:）。作为ex命令提示符，冒号出现在状态行（通常在屏幕最下一行）。按下中断键（通常是Del键），可终止正在执行的命令。多数文件管理命令都是在ex转义方式下执行的（例如，读取文件，把编辑缓冲区的内容写到文件中等）。转义命令执行后，自动回到命令方式。例如：\n\n```\n:1,$s/I/i/g 按Enter键\n```\n\n则从文件第一行至文件末尾（$）将大写I全部替换成小写i。vi编辑器的三种工作方式之间的转换如图所示。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/vi.jpg)\n \n \n [原文地址](http://man.linuxde.net/vi)","toc":false,"date":"2018-01-23T04:05:10.000Z","_content":"\nvi命令是UNIX操作系统和类UNIX操作系统中最通用的全屏幕纯文本编辑器。Linux中的vi编辑器叫vim，它是vi的增强版（vi Improved），与vi编辑器完全兼容，而且实现了很多增强功能。\n\nvi编辑器支持编辑模式和命令模式，编辑模式下可以完成文本的编辑功能，命令模式下可以完成对文件的操作命令，要正确使用vi编辑器就必须熟练掌握着两种模式的切换。默认情况下，打开vi编辑器后自动进入命令模式。从编辑模式切换到命令模式使用“esc”键，从命令模式切换到编辑模式使用“A”、“a”、“O”、“o”、“I”、“i”键。\n\nvi编辑器提供了丰富的内置命令，有些内置命令使用键盘组合键即可完成，有些内置命令则需要以冒号“：”开头输入。常用内置命令如下：\n\n<!-- more -->\n\n```\nCtrl+u：向文件首翻半屏；\nCtrl+d：向文件尾翻半屏；\nCtrl+f：向文件尾翻一屏；\nCtrl+b：向文件首翻一屏；\nEsc：从编辑模式切换到命令模式；\nZZ：命令模式下保存当前文件所做的修改后退出vi；\n:行号：光标跳转到指定行的行首；\n:$：光标跳转到最后一行的行首；\nx或X：删除一个字符，x删除光标后的，而X删除光标前的；\nD：删除从当前光标到光标所在行尾的全部字符；\ndd：删除光标行正行内容；\nndd：删除当前行及其后n-1行；\nnyy：将当前行及其下n行的内容保存到寄存器？中，其中？为一个字母，n为一个数字；\np：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的下方；\nP：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的上方；\n/字符串：文本查找操作，用于从当前光标所在位置开始向文件尾部查找指定字符串的内容，查找的字符串会被加亮显示；\n？name：文本查找操作，用于从当前光标所在位置开始向文件头部查找指定字符串的内容，查找的字符串会被加亮显示；\na，bs/F/T：替换文本操作，用于在第a行到第b行之间，将F字符串换成T字符串。其中，“s/”表示进行替换操作；\na：在当前字符后添加文本；\nA：在行末添加文本；\ni：在当前字符前插入文本；\nI：在行首插入文本；\no：在当前行后面插入一空行；\nO：在当前行前面插入一空行；\n:wq：在命令模式下，执行存盘退出操作；\n:w：在命令模式下，执行存盘操作；\n:w！：在命令模式下，执行强制存盘操作；\n:q：在命令模式下，执行退出vi操作；\n:q！：在命令模式下，执行强制退出vi操作；\n:e文件名：在命令模式下，打开并编辑指定名称的文件；\n:n：在命令模式下，如果同时打开多个文件，则继续编辑下一个文件；\n:f：在命令模式下，用于显示当前的文件名、光标所在行的行号以及显示比例；\n:set number：在命令模式下，用于在最左端显示行号；\n:set nonumber：在命令模式下，用于在最左端不显示行号；\n```\n\n## 语法\n\n```\nvi(选项)(参数)\n```\n\n## 选项\n\n```\n+<行号>：从指定行号的行开始先是文本内容；\n-b：以二进制模式打开文件，用于编辑二进制文件和可执行文件；\n-c<指令>：在完成对第一个文件编辑任务后，执行给出的指令；\n-d：以diff模式打开文件，当多个文件编辑时，显示文件差异部分；\n-l：使用lisp模式，打开“lisp”和“showmatch”；\n-m：取消写文件功能，重设“write”选项；\n-M：关闭修改功能；\n-n：不实用缓存功能；\n-o<文件数目>：指定同时打开指定数目的文件；\n-R：以只读方式打开文件；\n-s：安静模式，不现实指令的任何错误信息。\n```\n\n## 参数\n\n```\n文件列表：指定要编辑的文件列表。多个文件之间使用空格分隔开。\n```\n\n## 知识扩展\n\nvi编辑器有三种工作方式：命令方式、输入方式和ex转义方式。通过相应的命令或操作，在这三种工作方式之间可以进行转换。\n\n### 命令方式\n\n在Shell提示符后输入命令vi，进入vi编辑器，并处于vi的命令方式。此时，从键盘上输入的任何字符都被作为编辑命令来解释，例如，a(append）表示附加命令，i(insert）表示插入命令，x表示删除字符命令等。如果输入的字符不是vi的合法命令，则机器发出“报警声”，光标不移动。另外，在命令方式下输入的字符（即vi命令）并不在屏幕上显示出来，例如，输入i，屏幕上并无变化，但通过执行i命令，编辑器的工作方式却发生变化：由命令方式变为输入方式。\n\n### 输入方式\n\n通过输入vi的插入命令（i）、附加命令（a）、打开命令（o）、替换命令（s）、修改命令(c）或取代命令（r）可以从命令方式进入输入方式。在输入方式下，从键盘上输入的所有字符都被插入到正在编辑的缓冲区中，被当做该文件的正文。进入输入方式后，输入的可见字符都在屏幕上显示出来，而编辑命令不再起作用，仅作为普通字母出现。例如，在命令方式下输入字母i，进到输入方式，然后再输入i，就在屏幕上相应光标处添加一个字母i。\n\n由输入方式回到命令方式的办法是按下Esc键。如果已在命令方式下，那么按下Esc键就会发出“嘟嘟”声。为了确保用户想执行的vi命令是在命令方式下输入的，不妨多按几下Esc键，听到嘟声后再输入命令。\n\n### ex转义方式\n\nvi和ex编辑器的功能是相同的，二者的主要区别是用户界面。在vi中，命令通常是单个字母，如a,x,r等。而在ex中，命令是以Enter；键结束的命令行。vi有一个专门的“转义”命令，可访问很多面向行的ex命令。为使用ex转义方式，可输入一个冒号（:）。作为ex命令提示符，冒号出现在状态行（通常在屏幕最下一行）。按下中断键（通常是Del键），可终止正在执行的命令。多数文件管理命令都是在ex转义方式下执行的（例如，读取文件，把编辑缓冲区的内容写到文件中等）。转义命令执行后，自动回到命令方式。例如：\n\n```\n:1,$s/I/i/g 按Enter键\n```\n\n则从文件第一行至文件末尾（$）将大写I全部替换成小写i。vi编辑器的三种工作方式之间的转换如图所示。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/vi.jpg)\n \n \n [原文地址](http://man.linuxde.net/vi)","source":"_posts/vi命令.md","raw":"---\ntitle: vi命令\ntags:\n  - linux\noriginContent: >-\n  vi命令是UNIX操作系统和类UNIX操作系统中最通用的全屏幕纯文本编辑器。Linux中的vi编辑器叫vim，它是vi的增强版（vi\n  Improved），与vi编辑器完全兼容，而且实现了很多增强功能。\n\n\n  vi编辑器支持编辑模式和命令模式，编辑模式下可以完成文本的编辑功能，命令模式下可以完成对文件的操作命令，要正确使用vi编辑器就必须熟练掌握着两种模式的切换。默认情况下，打开vi编辑器后自动进入命令模式。从编辑模式切换到命令模式使用“esc”键，从命令模式切换到编辑模式使用“A”、“a”、“O”、“o”、“I”、“i”键。\n\n\n  vi编辑器提供了丰富的内置命令，有些内置命令使用键盘组合键即可完成，有些内置命令则需要以冒号“：”开头输入。常用内置命令如下：\n\n\n  <!-- more -->\n\n\n  ```\n\n  Ctrl+u：向文件首翻半屏；\n\n  Ctrl+d：向文件尾翻半屏；\n\n  Ctrl+f：向文件尾翻一屏；\n\n  Ctrl+b：向文件首翻一屏；\n\n  Esc：从编辑模式切换到命令模式；\n\n  ZZ：命令模式下保存当前文件所做的修改后退出vi；\n\n  :行号：光标跳转到指定行的行首；\n\n  :$：光标跳转到最后一行的行首；\n\n  x或X：删除一个字符，x删除光标后的，而X删除光标前的；\n\n  D：删除从当前光标到光标所在行尾的全部字符；\n\n  dd：删除光标行正行内容；\n\n  ndd：删除当前行及其后n-1行；\n\n  nyy：将当前行及其下n行的内容保存到寄存器？中，其中？为一个字母，n为一个数字；\n\n  p：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的下方；\n\n  P：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的上方；\n\n  /字符串：文本查找操作，用于从当前光标所在位置开始向文件尾部查找指定字符串的内容，查找的字符串会被加亮显示；\n\n  ？name：文本查找操作，用于从当前光标所在位置开始向文件头部查找指定字符串的内容，查找的字符串会被加亮显示；\n\n  a，bs/F/T：替换文本操作，用于在第a行到第b行之间，将F字符串换成T字符串。其中，“s/”表示进行替换操作；\n\n  a：在当前字符后添加文本；\n\n  A：在行末添加文本；\n\n  i：在当前字符前插入文本；\n\n  I：在行首插入文本；\n\n  o：在当前行后面插入一空行；\n\n  O：在当前行前面插入一空行；\n\n  :wq：在命令模式下，执行存盘退出操作；\n\n  :w：在命令模式下，执行存盘操作；\n\n  :w！：在命令模式下，执行强制存盘操作；\n\n  :q：在命令模式下，执行退出vi操作；\n\n  :q！：在命令模式下，执行强制退出vi操作；\n\n  :e文件名：在命令模式下，打开并编辑指定名称的文件；\n\n  :n：在命令模式下，如果同时打开多个文件，则继续编辑下一个文件；\n\n  :f：在命令模式下，用于显示当前的文件名、光标所在行的行号以及显示比例；\n\n  :set number：在命令模式下，用于在最左端显示行号；\n\n  :set nonumber：在命令模式下，用于在最左端不显示行号；\n\n  ```\n\n\n  ## 语法\n\n\n  ```\n\n  vi(选项)(参数)\n\n  ```\n\n\n  ## 选项\n\n\n  ```\n\n  +<行号>：从指定行号的行开始先是文本内容；\n\n  -b：以二进制模式打开文件，用于编辑二进制文件和可执行文件；\n\n  -c<指令>：在完成对第一个文件编辑任务后，执行给出的指令；\n\n  -d：以diff模式打开文件，当多个文件编辑时，显示文件差异部分；\n\n  -l：使用lisp模式，打开“lisp”和“showmatch”；\n\n  -m：取消写文件功能，重设“write”选项；\n\n  -M：关闭修改功能；\n\n  -n：不实用缓存功能；\n\n  -o<文件数目>：指定同时打开指定数目的文件；\n\n  -R：以只读方式打开文件；\n\n  -s：安静模式，不现实指令的任何错误信息。\n\n  ```\n\n\n  ## 参数\n\n\n  ```\n\n  文件列表：指定要编辑的文件列表。多个文件之间使用空格分隔开。\n\n  ```\n\n\n  ## 知识扩展\n\n\n  vi编辑器有三种工作方式：命令方式、输入方式和ex转义方式。通过相应的命令或操作，在这三种工作方式之间可以进行转换。\n\n\n  ### 命令方式\n\n\n  在Shell提示符后输入命令vi，进入vi编辑器，并处于vi的命令方式。此时，从键盘上输入的任何字符都被作为编辑命令来解释，例如，a(append）表示附加命令，i(insert）表示插入命令，x表示删除字符命令等。如果输入的字符不是vi的合法命令，则机器发出“报警声”，光标不移动。另外，在命令方式下输入的字符（即vi命令）并不在屏幕上显示出来，例如，输入i，屏幕上并无变化，但通过执行i命令，编辑器的工作方式却发生变化：由命令方式变为输入方式。\n\n\n  ### 输入方式\n\n\n  通过输入vi的插入命令（i）、附加命令（a）、打开命令（o）、替换命令（s）、修改命令(c）或取代命令（r）可以从命令方式进入输入方式。在输入方式下，从键盘上输入的所有字符都被插入到正在编辑的缓冲区中，被当做该文件的正文。进入输入方式后，输入的可见字符都在屏幕上显示出来，而编辑命令不再起作用，仅作为普通字母出现。例如，在命令方式下输入字母i，进到输入方式，然后再输入i，就在屏幕上相应光标处添加一个字母i。\n\n\n  由输入方式回到命令方式的办法是按下Esc键。如果已在命令方式下，那么按下Esc键就会发出“嘟嘟”声。为了确保用户想执行的vi命令是在命令方式下输入的，不妨多按几下Esc键，听到嘟声后再输入命令。\n\n\n  ### ex转义方式\n\n\n  vi和ex编辑器的功能是相同的，二者的主要区别是用户界面。在vi中，命令通常是单个字母，如a,x,r等。而在ex中，命令是以Enter；键结束的命令行。vi有一个专门的“转义”命令，可访问很多面向行的ex命令。为使用ex转义方式，可输入一个冒号（:）。作为ex命令提示符，冒号出现在状态行（通常在屏幕最下一行）。按下中断键（通常是Del键），可终止正在执行的命令。多数文件管理命令都是在ex转义方式下执行的（例如，读取文件，把编辑缓冲区的内容写到文件中等）。转义命令执行后，自动回到命令方式。例如：\n\n\n  ```\n\n  :1,$s/I/i/g 按Enter键\n\n  ```\n\n\n  则从文件第一行至文件末尾（$）将大写I全部替换成小写i。vi编辑器的三种工作方式之间的转换如图所示。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/vi.jpg)\n   \n   \n   [原文地址](http://man.linuxde.net/vi)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-23 12:05:10\n---\n\nvi命令是UNIX操作系统和类UNIX操作系统中最通用的全屏幕纯文本编辑器。Linux中的vi编辑器叫vim，它是vi的增强版（vi Improved），与vi编辑器完全兼容，而且实现了很多增强功能。\n\nvi编辑器支持编辑模式和命令模式，编辑模式下可以完成文本的编辑功能，命令模式下可以完成对文件的操作命令，要正确使用vi编辑器就必须熟练掌握着两种模式的切换。默认情况下，打开vi编辑器后自动进入命令模式。从编辑模式切换到命令模式使用“esc”键，从命令模式切换到编辑模式使用“A”、“a”、“O”、“o”、“I”、“i”键。\n\nvi编辑器提供了丰富的内置命令，有些内置命令使用键盘组合键即可完成，有些内置命令则需要以冒号“：”开头输入。常用内置命令如下：\n\n<!-- more -->\n\n```\nCtrl+u：向文件首翻半屏；\nCtrl+d：向文件尾翻半屏；\nCtrl+f：向文件尾翻一屏；\nCtrl+b：向文件首翻一屏；\nEsc：从编辑模式切换到命令模式；\nZZ：命令模式下保存当前文件所做的修改后退出vi；\n:行号：光标跳转到指定行的行首；\n:$：光标跳转到最后一行的行首；\nx或X：删除一个字符，x删除光标后的，而X删除光标前的；\nD：删除从当前光标到光标所在行尾的全部字符；\ndd：删除光标行正行内容；\nndd：删除当前行及其后n-1行；\nnyy：将当前行及其下n行的内容保存到寄存器？中，其中？为一个字母，n为一个数字；\np：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的下方；\nP：粘贴文本操作，用于将缓存区的内容粘贴到当前光标所在位置的上方；\n/字符串：文本查找操作，用于从当前光标所在位置开始向文件尾部查找指定字符串的内容，查找的字符串会被加亮显示；\n？name：文本查找操作，用于从当前光标所在位置开始向文件头部查找指定字符串的内容，查找的字符串会被加亮显示；\na，bs/F/T：替换文本操作，用于在第a行到第b行之间，将F字符串换成T字符串。其中，“s/”表示进行替换操作；\na：在当前字符后添加文本；\nA：在行末添加文本；\ni：在当前字符前插入文本；\nI：在行首插入文本；\no：在当前行后面插入一空行；\nO：在当前行前面插入一空行；\n:wq：在命令模式下，执行存盘退出操作；\n:w：在命令模式下，执行存盘操作；\n:w！：在命令模式下，执行强制存盘操作；\n:q：在命令模式下，执行退出vi操作；\n:q！：在命令模式下，执行强制退出vi操作；\n:e文件名：在命令模式下，打开并编辑指定名称的文件；\n:n：在命令模式下，如果同时打开多个文件，则继续编辑下一个文件；\n:f：在命令模式下，用于显示当前的文件名、光标所在行的行号以及显示比例；\n:set number：在命令模式下，用于在最左端显示行号；\n:set nonumber：在命令模式下，用于在最左端不显示行号；\n```\n\n## 语法\n\n```\nvi(选项)(参数)\n```\n\n## 选项\n\n```\n+<行号>：从指定行号的行开始先是文本内容；\n-b：以二进制模式打开文件，用于编辑二进制文件和可执行文件；\n-c<指令>：在完成对第一个文件编辑任务后，执行给出的指令；\n-d：以diff模式打开文件，当多个文件编辑时，显示文件差异部分；\n-l：使用lisp模式，打开“lisp”和“showmatch”；\n-m：取消写文件功能，重设“write”选项；\n-M：关闭修改功能；\n-n：不实用缓存功能；\n-o<文件数目>：指定同时打开指定数目的文件；\n-R：以只读方式打开文件；\n-s：安静模式，不现实指令的任何错误信息。\n```\n\n## 参数\n\n```\n文件列表：指定要编辑的文件列表。多个文件之间使用空格分隔开。\n```\n\n## 知识扩展\n\nvi编辑器有三种工作方式：命令方式、输入方式和ex转义方式。通过相应的命令或操作，在这三种工作方式之间可以进行转换。\n\n### 命令方式\n\n在Shell提示符后输入命令vi，进入vi编辑器，并处于vi的命令方式。此时，从键盘上输入的任何字符都被作为编辑命令来解释，例如，a(append）表示附加命令，i(insert）表示插入命令，x表示删除字符命令等。如果输入的字符不是vi的合法命令，则机器发出“报警声”，光标不移动。另外，在命令方式下输入的字符（即vi命令）并不在屏幕上显示出来，例如，输入i，屏幕上并无变化，但通过执行i命令，编辑器的工作方式却发生变化：由命令方式变为输入方式。\n\n### 输入方式\n\n通过输入vi的插入命令（i）、附加命令（a）、打开命令（o）、替换命令（s）、修改命令(c）或取代命令（r）可以从命令方式进入输入方式。在输入方式下，从键盘上输入的所有字符都被插入到正在编辑的缓冲区中，被当做该文件的正文。进入输入方式后，输入的可见字符都在屏幕上显示出来，而编辑命令不再起作用，仅作为普通字母出现。例如，在命令方式下输入字母i，进到输入方式，然后再输入i，就在屏幕上相应光标处添加一个字母i。\n\n由输入方式回到命令方式的办法是按下Esc键。如果已在命令方式下，那么按下Esc键就会发出“嘟嘟”声。为了确保用户想执行的vi命令是在命令方式下输入的，不妨多按几下Esc键，听到嘟声后再输入命令。\n\n### ex转义方式\n\nvi和ex编辑器的功能是相同的，二者的主要区别是用户界面。在vi中，命令通常是单个字母，如a,x,r等。而在ex中，命令是以Enter；键结束的命令行。vi有一个专门的“转义”命令，可访问很多面向行的ex命令。为使用ex转义方式，可输入一个冒号（:）。作为ex命令提示符，冒号出现在状态行（通常在屏幕最下一行）。按下中断键（通常是Del键），可终止正在执行的命令。多数文件管理命令都是在ex转义方式下执行的（例如，读取文件，把编辑缓冲区的内容写到文件中等）。转义命令执行后，自动回到命令方式。例如：\n\n```\n:1,$s/I/i/g 按Enter键\n```\n\n则从文件第一行至文件末尾（$）将大写I全部替换成小写i。vi编辑器的三种工作方式之间的转换如图所示。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/vi.jpg)\n \n \n [原文地址](http://man.linuxde.net/vi)","slug":"vi命令","published":1,"updated":"2019-03-23T10:23:41.476Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eku003fgyav11cygocq"},{"title":"一些广告术语汇总","originContent":"![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/1.jpeg)\n\nAdNetwork、AdExchange、DSP、SSP、RTB、DMP这些模式之间存在着内在的关系，所以在理解的时候，我们需要联系起来进行理解，不能分开。\n\n1. RTB（RealTimeBidding，实时竞价）\n\n定义：是一种利用第三方技术在数以百万计的网站上针对每一个用户展示行为进行评估以及出价的竞价技术。\n\n个人理解：如果把互联网比作蜘蛛网，那么当任何一只小生物触碰到这张网上的某个节点，它的每一个细微的动作都会带来一系列的反馈。与此同时，这张网的主人就会自动对闯入领域的访客进行信息分析。这张网的主人不断的记录着各种数据，当你第二次碰到这张网的时候，它从它的数据库发现访客的信息与它的数据库的某个信息相匹配，这时，它就可以根据这个信息进行相应的回应。每一天，这张网都在不断的进化，它在不断的储存新的数据，它越来越聪明，它试图了解每一个外来访客的行为和目的，最终它从被动的诱惑转向精准的捕捉。这就是RTB，也就是实时竞价。通过记录cookies,来解析用户的行为，从而实现精准投放广告的目的。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/2.jpeg)\n\n2. DSP（DemandSidePlatform，需求方平台）\n\n定义：需求方平台允许广告客户和广告机构更方便地访问，以及更有效地购买广告库存，因为该平台汇集了各种广告交易平台的库存。有了这一平台，就不需要再出现另一个繁琐的购买步骤——购买请求。\n\n个人理解：互联网里有成千上万的广告主，他们急需推广自己的产品，寻找优质的媒介和精准的目标用户，优化广告投放策略，提高投入产出比。简单的讲，DSP就是广告主服务平台，广告主可以在平台上设置广告的目标受众、投放地域、广告出价等等。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/3.jpeg)\n\n3. SSP（Sell-SidePlatform，供应方平台）\n\n定义：供应方平台能够让出版商也介入广告交易，从而使它们的库存广告可用。通过这一平台，出版商希望他们的库存广告可以获得最高的有效每千次展示费用，而不必以低价销售出去。\n\n个人理解：供应方平台，是站长服务平台。站长们可以在SSP上管理自己的广告位，控制广告的展现等。\n\nDSP和SSP的对比图如下：\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/4.jpeg)\n\n\n4. AdExchange（广告交易平台）\n\n定义：一个开放的、能够将出版商和广告商联系在一起的在线广告市场(类似于股票交易所)。交易平台里的广告存货并不一定都是溢价库存，只要出版商想要提供的，都可以在里面找到。\n\n个人理解：所谓的广告交易平台，就是一个能够让广告主在对的时间，对的地点接触到对的用户的地方。它可以为每一次广告的Impression(广告收视次数)来赋予一个独立的价值，其运用的实时竞价技术可以让广告主竞拍每一次广告显示在用户面前的机会。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/5.jpeg)\n\nAdExchange相对于传统模式还是有比较大的好处的，一方面节省了广告主的成本，另外一方面让站长的收益增加了，最重要的是让合适的广告展现给合适的用户，提升了用户体验。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.jpeg)\n\n5. DMP（Data-ManagementPlatform，数据管理平台）\n\n定义：数据管理平台能够帮助所有涉及广告库存购买和出售的各方管理其数据、更方便地使用第三方数据、增强他们对所有这些数据的理解、传回数据或将定制数据传入某一平台，以进行更好地定位。\n\n个人理解：是把分散的数据进行整合纳入统一的技术平台。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.1.jpeg)\n6. AdNetwork（广告网络平台）\n\n定义：广告网络是一个封闭的网络广告市场，网络业主作为中间环节先向出版商采购广告库存，然后再转售给买家，虽然有时候出版商也可以创建自己的广告网络。\n\n个人理解：是一个连接广告主和网络媒体的广告系统平台，一方面为广告主提供广告管理、发布和监测服务，另一方面为媒体兑现部分广告存货的价值。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/7.jpeg)","toc":false,"date":"2018-07-25T04:47:04.000Z","_content":"\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/1.jpeg)\n\nAdNetwork、AdExchange、DSP、SSP、RTB、DMP这些模式之间存在着内在的关系，所以在理解的时候，我们需要联系起来进行理解，不能分开。\n\n1. RTB（RealTimeBidding，实时竞价）\n\n定义：是一种利用第三方技术在数以百万计的网站上针对每一个用户展示行为进行评估以及出价的竞价技术。\n\n个人理解：如果把互联网比作蜘蛛网，那么当任何一只小生物触碰到这张网上的某个节点，它的每一个细微的动作都会带来一系列的反馈。与此同时，这张网的主人就会自动对闯入领域的访客进行信息分析。这张网的主人不断的记录着各种数据，当你第二次碰到这张网的时候，它从它的数据库发现访客的信息与它的数据库的某个信息相匹配，这时，它就可以根据这个信息进行相应的回应。每一天，这张网都在不断的进化，它在不断的储存新的数据，它越来越聪明，它试图了解每一个外来访客的行为和目的，最终它从被动的诱惑转向精准的捕捉。这就是RTB，也就是实时竞价。通过记录cookies,来解析用户的行为，从而实现精准投放广告的目的。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/2.jpeg)\n\n2. DSP（DemandSidePlatform，需求方平台）\n\n定义：需求方平台允许广告客户和广告机构更方便地访问，以及更有效地购买广告库存，因为该平台汇集了各种广告交易平台的库存。有了这一平台，就不需要再出现另一个繁琐的购买步骤——购买请求。\n\n个人理解：互联网里有成千上万的广告主，他们急需推广自己的产品，寻找优质的媒介和精准的目标用户，优化广告投放策略，提高投入产出比。简单的讲，DSP就是广告主服务平台，广告主可以在平台上设置广告的目标受众、投放地域、广告出价等等。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/3.jpeg)\n\n3. SSP（Sell-SidePlatform，供应方平台）\n\n定义：供应方平台能够让出版商也介入广告交易，从而使它们的库存广告可用。通过这一平台，出版商希望他们的库存广告可以获得最高的有效每千次展示费用，而不必以低价销售出去。\n\n个人理解：供应方平台，是站长服务平台。站长们可以在SSP上管理自己的广告位，控制广告的展现等。\n\nDSP和SSP的对比图如下：\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/4.jpeg)\n\n\n4. AdExchange（广告交易平台）\n\n定义：一个开放的、能够将出版商和广告商联系在一起的在线广告市场(类似于股票交易所)。交易平台里的广告存货并不一定都是溢价库存，只要出版商想要提供的，都可以在里面找到。\n\n个人理解：所谓的广告交易平台，就是一个能够让广告主在对的时间，对的地点接触到对的用户的地方。它可以为每一次广告的Impression(广告收视次数)来赋予一个独立的价值，其运用的实时竞价技术可以让广告主竞拍每一次广告显示在用户面前的机会。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/5.jpeg)\n\nAdExchange相对于传统模式还是有比较大的好处的，一方面节省了广告主的成本，另外一方面让站长的收益增加了，最重要的是让合适的广告展现给合适的用户，提升了用户体验。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.jpeg)\n\n5. DMP（Data-ManagementPlatform，数据管理平台）\n\n定义：数据管理平台能够帮助所有涉及广告库存购买和出售的各方管理其数据、更方便地使用第三方数据、增强他们对所有这些数据的理解、传回数据或将定制数据传入某一平台，以进行更好地定位。\n\n个人理解：是把分散的数据进行整合纳入统一的技术平台。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.1.jpeg)\n6. AdNetwork（广告网络平台）\n\n定义：广告网络是一个封闭的网络广告市场，网络业主作为中间环节先向出版商采购广告库存，然后再转售给买家，虽然有时候出版商也可以创建自己的广告网络。\n\n个人理解：是一个连接广告主和网络媒体的广告系统平台，一方面为广告主提供广告管理、发布和监测服务，另一方面为媒体兑现部分广告存货的价值。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/7.jpeg)","source":"_posts/一些广告术语汇总.md","raw":"---\ntitle: 一些广告术语汇总\ntags:\n  - 广告\noriginContent: >-\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/1.jpeg)\n\n\n  AdNetwork、AdExchange、DSP、SSP、RTB、DMP这些模式之间存在着内在的关系，所以在理解的时候，我们需要联系起来进行理解，不能分开。\n\n\n  1. RTB（RealTimeBidding，实时竞价）\n\n\n  定义：是一种利用第三方技术在数以百万计的网站上针对每一个用户展示行为进行评估以及出价的竞价技术。\n\n\n  个人理解：如果把互联网比作蜘蛛网，那么当任何一只小生物触碰到这张网上的某个节点，它的每一个细微的动作都会带来一系列的反馈。与此同时，这张网的主人就会自动对闯入领域的访客进行信息分析。这张网的主人不断的记录着各种数据，当你第二次碰到这张网的时候，它从它的数据库发现访客的信息与它的数据库的某个信息相匹配，这时，它就可以根据这个信息进行相应的回应。每一天，这张网都在不断的进化，它在不断的储存新的数据，它越来越聪明，它试图了解每一个外来访客的行为和目的，最终它从被动的诱惑转向精准的捕捉。这就是RTB，也就是实时竞价。通过记录cookies,来解析用户的行为，从而实现精准投放广告的目的。\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/2.jpeg)\n\n\n  2. DSP（DemandSidePlatform，需求方平台）\n\n\n  定义：需求方平台允许广告客户和广告机构更方便地访问，以及更有效地购买广告库存，因为该平台汇集了各种广告交易平台的库存。有了这一平台，就不需要再出现另一个繁琐的购买步骤——购买请求。\n\n\n  个人理解：互联网里有成千上万的广告主，他们急需推广自己的产品，寻找优质的媒介和精准的目标用户，优化广告投放策略，提高投入产出比。简单的讲，DSP就是广告主服务平台，广告主可以在平台上设置广告的目标受众、投放地域、广告出价等等。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/3.jpeg)\n\n\n  3. SSP（Sell-SidePlatform，供应方平台）\n\n\n  定义：供应方平台能够让出版商也介入广告交易，从而使它们的库存广告可用。通过这一平台，出版商希望他们的库存广告可以获得最高的有效每千次展示费用，而不必以低价销售出去。\n\n\n  个人理解：供应方平台，是站长服务平台。站长们可以在SSP上管理自己的广告位，控制广告的展现等。\n\n\n  DSP和SSP的对比图如下：\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/4.jpeg)\n\n\n\n  4. AdExchange（广告交易平台）\n\n\n  定义：一个开放的、能够将出版商和广告商联系在一起的在线广告市场(类似于股票交易所)。交易平台里的广告存货并不一定都是溢价库存，只要出版商想要提供的，都可以在里面找到。\n\n\n  个人理解：所谓的广告交易平台，就是一个能够让广告主在对的时间，对的地点接触到对的用户的地方。它可以为每一次广告的Impression(广告收视次数)来赋予一个独立的价值，其运用的实时竞价技术可以让广告主竞拍每一次广告显示在用户面前的机会。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/5.jpeg)\n\n\n  AdExchange相对于传统模式还是有比较大的好处的，一方面节省了广告主的成本，另外一方面让站长的收益增加了，最重要的是让合适的广告展现给合适的用户，提升了用户体验。\n\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.jpeg)\n\n\n  5. DMP（Data-ManagementPlatform，数据管理平台）\n\n\n  定义：数据管理平台能够帮助所有涉及广告库存购买和出售的各方管理其数据、更方便地使用第三方数据、增强他们对所有这些数据的理解、传回数据或将定制数据传入某一平台，以进行更好地定位。\n\n\n  个人理解：是把分散的数据进行整合纳入统一的技术平台。\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.1.jpeg)\n\n  6. AdNetwork（广告网络平台）\n\n\n  定义：广告网络是一个封闭的网络广告市场，网络业主作为中间环节先向出版商采购广告库存，然后再转售给买家，虽然有时候出版商也可以创建自己的广告网络。\n\n\n  个人理解：是一个连接广告主和网络媒体的广告系统平台，一方面为广告主提供广告管理、发布和监测服务，另一方面为媒体兑现部分广告存货的价值。\n\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/7.jpeg)\ncategories:\n  - 项目总结\ntoc: false\ndate: 2018-07-25 12:47:04\n---\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/1.jpeg)\n\nAdNetwork、AdExchange、DSP、SSP、RTB、DMP这些模式之间存在着内在的关系，所以在理解的时候，我们需要联系起来进行理解，不能分开。\n\n1. RTB（RealTimeBidding，实时竞价）\n\n定义：是一种利用第三方技术在数以百万计的网站上针对每一个用户展示行为进行评估以及出价的竞价技术。\n\n个人理解：如果把互联网比作蜘蛛网，那么当任何一只小生物触碰到这张网上的某个节点，它的每一个细微的动作都会带来一系列的反馈。与此同时，这张网的主人就会自动对闯入领域的访客进行信息分析。这张网的主人不断的记录着各种数据，当你第二次碰到这张网的时候，它从它的数据库发现访客的信息与它的数据库的某个信息相匹配，这时，它就可以根据这个信息进行相应的回应。每一天，这张网都在不断的进化，它在不断的储存新的数据，它越来越聪明，它试图了解每一个外来访客的行为和目的，最终它从被动的诱惑转向精准的捕捉。这就是RTB，也就是实时竞价。通过记录cookies,来解析用户的行为，从而实现精准投放广告的目的。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/2.jpeg)\n\n2. DSP（DemandSidePlatform，需求方平台）\n\n定义：需求方平台允许广告客户和广告机构更方便地访问，以及更有效地购买广告库存，因为该平台汇集了各种广告交易平台的库存。有了这一平台，就不需要再出现另一个繁琐的购买步骤——购买请求。\n\n个人理解：互联网里有成千上万的广告主，他们急需推广自己的产品，寻找优质的媒介和精准的目标用户，优化广告投放策略，提高投入产出比。简单的讲，DSP就是广告主服务平台，广告主可以在平台上设置广告的目标受众、投放地域、广告出价等等。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/3.jpeg)\n\n3. SSP（Sell-SidePlatform，供应方平台）\n\n定义：供应方平台能够让出版商也介入广告交易，从而使它们的库存广告可用。通过这一平台，出版商希望他们的库存广告可以获得最高的有效每千次展示费用，而不必以低价销售出去。\n\n个人理解：供应方平台，是站长服务平台。站长们可以在SSP上管理自己的广告位，控制广告的展现等。\n\nDSP和SSP的对比图如下：\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/4.jpeg)\n\n\n4. AdExchange（广告交易平台）\n\n定义：一个开放的、能够将出版商和广告商联系在一起的在线广告市场(类似于股票交易所)。交易平台里的广告存货并不一定都是溢价库存，只要出版商想要提供的，都可以在里面找到。\n\n个人理解：所谓的广告交易平台，就是一个能够让广告主在对的时间，对的地点接触到对的用户的地方。它可以为每一次广告的Impression(广告收视次数)来赋予一个独立的价值，其运用的实时竞价技术可以让广告主竞拍每一次广告显示在用户面前的机会。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/5.jpeg)\n\nAdExchange相对于传统模式还是有比较大的好处的，一方面节省了广告主的成本，另外一方面让站长的收益增加了，最重要的是让合适的广告展现给合适的用户，提升了用户体验。\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.jpeg)\n\n5. DMP（Data-ManagementPlatform，数据管理平台）\n\n定义：数据管理平台能够帮助所有涉及广告库存购买和出售的各方管理其数据、更方便地使用第三方数据、增强他们对所有这些数据的理解、传回数据或将定制数据传入某一平台，以进行更好地定位。\n\n个人理解：是把分散的数据进行整合纳入统一的技术平台。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/6.1.jpeg)\n6. AdNetwork（广告网络平台）\n\n定义：广告网络是一个封闭的网络广告市场，网络业主作为中间环节先向出版商采购广告库存，然后再转售给买家，虽然有时候出版商也可以创建自己的广告网络。\n\n个人理解：是一个连接广告主和网络媒体的广告系统平台，一方面为广告主提供广告管理、发布和监测服务，另一方面为媒体兑现部分广告存货的价值。\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/adImage/7.jpeg)","slug":"一些广告术语汇总","published":1,"updated":"2019-03-23T10:08:26.937Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eky003igyav61ifwb6n"},{"title":"websocket https 连接","originContent":"最近部署项目需要用到wss连接，这时候就需要自己配置nginx对应的https配置，\nwss连接实际上是通过https连接的，默认支持，所以我的配置如下：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n        location /gate {\n                proxy_pass https://127.0.0.1:3010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        location /connector_1 {\n                proxy_pass https://127.0.0.1:4010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```\n\n其中通过路由做了反向代理，这么做的坏处是开发环境不太好整，最好是运维开放这几个websocket端口\n\n找到运维，有些开放的，使用开放的就好了\n\n公司机器的外网非80端口被禁用了不少，找到运维才知道有哪些是不被禁用的，我们使用不被禁用的就没必要再配置那么多nginx配置了。\n\n公司内网wiki地址：http://wiki.letv.cn/pages/viewpage.action?pageId=56973252\n\n最后的配置方式如下即可：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```","toc":false,"date":"2018-04-02T06:14:26.000Z","_content":"\n最近部署项目需要用到wss连接，这时候就需要自己配置nginx对应的https配置，\nwss连接实际上是通过https连接的，默认支持，所以我的配置如下：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n        location /gate {\n                proxy_pass https://127.0.0.1:3010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        location /connector_1 {\n                proxy_pass https://127.0.0.1:4010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```\n\n其中通过路由做了反向代理，这么做的坏处是开发环境不太好整，最好是运维开放这几个websocket端口\n\n找到运维，有些开放的，使用开放的就好了\n\n公司机器的外网非80端口被禁用了不少，找到运维才知道有哪些是不被禁用的，我们使用不被禁用的就没必要再配置那么多nginx配置了。\n\n公司内网wiki地址：http://wiki.letv.cn/pages/viewpage.action?pageId=56973252\n\n最后的配置方式如下即可：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```","source":"_posts/websocket-https-连接.md","raw":"---\ntitle: websocket https 连接\ntags:\n  - websocket\noriginContent: |-\n  最近部署项目需要用到wss连接，这时候就需要自己配置nginx对应的https配置，\n  wss连接实际上是通过https连接的，默认支持，所以我的配置如下：\n\n  ```\n  map $http_upgrade $connection_upgrade {\n      default upgrade;\n      '' close;\n  }\n\n  server {\n          listen       443 ssl;\n          server_name  XXX.XX.XXX;\n\n          ssl on;\n          ssl_certificate ./keys/XXX.XX.XXX.crt;\n          ssl_certificate_key ./keys/XXX.XX.XXX.key;\n          ssl_session_timeout 5m;\n          ssl_protocols SSLv2 SSLv3 TLSv1;\n          ssl_ciphers HIGH:!aNULL:!MD5;\n          ssl_prefer_server_ciphers on;\n\n          access_log  /letv/logs/nginx/socket.access.log main;\n          error_log /letv/logs/nginx/socket.err.log;\n\n          root            /letv/www;\n          location /gate {\n                  proxy_pass https://127.0.0.1:3010;\n                  proxy_redirect      off;\n                  proxy_set_header X-Real-IP        $remote_addr;\n                  proxy_set_header Host             $host;\n                  proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                  proxy_http_version  1.1;\n                  proxy_set_header    Upgrade $http_upgrade;\n                  proxy_set_header    Connection 'upgrade';\n          }\n\n          location /connector_1 {\n                  proxy_pass https://127.0.0.1:4010;\n                  proxy_redirect      off;\n                  proxy_set_header X-Real-IP        $remote_addr;\n                  proxy_set_header Host             $host;\n                  proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                  proxy_http_version  1.1;\n                  proxy_set_header    Upgrade $http_upgrade;\n                  proxy_set_header    Connection 'upgrade';\n          }\n\n          error_page   500 502 503 504  /50x.html;\n          location = /50x.html {\n                  root   html;\n          }\n  }\n  ```\n\n  其中通过路由做了反向代理，这么做的坏处是开发环境不太好整，最好是运维开放这几个websocket端口\n\n  找到运维，有些开放的，使用开放的就好了\n\n  公司机器的外网非80端口被禁用了不少，找到运维才知道有哪些是不被禁用的，我们使用不被禁用的就没必要再配置那么多nginx配置了。\n\n  公司内网wiki地址：http://wiki.letv.cn/pages/viewpage.action?pageId=56973252\n\n  最后的配置方式如下即可：\n\n  ```\n  map $http_upgrade $connection_upgrade {\n      default upgrade;\n      '' close;\n  }\n\n  server {\n          listen       443 ssl;\n          server_name  XXX.XX.XXX;\n\n          ssl on;\n          ssl_certificate ./keys/XXX.XX.XXX.crt;\n          ssl_certificate_key ./keys/XXX.XX.XXX.key;\n          ssl_session_timeout 5m;\n          ssl_protocols SSLv2 SSLv3 TLSv1;\n          ssl_ciphers HIGH:!aNULL:!MD5;\n          ssl_prefer_server_ciphers on;\n\n          access_log  /letv/logs/nginx/socket.access.log main;\n          error_log /letv/logs/nginx/socket.err.log;\n\n          root            /letv/www;\n\n          error_page   500 502 503 504  /50x.html;\n          location = /50x.html {\n                  root   html;\n          }\n  }\n  ```\ncategories:\n  - Web开发\ntoc: false\ndate: 2018-04-02 14:14:26\n---\n\n最近部署项目需要用到wss连接，这时候就需要自己配置nginx对应的https配置，\nwss连接实际上是通过https连接的，默认支持，所以我的配置如下：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n        location /gate {\n                proxy_pass https://127.0.0.1:3010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        location /connector_1 {\n                proxy_pass https://127.0.0.1:4010;\n                proxy_redirect      off;\n                proxy_set_header X-Real-IP        $remote_addr;\n                proxy_set_header Host             $host;\n                proxy_set_header X-Forwarded-For  $proxy_add_x_forwarded_for;\n\n                proxy_http_version  1.1;\n                proxy_set_header    Upgrade $http_upgrade;\n                proxy_set_header    Connection 'upgrade';\n        }\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```\n\n其中通过路由做了反向代理，这么做的坏处是开发环境不太好整，最好是运维开放这几个websocket端口\n\n找到运维，有些开放的，使用开放的就好了\n\n公司机器的外网非80端口被禁用了不少，找到运维才知道有哪些是不被禁用的，我们使用不被禁用的就没必要再配置那么多nginx配置了。\n\n公司内网wiki地址：http://wiki.letv.cn/pages/viewpage.action?pageId=56973252\n\n最后的配置方式如下即可：\n\n```\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n        listen       443 ssl;\n        server_name  XXX.XX.XXX;\n\n        ssl on;\n        ssl_certificate ./keys/XXX.XX.XXX.crt;\n        ssl_certificate_key ./keys/XXX.XX.XXX.key;\n        ssl_session_timeout 5m;\n        ssl_protocols SSLv2 SSLv3 TLSv1;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        access_log  /letv/logs/nginx/socket.access.log main;\n        error_log /letv/logs/nginx/socket.err.log;\n\n        root            /letv/www;\n\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n                root   html;\n        }\n}\n```","slug":"websocket-https-连接","published":1,"updated":"2019-03-23T10:20:27.267Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1el2003mgyavns4q5fzu"},{"title":"一些职位的简写","originContent":"RD – Research & Develop 研发工程师\n\nFE – Front End 前端工程师\n\nBE – Back End 后端工程师\n\nQA – Quality Assurance 测试工程师\n\nDBA – Database Administrator 数据库\n\nPM – Product & Marketing 产品经理\n\nTS – Technology Support 技术支持\n\nOP – Operation 运维工程师\n\nUE(UX) – User Experience 用户体验设计师\n\nUI – User Interface 用户界面设计师\n\nUER – User Experience Research 用户研究\n\n<!-- more -->\n\n----------\n\n企业各职位英文缩写：\n\nGM(General Manager)总经理\n\nVP(Vice President)副总裁\n\nFVP(First Vice President)第一副总裁\n\nAVP(Assistant Vice President)副总裁助理\n\nCEO(Chief Executive Officer)首席执行官，类似总经理、总裁，是企业的法人代表。\n\nCOO(Chief Operations Officer)首席运营官，类似常务总经理\n\nCFO(Chief Financial Officer)首席财务官，类似财务总经理\n\nCIO(Chief Information Officer)首席信息官，主管企业信息的收集和发布\n\nCTO(Chief technology officer)首席技术官 类似总工程师\n\nHRD(Human Resource Director)人力资源总监\n\nOD(Operations Director)运营总监\n\nMD(Marketing Director)市场总监\n\nOM(Operations Manager)运作经理\n\nPM(Production Manager)生产经理\n\n(Product Manager)产品经理\n\n----------\n\nCAO: Art 艺术总监\n\nCBO: Business 商务总监\n\nCCO: Content 内容总监\n\nCDO: Development 开发总监\n\nCGO: Gonverment 政府关系\n\nCHO: Human resource 人事总监\n\nCJO: Jet 把营运指标都加一个或多个零使公司市值像火箭般上升的人\n\nCKO: Knowledge 知识总监\n\nCLO: Labour 工会主席\n\nCMO: Marketing 市场总监\n\nCNO: Negotiation 首席谈判代表CPO: Public relation 公关总监\n\nCQO: Quality control 质控总监\n\nCRO: Research 研究总监\n\nCSO: Sales 销售总监\n\nCUO: User 客户总监\n\nCVO: Valuation 评估总监\n\nCWO: Women 妇联主席\n\nCXO: 什么都可以管的不管部部长\n\nCYO: Yes 什么都点头的老好人\n\nCZO: 现在排最后，等待接班的太子","toc":false,"date":"2018-01-24T03:56:41.000Z","_content":"\nRD – Research & Develop 研发工程师\n\nFE – Front End 前端工程师\n\nBE – Back End 后端工程师\n\nQA – Quality Assurance 测试工程师\n\nDBA – Database Administrator 数据库\n\nPM – Product & Marketing 产品经理\n\nTS – Technology Support 技术支持\n\nOP – Operation 运维工程师\n\nUE(UX) – User Experience 用户体验设计师\n\nUI – User Interface 用户界面设计师\n\nUER – User Experience Research 用户研究\n\n<!-- more -->\n\n----------\n\n企业各职位英文缩写：\n\nGM(General Manager)总经理\n\nVP(Vice President)副总裁\n\nFVP(First Vice President)第一副总裁\n\nAVP(Assistant Vice President)副总裁助理\n\nCEO(Chief Executive Officer)首席执行官，类似总经理、总裁，是企业的法人代表。\n\nCOO(Chief Operations Officer)首席运营官，类似常务总经理\n\nCFO(Chief Financial Officer)首席财务官，类似财务总经理\n\nCIO(Chief Information Officer)首席信息官，主管企业信息的收集和发布\n\nCTO(Chief technology officer)首席技术官 类似总工程师\n\nHRD(Human Resource Director)人力资源总监\n\nOD(Operations Director)运营总监\n\nMD(Marketing Director)市场总监\n\nOM(Operations Manager)运作经理\n\nPM(Production Manager)生产经理\n\n(Product Manager)产品经理\n\n----------\n\nCAO: Art 艺术总监\n\nCBO: Business 商务总监\n\nCCO: Content 内容总监\n\nCDO: Development 开发总监\n\nCGO: Gonverment 政府关系\n\nCHO: Human resource 人事总监\n\nCJO: Jet 把营运指标都加一个或多个零使公司市值像火箭般上升的人\n\nCKO: Knowledge 知识总监\n\nCLO: Labour 工会主席\n\nCMO: Marketing 市场总监\n\nCNO: Negotiation 首席谈判代表CPO: Public relation 公关总监\n\nCQO: Quality control 质控总监\n\nCRO: Research 研究总监\n\nCSO: Sales 销售总监\n\nCUO: User 客户总监\n\nCVO: Valuation 评估总监\n\nCWO: Women 妇联主席\n\nCXO: 什么都可以管的不管部部长\n\nCYO: Yes 什么都点头的老好人\n\nCZO: 现在排最后，等待接班的太子","source":"_posts/一些职位的简写.md","raw":"---\ntitle: 一些职位的简写\ntags:\n  - 基本知识\noriginContent: |-\n  RD – Research & Develop 研发工程师\n\n  FE – Front End 前端工程师\n\n  BE – Back End 后端工程师\n\n  QA – Quality Assurance 测试工程师\n\n  DBA – Database Administrator 数据库\n\n  PM – Product & Marketing 产品经理\n\n  TS – Technology Support 技术支持\n\n  OP – Operation 运维工程师\n\n  UE(UX) – User Experience 用户体验设计师\n\n  UI – User Interface 用户界面设计师\n\n  UER – User Experience Research 用户研究\n\n  <!-- more -->\n\n  ----------\n\n  企业各职位英文缩写：\n\n  GM(General Manager)总经理\n\n  VP(Vice President)副总裁\n\n  FVP(First Vice President)第一副总裁\n\n  AVP(Assistant Vice President)副总裁助理\n\n  CEO(Chief Executive Officer)首席执行官，类似总经理、总裁，是企业的法人代表。\n\n  COO(Chief Operations Officer)首席运营官，类似常务总经理\n\n  CFO(Chief Financial Officer)首席财务官，类似财务总经理\n\n  CIO(Chief Information Officer)首席信息官，主管企业信息的收集和发布\n\n  CTO(Chief technology officer)首席技术官 类似总工程师\n\n  HRD(Human Resource Director)人力资源总监\n\n  OD(Operations Director)运营总监\n\n  MD(Marketing Director)市场总监\n\n  OM(Operations Manager)运作经理\n\n  PM(Production Manager)生产经理\n\n  (Product Manager)产品经理\n\n  ----------\n\n  CAO: Art 艺术总监\n\n  CBO: Business 商务总监\n\n  CCO: Content 内容总监\n\n  CDO: Development 开发总监\n\n  CGO: Gonverment 政府关系\n\n  CHO: Human resource 人事总监\n\n  CJO: Jet 把营运指标都加一个或多个零使公司市值像火箭般上升的人\n\n  CKO: Knowledge 知识总监\n\n  CLO: Labour 工会主席\n\n  CMO: Marketing 市场总监\n\n  CNO: Negotiation 首席谈判代表CPO: Public relation 公关总监\n\n  CQO: Quality control 质控总监\n\n  CRO: Research 研究总监\n\n  CSO: Sales 销售总监\n\n  CUO: User 客户总监\n\n  CVO: Valuation 评估总监\n\n  CWO: Women 妇联主席\n\n  CXO: 什么都可以管的不管部部长\n\n  CYO: Yes 什么都点头的老好人\n\n  CZO: 现在排最后，等待接班的太子\ncategories:\n  - 项目总结\ntoc: false\ndate: 2018-01-24 11:56:41\n---\n\nRD – Research & Develop 研发工程师\n\nFE – Front End 前端工程师\n\nBE – Back End 后端工程师\n\nQA – Quality Assurance 测试工程师\n\nDBA – Database Administrator 数据库\n\nPM – Product & Marketing 产品经理\n\nTS – Technology Support 技术支持\n\nOP – Operation 运维工程师\n\nUE(UX) – User Experience 用户体验设计师\n\nUI – User Interface 用户界面设计师\n\nUER – User Experience Research 用户研究\n\n<!-- more -->\n\n----------\n\n企业各职位英文缩写：\n\nGM(General Manager)总经理\n\nVP(Vice President)副总裁\n\nFVP(First Vice President)第一副总裁\n\nAVP(Assistant Vice President)副总裁助理\n\nCEO(Chief Executive Officer)首席执行官，类似总经理、总裁，是企业的法人代表。\n\nCOO(Chief Operations Officer)首席运营官，类似常务总经理\n\nCFO(Chief Financial Officer)首席财务官，类似财务总经理\n\nCIO(Chief Information Officer)首席信息官，主管企业信息的收集和发布\n\nCTO(Chief technology officer)首席技术官 类似总工程师\n\nHRD(Human Resource Director)人力资源总监\n\nOD(Operations Director)运营总监\n\nMD(Marketing Director)市场总监\n\nOM(Operations Manager)运作经理\n\nPM(Production Manager)生产经理\n\n(Product Manager)产品经理\n\n----------\n\nCAO: Art 艺术总监\n\nCBO: Business 商务总监\n\nCCO: Content 内容总监\n\nCDO: Development 开发总监\n\nCGO: Gonverment 政府关系\n\nCHO: Human resource 人事总监\n\nCJO: Jet 把营运指标都加一个或多个零使公司市值像火箭般上升的人\n\nCKO: Knowledge 知识总监\n\nCLO: Labour 工会主席\n\nCMO: Marketing 市场总监\n\nCNO: Negotiation 首席谈判代表CPO: Public relation 公关总监\n\nCQO: Quality control 质控总监\n\nCRO: Research 研究总监\n\nCSO: Sales 销售总监\n\nCUO: User 客户总监\n\nCVO: Valuation 评估总监\n\nCWO: Women 妇联主席\n\nCXO: 什么都可以管的不管部部长\n\nCYO: Yes 什么都点头的老好人\n\nCZO: 现在排最后，等待接班的太子","slug":"一些职位的简写","published":1,"updated":"2019-03-23T10:23:11.899Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1el8003pgyavcoxvszbl"},{"title":"升级Jenkins方法","originContent":"今天打开jenkins提示可以升级，于是按照提示点击下载，得到一个war包，因为使用的docker环境，这时候进入到对应的docker容器：\n\n<!-- more -->\n\n1. 进入到jenkins容器：nsenter --target [容器pid] --mount --uts --ipc --net --pid\n\n2. ps -aux | grep jenkins   查看jenkins安装路径\n\n\t```\n\t    jenkins      1  0.0  0.0   3144   244 ?        Ss   22:12   0:00 /bin/tini -- /usr/local/bin/jenkins.sh   \n\t    jenkins      5  4.7 19.8 2317472 201948 ?      Sl   22:12   0:35 java -jar /usr/share/jenkins/jenkins.war\n\t    root        163  0.0  0.0  13152   704 ?       S+   22:25   0:00 grep jenkins                             \n\t```\n\n3. cd /usr/share/jenkins/   进入jenkins目录\n\n4. cp jenkins.war jenkins.war.bak   备份一下，出问题时可以恢复\n\n5. wget wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.60.3/jenkins.war   这个链接地址就是jenkins里提示的下载按钮的链接地址\n\n6. 删除原来的jenkins.war 下载下来的是jenkins.war.1 重命名为jenkins.war即可：\n\n\t```\n\trm jenkins.war; \n\tmv jenkins.war.1 jenkins.war\n\t```\n\n7. 完成之后exit退出容器，重启容器，docker restart [容器id]","toc":false,"date":"2017-08-26T22:17:10.000Z","_content":"\n今天打开jenkins提示可以升级，于是按照提示点击下载，得到一个war包，因为使用的docker环境，这时候进入到对应的docker容器：\n\n<!-- more -->\n\n1. 进入到jenkins容器：nsenter --target [容器pid] --mount --uts --ipc --net --pid\n\n2. ps -aux | grep jenkins   查看jenkins安装路径\n\n\t```\n\t    jenkins      1  0.0  0.0   3144   244 ?        Ss   22:12   0:00 /bin/tini -- /usr/local/bin/jenkins.sh   \n\t    jenkins      5  4.7 19.8 2317472 201948 ?      Sl   22:12   0:35 java -jar /usr/share/jenkins/jenkins.war\n\t    root        163  0.0  0.0  13152   704 ?       S+   22:25   0:00 grep jenkins                             \n\t```\n\n3. cd /usr/share/jenkins/   进入jenkins目录\n\n4. cp jenkins.war jenkins.war.bak   备份一下，出问题时可以恢复\n\n5. wget wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.60.3/jenkins.war   这个链接地址就是jenkins里提示的下载按钮的链接地址\n\n6. 删除原来的jenkins.war 下载下来的是jenkins.war.1 重命名为jenkins.war即可：\n\n\t```\n\trm jenkins.war; \n\tmv jenkins.war.1 jenkins.war\n\t```\n\n7. 完成之后exit退出容器，重启容器，docker restart [容器id]","source":"_posts/升级Jenkins方法.md","raw":"---\ntitle: 升级Jenkins方法\ntags:\n  - jenkins\n  - docker\noriginContent: \"今天打开jenkins提示可以升级，于是按照提示点击下载，得到一个war包，因为使用的docker环境，这时候进入到对应的docker容器：\\n\\n<!-- more -->\\n\\n1. 进入到jenkins容器：nsenter --target [容器pid] --mount --uts --ipc --net --pid\\n\\n2. ps -aux | grep jenkins   查看jenkins安装路径\\n\\n\\t```\\n\\t    jenkins      1  0.0  0.0   3144   244 ?        Ss   22:12   0:00 /bin/tini -- /usr/local/bin/jenkins.sh   \\n\\t    jenkins      5  4.7 19.8 2317472 201948 ?      Sl   22:12   0:35 java -jar /usr/share/jenkins/jenkins.war\\n\\t    root        163  0.0  0.0  13152   704 ?       S+   22:25   0:00 grep jenkins                             \\n\\t```\\n\\n3. cd /usr/share/jenkins/   进入jenkins目录\\n\\n4. cp jenkins.war jenkins.war.bak   备份一下，出问题时可以恢复\\n\\n5. wget wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.60.3/jenkins.war   这个链接地址就是jenkins里提示的下载按钮的链接地址\\n\\n6. 删除原来的jenkins.war 下载下来的是jenkins.war.1 重命名为jenkins.war即可：\\n\\n\\t```\\n\\trm jenkins.war; \\n\\tmv jenkins.war.1 jenkins.war\\n\\t```\\n\\n7. 完成之后exit退出容器，重启容器，docker restart [容器id]\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 06:17:10\n---\n\n今天打开jenkins提示可以升级，于是按照提示点击下载，得到一个war包，因为使用的docker环境，这时候进入到对应的docker容器：\n\n<!-- more -->\n\n1. 进入到jenkins容器：nsenter --target [容器pid] --mount --uts --ipc --net --pid\n\n2. ps -aux | grep jenkins   查看jenkins安装路径\n\n\t```\n\t    jenkins      1  0.0  0.0   3144   244 ?        Ss   22:12   0:00 /bin/tini -- /usr/local/bin/jenkins.sh   \n\t    jenkins      5  4.7 19.8 2317472 201948 ?      Sl   22:12   0:35 java -jar /usr/share/jenkins/jenkins.war\n\t    root        163  0.0  0.0  13152   704 ?       S+   22:25   0:00 grep jenkins                             \n\t```\n\n3. cd /usr/share/jenkins/   进入jenkins目录\n\n4. cp jenkins.war jenkins.war.bak   备份一下，出问题时可以恢复\n\n5. wget wget https://mirrors.tuna.tsinghua.edu.cn/jenkins/war-stable/2.60.3/jenkins.war   这个链接地址就是jenkins里提示的下载按钮的链接地址\n\n6. 删除原来的jenkins.war 下载下来的是jenkins.war.1 重命名为jenkins.war即可：\n\n\t```\n\trm jenkins.war; \n\tmv jenkins.war.1 jenkins.war\n\t```\n\n7. 完成之后exit退出容器，重启容器，docker restart [容器id]","slug":"升级Jenkins方法","published":1,"updated":"2019-03-23T10:43:23.904Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elc003tgyavmupyg8hf"},{"title":"什么叫ocpm、ocpc、ocpa？","originContent":"大家在做头条、百度信息流广告投放的时候经常看到出价策略有ocpm、ocpc、ocpa，这些到底是什么呢？和cpm、cpc、cpa有什么不同？今天woshizmt给大家科普一下这些概念。\n\n所有的出价策略前加的单词“o”都是英文单词optimized的首字母，意思为“优化”，所以所有加o的广告都可叫做，按目标转化出价，比如OCPC还是按照cpc收费，但是按照广告主的效果额外做了优化，这个优化实现方式就是让广告主告诉系统你的优化目标具体是什么，你愿意为这个优化目标每一次付出多少钱。现在的今日头条广告、腾讯社交广告、百度信息流都已经具备这样的产品。\n\n<!-- more -->\n\n优化师在投放中都有这些问题：广告投放过程出价难、冲量难、转化成本不可控；数据该如何分析？看到了数据却看不出问题，全凭人工测试优化，累到吐血+常常跑偏…老板要转化还要控制成本！你是否也在投放中遇到过上述的困境，选什么定向又精准又有量？\n![11P513103A24b.jpg](http://pok5gaadc.bkt.clouddn.com/FlNEy6FQFrg95tIVk_DLOhEigNri)\n一、什么叫ocpm？\nOptimized Cost per Mille的缩写，即优化千次展现出价，本质还是按照cpm付费。采用更精准的点击率和转化率预估机制，将广告展现给最容易产生转化的用户，在获取流量的同时，提高转化率、降低转化成本，跑量提速更快。\n\n二、什么叫ocpc？\nOptimized Cost per Click的缩写，即优化点击付费，本质还是按照cpc付费。采用更科学的转化率预估机制的准确性，可帮助广告主在获取更多优质流 量的同时提高转化完成率。系统会在广告主出价基础上，基于多维度、实时反馈及历史积累的海量数据，并根据预估的转化率以及竞争环境智能化的动态调整出价，进而优化广告排序，帮助广告主竞得最适合的流量，并降低转化成本。\n扩展阅读：\n百度信息流oCPC出价原理及投放原理\n今日头条oCPC整体的优化方法大全\n\n三、什么叫ocpa？\nOptimized Cost per Action的缩写，即优化行为出价，本质还是按照cpa付费。当广告主在广告投放流程中选定特定的优化目标（例如：移动应用的激活,网站的下单），提供愿意为此投放目标而支付的平均价格，并及时、准确回传效果数据，我们将借助转化预估模型，实时预估每一次点击对广告主的转化价值，自动出价，最终按照点击扣费；同时，我们的转化预估模型会根据广告主的广告转化数据不断自动优化。\n扩展阅读：\n腾讯社交广告oCPA出价原理及投放方法\n公众号底部竞价广告支持智能优化（oCPA）等能力升级\n\n来源：http://www.woshizmt.cn/dsp/jrtt/698.html","toc":false,"date":"2019-03-22T10:20:29.000Z","_content":"\n大家在做头条、百度信息流广告投放的时候经常看到出价策略有ocpm、ocpc、ocpa，这些到底是什么呢？和cpm、cpc、cpa有什么不同？今天woshizmt给大家科普一下这些概念。\n\n所有的出价策略前加的单词“o”都是英文单词optimized的首字母，意思为“优化”，所以所有加o的广告都可叫做，按目标转化出价，比如OCPC还是按照cpc收费，但是按照广告主的效果额外做了优化，这个优化实现方式就是让广告主告诉系统你的优化目标具体是什么，你愿意为这个优化目标每一次付出多少钱。现在的今日头条广告、腾讯社交广告、百度信息流都已经具备这样的产品。\n\n<!-- more -->\n\n优化师在投放中都有这些问题：广告投放过程出价难、冲量难、转化成本不可控；数据该如何分析？看到了数据却看不出问题，全凭人工测试优化，累到吐血+常常跑偏…老板要转化还要控制成本！你是否也在投放中遇到过上述的困境，选什么定向又精准又有量？\n![11P513103A24b.jpg](http://pok5gaadc.bkt.clouddn.com/FlNEy6FQFrg95tIVk_DLOhEigNri)\n一、什么叫ocpm？\nOptimized Cost per Mille的缩写，即优化千次展现出价，本质还是按照cpm付费。采用更精准的点击率和转化率预估机制，将广告展现给最容易产生转化的用户，在获取流量的同时，提高转化率、降低转化成本，跑量提速更快。\n\n二、什么叫ocpc？\nOptimized Cost per Click的缩写，即优化点击付费，本质还是按照cpc付费。采用更科学的转化率预估机制的准确性，可帮助广告主在获取更多优质流 量的同时提高转化完成率。系统会在广告主出价基础上，基于多维度、实时反馈及历史积累的海量数据，并根据预估的转化率以及竞争环境智能化的动态调整出价，进而优化广告排序，帮助广告主竞得最适合的流量，并降低转化成本。\n扩展阅读：\n百度信息流oCPC出价原理及投放原理\n今日头条oCPC整体的优化方法大全\n\n三、什么叫ocpa？\nOptimized Cost per Action的缩写，即优化行为出价，本质还是按照cpa付费。当广告主在广告投放流程中选定特定的优化目标（例如：移动应用的激活,网站的下单），提供愿意为此投放目标而支付的平均价格，并及时、准确回传效果数据，我们将借助转化预估模型，实时预估每一次点击对广告主的转化价值，自动出价，最终按照点击扣费；同时，我们的转化预估模型会根据广告主的广告转化数据不断自动优化。\n扩展阅读：\n腾讯社交广告oCPA出价原理及投放方法\n公众号底部竞价广告支持智能优化（oCPA）等能力升级\n\n来源：http://www.woshizmt.cn/dsp/jrtt/698.html","source":"_posts/什么叫ocpm、ocpc、ocpa？.md","raw":"---\ntitle: 什么叫ocpm、ocpc、ocpa？\ntags:\n  - 广告\noriginContent: >-\n  大家在做头条、百度信息流广告投放的时候经常看到出价策略有ocpm、ocpc、ocpa，这些到底是什么呢？和cpm、cpc、cpa有什么不同？今天woshizmt给大家科普一下这些概念。\n\n\n  所有的出价策略前加的单词“o”都是英文单词optimized的首字母，意思为“优化”，所以所有加o的广告都可叫做，按目标转化出价，比如OCPC还是按照cpc收费，但是按照广告主的效果额外做了优化，这个优化实现方式就是让广告主告诉系统你的优化目标具体是什么，你愿意为这个优化目标每一次付出多少钱。现在的今日头条广告、腾讯社交广告、百度信息流都已经具备这样的产品。\n\n\n  <!-- more -->\n\n\n  优化师在投放中都有这些问题：广告投放过程出价难、冲量难、转化成本不可控；数据该如何分析？看到了数据却看不出问题，全凭人工测试优化，累到吐血+常常跑偏…老板要转化还要控制成本！你是否也在投放中遇到过上述的困境，选什么定向又精准又有量？\n\n  ![11P513103A24b.jpg](http://pok5gaadc.bkt.clouddn.com/FlNEy6FQFrg95tIVk_DLOhEigNri)\n\n  一、什么叫ocpm？\n\n  Optimized Cost per\n  Mille的缩写，即优化千次展现出价，本质还是按照cpm付费。采用更精准的点击率和转化率预估机制，将广告展现给最容易产生转化的用户，在获取流量的同时，提高转化率、降低转化成本，跑量提速更快。\n\n\n  二、什么叫ocpc？\n\n  Optimized Cost per\n  Click的缩写，即优化点击付费，本质还是按照cpc付费。采用更科学的转化率预估机制的准确性，可帮助广告主在获取更多优质流\n  量的同时提高转化完成率。系统会在广告主出价基础上，基于多维度、实时反馈及历史积累的海量数据，并根据预估的转化率以及竞争环境智能化的动态调整出价，进而优化广告排序，帮助广告主竞得最适合的流量，并降低转化成本。\n\n  扩展阅读：\n\n  百度信息流oCPC出价原理及投放原理\n\n  今日头条oCPC整体的优化方法大全\n\n\n  三、什么叫ocpa？\n\n  Optimized Cost per\n  Action的缩写，即优化行为出价，本质还是按照cpa付费。当广告主在广告投放流程中选定特定的优化目标（例如：移动应用的激活,网站的下单），提供愿意为此投放目标而支付的平均价格，并及时、准确回传效果数据，我们将借助转化预估模型，实时预估每一次点击对广告主的转化价值，自动出价，最终按照点击扣费；同时，我们的转化预估模型会根据广告主的广告转化数据不断自动优化。\n\n  扩展阅读：\n\n  腾讯社交广告oCPA出价原理及投放方法\n\n  公众号底部竞价广告支持智能优化（oCPA）等能力升级\n\n\n  来源：http://www.woshizmt.cn/dsp/jrtt/698.html\ncategories:\n  - 项目总结\ntoc: false\ndate: 2019-03-22 18:20:29\n---\n\n大家在做头条、百度信息流广告投放的时候经常看到出价策略有ocpm、ocpc、ocpa，这些到底是什么呢？和cpm、cpc、cpa有什么不同？今天woshizmt给大家科普一下这些概念。\n\n所有的出价策略前加的单词“o”都是英文单词optimized的首字母，意思为“优化”，所以所有加o的广告都可叫做，按目标转化出价，比如OCPC还是按照cpc收费，但是按照广告主的效果额外做了优化，这个优化实现方式就是让广告主告诉系统你的优化目标具体是什么，你愿意为这个优化目标每一次付出多少钱。现在的今日头条广告、腾讯社交广告、百度信息流都已经具备这样的产品。\n\n<!-- more -->\n\n优化师在投放中都有这些问题：广告投放过程出价难、冲量难、转化成本不可控；数据该如何分析？看到了数据却看不出问题，全凭人工测试优化，累到吐血+常常跑偏…老板要转化还要控制成本！你是否也在投放中遇到过上述的困境，选什么定向又精准又有量？\n![11P513103A24b.jpg](http://pok5gaadc.bkt.clouddn.com/FlNEy6FQFrg95tIVk_DLOhEigNri)\n一、什么叫ocpm？\nOptimized Cost per Mille的缩写，即优化千次展现出价，本质还是按照cpm付费。采用更精准的点击率和转化率预估机制，将广告展现给最容易产生转化的用户，在获取流量的同时，提高转化率、降低转化成本，跑量提速更快。\n\n二、什么叫ocpc？\nOptimized Cost per Click的缩写，即优化点击付费，本质还是按照cpc付费。采用更科学的转化率预估机制的准确性，可帮助广告主在获取更多优质流 量的同时提高转化完成率。系统会在广告主出价基础上，基于多维度、实时反馈及历史积累的海量数据，并根据预估的转化率以及竞争环境智能化的动态调整出价，进而优化广告排序，帮助广告主竞得最适合的流量，并降低转化成本。\n扩展阅读：\n百度信息流oCPC出价原理及投放原理\n今日头条oCPC整体的优化方法大全\n\n三、什么叫ocpa？\nOptimized Cost per Action的缩写，即优化行为出价，本质还是按照cpa付费。当广告主在广告投放流程中选定特定的优化目标（例如：移动应用的激活,网站的下单），提供愿意为此投放目标而支付的平均价格，并及时、准确回传效果数据，我们将借助转化预估模型，实时预估每一次点击对广告主的转化价值，自动出价，最终按照点击扣费；同时，我们的转化预估模型会根据广告主的广告转化数据不断自动优化。\n扩展阅读：\n腾讯社交广告oCPA出价原理及投放方法\n公众号底部竞价广告支持智能优化（oCPA）等能力升级\n\n来源：http://www.woshizmt.cn/dsp/jrtt/698.html","slug":"什么叫ocpm、ocpc、ocpa？","published":1,"updated":"2019-03-23T10:04:25.299Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elg003wgyav94gk76j2"},{"title":"在 CentOS 7 下安装配置 shadowsocks","originContent":"# 在 CentOS 7 下安装配置 shadowsocks\n\nCentOS 7 开始默认使用[Systemd](https://en.wikipedia.org/wiki/Systemd)作为开启启动脚本的管理工具，[Shadowsocks](https://github.com/shadowsocks/)则是当前比较受欢迎的科学上网工具，本文将介绍如何在 CentOS 下安装和配置 Shadowsocks 服务。\n\n<!-- more -->\n\n## 安装 pip\n\npip是 python 的包管理工具。在本文中将使用 python 版本的 shadowsocks，此版本的 shadowsocks 已发布到 pip 上，因此我们需要通过 pip 命令来安装。\n\n在控制台执行以下命令安装 pip：\n\n```\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\"\npython get-pip.py\n```\n\n## 安装配置 shadowsocks\n\n在控制台执行以下命令安装 shadowsocks：\n\n```\npip install --upgrade pip\npip install shadowsocks\n```\n\n安装完成后，需要创建配置文件`/etc/shadowsocks.json`，内容如下：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 8388,\n  \"password\": \"uzon57jd0v869t7w\",\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n如果需要配置多个密码可以这样：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"local_address\": \"127.0.0.1\",\n  \"local_port\": 1080,\n  \"port_password\": {\n    \"8080\": \"你的密码1\",\n    \"8081\": \"你的密码2\"\n  },\n  \"timeout\": 600,\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n\n说明：\n\n* `method`为加密方法，可选`aes-128-cfb`, `aes-192-cfb`, `aes-256-cfb`, `bf-cfb`, `cast5-cfb`, `des-cfb`, `rc4-md5`, `chacha20`, `salsa20`, `rc4`, `table`\n* `server_port`为服务监听端口\n* `password`为密码，可使用[密码生成工具](http://ucdok.com/project/generate_password.html)生成一个随机密码\n\n以上三项信息在配置 shadowsocks 客户端时需要配置一致，具体说明可查看 shadowsocks 的帮助文档。\n\n## 配置自启动\n\n新建启动脚本文件`/etc/systemd/system/shadowsocks.service`，内容如下：\n\n```\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json\n\n[Install]\nWantedBy=multi-user.target\n```\n\n执行以下命令启动 shadowsocks 服务：\n\n```\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n```\n\n为了检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态：\n\n```\nsystemctl status shadowsocks -l\n```\n\n如果服务启动成功，则控制台显示的信息可能类似这样：\n\n```\n● shadowsocks.service - Shadowsocks\n   Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; vendor preset: disabled)\n   Active: active (running) since Mon 2015-12-21 23:51:48 CST; 11min ago\n Main PID: 19334 (ssserver)\n   CGroup: /system.slice/shadowsocks.service\n           └─19334 /usr/bin/python /usr/bin/ssserver -c /etc/shadowsocks.json\n\nDec 21 23:51:48 morning.work systemd[1]: Started Shadowsocks.\nDec 21 23:51:48 morning.work systemd[1]: Starting Shadowsocks...\nDec 21 23:51:48 morning.work ssserver[19334]: INFO: loading config from /etc/shadowsocks.json\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     loading libcrypto from libcrypto.so.10\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     starting server at 0.0.0.0:8388\n```\n\n## 一键安装脚本\n\n新建文件`install-shadowsocks.sh`，内容如下：\n\n```\n#!/bin/bash\n# Install Shadowsocks on CentOS 7\n\necho \"Installing Shadowsocks...\"\n\nrandom-string()\n{\n    cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w ${1:-32} | head -n 1\n}\n\nCONFIG_FILE=/etc/shadowsocks.json\nSERVICE_FILE=/etc/systemd/system/shadowsocks.service\nSS_PASSWORD=$(random-string 32)\nSS_PORT=8388\nSS_METHOD=aes-256-cfb\nSS_IP=`ip route get 1 | awk '{print $NF;exit}'`\nGET_PIP_FILE=/tmp/get-pip.py\n\n# install pip\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"${GET_PIP_FILE}\"\npython ${GET_PIP_FILE}\n\n# install shadowsocks\npip install --upgrade pip\npip install shadowsocks\n\n# create shadowsocls config\ncat <<EOF | sudo tee ${CONFIG_FILE}\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": ${SS_PORT},\n  \"password\": \"${SS_PASSWORD}\",\n  \"method\": \"${SS_METHOD}\"\n}\nEOF\n\n# create service\ncat <<EOF | sudo tee ${SERVICE_FILE}\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c ${CONFIG_FILE}\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# start service\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n\n# view service status\nsleep 5\nsystemctl status shadowsocks -l\n\necho \"================================\"\necho \"\"\necho \"Congratulations! Shadowsocks has been installed on your system.\"\necho \"You shadowsocks connection info:\"\necho \"--------------------------------\"\necho \"server:      ${SS_IP}\"\necho \"server_port: ${SS_PORT}\"\necho \"password:    ${SS_PASSWORD}\"\necho \"method:      ${SS_METHOD}\"\necho \"--------------------------------\"\n```\n\n执行以下命令一键安装：\n\n```\nchmod +x install-shadowsocks.sh\n./install-shadowsocks.sh\n```\n\n也可以直接执行以下命令从 GitHub 下载安装脚本并执行：\n\n```\nbash <(curl -s http://morning.work/examples/2015-12/install-shadowsocks.sh)\n```\n\n安装完成后会自动打印出 Shadowsocks 的连接配置信息。比如：\n\n```\nCongratulations! Shadowsocks has been installed on your system.\nYou shadowsocks connection info:\n--------------------------------\nserver:      10.0.2.15\nserver_port: 8388\npassword:    RaskAAcW0IQrVcA7n0QLCEphhng7K4Yc\nmethod:      aes-256-cfb\n--------------------------------\n```\n\n原文链接：[早起搬砖](http://morning.work/page/2015-12/install-shadowsocks-on-centos-7.html)；盗窃可耻，分享光荣；好东西记录下来做个备忘，顺便帮作者推广下网站。","toc":false,"date":"2017-11-24T05:50:00.000Z","_content":"\n# 在 CentOS 7 下安装配置 shadowsocks\n\nCentOS 7 开始默认使用[Systemd](https://en.wikipedia.org/wiki/Systemd)作为开启启动脚本的管理工具，[Shadowsocks](https://github.com/shadowsocks/)则是当前比较受欢迎的科学上网工具，本文将介绍如何在 CentOS 下安装和配置 Shadowsocks 服务。\n\n<!-- more -->\n\n## 安装 pip\n\npip是 python 的包管理工具。在本文中将使用 python 版本的 shadowsocks，此版本的 shadowsocks 已发布到 pip 上，因此我们需要通过 pip 命令来安装。\n\n在控制台执行以下命令安装 pip：\n\n```\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\"\npython get-pip.py\n```\n\n## 安装配置 shadowsocks\n\n在控制台执行以下命令安装 shadowsocks：\n\n```\npip install --upgrade pip\npip install shadowsocks\n```\n\n安装完成后，需要创建配置文件`/etc/shadowsocks.json`，内容如下：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 8388,\n  \"password\": \"uzon57jd0v869t7w\",\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n如果需要配置多个密码可以这样：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"local_address\": \"127.0.0.1\",\n  \"local_port\": 1080,\n  \"port_password\": {\n    \"8080\": \"你的密码1\",\n    \"8081\": \"你的密码2\"\n  },\n  \"timeout\": 600,\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n\n说明：\n\n* `method`为加密方法，可选`aes-128-cfb`, `aes-192-cfb`, `aes-256-cfb`, `bf-cfb`, `cast5-cfb`, `des-cfb`, `rc4-md5`, `chacha20`, `salsa20`, `rc4`, `table`\n* `server_port`为服务监听端口\n* `password`为密码，可使用[密码生成工具](http://ucdok.com/project/generate_password.html)生成一个随机密码\n\n以上三项信息在配置 shadowsocks 客户端时需要配置一致，具体说明可查看 shadowsocks 的帮助文档。\n\n## 配置自启动\n\n新建启动脚本文件`/etc/systemd/system/shadowsocks.service`，内容如下：\n\n```\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json\n\n[Install]\nWantedBy=multi-user.target\n```\n\n执行以下命令启动 shadowsocks 服务：\n\n```\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n```\n\n为了检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态：\n\n```\nsystemctl status shadowsocks -l\n```\n\n如果服务启动成功，则控制台显示的信息可能类似这样：\n\n```\n● shadowsocks.service - Shadowsocks\n   Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; vendor preset: disabled)\n   Active: active (running) since Mon 2015-12-21 23:51:48 CST; 11min ago\n Main PID: 19334 (ssserver)\n   CGroup: /system.slice/shadowsocks.service\n           └─19334 /usr/bin/python /usr/bin/ssserver -c /etc/shadowsocks.json\n\nDec 21 23:51:48 morning.work systemd[1]: Started Shadowsocks.\nDec 21 23:51:48 morning.work systemd[1]: Starting Shadowsocks...\nDec 21 23:51:48 morning.work ssserver[19334]: INFO: loading config from /etc/shadowsocks.json\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     loading libcrypto from libcrypto.so.10\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     starting server at 0.0.0.0:8388\n```\n\n## 一键安装脚本\n\n新建文件`install-shadowsocks.sh`，内容如下：\n\n```\n#!/bin/bash\n# Install Shadowsocks on CentOS 7\n\necho \"Installing Shadowsocks...\"\n\nrandom-string()\n{\n    cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w ${1:-32} | head -n 1\n}\n\nCONFIG_FILE=/etc/shadowsocks.json\nSERVICE_FILE=/etc/systemd/system/shadowsocks.service\nSS_PASSWORD=$(random-string 32)\nSS_PORT=8388\nSS_METHOD=aes-256-cfb\nSS_IP=`ip route get 1 | awk '{print $NF;exit}'`\nGET_PIP_FILE=/tmp/get-pip.py\n\n# install pip\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"${GET_PIP_FILE}\"\npython ${GET_PIP_FILE}\n\n# install shadowsocks\npip install --upgrade pip\npip install shadowsocks\n\n# create shadowsocls config\ncat <<EOF | sudo tee ${CONFIG_FILE}\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": ${SS_PORT},\n  \"password\": \"${SS_PASSWORD}\",\n  \"method\": \"${SS_METHOD}\"\n}\nEOF\n\n# create service\ncat <<EOF | sudo tee ${SERVICE_FILE}\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c ${CONFIG_FILE}\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# start service\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n\n# view service status\nsleep 5\nsystemctl status shadowsocks -l\n\necho \"================================\"\necho \"\"\necho \"Congratulations! Shadowsocks has been installed on your system.\"\necho \"You shadowsocks connection info:\"\necho \"--------------------------------\"\necho \"server:      ${SS_IP}\"\necho \"server_port: ${SS_PORT}\"\necho \"password:    ${SS_PASSWORD}\"\necho \"method:      ${SS_METHOD}\"\necho \"--------------------------------\"\n```\n\n执行以下命令一键安装：\n\n```\nchmod +x install-shadowsocks.sh\n./install-shadowsocks.sh\n```\n\n也可以直接执行以下命令从 GitHub 下载安装脚本并执行：\n\n```\nbash <(curl -s http://morning.work/examples/2015-12/install-shadowsocks.sh)\n```\n\n安装完成后会自动打印出 Shadowsocks 的连接配置信息。比如：\n\n```\nCongratulations! Shadowsocks has been installed on your system.\nYou shadowsocks connection info:\n--------------------------------\nserver:      10.0.2.15\nserver_port: 8388\npassword:    RaskAAcW0IQrVcA7n0QLCEphhng7K4Yc\nmethod:      aes-256-cfb\n--------------------------------\n```\n\n原文链接：[早起搬砖](http://morning.work/page/2015-12/install-shadowsocks-on-centos-7.html)；盗窃可耻，分享光荣；好东西记录下来做个备忘，顺便帮作者推广下网站。","source":"_posts/在 CentOS 7 下安装配置 shadowsocks.md","raw":"---\ntitle: 在 CentOS 7 下安装配置 shadowsocks\ntags:\n  - 科学上网\noriginContent: >-\n  # 在 CentOS 7 下安装配置 shadowsocks\n\n\n  CentOS 7\n  开始默认使用[Systemd](https://en.wikipedia.org/wiki/Systemd)作为开启启动脚本的管理工具，[Shadowsocks](https://github.com/shadowsocks/)则是当前比较受欢迎的科学上网工具，本文将介绍如何在\n  CentOS 下安装和配置 Shadowsocks 服务。\n\n\n  <!-- more -->\n\n\n  ## 安装 pip\n\n\n  pip是 python 的包管理工具。在本文中将使用 python 版本的 shadowsocks，此版本的 shadowsocks 已发布到 pip\n  上，因此我们需要通过 pip 命令来安装。\n\n\n  在控制台执行以下命令安装 pip：\n\n\n  ```\n\n  curl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\"\n\n  python get-pip.py\n\n  ```\n\n\n  ## 安装配置 shadowsocks\n\n\n  在控制台执行以下命令安装 shadowsocks：\n\n\n  ```\n\n  pip install --upgrade pip\n\n  pip install shadowsocks\n\n  ```\n\n\n  安装完成后，需要创建配置文件`/etc/shadowsocks.json`，内容如下：\n\n\n  ```\n\n  {\n    \"server\": \"0.0.0.0\",\n    \"server_port\": 8388,\n    \"password\": \"uzon57jd0v869t7w\",\n    \"method\": \"aes-256-cfb\"\n  }\n\n  ```\n\n\n  如果需要配置多个密码可以这样：\n\n\n  ```\n\n  {\n    \"server\": \"0.0.0.0\",\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\": 1080,\n    \"port_password\": {\n      \"8080\": \"你的密码1\",\n      \"8081\": \"你的密码2\"\n    },\n    \"timeout\": 600,\n    \"method\": \"aes-256-cfb\"\n  }\n\n  ```\n\n\n\n  说明：\n\n\n  * `method`为加密方法，可选`aes-128-cfb`, `aes-192-cfb`, `aes-256-cfb`, `bf-cfb`,\n  `cast5-cfb`, `des-cfb`, `rc4-md5`, `chacha20`, `salsa20`, `rc4`, `table`\n\n  * `server_port`为服务监听端口\n\n  *\n  `password`为密码，可使用[密码生成工具](http://ucdok.com/project/generate_password.html)生成一个随机密码\n\n\n  以上三项信息在配置 shadowsocks 客户端时需要配置一致，具体说明可查看 shadowsocks 的帮助文档。\n\n\n  ## 配置自启动\n\n\n  新建启动脚本文件`/etc/systemd/system/shadowsocks.service`，内容如下：\n\n\n  ```\n\n  [Unit]\n\n  Description=Shadowsocks\n\n\n  [Service]\n\n  TimeoutStartSec=0\n\n  ExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json\n\n\n  [Install]\n\n  WantedBy=multi-user.target\n\n  ```\n\n\n  执行以下命令启动 shadowsocks 服务：\n\n\n  ```\n\n  systemctl enable shadowsocks\n\n  systemctl start shadowsocks\n\n  ```\n\n\n  为了检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态：\n\n\n  ```\n\n  systemctl status shadowsocks -l\n\n  ```\n\n\n  如果服务启动成功，则控制台显示的信息可能类似这样：\n\n\n  ```\n\n  ● shadowsocks.service - Shadowsocks\n     Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; vendor preset: disabled)\n     Active: active (running) since Mon 2015-12-21 23:51:48 CST; 11min ago\n   Main PID: 19334 (ssserver)\n     CGroup: /system.slice/shadowsocks.service\n             └─19334 /usr/bin/python /usr/bin/ssserver -c /etc/shadowsocks.json\n\n  Dec 21 23:51:48 morning.work systemd[1]: Started Shadowsocks.\n\n  Dec 21 23:51:48 morning.work systemd[1]: Starting Shadowsocks...\n\n  Dec 21 23:51:48 morning.work ssserver[19334]: INFO: loading config from\n  /etc/shadowsocks.json\n\n  Dec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO    \n  loading libcrypto from libcrypto.so.10\n\n  Dec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO    \n  starting server at 0.0.0.0:8388\n\n  ```\n\n\n  ## 一键安装脚本\n\n\n  新建文件`install-shadowsocks.sh`，内容如下：\n\n\n  ```\n\n  #!/bin/bash\n\n  # Install Shadowsocks on CentOS 7\n\n\n  echo \"Installing Shadowsocks...\"\n\n\n  random-string()\n\n  {\n      cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w ${1:-32} | head -n 1\n  }\n\n\n  CONFIG_FILE=/etc/shadowsocks.json\n\n  SERVICE_FILE=/etc/systemd/system/shadowsocks.service\n\n  SS_PASSWORD=$(random-string 32)\n\n  SS_PORT=8388\n\n  SS_METHOD=aes-256-cfb\n\n  SS_IP=`ip route get 1 | awk '{print $NF;exit}'`\n\n  GET_PIP_FILE=/tmp/get-pip.py\n\n\n  # install pip\n\n  curl \"https://bootstrap.pypa.io/get-pip.py\" -o \"${GET_PIP_FILE}\"\n\n  python ${GET_PIP_FILE}\n\n\n  # install shadowsocks\n\n  pip install --upgrade pip\n\n  pip install shadowsocks\n\n\n  # create shadowsocls config\n\n  cat <<EOF | sudo tee ${CONFIG_FILE}\n\n  {\n    \"server\": \"0.0.0.0\",\n    \"server_port\": ${SS_PORT},\n    \"password\": \"${SS_PASSWORD}\",\n    \"method\": \"${SS_METHOD}\"\n  }\n\n  EOF\n\n\n  # create service\n\n  cat <<EOF | sudo tee ${SERVICE_FILE}\n\n  [Unit]\n\n  Description=Shadowsocks\n\n\n  [Service]\n\n  TimeoutStartSec=0\n\n  ExecStart=/usr/bin/ssserver -c ${CONFIG_FILE}\n\n\n  [Install]\n\n  WantedBy=multi-user.target\n\n  EOF\n\n\n  # start service\n\n  systemctl enable shadowsocks\n\n  systemctl start shadowsocks\n\n\n  # view service status\n\n  sleep 5\n\n  systemctl status shadowsocks -l\n\n\n  echo \"================================\"\n\n  echo \"\"\n\n  echo \"Congratulations! Shadowsocks has been installed on your system.\"\n\n  echo \"You shadowsocks connection info:\"\n\n  echo \"--------------------------------\"\n\n  echo \"server:      ${SS_IP}\"\n\n  echo \"server_port: ${SS_PORT}\"\n\n  echo \"password:    ${SS_PASSWORD}\"\n\n  echo \"method:      ${SS_METHOD}\"\n\n  echo \"--------------------------------\"\n\n  ```\n\n\n  执行以下命令一键安装：\n\n\n  ```\n\n  chmod +x install-shadowsocks.sh\n\n  ./install-shadowsocks.sh\n\n  ```\n\n\n  也可以直接执行以下命令从 GitHub 下载安装脚本并执行：\n\n\n  ```\n\n  bash <(curl -s http://morning.work/examples/2015-12/install-shadowsocks.sh)\n\n  ```\n\n\n  安装完成后会自动打印出 Shadowsocks 的连接配置信息。比如：\n\n\n  ```\n\n  Congratulations! Shadowsocks has been installed on your system.\n\n  You shadowsocks connection info:\n\n  --------------------------------\n\n  server:      10.0.2.15\n\n  server_port: 8388\n\n  password:    RaskAAcW0IQrVcA7n0QLCEphhng7K4Yc\n\n  method:      aes-256-cfb\n\n  --------------------------------\n\n  ```\n\n\n  原文链接：[早起搬砖](http://morning.work/page/2015-12/install-shadowsocks-on-centos-7.html)；盗窃可耻，分享光荣；好东西记录下来做个备忘，顺便帮作者推广下网站。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-11-24 13:50:00\n---\n\n# 在 CentOS 7 下安装配置 shadowsocks\n\nCentOS 7 开始默认使用[Systemd](https://en.wikipedia.org/wiki/Systemd)作为开启启动脚本的管理工具，[Shadowsocks](https://github.com/shadowsocks/)则是当前比较受欢迎的科学上网工具，本文将介绍如何在 CentOS 下安装和配置 Shadowsocks 服务。\n\n<!-- more -->\n\n## 安装 pip\n\npip是 python 的包管理工具。在本文中将使用 python 版本的 shadowsocks，此版本的 shadowsocks 已发布到 pip 上，因此我们需要通过 pip 命令来安装。\n\n在控制台执行以下命令安装 pip：\n\n```\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"get-pip.py\"\npython get-pip.py\n```\n\n## 安装配置 shadowsocks\n\n在控制台执行以下命令安装 shadowsocks：\n\n```\npip install --upgrade pip\npip install shadowsocks\n```\n\n安装完成后，需要创建配置文件`/etc/shadowsocks.json`，内容如下：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": 8388,\n  \"password\": \"uzon57jd0v869t7w\",\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n如果需要配置多个密码可以这样：\n\n```\n{\n  \"server\": \"0.0.0.0\",\n  \"local_address\": \"127.0.0.1\",\n  \"local_port\": 1080,\n  \"port_password\": {\n    \"8080\": \"你的密码1\",\n    \"8081\": \"你的密码2\"\n  },\n  \"timeout\": 600,\n  \"method\": \"aes-256-cfb\"\n}\n```\n\n\n说明：\n\n* `method`为加密方法，可选`aes-128-cfb`, `aes-192-cfb`, `aes-256-cfb`, `bf-cfb`, `cast5-cfb`, `des-cfb`, `rc4-md5`, `chacha20`, `salsa20`, `rc4`, `table`\n* `server_port`为服务监听端口\n* `password`为密码，可使用[密码生成工具](http://ucdok.com/project/generate_password.html)生成一个随机密码\n\n以上三项信息在配置 shadowsocks 客户端时需要配置一致，具体说明可查看 shadowsocks 的帮助文档。\n\n## 配置自启动\n\n新建启动脚本文件`/etc/systemd/system/shadowsocks.service`，内容如下：\n\n```\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c /etc/shadowsocks.json\n\n[Install]\nWantedBy=multi-user.target\n```\n\n执行以下命令启动 shadowsocks 服务：\n\n```\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n```\n\n为了检查 shadowsocks 服务是否已成功启动，可以执行以下命令查看服务的状态：\n\n```\nsystemctl status shadowsocks -l\n```\n\n如果服务启动成功，则控制台显示的信息可能类似这样：\n\n```\n● shadowsocks.service - Shadowsocks\n   Loaded: loaded (/etc/systemd/system/shadowsocks.service; enabled; vendor preset: disabled)\n   Active: active (running) since Mon 2015-12-21 23:51:48 CST; 11min ago\n Main PID: 19334 (ssserver)\n   CGroup: /system.slice/shadowsocks.service\n           └─19334 /usr/bin/python /usr/bin/ssserver -c /etc/shadowsocks.json\n\nDec 21 23:51:48 morning.work systemd[1]: Started Shadowsocks.\nDec 21 23:51:48 morning.work systemd[1]: Starting Shadowsocks...\nDec 21 23:51:48 morning.work ssserver[19334]: INFO: loading config from /etc/shadowsocks.json\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     loading libcrypto from libcrypto.so.10\nDec 21 23:51:48 morning.work ssserver[19334]: 2015-12-21 23:51:48 INFO     starting server at 0.0.0.0:8388\n```\n\n## 一键安装脚本\n\n新建文件`install-shadowsocks.sh`，内容如下：\n\n```\n#!/bin/bash\n# Install Shadowsocks on CentOS 7\n\necho \"Installing Shadowsocks...\"\n\nrandom-string()\n{\n    cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w ${1:-32} | head -n 1\n}\n\nCONFIG_FILE=/etc/shadowsocks.json\nSERVICE_FILE=/etc/systemd/system/shadowsocks.service\nSS_PASSWORD=$(random-string 32)\nSS_PORT=8388\nSS_METHOD=aes-256-cfb\nSS_IP=`ip route get 1 | awk '{print $NF;exit}'`\nGET_PIP_FILE=/tmp/get-pip.py\n\n# install pip\ncurl \"https://bootstrap.pypa.io/get-pip.py\" -o \"${GET_PIP_FILE}\"\npython ${GET_PIP_FILE}\n\n# install shadowsocks\npip install --upgrade pip\npip install shadowsocks\n\n# create shadowsocls config\ncat <<EOF | sudo tee ${CONFIG_FILE}\n{\n  \"server\": \"0.0.0.0\",\n  \"server_port\": ${SS_PORT},\n  \"password\": \"${SS_PASSWORD}\",\n  \"method\": \"${SS_METHOD}\"\n}\nEOF\n\n# create service\ncat <<EOF | sudo tee ${SERVICE_FILE}\n[Unit]\nDescription=Shadowsocks\n\n[Service]\nTimeoutStartSec=0\nExecStart=/usr/bin/ssserver -c ${CONFIG_FILE}\n\n[Install]\nWantedBy=multi-user.target\nEOF\n\n# start service\nsystemctl enable shadowsocks\nsystemctl start shadowsocks\n\n# view service status\nsleep 5\nsystemctl status shadowsocks -l\n\necho \"================================\"\necho \"\"\necho \"Congratulations! Shadowsocks has been installed on your system.\"\necho \"You shadowsocks connection info:\"\necho \"--------------------------------\"\necho \"server:      ${SS_IP}\"\necho \"server_port: ${SS_PORT}\"\necho \"password:    ${SS_PASSWORD}\"\necho \"method:      ${SS_METHOD}\"\necho \"--------------------------------\"\n```\n\n执行以下命令一键安装：\n\n```\nchmod +x install-shadowsocks.sh\n./install-shadowsocks.sh\n```\n\n也可以直接执行以下命令从 GitHub 下载安装脚本并执行：\n\n```\nbash <(curl -s http://morning.work/examples/2015-12/install-shadowsocks.sh)\n```\n\n安装完成后会自动打印出 Shadowsocks 的连接配置信息。比如：\n\n```\nCongratulations! Shadowsocks has been installed on your system.\nYou shadowsocks connection info:\n--------------------------------\nserver:      10.0.2.15\nserver_port: 8388\npassword:    RaskAAcW0IQrVcA7n0QLCEphhng7K4Yc\nmethod:      aes-256-cfb\n--------------------------------\n```\n\n原文链接：[早起搬砖](http://morning.work/page/2015-12/install-shadowsocks-on-centos-7.html)；盗窃可耻，分享光荣；好东西记录下来做个备忘，顺便帮作者推广下网站。","slug":"在 CentOS 7 下安装配置 shadowsocks","published":1,"updated":"2019-03-23T10:31:04.490Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elk0040gyav09rtlcf1"},{"title":"如何使用electron自动更新功能","originContent":"最近做了个项目，要用到electron的自动更新功能。\n\nmark","toc":false,"date":"2019-03-22T10:13:34.000Z","_content":"\n最近做了个项目，要用到electron的自动更新功能。\n\nmark","source":"_posts/如何使用electron自动更新功能.md","raw":"---\ntitle: 如何使用electron自动更新功能\ntags:\n  - electron\noriginContent: |-\n  最近做了个项目，要用到electron的自动更新功能。\n\n  mark\ncategories:\n  - Web开发\ntoc: false\ndate: 2019-03-22 18:13:34\n---\n\n最近做了个项目，要用到electron的自动更新功能。\n\nmark","slug":"如何使用electron自动更新功能","published":1,"updated":"2019-03-23T10:04:09.852Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elo0043gyav42fneaph"},{"title":"如何通过linux ssh远程linux不用输入密码登入","originContent":"1. 首先登入一台linux服务器，此台做为母机（即登入其他linux系统用这台做为入口）；执行一行命令生成key文件：\n\n```\nssh-keygen -t rsa\n```\n\n2. 在母机上，进入/root/.ssh目录，找到id_rsa.pub该文件，这个文件就是刚才执行ssh-keygen所生成的公钥key文件。\n\n```\ncd ~/.ssh/\nls -lsh\n```\n\n3. 用scp命令，将母机产生的key拷一份到远程的linux服务器上，并命名成authorized_keys；这一步的操作需要手动输入密码。\n\n```\nscp ~/.ssh/id_rsa.pub  root@192.168.1.113:/root/.ssh/authorized_keys\n```\n\n4. 现在为止，你已完成了所有的操作；可在母机通过ssh root@192.168.1.113 你会发现不在用输放密码了。相同的scp命令也是一样的情况，无需手动输入密码。","toc":false,"date":"2018-04-08T05:52:41.000Z","_content":"\n1. 首先登入一台linux服务器，此台做为母机（即登入其他linux系统用这台做为入口）；执行一行命令生成key文件：\n\n```\nssh-keygen -t rsa\n```\n\n2. 在母机上，进入/root/.ssh目录，找到id_rsa.pub该文件，这个文件就是刚才执行ssh-keygen所生成的公钥key文件。\n\n```\ncd ~/.ssh/\nls -lsh\n```\n\n3. 用scp命令，将母机产生的key拷一份到远程的linux服务器上，并命名成authorized_keys；这一步的操作需要手动输入密码。\n\n```\nscp ~/.ssh/id_rsa.pub  root@192.168.1.113:/root/.ssh/authorized_keys\n```\n\n4. 现在为止，你已完成了所有的操作；可在母机通过ssh root@192.168.1.113 你会发现不在用输放密码了。相同的scp命令也是一样的情况，无需手动输入密码。","source":"_posts/如何通过linux-ssh远程linux不用输入密码登入.md","raw":"---\ntitle: 如何通过linux ssh远程linux不用输入密码登入\ntags:\n  - linux\noriginContent: >-\n  1. 首先登入一台linux服务器，此台做为母机（即登入其他linux系统用这台做为入口）；执行一行命令生成key文件：\n\n\n  ```\n\n  ssh-keygen -t rsa\n\n  ```\n\n\n  2. 在母机上，进入/root/.ssh目录，找到id_rsa.pub该文件，这个文件就是刚才执行ssh-keygen所生成的公钥key文件。\n\n\n  ```\n\n  cd ~/.ssh/\n\n  ls -lsh\n\n  ```\n\n\n  3. 用scp命令，将母机产生的key拷一份到远程的linux服务器上，并命名成authorized_keys；这一步的操作需要手动输入密码。\n\n\n  ```\n\n  scp ~/.ssh/id_rsa.pub  root@192.168.1.113:/root/.ssh/authorized_keys\n\n  ```\n\n\n  4. 现在为止，你已完成了所有的操作；可在母机通过ssh root@192.168.1.113\n  你会发现不在用输放密码了。相同的scp命令也是一样的情况，无需手动输入密码。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-04-08 13:52:41\n---\n\n1. 首先登入一台linux服务器，此台做为母机（即登入其他linux系统用这台做为入口）；执行一行命令生成key文件：\n\n```\nssh-keygen -t rsa\n```\n\n2. 在母机上，进入/root/.ssh目录，找到id_rsa.pub该文件，这个文件就是刚才执行ssh-keygen所生成的公钥key文件。\n\n```\ncd ~/.ssh/\nls -lsh\n```\n\n3. 用scp命令，将母机产生的key拷一份到远程的linux服务器上，并命名成authorized_keys；这一步的操作需要手动输入密码。\n\n```\nscp ~/.ssh/id_rsa.pub  root@192.168.1.113:/root/.ssh/authorized_keys\n```\n\n4. 现在为止，你已完成了所有的操作；可在母机通过ssh root@192.168.1.113 你会发现不在用输放密码了。相同的scp命令也是一样的情况，无需手动输入密码。","slug":"如何通过linux-ssh远程linux不用输入密码登入","published":1,"updated":"2019-03-23T10:19:38.807Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elr0047gyav42gyidrb"},{"title":"域名解析中A记录、CNAME、MX记录、NS记录的区别和联系","originContent":"## A记录\n\n又称IP指向，用户可以在此设置子域名并指向到自己的目标主机地址上，从而实现通过域名找到服务器。\n\n说明：·指向的目标主机地址类型只能使用IP地址；\n\n## CNAME\n\n通常称别名指向。可以为一个主机设置别名。比如设置test.mydomain.com，用来指向一个主机www.rddns.com那么以后就可以用test.mydomain.com来代替访问www.rddns.com了。\n\n说明：CNAME的目标主机地址只能使用主机名，不能使用IP地址；·主机名前不能有任何其他前缀，如：http://等是不被允许的；·A记录优先于CNAME记录。即如果一个主机地址同时存在A记录和CNAME记录，则CNAME记录不生效。\n\n<!-- more -->\n\n## MX记录\n\n邮件交换记录。用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。如：用户所用的邮件是以域名mydomain.com为结尾的，则需要在管理界面中添加该域名的MX记录来处理所有以@mydomain.com结尾的邮件。\n\n说明：MX记录可以使用主机名或IP地址；·MX记录可以通过设置优先级实现主辅服务器设置，“优先级”中的数字越小表示级别越高。也可以使用相同优先级达到负载均衡的目的；·如果在“主机名”中填入子域名则此MX记录只对该子域名生效。\n\n## NS记录\n\n解析服务器记录。用来表明由哪台服务器对该域名进行解析。这里的NS记录只对子域名生效。\n\n例如用户希望由12.34.56.78这台服务器解析news.mydomain.com，则需要设置news.mydomain.com的NS记录。\n\n说明：·“优先级”中的数字越小表示级别越高；·“IP地址/主机名”中既可以填写IP地址，也可以填写像ns.mydomain.com这样的主机地址，但必须保证该主机地址有效。\n\n如，将news.mydomain.com的NS记录指向到ns.mydomain.com，在设置NS记录的同时还需要设置ns.mydomain.com的指向，\n\n否则NS记录将无法正常解析；·NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。\n\n## 什么是负载均衡服务器？\n\n负载均衡(Server Load Balancing，SLB)是指在一系列资源上面智能地分布网络负载。负载均衡可以减少网络拥塞，提高整体网络性能，提高自愈性，并确保企业关键性应用的可用性。当相同子域有多个目标地址，或域名的MX记录有多个目标地址且优先级相同时，表示轮循，可以达到负载均衡的目的，但需要虚拟主机和邮箱服务商支持。\n\n## 什么是TTL？\n\nTTL值TTL值全称是“生存时间（Time To Live)”，简单的说它表示DNS记录在DNS服务器上缓存时间。这个缓存时间太长和太短都不好，如果缓存时间太长，一旦域名被解析到的IP有变化，会导致被客户端缓存的域名无法解析到变化后的IP地址，以致该域名不能正常解析，这段时间内有可能会有一部分用户无法访问网站。如果缓存时间太短，会导致用户每次访问网站都要重新解析一次域名。","toc":false,"date":"2018-01-11T06:32:12.000Z","_content":"\n## A记录\n\n又称IP指向，用户可以在此设置子域名并指向到自己的目标主机地址上，从而实现通过域名找到服务器。\n\n说明：·指向的目标主机地址类型只能使用IP地址；\n\n## CNAME\n\n通常称别名指向。可以为一个主机设置别名。比如设置test.mydomain.com，用来指向一个主机www.rddns.com那么以后就可以用test.mydomain.com来代替访问www.rddns.com了。\n\n说明：CNAME的目标主机地址只能使用主机名，不能使用IP地址；·主机名前不能有任何其他前缀，如：http://等是不被允许的；·A记录优先于CNAME记录。即如果一个主机地址同时存在A记录和CNAME记录，则CNAME记录不生效。\n\n<!-- more -->\n\n## MX记录\n\n邮件交换记录。用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。如：用户所用的邮件是以域名mydomain.com为结尾的，则需要在管理界面中添加该域名的MX记录来处理所有以@mydomain.com结尾的邮件。\n\n说明：MX记录可以使用主机名或IP地址；·MX记录可以通过设置优先级实现主辅服务器设置，“优先级”中的数字越小表示级别越高。也可以使用相同优先级达到负载均衡的目的；·如果在“主机名”中填入子域名则此MX记录只对该子域名生效。\n\n## NS记录\n\n解析服务器记录。用来表明由哪台服务器对该域名进行解析。这里的NS记录只对子域名生效。\n\n例如用户希望由12.34.56.78这台服务器解析news.mydomain.com，则需要设置news.mydomain.com的NS记录。\n\n说明：·“优先级”中的数字越小表示级别越高；·“IP地址/主机名”中既可以填写IP地址，也可以填写像ns.mydomain.com这样的主机地址，但必须保证该主机地址有效。\n\n如，将news.mydomain.com的NS记录指向到ns.mydomain.com，在设置NS记录的同时还需要设置ns.mydomain.com的指向，\n\n否则NS记录将无法正常解析；·NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。\n\n## 什么是负载均衡服务器？\n\n负载均衡(Server Load Balancing，SLB)是指在一系列资源上面智能地分布网络负载。负载均衡可以减少网络拥塞，提高整体网络性能，提高自愈性，并确保企业关键性应用的可用性。当相同子域有多个目标地址，或域名的MX记录有多个目标地址且优先级相同时，表示轮循，可以达到负载均衡的目的，但需要虚拟主机和邮箱服务商支持。\n\n## 什么是TTL？\n\nTTL值TTL值全称是“生存时间（Time To Live)”，简单的说它表示DNS记录在DNS服务器上缓存时间。这个缓存时间太长和太短都不好，如果缓存时间太长，一旦域名被解析到的IP有变化，会导致被客户端缓存的域名无法解析到变化后的IP地址，以致该域名不能正常解析，这段时间内有可能会有一部分用户无法访问网站。如果缓存时间太短，会导致用户每次访问网站都要重新解析一次域名。","source":"_posts/域名解析中A记录、CNAME、MX记录、NS记录的区别和联系.md","raw":"---\ntitle: 域名解析中A记录、CNAME、MX记录、NS记录的区别和联系\ntags:\n  - 域名\noriginContent: >-\n  ## A记录\n\n\n  又称IP指向，用户可以在此设置子域名并指向到自己的目标主机地址上，从而实现通过域名找到服务器。\n\n\n  说明：·指向的目标主机地址类型只能使用IP地址；\n\n\n  ## CNAME\n\n\n  通常称别名指向。可以为一个主机设置别名。比如设置test.mydomain.com，用来指向一个主机www.rddns.com那么以后就可以用test.mydomain.com来代替访问www.rddns.com了。\n\n\n  说明：CNAME的目标主机地址只能使用主机名，不能使用IP地址；·主机名前不能有任何其他前缀，如：http://等是不被允许的；·A记录优先于CNAME记录。即如果一个主机地址同时存在A记录和CNAME记录，则CNAME记录不生效。\n\n\n  <!-- more -->\n\n\n  ## MX记录\n\n\n  邮件交换记录。用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。如：用户所用的邮件是以域名mydomain.com为结尾的，则需要在管理界面中添加该域名的MX记录来处理所有以@mydomain.com结尾的邮件。\n\n\n  说明：MX记录可以使用主机名或IP地址；·MX记录可以通过设置优先级实现主辅服务器设置，“优先级”中的数字越小表示级别越高。也可以使用相同优先级达到负载均衡的目的；·如果在“主机名”中填入子域名则此MX记录只对该子域名生效。\n\n\n  ## NS记录\n\n\n  解析服务器记录。用来表明由哪台服务器对该域名进行解析。这里的NS记录只对子域名生效。\n\n\n  例如用户希望由12.34.56.78这台服务器解析news.mydomain.com，则需要设置news.mydomain.com的NS记录。\n\n\n  说明：·“优先级”中的数字越小表示级别越高；·“IP地址/主机名”中既可以填写IP地址，也可以填写像ns.mydomain.com这样的主机地址，但必须保证该主机地址有效。\n\n\n  如，将news.mydomain.com的NS记录指向到ns.mydomain.com，在设置NS记录的同时还需要设置ns.mydomain.com的指向，\n\n\n  否则NS记录将无法正常解析；·NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。\n\n\n  ## 什么是负载均衡服务器？\n\n\n  负载均衡(Server Load\n  Balancing，SLB)是指在一系列资源上面智能地分布网络负载。负载均衡可以减少网络拥塞，提高整体网络性能，提高自愈性，并确保企业关键性应用的可用性。当相同子域有多个目标地址，或域名的MX记录有多个目标地址且优先级相同时，表示轮循，可以达到负载均衡的目的，但需要虚拟主机和邮箱服务商支持。\n\n\n  ## 什么是TTL？\n\n\n  TTL值TTL值全称是“生存时间（Time To\n  Live)”，简单的说它表示DNS记录在DNS服务器上缓存时间。这个缓存时间太长和太短都不好，如果缓存时间太长，一旦域名被解析到的IP有变化，会导致被客户端缓存的域名无法解析到变化后的IP地址，以致该域名不能正常解析，这段时间内有可能会有一部分用户无法访问网站。如果缓存时间太短，会导致用户每次访问网站都要重新解析一次域名。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-01-11 14:32:12\n---\n\n## A记录\n\n又称IP指向，用户可以在此设置子域名并指向到自己的目标主机地址上，从而实现通过域名找到服务器。\n\n说明：·指向的目标主机地址类型只能使用IP地址；\n\n## CNAME\n\n通常称别名指向。可以为一个主机设置别名。比如设置test.mydomain.com，用来指向一个主机www.rddns.com那么以后就可以用test.mydomain.com来代替访问www.rddns.com了。\n\n说明：CNAME的目标主机地址只能使用主机名，不能使用IP地址；·主机名前不能有任何其他前缀，如：http://等是不被允许的；·A记录优先于CNAME记录。即如果一个主机地址同时存在A记录和CNAME记录，则CNAME记录不生效。\n\n<!-- more -->\n\n## MX记录\n\n邮件交换记录。用于将以该域名为结尾的电子邮件指向对应的邮件服务器以进行处理。如：用户所用的邮件是以域名mydomain.com为结尾的，则需要在管理界面中添加该域名的MX记录来处理所有以@mydomain.com结尾的邮件。\n\n说明：MX记录可以使用主机名或IP地址；·MX记录可以通过设置优先级实现主辅服务器设置，“优先级”中的数字越小表示级别越高。也可以使用相同优先级达到负载均衡的目的；·如果在“主机名”中填入子域名则此MX记录只对该子域名生效。\n\n## NS记录\n\n解析服务器记录。用来表明由哪台服务器对该域名进行解析。这里的NS记录只对子域名生效。\n\n例如用户希望由12.34.56.78这台服务器解析news.mydomain.com，则需要设置news.mydomain.com的NS记录。\n\n说明：·“优先级”中的数字越小表示级别越高；·“IP地址/主机名”中既可以填写IP地址，也可以填写像ns.mydomain.com这样的主机地址，但必须保证该主机地址有效。\n\n如，将news.mydomain.com的NS记录指向到ns.mydomain.com，在设置NS记录的同时还需要设置ns.mydomain.com的指向，\n\n否则NS记录将无法正常解析；·NS记录优先于A记录。即，如果一个主机地址同时存在NS记录和A记录，则A记录不生效。这里的NS记录只对子域名生效。\n\n## 什么是负载均衡服务器？\n\n负载均衡(Server Load Balancing，SLB)是指在一系列资源上面智能地分布网络负载。负载均衡可以减少网络拥塞，提高整体网络性能，提高自愈性，并确保企业关键性应用的可用性。当相同子域有多个目标地址，或域名的MX记录有多个目标地址且优先级相同时，表示轮循，可以达到负载均衡的目的，但需要虚拟主机和邮箱服务商支持。\n\n## 什么是TTL？\n\nTTL值TTL值全称是“生存时间（Time To Live)”，简单的说它表示DNS记录在DNS服务器上缓存时间。这个缓存时间太长和太短都不好，如果缓存时间太长，一旦域名被解析到的IP有变化，会导致被客户端缓存的域名无法解析到变化后的IP地址，以致该域名不能正常解析，这段时间内有可能会有一部分用户无法访问网站。如果缓存时间太短，会导致用户每次访问网站都要重新解析一次域名。","slug":"域名解析中A记录、CNAME、MX记录、NS记录的区别和联系","published":1,"updated":"2019-03-23T10:25:01.960Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elv004agyavmwf9k843"},{"title":"更改location的URI","originContent":"在location块中，除了使用root指令指明请求处理根目录，还可以使用alias指令改变location接收到的URI的请求路径，其语法结构为：\n\n<!-- more -->\n\n```\nalias path;\n```\n\n其中，path即为修改后的根路径。同样，次变量中也可以包含除了$document_root和$realpath_root之外的其他Nginx服务器预设变量。\n\n这个指令的作用有点不好理解，我们来看一个示例：\n\n```\nlocation ~ ^/data/(.+\\.(html|htm))$ {\n    alias   /locationtest1/other/$1;\n}\n```\n\n当此location块接收到'/data/index.html'的请求时，匹配成功，之后根据alias指令的配置，Nginx服务器将到/locationtest1/other目录下找到index.html并相应请求。可以看到，通过alias指令的配置，根路径已经从/data更改为/locationtest1/other了。\n\n> 如果没有alias设置，那么/data/index.html对应的文件路径就是[root_path]/data/index.html，这个设置这里我觉得最大的用处应该是为了减少路由的层级，比如我们为一个相对复杂的路径设置一个别名，这个别名对应一个简单的路径，在开发和使用的时候会相对简单一些，同时可以解耦一些业务，这个简易路径可以针对具体后端业务场景，而前端场景则可以相对随意一些，设置一个别名指向这个简易路径即可。","toc":false,"date":"2017-08-27T10:55:04.000Z","_content":"\n在location块中，除了使用root指令指明请求处理根目录，还可以使用alias指令改变location接收到的URI的请求路径，其语法结构为：\n\n<!-- more -->\n\n```\nalias path;\n```\n\n其中，path即为修改后的根路径。同样，次变量中也可以包含除了$document_root和$realpath_root之外的其他Nginx服务器预设变量。\n\n这个指令的作用有点不好理解，我们来看一个示例：\n\n```\nlocation ~ ^/data/(.+\\.(html|htm))$ {\n    alias   /locationtest1/other/$1;\n}\n```\n\n当此location块接收到'/data/index.html'的请求时，匹配成功，之后根据alias指令的配置，Nginx服务器将到/locationtest1/other目录下找到index.html并相应请求。可以看到，通过alias指令的配置，根路径已经从/data更改为/locationtest1/other了。\n\n> 如果没有alias设置，那么/data/index.html对应的文件路径就是[root_path]/data/index.html，这个设置这里我觉得最大的用处应该是为了减少路由的层级，比如我们为一个相对复杂的路径设置一个别名，这个别名对应一个简单的路径，在开发和使用的时候会相对简单一些，同时可以解耦一些业务，这个简易路径可以针对具体后端业务场景，而前端场景则可以相对随意一些，设置一个别名指向这个简易路径即可。","source":"_posts/更改location的URI.md","raw":"---\ntitle: 更改location的URI\ntags:\n  - nginx\noriginContent: >-\n  在location块中，除了使用root指令指明请求处理根目录，还可以使用alias指令改变location接收到的URI的请求路径，其语法结构为：\n\n\n  <!-- more -->\n\n\n  ```\n\n  alias path;\n\n  ```\n\n\n  其中，path即为修改后的根路径。同样，次变量中也可以包含除了$document_root和$realpath_root之外的其他Nginx服务器预设变量。\n\n\n  这个指令的作用有点不好理解，我们来看一个示例：\n\n\n  ```\n\n  location ~ ^/data/(.+\\.(html|htm))$ {\n      alias   /locationtest1/other/$1;\n  }\n\n  ```\n\n\n  当此location块接收到'/data/index.html'的请求时，匹配成功，之后根据alias指令的配置，Nginx服务器将到/locationtest1/other目录下找到index.html并相应请求。可以看到，通过alias指令的配置，根路径已经从/data更改为/locationtest1/other了。\n\n\n  >\n  如果没有alias设置，那么/data/index.html对应的文件路径就是[root_path]/data/index.html，这个设置这里我觉得最大的用处应该是为了减少路由的层级，比如我们为一个相对复杂的路径设置一个别名，这个别名对应一个简单的路径，在开发和使用的时候会相对简单一些，同时可以解耦一些业务，这个简易路径可以针对具体后端业务场景，而前端场景则可以相对随意一些，设置一个别名指向这个简易路径即可。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 18:55:04\n---\n\n在location块中，除了使用root指令指明请求处理根目录，还可以使用alias指令改变location接收到的URI的请求路径，其语法结构为：\n\n<!-- more -->\n\n```\nalias path;\n```\n\n其中，path即为修改后的根路径。同样，次变量中也可以包含除了$document_root和$realpath_root之外的其他Nginx服务器预设变量。\n\n这个指令的作用有点不好理解，我们来看一个示例：\n\n```\nlocation ~ ^/data/(.+\\.(html|htm))$ {\n    alias   /locationtest1/other/$1;\n}\n```\n\n当此location块接收到'/data/index.html'的请求时，匹配成功，之后根据alias指令的配置，Nginx服务器将到/locationtest1/other目录下找到index.html并相应请求。可以看到，通过alias指令的配置，根路径已经从/data更改为/locationtest1/other了。\n\n> 如果没有alias设置，那么/data/index.html对应的文件路径就是[root_path]/data/index.html，这个设置这里我觉得最大的用处应该是为了减少路由的层级，比如我们为一个相对复杂的路径设置一个别名，这个别名对应一个简单的路径，在开发和使用的时候会相对简单一些，同时可以解耦一些业务，这个简易路径可以针对具体后端业务场景，而前端场景则可以相对随意一些，设置一个别名指向这个简易路径即可。","slug":"更改location的URI","published":1,"updated":"2019-03-23T10:41:29.033Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1elz004egyav60va4pe1"},{"title":"本机连接vagrant虚拟机创建的mysql数据库","originContent":"当学习数据库的时候经常会用到虚拟机，以避免把自己的机器当成测试机搞来搞去，这里我用的是vagrant，用起来比较方便，\n我在vagrant里边创建了一个数据库，希望通过本机的可视化工具连接上，直接连接发现会报错：\n\n```\nHost '192.168.33.1' is not allowed to connect to this MariaDB server\n```\n\n<!-- more -->\n\n这应该是数据库本身对外部访问的一个限制，现在我们处理一下：\n\n```\nCREATE USER 'kivi'@'localhost' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'localhost' WITH GRANT OPTION;\n\nCREATE USER 'kivi'@'%' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'%' WITH GRANT OPTION;\n```\n\n好了，在虚拟机的数据库环境执行完这四条命令以后，我们在使用工具连接，用户名kivi，密码kivi；\n\n成功连接！","toc":false,"date":"2018-02-25T04:30:38.000Z","_content":"\n当学习数据库的时候经常会用到虚拟机，以避免把自己的机器当成测试机搞来搞去，这里我用的是vagrant，用起来比较方便，\n我在vagrant里边创建了一个数据库，希望通过本机的可视化工具连接上，直接连接发现会报错：\n\n```\nHost '192.168.33.1' is not allowed to connect to this MariaDB server\n```\n\n<!-- more -->\n\n这应该是数据库本身对外部访问的一个限制，现在我们处理一下：\n\n```\nCREATE USER 'kivi'@'localhost' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'localhost' WITH GRANT OPTION;\n\nCREATE USER 'kivi'@'%' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'%' WITH GRANT OPTION;\n```\n\n好了，在虚拟机的数据库环境执行完这四条命令以后，我们在使用工具连接，用户名kivi，密码kivi；\n\n成功连接！","source":"_posts/本机连接vagrant虚拟机创建的mysql数据库.md","raw":"---\ntitle: 本机连接vagrant虚拟机创建的mysql数据库\ntags:\n  - mysql\n  - vagrant\noriginContent: |-\n  当学习数据库的时候经常会用到虚拟机，以避免把自己的机器当成测试机搞来搞去，这里我用的是vagrant，用起来比较方便，\n  我在vagrant里边创建了一个数据库，希望通过本机的可视化工具连接上，直接连接发现会报错：\n\n  ```\n  Host '192.168.33.1' is not allowed to connect to this MariaDB server\n  ```\n\n  <!-- more -->\n\n  这应该是数据库本身对外部访问的一个限制，现在我们处理一下：\n\n  ```\n  CREATE USER 'kivi'@'localhost' IDENTIFIED BY 'kivi';\n\n  GRANT ALL PRIVILEGES ON *.* TO 'kivi'@'localhost' WITH GRANT OPTION;\n\n  CREATE USER 'kivi'@'%' IDENTIFIED BY 'kivi';\n\n  GRANT ALL PRIVILEGES ON *.* TO 'kivi'@'%' WITH GRANT OPTION;\n  ```\n\n  好了，在虚拟机的数据库环境执行完这四条命令以后，我们在使用工具连接，用户名kivi，密码kivi；\n\n  成功连接！\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-02-25 12:30:38\n---\n\n当学习数据库的时候经常会用到虚拟机，以避免把自己的机器当成测试机搞来搞去，这里我用的是vagrant，用起来比较方便，\n我在vagrant里边创建了一个数据库，希望通过本机的可视化工具连接上，直接连接发现会报错：\n\n```\nHost '192.168.33.1' is not allowed to connect to this MariaDB server\n```\n\n<!-- more -->\n\n这应该是数据库本身对外部访问的一个限制，现在我们处理一下：\n\n```\nCREATE USER 'kivi'@'localhost' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'localhost' WITH GRANT OPTION;\n\nCREATE USER 'kivi'@'%' IDENTIFIED BY 'kivi';\n\nGRANT ALL PRIVILEGES ON *.* TO 'kivi'@'%' WITH GRANT OPTION;\n```\n\n好了，在虚拟机的数据库环境执行完这四条命令以后，我们在使用工具连接，用户名kivi，密码kivi；\n\n成功连接！","slug":"本机连接vagrant虚拟机创建的mysql数据库","published":1,"updated":"2019-03-23T10:22:18.625Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1em2004hgyav57xfoe9o"},{"title":"安装pomelo","originContent":"pomelo是基于Node.js的，目前pomelo已经**完全支持Windows、Linux、Mac**等多种平台。\n\n如果是windows系统，请参考原文，由于我用的是mac os系统与linux环境，因此windows环境不再做验证工作。\n\n<!-- more -->\n\n## 准备\n* 确保你的机器**可以上网**,因为安装pomelo的过程需要从网上下载其依赖的包。\n* 确保你的系统上已经要**安装了Node**，目前最新的Node提供了已经编译好的二进制安装包，包括Windows，Mac和Linux等平台。想省事的话，直接去这里下载对应的安装包，直接安装就好了。Node同时也提供了传统的从源码编译的方式安装，不过比起直接使用二进制的方式要麻烦。\n* 确保你的系统中安装有**python(2.5 < version < 3.0)**以及**C++的编译器**。Node的源码主要由C++代码和JavaScript代码构成，但是却用**gyp**工具来做源码的项目管理，该工具采用Python语言写成的。对于非windows平台，一般都会预装Python以及C++编译工具；对于Windows系统，请确保你的Windows系统包含源码编译工具。在Windows平台上，Node.js采用gyp来生成Visual Studio Solution文件，最终通过VC++的编译器将其编译为二进制文件。\n* 虽然pomelo是用Javascript写成，但是pomelo依赖的库中，有使用了C++语言写的扩展，因此安装pomelo的过程中会使用到C++编译器。 所以，在安装之前请确保你的Windows系统满足以下两个条件：\n\t1. **python(2.5<version<3.0)**。\n\t2. **VC++ 编译器**，包含在Visual Studio 2010中（VC++ 2010 Express亦可）。对于windows8的用户，需要安装Microsoft Visual Studio C++ 2012。\n* 如果你使用的是Mac OS X系统, 则需要安装**Xcode Command Line Tools**或者**Xcode的完整包**以及make工具.\n\n## 安装pomelo\n使用npm(node包管理工具)全局安装pomelo:\n\n```\n$ npm install pomelo -g\n```\n\n可以通过如下命令下载源代码的方式安装\n\n```\n$ git clone https://github.com/NetEase/pomelo.git\n$ cd pomelo\n$ npm install -g\n```\n\n其中-g表示全局安装，关于npm的使用问题，可以参考npm的文档，里面有详细的npm使用的介绍。如果安装过程中没有报错误，说明安装成功。\n\nwindows下安装经验：\n\n```\n1. node,vs2010 和 python(2.5<v<3) 都是32位或者都是64位的。\n2. 配置  PYTHON=d:\\Python27\\python.exe(设置成你自己的路径)。注意不是path里面,而是和path同级的，直接在全局或者当前用户下配置。\n3. 保证环境变量path里面有 %SystemRoot%\\system32;%SystemRoot%;%SystemRoot%\\System32\\Wbem;\n  注： 这三个环境变量中貌似只有%SystemRoot%\\system32这个环境变量有用，没具体试（没有他会报CreateProcessW找不到的错误)。\n4. 如果在命令行界面安装pomelo失败，可以在Visual Studio的命令行界面安装。\n```\n\n下面我们将通过一个HelloWorld项目来检验我们的安装是否成功。\n\n**总结一下：直接`npm install pomelo -g`在机器上就可以用了 不用看上面太多东西，只有当你无法使用的时候再看看就行了**\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E5%AE%89%E8%A3%85pomelo)","toc":false,"date":"2018-02-28T03:55:04.000Z","_content":"\npomelo是基于Node.js的，目前pomelo已经**完全支持Windows、Linux、Mac**等多种平台。\n\n如果是windows系统，请参考原文，由于我用的是mac os系统与linux环境，因此windows环境不再做验证工作。\n\n<!-- more -->\n\n## 准备\n* 确保你的机器**可以上网**,因为安装pomelo的过程需要从网上下载其依赖的包。\n* 确保你的系统上已经要**安装了Node**，目前最新的Node提供了已经编译好的二进制安装包，包括Windows，Mac和Linux等平台。想省事的话，直接去这里下载对应的安装包，直接安装就好了。Node同时也提供了传统的从源码编译的方式安装，不过比起直接使用二进制的方式要麻烦。\n* 确保你的系统中安装有**python(2.5 < version < 3.0)**以及**C++的编译器**。Node的源码主要由C++代码和JavaScript代码构成，但是却用**gyp**工具来做源码的项目管理，该工具采用Python语言写成的。对于非windows平台，一般都会预装Python以及C++编译工具；对于Windows系统，请确保你的Windows系统包含源码编译工具。在Windows平台上，Node.js采用gyp来生成Visual Studio Solution文件，最终通过VC++的编译器将其编译为二进制文件。\n* 虽然pomelo是用Javascript写成，但是pomelo依赖的库中，有使用了C++语言写的扩展，因此安装pomelo的过程中会使用到C++编译器。 所以，在安装之前请确保你的Windows系统满足以下两个条件：\n\t1. **python(2.5<version<3.0)**。\n\t2. **VC++ 编译器**，包含在Visual Studio 2010中（VC++ 2010 Express亦可）。对于windows8的用户，需要安装Microsoft Visual Studio C++ 2012。\n* 如果你使用的是Mac OS X系统, 则需要安装**Xcode Command Line Tools**或者**Xcode的完整包**以及make工具.\n\n## 安装pomelo\n使用npm(node包管理工具)全局安装pomelo:\n\n```\n$ npm install pomelo -g\n```\n\n可以通过如下命令下载源代码的方式安装\n\n```\n$ git clone https://github.com/NetEase/pomelo.git\n$ cd pomelo\n$ npm install -g\n```\n\n其中-g表示全局安装，关于npm的使用问题，可以参考npm的文档，里面有详细的npm使用的介绍。如果安装过程中没有报错误，说明安装成功。\n\nwindows下安装经验：\n\n```\n1. node,vs2010 和 python(2.5<v<3) 都是32位或者都是64位的。\n2. 配置  PYTHON=d:\\Python27\\python.exe(设置成你自己的路径)。注意不是path里面,而是和path同级的，直接在全局或者当前用户下配置。\n3. 保证环境变量path里面有 %SystemRoot%\\system32;%SystemRoot%;%SystemRoot%\\System32\\Wbem;\n  注： 这三个环境变量中貌似只有%SystemRoot%\\system32这个环境变量有用，没具体试（没有他会报CreateProcessW找不到的错误)。\n4. 如果在命令行界面安装pomelo失败，可以在Visual Studio的命令行界面安装。\n```\n\n下面我们将通过一个HelloWorld项目来检验我们的安装是否成功。\n\n**总结一下：直接`npm install pomelo -g`在机器上就可以用了 不用看上面太多东西，只有当你无法使用的时候再看看就行了**\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E5%AE%89%E8%A3%85pomelo)","source":"_posts/安装pomelo.md","raw":"---\ntitle: 安装pomelo\ntags:\n  - pomelo\noriginContent: \"pomelo是基于Node.js的，目前pomelo已经**完全支持Windows、Linux、Mac**等多种平台。\\n\\n如果是windows系统，请参考原文，由于我用的是mac os系统与linux环境，因此windows环境不再做验证工作。\\n\\n<!-- more -->\\n\\n## 准备\\n* 确保你的机器**可以上网**,因为安装pomelo的过程需要从网上下载其依赖的包。\\n* 确保你的系统上已经要**安装了Node**，目前最新的Node提供了已经编译好的二进制安装包，包括Windows，Mac和Linux等平台。想省事的话，直接去这里下载对应的安装包，直接安装就好了。Node同时也提供了传统的从源码编译的方式安装，不过比起直接使用二进制的方式要麻烦。\\n* 确保你的系统中安装有**python(2.5 < version < 3.0)**以及**C++的编译器**。Node的源码主要由C++代码和JavaScript代码构成，但是却用**gyp**工具来做源码的项目管理，该工具采用Python语言写成的。对于非windows平台，一般都会预装Python以及C++编译工具；对于Windows系统，请确保你的Windows系统包含源码编译工具。在Windows平台上，Node.js采用gyp来生成Visual Studio Solution文件，最终通过VC++的编译器将其编译为二进制文件。\\n* 虽然pomelo是用Javascript写成，但是pomelo依赖的库中，有使用了C++语言写的扩展，因此安装pomelo的过程中会使用到C++编译器。 所以，在安装之前请确保你的Windows系统满足以下两个条件：\\n\\t1. **python(2.5<version<3.0)**。\\n\\t2. **VC++ 编译器**，包含在Visual Studio 2010中（VC++ 2010 Express亦可）。对于windows8的用户，需要安装Microsoft Visual Studio C++ 2012。\\n* 如果你使用的是Mac OS X系统, 则需要安装**Xcode Command Line Tools**或者**Xcode的完整包**以及make工具.\\n\\n## 安装pomelo\\n使用npm(node包管理工具)全局安装pomelo:\\n\\n```\\n$ npm install pomelo -g\\n```\\n\\n可以通过如下命令下载源代码的方式安装\\n\\n```\\n$ git clone https://github.com/NetEase/pomelo.git\\n$ cd pomelo\\n$ npm install -g\\n```\\n\\n其中-g表示全局安装，关于npm的使用问题，可以参考npm的文档，里面有详细的npm使用的介绍。如果安装过程中没有报错误，说明安装成功。\\n\\nwindows下安装经验：\\n\\n```\\n1. node,vs2010 和 python(2.5<v<3) 都是32位或者都是64位的。\\n2. 配置  PYTHON=d:\\\\Python27\\\\python.exe(设置成你自己的路径)。注意不是path里面,而是和path同级的，直接在全局或者当前用户下配置。\\n3. 保证环境变量path里面有 %SystemRoot%\\\\system32;%SystemRoot%;%SystemRoot%\\\\System32\\\\Wbem;\\n  注： 这三个环境变量中貌似只有%SystemRoot%\\\\system32这个环境变量有用，没具体试（没有他会报CreateProcessW找不到的错误)。\\n4. 如果在命令行界面安装pomelo失败，可以在Visual Studio的命令行界面安装。\\n```\\n\\n下面我们将通过一个HelloWorld项目来检验我们的安装是否成功。\\n\\n**总结一下：直接`npm install pomelo -g`在机器上就可以用了 不用看上面太多东西，只有当你无法使用的时候再看看就行了**\\n\\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E5%AE%89%E8%A3%85pomelo)\"\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-02-28 11:55:04\n---\n\npomelo是基于Node.js的，目前pomelo已经**完全支持Windows、Linux、Mac**等多种平台。\n\n如果是windows系统，请参考原文，由于我用的是mac os系统与linux环境，因此windows环境不再做验证工作。\n\n<!-- more -->\n\n## 准备\n* 确保你的机器**可以上网**,因为安装pomelo的过程需要从网上下载其依赖的包。\n* 确保你的系统上已经要**安装了Node**，目前最新的Node提供了已经编译好的二进制安装包，包括Windows，Mac和Linux等平台。想省事的话，直接去这里下载对应的安装包，直接安装就好了。Node同时也提供了传统的从源码编译的方式安装，不过比起直接使用二进制的方式要麻烦。\n* 确保你的系统中安装有**python(2.5 < version < 3.0)**以及**C++的编译器**。Node的源码主要由C++代码和JavaScript代码构成，但是却用**gyp**工具来做源码的项目管理，该工具采用Python语言写成的。对于非windows平台，一般都会预装Python以及C++编译工具；对于Windows系统，请确保你的Windows系统包含源码编译工具。在Windows平台上，Node.js采用gyp来生成Visual Studio Solution文件，最终通过VC++的编译器将其编译为二进制文件。\n* 虽然pomelo是用Javascript写成，但是pomelo依赖的库中，有使用了C++语言写的扩展，因此安装pomelo的过程中会使用到C++编译器。 所以，在安装之前请确保你的Windows系统满足以下两个条件：\n\t1. **python(2.5<version<3.0)**。\n\t2. **VC++ 编译器**，包含在Visual Studio 2010中（VC++ 2010 Express亦可）。对于windows8的用户，需要安装Microsoft Visual Studio C++ 2012。\n* 如果你使用的是Mac OS X系统, 则需要安装**Xcode Command Line Tools**或者**Xcode的完整包**以及make工具.\n\n## 安装pomelo\n使用npm(node包管理工具)全局安装pomelo:\n\n```\n$ npm install pomelo -g\n```\n\n可以通过如下命令下载源代码的方式安装\n\n```\n$ git clone https://github.com/NetEase/pomelo.git\n$ cd pomelo\n$ npm install -g\n```\n\n其中-g表示全局安装，关于npm的使用问题，可以参考npm的文档，里面有详细的npm使用的介绍。如果安装过程中没有报错误，说明安装成功。\n\nwindows下安装经验：\n\n```\n1. node,vs2010 和 python(2.5<v<3) 都是32位或者都是64位的。\n2. 配置  PYTHON=d:\\Python27\\python.exe(设置成你自己的路径)。注意不是path里面,而是和path同级的，直接在全局或者当前用户下配置。\n3. 保证环境变量path里面有 %SystemRoot%\\system32;%SystemRoot%;%SystemRoot%\\System32\\Wbem;\n  注： 这三个环境变量中貌似只有%SystemRoot%\\system32这个环境变量有用，没具体试（没有他会报CreateProcessW找不到的错误)。\n4. 如果在命令行界面安装pomelo失败，可以在Visual Studio的命令行界面安装。\n```\n\n下面我们将通过一个HelloWorld项目来检验我们的安装是否成功。\n\n**总结一下：直接`npm install pomelo -g`在机器上就可以用了 不用看上面太多东西，只有当你无法使用的时候再看看就行了**\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E5%AE%89%E8%A3%85pomelo)","slug":"安装pomelo","published":1,"updated":"2019-03-23T10:21:48.090Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1em9004lgyavs5kxhs2a"},{"title":"每天读一遍，不久你就会有改变","originContent":"很久以前记录的一个文章，具体来源也不知道了，今天看到觉得应该记下来：\n\n<!-- more -->\n\n1. 别低估任何人。\n\n2. 你没那么多观众，别那么累。\n\n3. 温和对人对事。不要随意发脾气，谁都不欠你的。\n\n4. 现在很痛苦，等过阵子回头看看，会发现其实那都不算事。\n\n5. 和对自己有恶意的人绝交。人有绝交，才有至交。\n\n6. 学会宽容伤害自己的人，因为他们很可怜，各人都有自己的难处，大家都不容易。 \n\n7. 学会放弃，拽的越紧，痛苦的是自己。\n\n8. 低调，取舍间，必有得失。\n\n9. 不要试图给自己找任何借口，错误面前没人爱听那些借口。\n\n10. 慎言，独立，学会妥协的同时，也要坚持自己最基本的原则。\n\n11. 付出并不一定有结果。坚持可能会导致失去更多。\n\n12. 过去的事情可以不忘记，但一定要放下。\n\n13. 活得轻松，任何事都作一个最好的打算和最坏的打算。\n\n14. 做一个简单的人，踏实而务实。不沉溺幻想。不庸人自扰。\n\n15. 不说谎话，因为总有被拆穿的一天。\n\n16. 别人光鲜的背后或者有着太多不为人知的痛苦\n\n17. 尽量充实自己。不要停止学习。不管学习什么，语言，厨艺，各种技能。\n\n18. 注意自己的修养，你就是孩子的第一位老师。\n\n19. 孝顺父母。不只是嘴上说说，即使多打几个电话也是很好的。\n\n20. 爱父母，因为他们给了你生命，同时也是爱你爱的最无私的人。\n\n21. 偶尔也要现实和虚伪一点，因为不那样做的话，很难混。\n\n22. 收敛自己的脾气，偶尔要刻意沉默，因为冲动会做下让自己无法挽回的事情。\n\n23. 无论什么时候，做什么事情，要思考。\n\n24. 永远不要给背叛过自己的朋友第二次的背叛的机会。\n\n25. 无论是谁，都有自己的限度。特别是信任。\n\n26. 懂得倾听别人的忠告。\n\n27. 别人说的记在脑袋里，而自己的，则放在心里。\n\n28. 尽量不要讲同事朋友的八卦。\n\n29. 信佛，信因果，在真正的因果面前，人的力量是微不足道的。\n\n30. 坦然接受生活给你的馈赠吧，不管是好的还是坏的。\n\n31. 真正了解无常的含义，当你痛苦时，你要想这痛苦不是永恒的，当你快乐时，你要想这快乐也不是永恒的。\n\n32. 要快乐，要开朗，要坚韧，要温暖，对人要真诚。\n\n33. 空虚无聊的时候就读书，但一定得有自己的生活目标和计划。\n\n34. 对人性的弱点有清醒的认识，但要相信真诚的爱情，对爱情永远怀有单纯的向往。\n\n35. 不要太过依赖除自己以外的人，因为只有自己不会抛弃自己。\n\n36. 永远对生活充满希望，对于困境与磨难，微笑面对。\n\n37. 多看书，看好书。\n\n38. 少吃点，吃好的。\n\n39. 古龙说过，爱笑的女孩子，运气不会太差。\n\n40. 多交朋友，交好的朋友。女人一定要有闺密。\n\n41. 请记得，好朋友的定义是：你混的好，她打心眼里为你开心；你混的不好，她由衷的为你着急。\n\n42. 要有梦想，即使遥远。\n\n43. 努力爱一个人。付出，不一定会有收获；不付出，却一定不会有收获，不要奢望出现奇迹。\n\n44. 承诺是一件美好的事情，但美好的东西往往不会变为现实。\n\n45. 每个人都有自己鲜明的主张和个性，不要识途去改变他人，同样，也不要被他人所改变。改了，就不是自己了。\n\n46. 没有十全十美的东西，没有十全十美的人，关键是清楚到底想要什么。得到想要的，肯定会失去另外一部分。如果什么都想要，只会什么都得不到。\n\n47. 这个世界最脆弱的是生命，身体健康，很重要。\n\n48. 老天爷对每个人都是公平的。\n\n49. 不要试图控制别人，不要要求别人理解你\n\n50. 活在当下，别在怀念过去或者憧憬未来中浪费掉你现在的生活\n\n51. 不要忘本，任何时候，任何事情\n\n52. 要诚恳，要坦然，要慷慨，要宽容，要有平常心\n\n53. 学会忘记, 善忘是一件好事\n\n54. 要乐观，要积极，多笑，多照镜子\n\n55. 相信他说的话，但不要当真。\n\n56. 凡事多长心眼。\n\n57. 不要自作聪明。\n\n58. 做自己的决定。然后准备好承担后果。从一开始就提醒自己，世上没有后悔药吃。\n\n59. 自己不喜欢的人，可以报之以沉默微笑；自己喜欢的人，那就随便怎么样了，因为你的喜爱会挡也挡不住地流露出来。\n\n60. 相信因果报应！相信轮回！\n\n61. 要学会忍耐与坚持！\n\n62. 这个世界上没有真正的爱情⋯⋯时间可以冲淡一切\n\n63. 不要做刺猬 能不与人结仇就不与人结仇，谁也不跟谁一辈子，有些事情没必要记在心上\n\n64. 有时要学会听取身边人的意见，更多时候这样才不会让自己受到伤害。\n\n65. 忘记过去才能有新的开始。\n\n66. 这个世界很不公平。\n\n67. 不要太依赖朋友，人性基本都有恶的一面。\n\n68. 爱情很美好，相信爱情。如果连爱情都不相信那人生岂不太苦了？\n\n69. 想得到一样一定会失去另一件东西。\n\n70. 痛苦让人成长，是你进步的一个机会，一个挑战。别害怕痛苦的事情，它有另一面积极的作用。\n\n71. 人就是孤独的，缓解它带来的痛苦的唯一方式就是平静的","toc":false,"date":"2017-10-13T06:03:00.000Z","_content":"\n很久以前记录的一个文章，具体来源也不知道了，今天看到觉得应该记下来：\n\n<!-- more -->\n\n1. 别低估任何人。\n\n2. 你没那么多观众，别那么累。\n\n3. 温和对人对事。不要随意发脾气，谁都不欠你的。\n\n4. 现在很痛苦，等过阵子回头看看，会发现其实那都不算事。\n\n5. 和对自己有恶意的人绝交。人有绝交，才有至交。\n\n6. 学会宽容伤害自己的人，因为他们很可怜，各人都有自己的难处，大家都不容易。 \n\n7. 学会放弃，拽的越紧，痛苦的是自己。\n\n8. 低调，取舍间，必有得失。\n\n9. 不要试图给自己找任何借口，错误面前没人爱听那些借口。\n\n10. 慎言，独立，学会妥协的同时，也要坚持自己最基本的原则。\n\n11. 付出并不一定有结果。坚持可能会导致失去更多。\n\n12. 过去的事情可以不忘记，但一定要放下。\n\n13. 活得轻松，任何事都作一个最好的打算和最坏的打算。\n\n14. 做一个简单的人，踏实而务实。不沉溺幻想。不庸人自扰。\n\n15. 不说谎话，因为总有被拆穿的一天。\n\n16. 别人光鲜的背后或者有着太多不为人知的痛苦\n\n17. 尽量充实自己。不要停止学习。不管学习什么，语言，厨艺，各种技能。\n\n18. 注意自己的修养，你就是孩子的第一位老师。\n\n19. 孝顺父母。不只是嘴上说说，即使多打几个电话也是很好的。\n\n20. 爱父母，因为他们给了你生命，同时也是爱你爱的最无私的人。\n\n21. 偶尔也要现实和虚伪一点，因为不那样做的话，很难混。\n\n22. 收敛自己的脾气，偶尔要刻意沉默，因为冲动会做下让自己无法挽回的事情。\n\n23. 无论什么时候，做什么事情，要思考。\n\n24. 永远不要给背叛过自己的朋友第二次的背叛的机会。\n\n25. 无论是谁，都有自己的限度。特别是信任。\n\n26. 懂得倾听别人的忠告。\n\n27. 别人说的记在脑袋里，而自己的，则放在心里。\n\n28. 尽量不要讲同事朋友的八卦。\n\n29. 信佛，信因果，在真正的因果面前，人的力量是微不足道的。\n\n30. 坦然接受生活给你的馈赠吧，不管是好的还是坏的。\n\n31. 真正了解无常的含义，当你痛苦时，你要想这痛苦不是永恒的，当你快乐时，你要想这快乐也不是永恒的。\n\n32. 要快乐，要开朗，要坚韧，要温暖，对人要真诚。\n\n33. 空虚无聊的时候就读书，但一定得有自己的生活目标和计划。\n\n34. 对人性的弱点有清醒的认识，但要相信真诚的爱情，对爱情永远怀有单纯的向往。\n\n35. 不要太过依赖除自己以外的人，因为只有自己不会抛弃自己。\n\n36. 永远对生活充满希望，对于困境与磨难，微笑面对。\n\n37. 多看书，看好书。\n\n38. 少吃点，吃好的。\n\n39. 古龙说过，爱笑的女孩子，运气不会太差。\n\n40. 多交朋友，交好的朋友。女人一定要有闺密。\n\n41. 请记得，好朋友的定义是：你混的好，她打心眼里为你开心；你混的不好，她由衷的为你着急。\n\n42. 要有梦想，即使遥远。\n\n43. 努力爱一个人。付出，不一定会有收获；不付出，却一定不会有收获，不要奢望出现奇迹。\n\n44. 承诺是一件美好的事情，但美好的东西往往不会变为现实。\n\n45. 每个人都有自己鲜明的主张和个性，不要识途去改变他人，同样，也不要被他人所改变。改了，就不是自己了。\n\n46. 没有十全十美的东西，没有十全十美的人，关键是清楚到底想要什么。得到想要的，肯定会失去另外一部分。如果什么都想要，只会什么都得不到。\n\n47. 这个世界最脆弱的是生命，身体健康，很重要。\n\n48. 老天爷对每个人都是公平的。\n\n49. 不要试图控制别人，不要要求别人理解你\n\n50. 活在当下，别在怀念过去或者憧憬未来中浪费掉你现在的生活\n\n51. 不要忘本，任何时候，任何事情\n\n52. 要诚恳，要坦然，要慷慨，要宽容，要有平常心\n\n53. 学会忘记, 善忘是一件好事\n\n54. 要乐观，要积极，多笑，多照镜子\n\n55. 相信他说的话，但不要当真。\n\n56. 凡事多长心眼。\n\n57. 不要自作聪明。\n\n58. 做自己的决定。然后准备好承担后果。从一开始就提醒自己，世上没有后悔药吃。\n\n59. 自己不喜欢的人，可以报之以沉默微笑；自己喜欢的人，那就随便怎么样了，因为你的喜爱会挡也挡不住地流露出来。\n\n60. 相信因果报应！相信轮回！\n\n61. 要学会忍耐与坚持！\n\n62. 这个世界上没有真正的爱情⋯⋯时间可以冲淡一切\n\n63. 不要做刺猬 能不与人结仇就不与人结仇，谁也不跟谁一辈子，有些事情没必要记在心上\n\n64. 有时要学会听取身边人的意见，更多时候这样才不会让自己受到伤害。\n\n65. 忘记过去才能有新的开始。\n\n66. 这个世界很不公平。\n\n67. 不要太依赖朋友，人性基本都有恶的一面。\n\n68. 爱情很美好，相信爱情。如果连爱情都不相信那人生岂不太苦了？\n\n69. 想得到一样一定会失去另一件东西。\n\n70. 痛苦让人成长，是你进步的一个机会，一个挑战。别害怕痛苦的事情，它有另一面积极的作用。\n\n71. 人就是孤独的，缓解它带来的痛苦的唯一方式就是平静的","source":"_posts/每天读一遍，不就你就会有改变.md","raw":"---\ntitle: 每天读一遍，不久你就会有改变\ntags:\n  - plan\noriginContent: |-\n  很久以前记录的一个文章，具体来源也不知道了，今天看到觉得应该记下来：\n\n  <!-- more -->\n\n  1. 别低估任何人。\n\n  2. 你没那么多观众，别那么累。\n\n  3. 温和对人对事。不要随意发脾气，谁都不欠你的。\n\n  4. 现在很痛苦，等过阵子回头看看，会发现其实那都不算事。\n\n  5. 和对自己有恶意的人绝交。人有绝交，才有至交。\n\n  6. 学会宽容伤害自己的人，因为他们很可怜，各人都有自己的难处，大家都不容易。 \n\n  7. 学会放弃，拽的越紧，痛苦的是自己。\n\n  8. 低调，取舍间，必有得失。\n\n  9. 不要试图给自己找任何借口，错误面前没人爱听那些借口。\n\n  10. 慎言，独立，学会妥协的同时，也要坚持自己最基本的原则。\n\n  11. 付出并不一定有结果。坚持可能会导致失去更多。\n\n  12. 过去的事情可以不忘记，但一定要放下。\n\n  13. 活得轻松，任何事都作一个最好的打算和最坏的打算。\n\n  14. 做一个简单的人，踏实而务实。不沉溺幻想。不庸人自扰。\n\n  15. 不说谎话，因为总有被拆穿的一天。\n\n  16. 别人光鲜的背后或者有着太多不为人知的痛苦\n\n  17. 尽量充实自己。不要停止学习。不管学习什么，语言，厨艺，各种技能。\n\n  18. 注意自己的修养，你就是孩子的第一位老师。\n\n  19. 孝顺父母。不只是嘴上说说，即使多打几个电话也是很好的。\n\n  20. 爱父母，因为他们给了你生命，同时也是爱你爱的最无私的人。\n\n  21. 偶尔也要现实和虚伪一点，因为不那样做的话，很难混。\n\n  22. 收敛自己的脾气，偶尔要刻意沉默，因为冲动会做下让自己无法挽回的事情。\n\n  23. 无论什么时候，做什么事情，要思考。\n\n  24. 永远不要给背叛过自己的朋友第二次的背叛的机会。\n\n  25. 无论是谁，都有自己的限度。特别是信任。\n\n  26. 懂得倾听别人的忠告。\n\n  27. 别人说的记在脑袋里，而自己的，则放在心里。\n\n  28. 尽量不要讲同事朋友的八卦。\n\n  29. 信佛，信因果，在真正的因果面前，人的力量是微不足道的。\n\n  30. 坦然接受生活给你的馈赠吧，不管是好的还是坏的。\n\n  31. 真正了解无常的含义，当你痛苦时，你要想这痛苦不是永恒的，当你快乐时，你要想这快乐也不是永恒的。\n\n  32. 要快乐，要开朗，要坚韧，要温暖，对人要真诚。\n\n  33. 空虚无聊的时候就读书，但一定得有自己的生活目标和计划。\n\n  34. 对人性的弱点有清醒的认识，但要相信真诚的爱情，对爱情永远怀有单纯的向往。\n\n  35. 不要太过依赖除自己以外的人，因为只有自己不会抛弃自己。\n\n  36. 永远对生活充满希望，对于困境与磨难，微笑面对。\n\n  37. 多看书，看好书。\n\n  38. 少吃点，吃好的。\n\n  39. 古龙说过，爱笑的女孩子，运气不会太差。\n\n  40. 多交朋友，交好的朋友。女人一定要有闺密。\n\n  41. 请记得，好朋友的定义是：你混的好，她打心眼里为你开心；你混的不好，她由衷的为你着急。\n\n  42. 要有梦想，即使遥远。\n\n  43. 努力爱一个人。付出，不一定会有收获；不付出，却一定不会有收获，不要奢望出现奇迹。\n\n  44. 承诺是一件美好的事情，但美好的东西往往不会变为现实。\n\n  45. 每个人都有自己鲜明的主张和个性，不要识途去改变他人，同样，也不要被他人所改变。改了，就不是自己了。\n\n  46. 没有十全十美的东西，没有十全十美的人，关键是清楚到底想要什么。得到想要的，肯定会失去另外一部分。如果什么都想要，只会什么都得不到。\n\n  47. 这个世界最脆弱的是生命，身体健康，很重要。\n\n  48. 老天爷对每个人都是公平的。\n\n  49. 不要试图控制别人，不要要求别人理解你\n\n  50. 活在当下，别在怀念过去或者憧憬未来中浪费掉你现在的生活\n\n  51. 不要忘本，任何时候，任何事情\n\n  52. 要诚恳，要坦然，要慷慨，要宽容，要有平常心\n\n  53. 学会忘记, 善忘是一件好事\n\n  54. 要乐观，要积极，多笑，多照镜子\n\n  55. 相信他说的话，但不要当真。\n\n  56. 凡事多长心眼。\n\n  57. 不要自作聪明。\n\n  58. 做自己的决定。然后准备好承担后果。从一开始就提醒自己，世上没有后悔药吃。\n\n  59. 自己不喜欢的人，可以报之以沉默微笑；自己喜欢的人，那就随便怎么样了，因为你的喜爱会挡也挡不住地流露出来。\n\n  60. 相信因果报应！相信轮回！\n\n  61. 要学会忍耐与坚持！\n\n  62. 这个世界上没有真正的爱情⋯⋯时间可以冲淡一切\n\n  63. 不要做刺猬 能不与人结仇就不与人结仇，谁也不跟谁一辈子，有些事情没必要记在心上\n\n  64. 有时要学会听取身边人的意见，更多时候这样才不会让自己受到伤害。\n\n  65. 忘记过去才能有新的开始。\n\n  66. 这个世界很不公平。\n\n  67. 不要太依赖朋友，人性基本都有恶的一面。\n\n  68. 爱情很美好，相信爱情。如果连爱情都不相信那人生岂不太苦了？\n\n  69. 想得到一样一定会失去另一件东西。\n\n  70. 痛苦让人成长，是你进步的一个机会，一个挑战。别害怕痛苦的事情，它有另一面积极的作用。\n\n  71. 人就是孤独的，缓解它带来的痛苦的唯一方式就是平静的\ncategories:\n  - 生活玩乐\ntoc: false\ndate: 2017-10-13 14:03:00\n---\n\n很久以前记录的一个文章，具体来源也不知道了，今天看到觉得应该记下来：\n\n<!-- more -->\n\n1. 别低估任何人。\n\n2. 你没那么多观众，别那么累。\n\n3. 温和对人对事。不要随意发脾气，谁都不欠你的。\n\n4. 现在很痛苦，等过阵子回头看看，会发现其实那都不算事。\n\n5. 和对自己有恶意的人绝交。人有绝交，才有至交。\n\n6. 学会宽容伤害自己的人，因为他们很可怜，各人都有自己的难处，大家都不容易。 \n\n7. 学会放弃，拽的越紧，痛苦的是自己。\n\n8. 低调，取舍间，必有得失。\n\n9. 不要试图给自己找任何借口，错误面前没人爱听那些借口。\n\n10. 慎言，独立，学会妥协的同时，也要坚持自己最基本的原则。\n\n11. 付出并不一定有结果。坚持可能会导致失去更多。\n\n12. 过去的事情可以不忘记，但一定要放下。\n\n13. 活得轻松，任何事都作一个最好的打算和最坏的打算。\n\n14. 做一个简单的人，踏实而务实。不沉溺幻想。不庸人自扰。\n\n15. 不说谎话，因为总有被拆穿的一天。\n\n16. 别人光鲜的背后或者有着太多不为人知的痛苦\n\n17. 尽量充实自己。不要停止学习。不管学习什么，语言，厨艺，各种技能。\n\n18. 注意自己的修养，你就是孩子的第一位老师。\n\n19. 孝顺父母。不只是嘴上说说，即使多打几个电话也是很好的。\n\n20. 爱父母，因为他们给了你生命，同时也是爱你爱的最无私的人。\n\n21. 偶尔也要现实和虚伪一点，因为不那样做的话，很难混。\n\n22. 收敛自己的脾气，偶尔要刻意沉默，因为冲动会做下让自己无法挽回的事情。\n\n23. 无论什么时候，做什么事情，要思考。\n\n24. 永远不要给背叛过自己的朋友第二次的背叛的机会。\n\n25. 无论是谁，都有自己的限度。特别是信任。\n\n26. 懂得倾听别人的忠告。\n\n27. 别人说的记在脑袋里，而自己的，则放在心里。\n\n28. 尽量不要讲同事朋友的八卦。\n\n29. 信佛，信因果，在真正的因果面前，人的力量是微不足道的。\n\n30. 坦然接受生活给你的馈赠吧，不管是好的还是坏的。\n\n31. 真正了解无常的含义，当你痛苦时，你要想这痛苦不是永恒的，当你快乐时，你要想这快乐也不是永恒的。\n\n32. 要快乐，要开朗，要坚韧，要温暖，对人要真诚。\n\n33. 空虚无聊的时候就读书，但一定得有自己的生活目标和计划。\n\n34. 对人性的弱点有清醒的认识，但要相信真诚的爱情，对爱情永远怀有单纯的向往。\n\n35. 不要太过依赖除自己以外的人，因为只有自己不会抛弃自己。\n\n36. 永远对生活充满希望，对于困境与磨难，微笑面对。\n\n37. 多看书，看好书。\n\n38. 少吃点，吃好的。\n\n39. 古龙说过，爱笑的女孩子，运气不会太差。\n\n40. 多交朋友，交好的朋友。女人一定要有闺密。\n\n41. 请记得，好朋友的定义是：你混的好，她打心眼里为你开心；你混的不好，她由衷的为你着急。\n\n42. 要有梦想，即使遥远。\n\n43. 努力爱一个人。付出，不一定会有收获；不付出，却一定不会有收获，不要奢望出现奇迹。\n\n44. 承诺是一件美好的事情，但美好的东西往往不会变为现实。\n\n45. 每个人都有自己鲜明的主张和个性，不要识途去改变他人，同样，也不要被他人所改变。改了，就不是自己了。\n\n46. 没有十全十美的东西，没有十全十美的人，关键是清楚到底想要什么。得到想要的，肯定会失去另外一部分。如果什么都想要，只会什么都得不到。\n\n47. 这个世界最脆弱的是生命，身体健康，很重要。\n\n48. 老天爷对每个人都是公平的。\n\n49. 不要试图控制别人，不要要求别人理解你\n\n50. 活在当下，别在怀念过去或者憧憬未来中浪费掉你现在的生活\n\n51. 不要忘本，任何时候，任何事情\n\n52. 要诚恳，要坦然，要慷慨，要宽容，要有平常心\n\n53. 学会忘记, 善忘是一件好事\n\n54. 要乐观，要积极，多笑，多照镜子\n\n55. 相信他说的话，但不要当真。\n\n56. 凡事多长心眼。\n\n57. 不要自作聪明。\n\n58. 做自己的决定。然后准备好承担后果。从一开始就提醒自己，世上没有后悔药吃。\n\n59. 自己不喜欢的人，可以报之以沉默微笑；自己喜欢的人，那就随便怎么样了，因为你的喜爱会挡也挡不住地流露出来。\n\n60. 相信因果报应！相信轮回！\n\n61. 要学会忍耐与坚持！\n\n62. 这个世界上没有真正的爱情⋯⋯时间可以冲淡一切\n\n63. 不要做刺猬 能不与人结仇就不与人结仇，谁也不跟谁一辈子，有些事情没必要记在心上\n\n64. 有时要学会听取身边人的意见，更多时候这样才不会让自己受到伤害。\n\n65. 忘记过去才能有新的开始。\n\n66. 这个世界很不公平。\n\n67. 不要太依赖朋友，人性基本都有恶的一面。\n\n68. 爱情很美好，相信爱情。如果连爱情都不相信那人生岂不太苦了？\n\n69. 想得到一样一定会失去另一件东西。\n\n70. 痛苦让人成长，是你进步的一个机会，一个挑战。别害怕痛苦的事情，它有另一面积极的作用。\n\n71. 人就是孤独的，缓解它带来的痛苦的唯一方式就是平静的","slug":"每天读一遍，不就你就会有改变","published":1,"updated":"2019-03-23T10:35:08.376Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1emd004ogyavgj5wg1uv"},{"title":"每个人都背负这一个十字架","originContent":"<!-- more -->\n\n![每个人都背负着一个沉重的十字架](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E9%83%BD%E8%83%8C%E8%B4%9F%E7%9D%80%E5%8D%81%E5%AD%97%E6%9E%B6.jpg)","toc":false,"date":"2017-10-13T07:09:53.000Z","_content":"\n<!-- more -->\n\n![每个人都背负着一个沉重的十字架](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E9%83%BD%E8%83%8C%E8%B4%9F%E7%9D%80%E5%8D%81%E5%AD%97%E6%9E%B6.jpg)","source":"_posts/每个人都背负这一个十字架.md","raw":"---\ntitle: 每个人都背负这一个十字架\ntags:\n  - plan\noriginContent: >-\n  <!-- more -->\n\n\n  ![每个人都背负着一个沉重的十字架](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E9%83%BD%E8%83%8C%E8%B4%9F%E7%9D%80%E5%8D%81%E5%AD%97%E6%9E%B6.jpg)\ncategories:\n  - 生活玩乐\ntoc: false\ndate: 2017-10-13 15:09:53\n---\n\n<!-- more -->\n\n![每个人都背负着一个沉重的十字架](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E6%AF%8F%E4%B8%AA%E4%BA%BA%E9%83%BD%E8%83%8C%E8%B4%9F%E7%9D%80%E5%8D%81%E5%AD%97%E6%9E%B6.jpg)","slug":"每个人都背负这一个十字架","published":1,"updated":"2019-03-23T10:33:29.560Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1emg004sgyavq3qsd5sa"},{"title":"看懂UML类图和时序图","originContent":"这里不会将UML的各种元素都提到，我只想讲讲类图中各个类之间的关系； 能看懂类图中各个类之间的线条、箭头代表什么意思后，也就足够应对 日常的工作和交流； 同时，我们应该能将类图所表达的含义和最终的代码对应起来； 有了这些知识，看后面章节的设计模式结构图就没有什么问题了；\n\n本章所有图形使用Enterprise Architect 9.2来画,所有示例详见根目录下的design_patterns.EAP\n\n## 从一个示例开始\n\n请看以下这个类图，类之间的关系是我们需要关注的：\n\n\n车的类图结构为<<abstract>>，表示车是一个抽象类；\n它有两个继承类：小汽车和自行车；它们之间的关系为实现关系，使用带空心箭头的虚线表示；\n小汽车为与SUV之间也是继承关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示；\n小汽车与发动机之间是组合关系，使用带实心箭头的实线表示；\n学生与班级之间是聚合关系，使用带空心箭头的实线表示；\n学生与身份证之间为关联关系，使用一根实线表示；\n学生上学需要用到自行车，与自行车是一种依赖关系，使用带箭头的虚线表示；\n\n下面我们将介绍这六种关系；\n\n## 类之间的关系\n\n### 泛化关系(generalization)\n\n类的继承结构表现在UML中为：泛化(generalize)与实现(realize)：\n\n继承关系为 is-a的关系；两个对象之间如果可以用 is-a 来表示，就是继承关系：（..是..)\n\neg：自行车是车、猫是动物\n\n泛化关系用一条带空心箭头的直接表示；如下图表示（A继承自B）；\n\neg：汽车在现实中有实现，可用汽车定义具体的对象；汽车与SUV之间为泛化关系；\n\n注：最终代码中，泛化关系表现为继承非抽象类；\n\n### 实现关系(realize)\n\n实现关系用一条带空心箭头的虚线表示；\n\neg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才 可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解）\n\n注：最终代码中，实现关系表现为继承抽象类；\n\n### 聚合关系(aggregation)\n\n聚合关系用一条带空心菱形箭头的直线表示，如下图表示A聚合到B上，或者说B由A组成；\n\n聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义；例如一个部门由多个员工组成；\n\n与组合关系不同的是，整体和部分不是强依赖的，即使整体不存在了，部分仍然存在；例如， 部门撤销了，人员不会消失，他们依然存在；\n\n### 组合关系(composition)\n\n组合关系用一条带实心菱形箭头直线表示，如下图表示A组成B，或者B由A组成；\n\n与聚合关系一样，组合关系同样表示整体由部分构成的语义；比如公司由多个部门组成；\n\n但组合关系是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了；例如， 公司不存在了，部门也将不存在了；\n\n### 关联关系(association)\n\n关联关系是用一条直线表示的；它描述不同类的对象之间的结构关系；它是一种静态关系， 通常与运行状态无关，一般由常识等因素决定的；它一般用来定义对象之间静态的、天然的结构； 所以，关联关系是一种“强关联”的关系；\n\n比如，乘车人和车票之间就是一种关联关系；学生和学校就是一种关联关系；\n\n关联关系默认不强调方向，表示对象间相互知道；如果特别强调方向，如下图，表示A知道B，但 B不知道A；\n\n注：在最终代码中，关联对象通常是以成员变量的形式实现的；\n\n### 依赖关系(dependency)\n\n依赖关系是用一套带箭头的虚线表示的；如下图表示A依赖于B；他描述一个对象在运行期间会用到另一个对象的关系；\n\n与关联关系不同的是，它是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化； 依赖关系也可能发生变化；\n\n显然，依赖也有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生；\n\n注：在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还是“使用”对方的方法和属性；\n\n## 时序图\n\n为了展示对象之间的交互细节，后续对设计模式解析的章节，都会用到时序图；\n\n时序图（Sequence Diagram）是显示对象之间交互的图，这些对象是按时间顺序排列的。时序图中显示的是参与交互的对象及其对象之间消息交互的顺序。\n\n时序图包括的建模元素主要有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等等。\n\n关于时序图，以下这篇文章将概念介绍的比较详细；更多实例应用，参见后续章节模式中的时序图；\n\nhttp://smartlife.blog.51cto.com/1146871/284874","toc":false,"date":"2018-02-02T03:02:11.000Z","_content":"\n这里不会将UML的各种元素都提到，我只想讲讲类图中各个类之间的关系； 能看懂类图中各个类之间的线条、箭头代表什么意思后，也就足够应对 日常的工作和交流； 同时，我们应该能将类图所表达的含义和最终的代码对应起来； 有了这些知识，看后面章节的设计模式结构图就没有什么问题了；\n\n本章所有图形使用Enterprise Architect 9.2来画,所有示例详见根目录下的design_patterns.EAP\n\n## 从一个示例开始\n\n请看以下这个类图，类之间的关系是我们需要关注的：\n\n\n车的类图结构为<<abstract>>，表示车是一个抽象类；\n它有两个继承类：小汽车和自行车；它们之间的关系为实现关系，使用带空心箭头的虚线表示；\n小汽车为与SUV之间也是继承关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示；\n小汽车与发动机之间是组合关系，使用带实心箭头的实线表示；\n学生与班级之间是聚合关系，使用带空心箭头的实线表示；\n学生与身份证之间为关联关系，使用一根实线表示；\n学生上学需要用到自行车，与自行车是一种依赖关系，使用带箭头的虚线表示；\n\n下面我们将介绍这六种关系；\n\n## 类之间的关系\n\n### 泛化关系(generalization)\n\n类的继承结构表现在UML中为：泛化(generalize)与实现(realize)：\n\n继承关系为 is-a的关系；两个对象之间如果可以用 is-a 来表示，就是继承关系：（..是..)\n\neg：自行车是车、猫是动物\n\n泛化关系用一条带空心箭头的直接表示；如下图表示（A继承自B）；\n\neg：汽车在现实中有实现，可用汽车定义具体的对象；汽车与SUV之间为泛化关系；\n\n注：最终代码中，泛化关系表现为继承非抽象类；\n\n### 实现关系(realize)\n\n实现关系用一条带空心箭头的虚线表示；\n\neg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才 可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解）\n\n注：最终代码中，实现关系表现为继承抽象类；\n\n### 聚合关系(aggregation)\n\n聚合关系用一条带空心菱形箭头的直线表示，如下图表示A聚合到B上，或者说B由A组成；\n\n聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义；例如一个部门由多个员工组成；\n\n与组合关系不同的是，整体和部分不是强依赖的，即使整体不存在了，部分仍然存在；例如， 部门撤销了，人员不会消失，他们依然存在；\n\n### 组合关系(composition)\n\n组合关系用一条带实心菱形箭头直线表示，如下图表示A组成B，或者B由A组成；\n\n与聚合关系一样，组合关系同样表示整体由部分构成的语义；比如公司由多个部门组成；\n\n但组合关系是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了；例如， 公司不存在了，部门也将不存在了；\n\n### 关联关系(association)\n\n关联关系是用一条直线表示的；它描述不同类的对象之间的结构关系；它是一种静态关系， 通常与运行状态无关，一般由常识等因素决定的；它一般用来定义对象之间静态的、天然的结构； 所以，关联关系是一种“强关联”的关系；\n\n比如，乘车人和车票之间就是一种关联关系；学生和学校就是一种关联关系；\n\n关联关系默认不强调方向，表示对象间相互知道；如果特别强调方向，如下图，表示A知道B，但 B不知道A；\n\n注：在最终代码中，关联对象通常是以成员变量的形式实现的；\n\n### 依赖关系(dependency)\n\n依赖关系是用一套带箭头的虚线表示的；如下图表示A依赖于B；他描述一个对象在运行期间会用到另一个对象的关系；\n\n与关联关系不同的是，它是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化； 依赖关系也可能发生变化；\n\n显然，依赖也有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生；\n\n注：在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还是“使用”对方的方法和属性；\n\n## 时序图\n\n为了展示对象之间的交互细节，后续对设计模式解析的章节，都会用到时序图；\n\n时序图（Sequence Diagram）是显示对象之间交互的图，这些对象是按时间顺序排列的。时序图中显示的是参与交互的对象及其对象之间消息交互的顺序。\n\n时序图包括的建模元素主要有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等等。\n\n关于时序图，以下这篇文章将概念介绍的比较详细；更多实例应用，参见后续章节模式中的时序图；\n\nhttp://smartlife.blog.51cto.com/1146871/284874","source":"_posts/看懂UML类图和时序图.md","raw":"---\ntitle: 看懂UML类图和时序图\ntags:\n  - UML\noriginContent: >-\n  这里不会将UML的各种元素都提到，我只想讲讲类图中各个类之间的关系； 能看懂类图中各个类之间的线条、箭头代表什么意思后，也就足够应对 日常的工作和交流；\n  同时，我们应该能将类图所表达的含义和最终的代码对应起来； 有了这些知识，看后面章节的设计模式结构图就没有什么问题了；\n\n\n  本章所有图形使用Enterprise Architect 9.2来画,所有示例详见根目录下的design_patterns.EAP\n\n\n  ## 从一个示例开始\n\n\n  请看以下这个类图，类之间的关系是我们需要关注的：\n\n\n\n  车的类图结构为<<abstract>>，表示车是一个抽象类；\n\n  它有两个继承类：小汽车和自行车；它们之间的关系为实现关系，使用带空心箭头的虚线表示；\n\n  小汽车为与SUV之间也是继承关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示；\n\n  小汽车与发动机之间是组合关系，使用带实心箭头的实线表示；\n\n  学生与班级之间是聚合关系，使用带空心箭头的实线表示；\n\n  学生与身份证之间为关联关系，使用一根实线表示；\n\n  学生上学需要用到自行车，与自行车是一种依赖关系，使用带箭头的虚线表示；\n\n\n  下面我们将介绍这六种关系；\n\n\n  ## 类之间的关系\n\n\n  ### 泛化关系(generalization)\n\n\n  类的继承结构表现在UML中为：泛化(generalize)与实现(realize)：\n\n\n  继承关系为 is-a的关系；两个对象之间如果可以用 is-a 来表示，就是继承关系：（..是..)\n\n\n  eg：自行车是车、猫是动物\n\n\n  泛化关系用一条带空心箭头的直接表示；如下图表示（A继承自B）；\n\n\n  eg：汽车在现实中有实现，可用汽车定义具体的对象；汽车与SUV之间为泛化关系；\n\n\n  注：最终代码中，泛化关系表现为继承非抽象类；\n\n\n  ### 实现关系(realize)\n\n\n  实现关系用一条带空心箭头的虚线表示；\n\n\n  eg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才\n  可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解）\n\n\n  注：最终代码中，实现关系表现为继承抽象类；\n\n\n  ### 聚合关系(aggregation)\n\n\n  聚合关系用一条带空心菱形箭头的直线表示，如下图表示A聚合到B上，或者说B由A组成；\n\n\n  聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义；例如一个部门由多个员工组成；\n\n\n  与组合关系不同的是，整体和部分不是强依赖的，即使整体不存在了，部分仍然存在；例如， 部门撤销了，人员不会消失，他们依然存在；\n\n\n  ### 组合关系(composition)\n\n\n  组合关系用一条带实心菱形箭头直线表示，如下图表示A组成B，或者B由A组成；\n\n\n  与聚合关系一样，组合关系同样表示整体由部分构成的语义；比如公司由多个部门组成；\n\n\n  但组合关系是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了；例如， 公司不存在了，部门也将不存在了；\n\n\n  ### 关联关系(association)\n\n\n  关联关系是用一条直线表示的；它描述不同类的对象之间的结构关系；它是一种静态关系，\n  通常与运行状态无关，一般由常识等因素决定的；它一般用来定义对象之间静态的、天然的结构； 所以，关联关系是一种“强关联”的关系；\n\n\n  比如，乘车人和车票之间就是一种关联关系；学生和学校就是一种关联关系；\n\n\n  关联关系默认不强调方向，表示对象间相互知道；如果特别强调方向，如下图，表示A知道B，但 B不知道A；\n\n\n  注：在最终代码中，关联对象通常是以成员变量的形式实现的；\n\n\n  ### 依赖关系(dependency)\n\n\n  依赖关系是用一套带箭头的虚线表示的；如下图表示A依赖于B；他描述一个对象在运行期间会用到另一个对象的关系；\n\n\n  与关联关系不同的是，它是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化； 依赖关系也可能发生变化；\n\n\n  显然，依赖也有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生；\n\n\n  注：在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还是“使用”对方的方法和属性；\n\n\n  ## 时序图\n\n\n  为了展示对象之间的交互细节，后续对设计模式解析的章节，都会用到时序图；\n\n\n  时序图（Sequence Diagram）是显示对象之间交互的图，这些对象是按时间顺序排列的。时序图中显示的是参与交互的对象及其对象之间消息交互的顺序。\n\n\n  时序图包括的建模元素主要有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等等。\n\n\n  关于时序图，以下这篇文章将概念介绍的比较详细；更多实例应用，参见后续章节模式中的时序图；\n\n\n  http://smartlife.blog.51cto.com/1146871/284874\ncategories:\n  - 项目总结\ntoc: false\ndate: 2018-02-02 11:02:11\n---\n\n这里不会将UML的各种元素都提到，我只想讲讲类图中各个类之间的关系； 能看懂类图中各个类之间的线条、箭头代表什么意思后，也就足够应对 日常的工作和交流； 同时，我们应该能将类图所表达的含义和最终的代码对应起来； 有了这些知识，看后面章节的设计模式结构图就没有什么问题了；\n\n本章所有图形使用Enterprise Architect 9.2来画,所有示例详见根目录下的design_patterns.EAP\n\n## 从一个示例开始\n\n请看以下这个类图，类之间的关系是我们需要关注的：\n\n\n车的类图结构为<<abstract>>，表示车是一个抽象类；\n它有两个继承类：小汽车和自行车；它们之间的关系为实现关系，使用带空心箭头的虚线表示；\n小汽车为与SUV之间也是继承关系，它们之间的关系为泛化关系，使用带空心箭头的实线表示；\n小汽车与发动机之间是组合关系，使用带实心箭头的实线表示；\n学生与班级之间是聚合关系，使用带空心箭头的实线表示；\n学生与身份证之间为关联关系，使用一根实线表示；\n学生上学需要用到自行车，与自行车是一种依赖关系，使用带箭头的虚线表示；\n\n下面我们将介绍这六种关系；\n\n## 类之间的关系\n\n### 泛化关系(generalization)\n\n类的继承结构表现在UML中为：泛化(generalize)与实现(realize)：\n\n继承关系为 is-a的关系；两个对象之间如果可以用 is-a 来表示，就是继承关系：（..是..)\n\neg：自行车是车、猫是动物\n\n泛化关系用一条带空心箭头的直接表示；如下图表示（A继承自B）；\n\neg：汽车在现实中有实现，可用汽车定义具体的对象；汽车与SUV之间为泛化关系；\n\n注：最终代码中，泛化关系表现为继承非抽象类；\n\n### 实现关系(realize)\n\n实现关系用一条带空心箭头的虚线表示；\n\neg：”车”为一个抽象概念，在现实中并无法直接用来定义对象；只有指明具体的子类(汽车还是自行车)，才 可以用来定义对象（”车”这个类在C++中用抽象类表示，在JAVA中有接口这个概念，更容易理解）\n\n注：最终代码中，实现关系表现为继承抽象类；\n\n### 聚合关系(aggregation)\n\n聚合关系用一条带空心菱形箭头的直线表示，如下图表示A聚合到B上，或者说B由A组成；\n\n聚合关系用于表示实体对象之间的关系，表示整体由部分构成的语义；例如一个部门由多个员工组成；\n\n与组合关系不同的是，整体和部分不是强依赖的，即使整体不存在了，部分仍然存在；例如， 部门撤销了，人员不会消失，他们依然存在；\n\n### 组合关系(composition)\n\n组合关系用一条带实心菱形箭头直线表示，如下图表示A组成B，或者B由A组成；\n\n与聚合关系一样，组合关系同样表示整体由部分构成的语义；比如公司由多个部门组成；\n\n但组合关系是一种强依赖的特殊聚合关系，如果整体不存在了，则部分也不存在了；例如， 公司不存在了，部门也将不存在了；\n\n### 关联关系(association)\n\n关联关系是用一条直线表示的；它描述不同类的对象之间的结构关系；它是一种静态关系， 通常与运行状态无关，一般由常识等因素决定的；它一般用来定义对象之间静态的、天然的结构； 所以，关联关系是一种“强关联”的关系；\n\n比如，乘车人和车票之间就是一种关联关系；学生和学校就是一种关联关系；\n\n关联关系默认不强调方向，表示对象间相互知道；如果特别强调方向，如下图，表示A知道B，但 B不知道A；\n\n注：在最终代码中，关联对象通常是以成员变量的形式实现的；\n\n### 依赖关系(dependency)\n\n依赖关系是用一套带箭头的虚线表示的；如下图表示A依赖于B；他描述一个对象在运行期间会用到另一个对象的关系；\n\n与关联关系不同的是，它是一种临时性的关系，通常在运行期间产生，并且随着运行时的变化； 依赖关系也可能发生变化；\n\n显然，依赖也有方向，双向依赖是一种非常糟糕的结构，我们总是应该保持单向依赖，杜绝双向依赖的产生；\n\n注：在最终代码中，依赖关系体现为类构造方法及类方法的传入参数，箭头的指向为调用关系；依赖关系除了临时知道对方外，还是“使用”对方的方法和属性；\n\n## 时序图\n\n为了展示对象之间的交互细节，后续对设计模式解析的章节，都会用到时序图；\n\n时序图（Sequence Diagram）是显示对象之间交互的图，这些对象是按时间顺序排列的。时序图中显示的是参与交互的对象及其对象之间消息交互的顺序。\n\n时序图包括的建模元素主要有：对象（Actor）、生命线（Lifeline）、控制焦点（Focus of control）、消息（Message）等等。\n\n关于时序图，以下这篇文章将概念介绍的比较详细；更多实例应用，参见后续章节模式中的时序图；\n\nhttp://smartlife.blog.51cto.com/1146871/284874","slug":"看懂UML类图和时序图","published":1,"updated":"2019-03-23T10:22:42.515Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1emj004wgyav8dfxmcmn"},{"title":"使用js判断浏览器","originContent":"直接看代码：\n\n```\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n<script >\n    var userAgent = navigator.userAgent;\n    var isOpera = userAgent.indexOf(\"Opera\") > -1;\n    var isMaxthon = userAgent.indexOf(\"Maxthon\") > -1 ;\n    var isIE = userAgent.indexOf(\"compatible\") > -1 && userAgent.indexOf(\"MSIE\") > -1 && !isOpera ;\n    var isFF = userAgent.indexOf(\"Firefox\") > -1 ;\n    var isSafari = userAgent.indexOf(\"Safari\") > -1 && userAgent.indexOf(\"Chrome\") < 1 ;\n    var isChrome = userAgent.indexOf(\"Chrome\") > -1 ;\n    var isIE5 = isIE55 = isIE6 = isIE7 = isIE8 = false;\n\n    if(isFF){document.write(\"当前浏览器是  Firefox\");}\n    if(isMaxthon){document.write(\"当前浏览器是 傲游(webkit核心)\");}\n    if(isOpera){document.write(\"当前浏览器是  Opera\");}\n    if(isSafari){document.write(\"当前浏览器是  Safari\");}\n    if(isChrome){document.write(\"当前浏览器是  Chrome\");}\n    if(isIE){document.write(\"当前浏览器是  IE\");}\n</script>\n```","toc":false,"date":"2018-06-08T12:54:00.000Z","_content":"\n直接看代码：\n\n```\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n<script >\n    var userAgent = navigator.userAgent;\n    var isOpera = userAgent.indexOf(\"Opera\") > -1;\n    var isMaxthon = userAgent.indexOf(\"Maxthon\") > -1 ;\n    var isIE = userAgent.indexOf(\"compatible\") > -1 && userAgent.indexOf(\"MSIE\") > -1 && !isOpera ;\n    var isFF = userAgent.indexOf(\"Firefox\") > -1 ;\n    var isSafari = userAgent.indexOf(\"Safari\") > -1 && userAgent.indexOf(\"Chrome\") < 1 ;\n    var isChrome = userAgent.indexOf(\"Chrome\") > -1 ;\n    var isIE5 = isIE55 = isIE6 = isIE7 = isIE8 = false;\n\n    if(isFF){document.write(\"当前浏览器是  Firefox\");}\n    if(isMaxthon){document.write(\"当前浏览器是 傲游(webkit核心)\");}\n    if(isOpera){document.write(\"当前浏览器是  Opera\");}\n    if(isSafari){document.write(\"当前浏览器是  Safari\");}\n    if(isChrome){document.write(\"当前浏览器是  Chrome\");}\n    if(isIE){document.write(\"当前浏览器是  IE\");}\n</script>\n```","source":"_posts/使用js判断浏览器.md","raw":"---\ntitle: 使用js判断浏览器\ntags:\n  - javascript\noriginContent: |-\n  直接看代码：\n\n  ```\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n  <script >\n      var userAgent = navigator.userAgent;\n      var isOpera = userAgent.indexOf(\"Opera\") > -1;\n      var isMaxthon = userAgent.indexOf(\"Maxthon\") > -1 ;\n      var isIE = userAgent.indexOf(\"compatible\") > -1 && userAgent.indexOf(\"MSIE\") > -1 && !isOpera ;\n      var isFF = userAgent.indexOf(\"Firefox\") > -1 ;\n      var isSafari = userAgent.indexOf(\"Safari\") > -1 && userAgent.indexOf(\"Chrome\") < 1 ;\n      var isChrome = userAgent.indexOf(\"Chrome\") > -1 ;\n      var isIE5 = isIE55 = isIE6 = isIE7 = isIE8 = false;\n\n      if(isFF){document.write(\"当前浏览器是  Firefox\");}\n      if(isMaxthon){document.write(\"当前浏览器是 傲游(webkit核心)\");}\n      if(isOpera){document.write(\"当前浏览器是  Opera\");}\n      if(isSafari){document.write(\"当前浏览器是  Safari\");}\n      if(isChrome){document.write(\"当前浏览器是  Chrome\");}\n      if(isIE){document.write(\"当前浏览器是  IE\");}\n  </script>\n  ```\ncategories:\n  - Web开发\ntoc: false\ndate: 2018-06-08 20:54:00\n---\n\n直接看代码：\n\n```\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n<script >\n    var userAgent = navigator.userAgent;\n    var isOpera = userAgent.indexOf(\"Opera\") > -1;\n    var isMaxthon = userAgent.indexOf(\"Maxthon\") > -1 ;\n    var isIE = userAgent.indexOf(\"compatible\") > -1 && userAgent.indexOf(\"MSIE\") > -1 && !isOpera ;\n    var isFF = userAgent.indexOf(\"Firefox\") > -1 ;\n    var isSafari = userAgent.indexOf(\"Safari\") > -1 && userAgent.indexOf(\"Chrome\") < 1 ;\n    var isChrome = userAgent.indexOf(\"Chrome\") > -1 ;\n    var isIE5 = isIE55 = isIE6 = isIE7 = isIE8 = false;\n\n    if(isFF){document.write(\"当前浏览器是  Firefox\");}\n    if(isMaxthon){document.write(\"当前浏览器是 傲游(webkit核心)\");}\n    if(isOpera){document.write(\"当前浏览器是  Opera\");}\n    if(isSafari){document.write(\"当前浏览器是  Safari\");}\n    if(isChrome){document.write(\"当前浏览器是  Chrome\");}\n    if(isIE){document.write(\"当前浏览器是  IE\");}\n</script>\n```","slug":"使用js判断浏览器","published":1,"updated":"2019-03-23T10:13:43.656Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1emm004zgyavpp15nf0z"},{"title":"留不住的心就让他飞吧","originContent":"图片是很久以前存下来的了，看到后放到日志里边\n\n<!-- more -->\n\n![留不住的心就让它飞吧](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E7%95%99%E4%B8%8D%E4%BD%8F%E7%9A%84%E5%BF%83%E5%B0%B1%E8%AE%A9%E4%BB%96%E9%A3%9E%E5%90%A7.gif)","toc":false,"date":"2017-10-13T06:22:34.000Z","_content":"\n图片是很久以前存下来的了，看到后放到日志里边\n\n<!-- more -->\n\n![留不住的心就让它飞吧](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E7%95%99%E4%B8%8D%E4%BD%8F%E7%9A%84%E5%BF%83%E5%B0%B1%E8%AE%A9%E4%BB%96%E9%A3%9E%E5%90%A7.gif)","source":"_posts/留不住的心就让他飞吧.md","raw":"---\ntitle: 留不住的心就让他飞吧\ntags:\n  - plan\noriginContent: >-\n  图片是很久以前存下来的了，看到后放到日志里边\n\n\n  <!-- more -->\n\n\n  ![留不住的心就让它飞吧](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E7%95%99%E4%B8%8D%E4%BD%8F%E7%9A%84%E5%BF%83%E5%B0%B1%E8%AE%A9%E4%BB%96%E9%A3%9E%E5%90%A7.gif)\ncategories:\n  - 生活玩乐\ntoc: false\ndate: 2017-10-13 14:22:34\n---\n\n图片是很久以前存下来的了，看到后放到日志里边\n\n<!-- more -->\n\n![留不住的心就让它飞吧](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E7%95%99%E4%B8%8D%E4%BD%8F%E7%9A%84%E5%BF%83%E5%B0%B1%E8%AE%A9%E4%BB%96%E9%A3%9E%E5%90%A7.gif)","slug":"留不住的心就让他飞吧","published":1,"updated":"2019-03-23T10:34:46.183Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ems0053gyavjjlf0f2y"},{"title":"移动端开发调试工具神器--Weinre使用方法","originContent":"前端开发调试必备：\n\n1. DOM操作断点调试；\n2. debugger断点调试；\n3. native方法hook（个人暂时还没有试过，不知效果如何）；\n4. 远程映射本地测试；\n5. Weinre移动调试（详细介绍）；\n\n像Dom断点调试和debugger断点调试我认为是大家经常用到的方法，或者是当前比较火狐下比较流行的Fiexbug调试工具；今天我们主要是研究Weinre调试工具的；\n\n当然，作为前端开发人员，令人比较乏味的即使手机端各个版本的支持程度，例如就拿iphone来说，虽然都是-webkit内核，如果你添加的动画，如-webkit-translate.......当然考虑到兼容性问题，你会带上前缀-webkit，但你本想手机端大多是支持HTML5和css3的，所以就试下了不带前缀-webkit，结果，呵呵，那么问题来了，iphone5s以下会有问题，以上就没有问题，所以你懂得，最好加上前缀-webkit，不过像最近比较新的版本的Andirod对CSS3的属性支持度还是不错的；\n\n接下来，我们介绍下重点：\n\n安装weinre\n\nweinre可以通过npm按照（个人也是比较推荐的）\n\n```\nnpm install -g weinre  (按照完成后，可以在cmd上，查看下版本号，看是否按照成功)\n```\n\n按照之后，可以执行下面的命令来启动：\n\n```\nweinre --httpPort 8080 --boundHost -all-\n```\n\nok!如果没有什么问题的话，我们打开谷歌浏览器（-webkit内核）输入：http://127.0.0.1:8080/   会看到以下界面\n\n以上这个便是庐山正面目了，上图的“debug client user interface”是weinre的Debug客户端，点击进入后看到目前还没有被测试的网页：\n\nTargets显示的none\n\nOK!那么我们继续，添加Debug Target\n\n有两种方式：\n\n1. Target Script（需要向页面中添加一个js）：\n\n```\n<script src=\"http://192.168.1.69:8080/target/target-script-min.js#anonymous\" type=\"text/javascript\"></script>\n```\n\n注意：标红的部分是你自己的IP地址和端口号，自己适配去调；\n\n2. 我们也可以将一段js保存到移动设备的书签中\njavascript:(function(e){e.setAttribute(\"src\",\"http://127.0.0.1:8080/target/target-script-min.js#anonymous\");document.getElementsByTagName(\"body\")[0].appendChild(e);})(document.createElement(\"script\"));void(0);\n\n\n最后：手机测试：\n1. 手机连接Wifi,必须和电脑在同一段网络，我用的是XAMPP模拟服务器，大家可以上网查用法，然后用自己的手机测试你要测试的网页即可；\n现在回到电脑端  http://127.0.0.1:8080    点击“debug client user interface:”  如果没有问题的话，就已经成功添加了Debug Target:\n\n提示：注意手机不要锁屏，不然调试会断开！\n\n2. 调试开始：\n\n自己可以查查各个组件！","toc":false,"date":"2018-04-17T06:06:56.000Z","_content":"\n前端开发调试必备：\n\n1. DOM操作断点调试；\n2. debugger断点调试；\n3. native方法hook（个人暂时还没有试过，不知效果如何）；\n4. 远程映射本地测试；\n5. Weinre移动调试（详细介绍）；\n\n像Dom断点调试和debugger断点调试我认为是大家经常用到的方法，或者是当前比较火狐下比较流行的Fiexbug调试工具；今天我们主要是研究Weinre调试工具的；\n\n当然，作为前端开发人员，令人比较乏味的即使手机端各个版本的支持程度，例如就拿iphone来说，虽然都是-webkit内核，如果你添加的动画，如-webkit-translate.......当然考虑到兼容性问题，你会带上前缀-webkit，但你本想手机端大多是支持HTML5和css3的，所以就试下了不带前缀-webkit，结果，呵呵，那么问题来了，iphone5s以下会有问题，以上就没有问题，所以你懂得，最好加上前缀-webkit，不过像最近比较新的版本的Andirod对CSS3的属性支持度还是不错的；\n\n接下来，我们介绍下重点：\n\n安装weinre\n\nweinre可以通过npm按照（个人也是比较推荐的）\n\n```\nnpm install -g weinre  (按照完成后，可以在cmd上，查看下版本号，看是否按照成功)\n```\n\n按照之后，可以执行下面的命令来启动：\n\n```\nweinre --httpPort 8080 --boundHost -all-\n```\n\nok!如果没有什么问题的话，我们打开谷歌浏览器（-webkit内核）输入：http://127.0.0.1:8080/   会看到以下界面\n\n以上这个便是庐山正面目了，上图的“debug client user interface”是weinre的Debug客户端，点击进入后看到目前还没有被测试的网页：\n\nTargets显示的none\n\nOK!那么我们继续，添加Debug Target\n\n有两种方式：\n\n1. Target Script（需要向页面中添加一个js）：\n\n```\n<script src=\"http://192.168.1.69:8080/target/target-script-min.js#anonymous\" type=\"text/javascript\"></script>\n```\n\n注意：标红的部分是你自己的IP地址和端口号，自己适配去调；\n\n2. 我们也可以将一段js保存到移动设备的书签中\njavascript:(function(e){e.setAttribute(\"src\",\"http://127.0.0.1:8080/target/target-script-min.js#anonymous\");document.getElementsByTagName(\"body\")[0].appendChild(e);})(document.createElement(\"script\"));void(0);\n\n\n最后：手机测试：\n1. 手机连接Wifi,必须和电脑在同一段网络，我用的是XAMPP模拟服务器，大家可以上网查用法，然后用自己的手机测试你要测试的网页即可；\n现在回到电脑端  http://127.0.0.1:8080    点击“debug client user interface:”  如果没有问题的话，就已经成功添加了Debug Target:\n\n提示：注意手机不要锁屏，不然调试会断开！\n\n2. 调试开始：\n\n自己可以查查各个组件！","source":"_posts/移动端开发调试工具神器-Weinre使用方法.md","raw":"---\ntitle: 移动端开发调试工具神器--Weinre使用方法\ntags:\n  - 开发调试\noriginContent: >-\n  前端开发调试必备：\n\n\n  1. DOM操作断点调试；\n\n  2. debugger断点调试；\n\n  3. native方法hook（个人暂时还没有试过，不知效果如何）；\n\n  4. 远程映射本地测试；\n\n  5. Weinre移动调试（详细介绍）；\n\n\n  像Dom断点调试和debugger断点调试我认为是大家经常用到的方法，或者是当前比较火狐下比较流行的Fiexbug调试工具；今天我们主要是研究Weinre调试工具的；\n\n\n  当然，作为前端开发人员，令人比较乏味的即使手机端各个版本的支持程度，例如就拿iphone来说，虽然都是-webkit内核，如果你添加的动画，如-webkit-translate.......当然考虑到兼容性问题，你会带上前缀-webkit，但你本想手机端大多是支持HTML5和css3的，所以就试下了不带前缀-webkit，结果，呵呵，那么问题来了，iphone5s以下会有问题，以上就没有问题，所以你懂得，最好加上前缀-webkit，不过像最近比较新的版本的Andirod对CSS3的属性支持度还是不错的；\n\n\n  接下来，我们介绍下重点：\n\n\n  安装weinre\n\n\n  weinre可以通过npm按照（个人也是比较推荐的）\n\n\n  ```\n\n  npm install -g weinre  (按照完成后，可以在cmd上，查看下版本号，看是否按照成功)\n\n  ```\n\n\n  按照之后，可以执行下面的命令来启动：\n\n\n  ```\n\n  weinre --httpPort 8080 --boundHost -all-\n\n  ```\n\n\n  ok!如果没有什么问题的话，我们打开谷歌浏览器（-webkit内核）输入：http://127.0.0.1:8080/   会看到以下界面\n\n\n  以上这个便是庐山正面目了，上图的“debug client user\n  interface”是weinre的Debug客户端，点击进入后看到目前还没有被测试的网页：\n\n\n  Targets显示的none\n\n\n  OK!那么我们继续，添加Debug Target\n\n\n  有两种方式：\n\n\n  1. Target Script（需要向页面中添加一个js）：\n\n\n  ```\n\n  <script src=\"http://192.168.1.69:8080/target/target-script-min.js#anonymous\"\n  type=\"text/javascript\"></script>\n\n  ```\n\n\n  注意：标红的部分是你自己的IP地址和端口号，自己适配去调；\n\n\n  2. 我们也可以将一段js保存到移动设备的书签中\n\n  javascript:(function(e){e.setAttribute(\"src\",\"http://127.0.0.1:8080/target/target-script-min.js#anonymous\");document.getElementsByTagName(\"body\")[0].appendChild(e);})(document.createElement(\"script\"));void(0);\n\n\n\n  最后：手机测试：\n\n  1. 手机连接Wifi,必须和电脑在同一段网络，我用的是XAMPP模拟服务器，大家可以上网查用法，然后用自己的手机测试你要测试的网页即可；\n\n  现在回到电脑端  http://127.0.0.1:8080    点击“debug client user interface:” \n  如果没有问题的话，就已经成功添加了Debug Target:\n\n\n  提示：注意手机不要锁屏，不然调试会断开！\n\n\n  2. 调试开始：\n\n\n  自己可以查查各个组件！\ncategories:\n  - H5开发\ntoc: false\ndate: 2018-04-17 14:06:56\n---\n\n前端开发调试必备：\n\n1. DOM操作断点调试；\n2. debugger断点调试；\n3. native方法hook（个人暂时还没有试过，不知效果如何）；\n4. 远程映射本地测试；\n5. Weinre移动调试（详细介绍）；\n\n像Dom断点调试和debugger断点调试我认为是大家经常用到的方法，或者是当前比较火狐下比较流行的Fiexbug调试工具；今天我们主要是研究Weinre调试工具的；\n\n当然，作为前端开发人员，令人比较乏味的即使手机端各个版本的支持程度，例如就拿iphone来说，虽然都是-webkit内核，如果你添加的动画，如-webkit-translate.......当然考虑到兼容性问题，你会带上前缀-webkit，但你本想手机端大多是支持HTML5和css3的，所以就试下了不带前缀-webkit，结果，呵呵，那么问题来了，iphone5s以下会有问题，以上就没有问题，所以你懂得，最好加上前缀-webkit，不过像最近比较新的版本的Andirod对CSS3的属性支持度还是不错的；\n\n接下来，我们介绍下重点：\n\n安装weinre\n\nweinre可以通过npm按照（个人也是比较推荐的）\n\n```\nnpm install -g weinre  (按照完成后，可以在cmd上，查看下版本号，看是否按照成功)\n```\n\n按照之后，可以执行下面的命令来启动：\n\n```\nweinre --httpPort 8080 --boundHost -all-\n```\n\nok!如果没有什么问题的话，我们打开谷歌浏览器（-webkit内核）输入：http://127.0.0.1:8080/   会看到以下界面\n\n以上这个便是庐山正面目了，上图的“debug client user interface”是weinre的Debug客户端，点击进入后看到目前还没有被测试的网页：\n\nTargets显示的none\n\nOK!那么我们继续，添加Debug Target\n\n有两种方式：\n\n1. Target Script（需要向页面中添加一个js）：\n\n```\n<script src=\"http://192.168.1.69:8080/target/target-script-min.js#anonymous\" type=\"text/javascript\"></script>\n```\n\n注意：标红的部分是你自己的IP地址和端口号，自己适配去调；\n\n2. 我们也可以将一段js保存到移动设备的书签中\njavascript:(function(e){e.setAttribute(\"src\",\"http://127.0.0.1:8080/target/target-script-min.js#anonymous\");document.getElementsByTagName(\"body\")[0].appendChild(e);})(document.createElement(\"script\"));void(0);\n\n\n最后：手机测试：\n1. 手机连接Wifi,必须和电脑在同一段网络，我用的是XAMPP模拟服务器，大家可以上网查用法，然后用自己的手机测试你要测试的网页即可；\n现在回到电脑端  http://127.0.0.1:8080    点击“debug client user interface:”  如果没有问题的话，就已经成功添加了Debug Target:\n\n提示：注意手机不要锁屏，不然调试会断开！\n\n2. 调试开始：\n\n自己可以查查各个组件！","slug":"移动端开发调试工具神器-Weinre使用方法","published":1,"updated":"2019-03-23T10:17:32.093Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1emw0057gyavi53xxh74"},{"title":"欢迎使用pomelo","originContent":"pomelo是一个游戏服务器框架，与以往单进程的游戏框架不同, 它是**高性能、高可伸缩、分布式多进程**的游戏服务器框架，并且使用很简单。它包括基础开发框架和一系列相关工具和库，可以帮助开发者省去游戏开发中枯燥的重复劳动和底层逻辑工作，免除开发者的重造轮子，让开发者可以更多地去关注游戏的具体逻辑，大大提高开发效率。pomelo强大的可伸缩性和灵活性使得pomelo也**可以作为通用的分布式实时应用开发框架**，用于一些高实时应用的开发，而且pomelo在很多方面的表现甚至超越了现有的开源实时应用框架。**pomelo支持所有主流平台的客户端**，并提供了客户端的开发库，使得客户端的开发变得很友好。\n\n<!-- more -->\n\n## pomelo组成\npomelo 是由一系列相互之间弱耦合的部分**组合而成**的，包括：\n\n### 框架\n**框架是pomelo最核心的部分;**\n\n### 库\npomelo提供了很多库，有些是跟游戏逻辑完全相关的，如**AI**，**AOI**，**寻路**等；也有与游戏逻辑无关但比较通用的，如**定时任务**执行， **数据同步**等等；\n\n### 工具\npomelo提供了**服务器管理控制工具**、**命令行工具**、**压力测试工具**等一系列工具；\n\n### 客户端库\npomelo提供了**各类平台的客户端开发库**，包括js, C, C#，Android, iOS, Unity3D等等，几乎支持涵盖了目前所有的主流平台，由于**pomelo的协议是开放**的，架构耦合松散，对于没有支持的客户端平台，用户也可以**很容易地开发出自己需要的库，定制自己的通信协议**；\n\n### demo\n一个框架需要强大的demo来展示功能并为开发者提供示例，pomelo提供了全平台的聊天demo和基于HTML5的捡宝demo，系统还提供了一个强大的基于HTML5开发的MMO游戏demo [Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】。\n\n## 为什么使用pomelo？\n高并发、高实时的游戏服务器的开发是很复杂的工作。跟web应用一样，一个好的开源容器或开发框架可以大大减少游戏服务器开发的复杂性，让开发变得更加容易。遗憾的是目前在游戏服务器开发领域一直没有太好的开源解决方案。pomelo将填补这个空白，打造一款**完全开源的高性能高并发游戏服务器框架**。pomelo的优势有以下几点：\n\n### 架构的可伸缩性好\n采用**多进程单线程的运行架构**，扩展服务器非常方便，node.js的网络io优势提供了高可伸缩性，写好的应用只需要简单地修改一下配置就能轻松地伸缩扩充；\n\n### 易用\npomelo基于轻量级的nodejs，其开发模型与web应用的开发类似，基于**convention over configuration(约定优于配置)**的理念，几乎零配置，api的设计也很精简，很容易上手，开发快速；\n\n### 框架的松耦合和可扩展性好\n遵循node.js微模块的原则，框架本身只有很少的代码，**所有component、库、工具都可以用npm module的形式扩展进来**，任何第三方都可以根据自己的需要开发自定义module，并把它整合到pomelo的框架中。\n\n### 完整的demo和文档\npomelo提供了完整的中英文文档，pomelo还提供一个完整的开源MMO游戏demo--[Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】，一个超过1万行代码的游戏demo，使开发者可以随时借鉴demo的设计与开发思路。\n\n## pomelo的定位\npomelo是一个轻量级的服务器框架，它最适合的应用领域是网页游戏、社交游戏、移动游戏的服务端，开发者会发现pomelo可以用如此少的代码达到强大的扩展性和伸缩性。当然还不仅仅是游戏，用pomelo开发高实时web应用也如此合适， 而且伸缩性比其它框架好。\n\n不推荐将pomelo用于大型的MMORPG（Multiplayer Online Role-PlayingGame）（大型多人在线角色扮演游戏）游戏开发，尤其是大型3D游戏， 还是需要象**Bigworld**这样的商用引擎来支撑。\n\n好了，是不是有迫不及待了，那就赶快安装pomelo来试试吧。\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8pomelo)","toc":false,"date":"2018-02-28T03:32:28.000Z","_content":"\npomelo是一个游戏服务器框架，与以往单进程的游戏框架不同, 它是**高性能、高可伸缩、分布式多进程**的游戏服务器框架，并且使用很简单。它包括基础开发框架和一系列相关工具和库，可以帮助开发者省去游戏开发中枯燥的重复劳动和底层逻辑工作，免除开发者的重造轮子，让开发者可以更多地去关注游戏的具体逻辑，大大提高开发效率。pomelo强大的可伸缩性和灵活性使得pomelo也**可以作为通用的分布式实时应用开发框架**，用于一些高实时应用的开发，而且pomelo在很多方面的表现甚至超越了现有的开源实时应用框架。**pomelo支持所有主流平台的客户端**，并提供了客户端的开发库，使得客户端的开发变得很友好。\n\n<!-- more -->\n\n## pomelo组成\npomelo 是由一系列相互之间弱耦合的部分**组合而成**的，包括：\n\n### 框架\n**框架是pomelo最核心的部分;**\n\n### 库\npomelo提供了很多库，有些是跟游戏逻辑完全相关的，如**AI**，**AOI**，**寻路**等；也有与游戏逻辑无关但比较通用的，如**定时任务**执行， **数据同步**等等；\n\n### 工具\npomelo提供了**服务器管理控制工具**、**命令行工具**、**压力测试工具**等一系列工具；\n\n### 客户端库\npomelo提供了**各类平台的客户端开发库**，包括js, C, C#，Android, iOS, Unity3D等等，几乎支持涵盖了目前所有的主流平台，由于**pomelo的协议是开放**的，架构耦合松散，对于没有支持的客户端平台，用户也可以**很容易地开发出自己需要的库，定制自己的通信协议**；\n\n### demo\n一个框架需要强大的demo来展示功能并为开发者提供示例，pomelo提供了全平台的聊天demo和基于HTML5的捡宝demo，系统还提供了一个强大的基于HTML5开发的MMO游戏demo [Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】。\n\n## 为什么使用pomelo？\n高并发、高实时的游戏服务器的开发是很复杂的工作。跟web应用一样，一个好的开源容器或开发框架可以大大减少游戏服务器开发的复杂性，让开发变得更加容易。遗憾的是目前在游戏服务器开发领域一直没有太好的开源解决方案。pomelo将填补这个空白，打造一款**完全开源的高性能高并发游戏服务器框架**。pomelo的优势有以下几点：\n\n### 架构的可伸缩性好\n采用**多进程单线程的运行架构**，扩展服务器非常方便，node.js的网络io优势提供了高可伸缩性，写好的应用只需要简单地修改一下配置就能轻松地伸缩扩充；\n\n### 易用\npomelo基于轻量级的nodejs，其开发模型与web应用的开发类似，基于**convention over configuration(约定优于配置)**的理念，几乎零配置，api的设计也很精简，很容易上手，开发快速；\n\n### 框架的松耦合和可扩展性好\n遵循node.js微模块的原则，框架本身只有很少的代码，**所有component、库、工具都可以用npm module的形式扩展进来**，任何第三方都可以根据自己的需要开发自定义module，并把它整合到pomelo的框架中。\n\n### 完整的demo和文档\npomelo提供了完整的中英文文档，pomelo还提供一个完整的开源MMO游戏demo--[Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】，一个超过1万行代码的游戏demo，使开发者可以随时借鉴demo的设计与开发思路。\n\n## pomelo的定位\npomelo是一个轻量级的服务器框架，它最适合的应用领域是网页游戏、社交游戏、移动游戏的服务端，开发者会发现pomelo可以用如此少的代码达到强大的扩展性和伸缩性。当然还不仅仅是游戏，用pomelo开发高实时web应用也如此合适， 而且伸缩性比其它框架好。\n\n不推荐将pomelo用于大型的MMORPG（Multiplayer Online Role-PlayingGame）（大型多人在线角色扮演游戏）游戏开发，尤其是大型3D游戏， 还是需要象**Bigworld**这样的商用引擎来支撑。\n\n好了，是不是有迫不及待了，那就赶快安装pomelo来试试吧。\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8pomelo)","source":"_posts/欢迎使用pomelo.md","raw":"---\ntitle: 欢迎使用pomelo\ntags:\n  - pomelo\noriginContent: >-\n  pomelo是一个游戏服务器框架，与以往单进程的游戏框架不同,\n  它是**高性能、高可伸缩、分布式多进程**的游戏服务器框架，并且使用很简单。它包括基础开发框架和一系列相关工具和库，可以帮助开发者省去游戏开发中枯燥的重复劳动和底层逻辑工作，免除开发者的重造轮子，让开发者可以更多地去关注游戏的具体逻辑，大大提高开发效率。pomelo强大的可伸缩性和灵活性使得pomelo也**可以作为通用的分布式实时应用开发框架**，用于一些高实时应用的开发，而且pomelo在很多方面的表现甚至超越了现有的开源实时应用框架。**pomelo支持所有主流平台的客户端**，并提供了客户端的开发库，使得客户端的开发变得很友好。\n\n\n  <!-- more -->\n\n\n  ## pomelo组成\n\n  pomelo 是由一系列相互之间弱耦合的部分**组合而成**的，包括：\n\n\n  ### 框架\n\n  **框架是pomelo最核心的部分;**\n\n\n  ### 库\n\n  pomelo提供了很多库，有些是跟游戏逻辑完全相关的，如**AI**，**AOI**，**寻路**等；也有与游戏逻辑无关但比较通用的，如**定时任务**执行，\n  **数据同步**等等；\n\n\n  ### 工具\n\n  pomelo提供了**服务器管理控制工具**、**命令行工具**、**压力测试工具**等一系列工具；\n\n\n  ### 客户端库\n\n  pomelo提供了**各类平台的客户端开发库**，包括js, C, C#，Android, iOS,\n  Unity3D等等，几乎支持涵盖了目前所有的主流平台，由于**pomelo的协议是开放**的，架构耦合松散，对于没有支持的客户端平台，用户也可以**很容易地开发出自己需要的库，定制自己的通信协议**；\n\n\n  ### demo\n\n  一个框架需要强大的demo来展示功能并为开发者提供示例，pomelo提供了全平台的聊天demo和基于HTML5的捡宝demo，系统还提供了一个强大的基于HTML5开发的MMO游戏demo\n  [Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】。\n\n\n  ## 为什么使用pomelo？\n\n  高并发、高实时的游戏服务器的开发是很复杂的工作。跟web应用一样，一个好的开源容器或开发框架可以大大减少游戏服务器开发的复杂性，让开发变得更加容易。遗憾的是目前在游戏服务器开发领域一直没有太好的开源解决方案。pomelo将填补这个空白，打造一款**完全开源的高性能高并发游戏服务器框架**。pomelo的优势有以下几点：\n\n\n  ### 架构的可伸缩性好\n\n  采用**多进程单线程的运行架构**，扩展服务器非常方便，node.js的网络io优势提供了高可伸缩性，写好的应用只需要简单地修改一下配置就能轻松地伸缩扩充；\n\n\n  ### 易用\n\n  pomelo基于轻量级的nodejs，其开发模型与web应用的开发类似，基于**convention over\n  configuration(约定优于配置)**的理念，几乎零配置，api的设计也很精简，很容易上手，开发快速；\n\n\n  ### 框架的松耦合和可扩展性好\n\n  遵循node.js微模块的原则，框架本身只有很少的代码，**所有component、库、工具都可以用npm\n  module的形式扩展进来**，任何第三方都可以根据自己的需要开发自定义module，并把它整合到pomelo的框架中。\n\n\n  ### 完整的demo和文档\n\n  pomelo提供了完整的中英文文档，pomelo还提供一个完整的开源MMO游戏demo--[Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】，一个超过1万行代码的游戏demo，使开发者可以随时借鉴demo的设计与开发思路。\n\n\n  ## pomelo的定位\n\n  pomelo是一个轻量级的服务器框架，它最适合的应用领域是网页游戏、社交游戏、移动游戏的服务端，开发者会发现pomelo可以用如此少的代码达到强大的扩展性和伸缩性。当然还不仅仅是游戏，用pomelo开发高实时web应用也如此合适，\n  而且伸缩性比其它框架好。\n\n\n  不推荐将pomelo用于大型的MMORPG（Multiplayer Online\n  Role-PlayingGame）（大型多人在线角色扮演游戏）游戏开发，尤其是大型3D游戏， 还是需要象**Bigworld**这样的商用引擎来支撑。\n\n\n  好了，是不是有迫不及待了，那就赶快安装pomelo来试试吧。\n\n\n  [原文地址](https://github.com/NetEase/pomelo/wiki/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8pomelo)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2018-02-28 11:32:28\n---\n\npomelo是一个游戏服务器框架，与以往单进程的游戏框架不同, 它是**高性能、高可伸缩、分布式多进程**的游戏服务器框架，并且使用很简单。它包括基础开发框架和一系列相关工具和库，可以帮助开发者省去游戏开发中枯燥的重复劳动和底层逻辑工作，免除开发者的重造轮子，让开发者可以更多地去关注游戏的具体逻辑，大大提高开发效率。pomelo强大的可伸缩性和灵活性使得pomelo也**可以作为通用的分布式实时应用开发框架**，用于一些高实时应用的开发，而且pomelo在很多方面的表现甚至超越了现有的开源实时应用框架。**pomelo支持所有主流平台的客户端**，并提供了客户端的开发库，使得客户端的开发变得很友好。\n\n<!-- more -->\n\n## pomelo组成\npomelo 是由一系列相互之间弱耦合的部分**组合而成**的，包括：\n\n### 框架\n**框架是pomelo最核心的部分;**\n\n### 库\npomelo提供了很多库，有些是跟游戏逻辑完全相关的，如**AI**，**AOI**，**寻路**等；也有与游戏逻辑无关但比较通用的，如**定时任务**执行， **数据同步**等等；\n\n### 工具\npomelo提供了**服务器管理控制工具**、**命令行工具**、**压力测试工具**等一系列工具；\n\n### 客户端库\npomelo提供了**各类平台的客户端开发库**，包括js, C, C#，Android, iOS, Unity3D等等，几乎支持涵盖了目前所有的主流平台，由于**pomelo的协议是开放**的，架构耦合松散，对于没有支持的客户端平台，用户也可以**很容易地开发出自己需要的库，定制自己的通信协议**；\n\n### demo\n一个框架需要强大的demo来展示功能并为开发者提供示例，pomelo提供了全平台的聊天demo和基于HTML5的捡宝demo，系统还提供了一个强大的基于HTML5开发的MMO游戏demo [Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】。\n\n## 为什么使用pomelo？\n高并发、高实时的游戏服务器的开发是很复杂的工作。跟web应用一样，一个好的开源容器或开发框架可以大大减少游戏服务器开发的复杂性，让开发变得更加容易。遗憾的是目前在游戏服务器开发领域一直没有太好的开源解决方案。pomelo将填补这个空白，打造一款**完全开源的高性能高并发游戏服务器框架**。pomelo的优势有以下几点：\n\n### 架构的可伸缩性好\n采用**多进程单线程的运行架构**，扩展服务器非常方便，node.js的网络io优势提供了高可伸缩性，写好的应用只需要简单地修改一下配置就能轻松地伸缩扩充；\n\n### 易用\npomelo基于轻量级的nodejs，其开发模型与web应用的开发类似，基于**convention over configuration(约定优于配置)**的理念，几乎零配置，api的设计也很精简，很容易上手，开发快速；\n\n### 框架的松耦合和可扩展性好\n遵循node.js微模块的原则，框架本身只有很少的代码，**所有component、库、工具都可以用npm module的形式扩展进来**，任何第三方都可以根据自己的需要开发自定义module，并把它整合到pomelo的框架中。\n\n### 完整的demo和文档\npomelo提供了完整的中英文文档，pomelo还提供一个完整的开源MMO游戏demo--[Lordofpomelo](http://pomelo.netease.com/lordofpomelo/)【[源码](https://github.com/NetEase/lordofpomelo)】，一个超过1万行代码的游戏demo，使开发者可以随时借鉴demo的设计与开发思路。\n\n## pomelo的定位\npomelo是一个轻量级的服务器框架，它最适合的应用领域是网页游戏、社交游戏、移动游戏的服务端，开发者会发现pomelo可以用如此少的代码达到强大的扩展性和伸缩性。当然还不仅仅是游戏，用pomelo开发高实时web应用也如此合适， 而且伸缩性比其它框架好。\n\n不推荐将pomelo用于大型的MMORPG（Multiplayer Online Role-PlayingGame）（大型多人在线角色扮演游戏）游戏开发，尤其是大型3D游戏， 还是需要象**Bigworld**这样的商用引擎来支撑。\n\n好了，是不是有迫不及待了，那就赶快安装pomelo来试试吧。\n\n[原文地址](https://github.com/NetEase/pomelo/wiki/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8pomelo)","slug":"欢迎使用pomelo","published":1,"updated":"2019-03-23T10:21:56.701Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1en0005bgyavkog4qpfq"},{"title":"网页中常见的错误码","originContent":"# 100（继续）\n请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。\n\n<!-- more -->\n\n# 101（切换协议）\n请求者已要求服务器切换协议，服务器已确认并准备切换。\n# 2xx（成功）\n表示成功处理了请求的状态码。\n## 200（成功）\n服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot 已成功检索到该文件。\n## 201（已创建）\n请求成功并且服务器创建了新的资源。\n## 202（已接受）\n服务器已接受请求，但尚未处理。\n## 203（非授权信息）\n服务器已成功处理了请求，但返回的信息可能来自另一来源。\n## 204（无内容）\n服务器成功处理了请求，但没有返回任何内容。\n## 205（重置内容）\n服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图（例如，清除表单内容以输入新内容）。\n## 206（部分内容）\n服务器成功处理了部分 GET 请求。\n# 3xx（重定向）\n要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下 Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。\n## 300（多种选择）\n针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。\n## 301（永久移动）\n请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码告诉 Googlebot 某个网页或网站已永久移动到新位置。\n## 302（临时移动）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个网页或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n## 303（查看其他位置）\n请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。对于除 HEAD 之外的所有请求，服务器会自动转到其他位置。\n## 304（未修改）\n自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。\n如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应（称为 If-Modified-Since HTTP 标头）。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。\n## 305（使用代理）\n请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。\n## 307（临时重定向）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 <a href=answer.py?answer=>301</a> 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个页面或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n# 4xx（请求错误）\n这些状态码表示请求可能出错，妨碍了服务器的处理。\n## 400（错误请求）\n服务器不理解请求的语法。\n## 401（未授权）\n请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。\n## 403（禁止）\n服务器拒绝请求。如果您在 Googlebot 尝试抓取您网站上的有效网页时看到此状态码（您可以在 Google 网站管理员工具诊断下的网络抓取页面上看到此信息），可能是您的服务器或主机拒绝了 Googlebot 访问。\n## 404（未找到）\n服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。如果您的网站上没有 robots.txt 文件，而您在 Google 网站管理员工具“诊断”标签的 robots.txt 页上看到此状态码，则这是正确的状态码。但是，如果您有 robots.txt 文件而又看到此状态码，则说明您的 robots.txt 文件可能命名错误或位于错误的位置（该文件应当位于顶级域，名为 robots.txt）。如果对于 Googlebot 抓取的网址看到此状态码（在”诊断”标签的 HTTP 错误页面上），则表示 Googlebot 跟随的可能是另一个页面的无效链接（是旧链接或输入有误的链接）。\n## 405（方法禁用）\n禁用请求中指定的方法。\n## 406（不接受）\n无法使用请求的内容特性响应请求的网页。\n## 407（需要代理授权）\n此状态码与 <a href=answer.py?answer=35128>401（未授权）</a>类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。\n## 408（请求超时）\n服务器等候请求时发生超时。\n## 409（冲突）\n服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。\n## 410（已删除）\n如果请求的资源已永久删除，服务器就会返回此响应。该代码与 404（未找到）代码类似，但在资源以前存在而现在不存在的情况下，有时会用来替代 404 代码。如果资源已永久移动，您应使用 301 指定资源的新位置。\n## 411（需要有效长度）\n服务器不接受不含有效内容长度标头字段的请求。\n## 412（未满足前提条件）\n服务器未满足请求者在请求中设置的其中一个前提条件。\n## 413（请求实体过大）\n服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。\n## 414（请求的 URI 过长）\n请求的 URI（通常为网址）过长，服务器无法处理。\n## 415（不支持的媒体类型）\n请求的格式不受请求页面的支持。\n## 416（请求范围不符合要求）\n如果页面无法提供请求的范围，则服务器会返回此状态码。\n## 417（未满足期望值）\n服务器未满足”期望”请求标头字段的要求。\n# 5xx（服务器错误）\n这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。\n## 500（服务器内部错误）\n服务器遇到错误，无法完成请求。\n## 501（尚未实施）\n服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。\n## 502（错误网关）\n服务器作为网关或代理，从上游服务器收到无效响应。\n## 503（服务不可用）\n服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。\n## 504（网关超时）\n服务器作为网关或代理，但是没有及时从上游服务器收到请求。\n## 505（HTTP 版本不受支持）\n服务器不支持请求中所用的 HTTP 协议版本。","toc":false,"date":"2017-07-20T02:00:00.000Z","_content":"\n# 100（继续）\n请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。\n\n<!-- more -->\n\n# 101（切换协议）\n请求者已要求服务器切换协议，服务器已确认并准备切换。\n# 2xx（成功）\n表示成功处理了请求的状态码。\n## 200（成功）\n服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot 已成功检索到该文件。\n## 201（已创建）\n请求成功并且服务器创建了新的资源。\n## 202（已接受）\n服务器已接受请求，但尚未处理。\n## 203（非授权信息）\n服务器已成功处理了请求，但返回的信息可能来自另一来源。\n## 204（无内容）\n服务器成功处理了请求，但没有返回任何内容。\n## 205（重置内容）\n服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图（例如，清除表单内容以输入新内容）。\n## 206（部分内容）\n服务器成功处理了部分 GET 请求。\n# 3xx（重定向）\n要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下 Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。\n## 300（多种选择）\n针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。\n## 301（永久移动）\n请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码告诉 Googlebot 某个网页或网站已永久移动到新位置。\n## 302（临时移动）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个网页或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n## 303（查看其他位置）\n请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。对于除 HEAD 之外的所有请求，服务器会自动转到其他位置。\n## 304（未修改）\n自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。\n如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应（称为 If-Modified-Since HTTP 标头）。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。\n## 305（使用代理）\n请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。\n## 307（临时重定向）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 <a href=answer.py?answer=>301</a> 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个页面或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n# 4xx（请求错误）\n这些状态码表示请求可能出错，妨碍了服务器的处理。\n## 400（错误请求）\n服务器不理解请求的语法。\n## 401（未授权）\n请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。\n## 403（禁止）\n服务器拒绝请求。如果您在 Googlebot 尝试抓取您网站上的有效网页时看到此状态码（您可以在 Google 网站管理员工具诊断下的网络抓取页面上看到此信息），可能是您的服务器或主机拒绝了 Googlebot 访问。\n## 404（未找到）\n服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。如果您的网站上没有 robots.txt 文件，而您在 Google 网站管理员工具“诊断”标签的 robots.txt 页上看到此状态码，则这是正确的状态码。但是，如果您有 robots.txt 文件而又看到此状态码，则说明您的 robots.txt 文件可能命名错误或位于错误的位置（该文件应当位于顶级域，名为 robots.txt）。如果对于 Googlebot 抓取的网址看到此状态码（在”诊断”标签的 HTTP 错误页面上），则表示 Googlebot 跟随的可能是另一个页面的无效链接（是旧链接或输入有误的链接）。\n## 405（方法禁用）\n禁用请求中指定的方法。\n## 406（不接受）\n无法使用请求的内容特性响应请求的网页。\n## 407（需要代理授权）\n此状态码与 <a href=answer.py?answer=35128>401（未授权）</a>类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。\n## 408（请求超时）\n服务器等候请求时发生超时。\n## 409（冲突）\n服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。\n## 410（已删除）\n如果请求的资源已永久删除，服务器就会返回此响应。该代码与 404（未找到）代码类似，但在资源以前存在而现在不存在的情况下，有时会用来替代 404 代码。如果资源已永久移动，您应使用 301 指定资源的新位置。\n## 411（需要有效长度）\n服务器不接受不含有效内容长度标头字段的请求。\n## 412（未满足前提条件）\n服务器未满足请求者在请求中设置的其中一个前提条件。\n## 413（请求实体过大）\n服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。\n## 414（请求的 URI 过长）\n请求的 URI（通常为网址）过长，服务器无法处理。\n## 415（不支持的媒体类型）\n请求的格式不受请求页面的支持。\n## 416（请求范围不符合要求）\n如果页面无法提供请求的范围，则服务器会返回此状态码。\n## 417（未满足期望值）\n服务器未满足”期望”请求标头字段的要求。\n# 5xx（服务器错误）\n这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。\n## 500（服务器内部错误）\n服务器遇到错误，无法完成请求。\n## 501（尚未实施）\n服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。\n## 502（错误网关）\n服务器作为网关或代理，从上游服务器收到无效响应。\n## 503（服务不可用）\n服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。\n## 504（网关超时）\n服务器作为网关或代理，但是没有及时从上游服务器收到请求。\n## 505（HTTP 版本不受支持）\n服务器不支持请求中所用的 HTTP 协议版本。","source":"_posts/网页中常见的错误码.md","raw":"---\ntitle: 网页中常见的错误码\ntags:\n  - 运维\noriginContent: >-\n  # 100（继续）\n\n  请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。\n\n\n  <!-- more -->\n\n\n  # 101（切换协议）\n\n  请求者已要求服务器切换协议，服务器已确认并准备切换。\n\n  # 2xx（成功）\n\n  表示成功处理了请求的状态码。\n\n  ## 200（成功）\n\n  服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot\n  已成功检索到该文件。\n\n  ## 201（已创建）\n\n  请求成功并且服务器创建了新的资源。\n\n  ## 202（已接受）\n\n  服务器已接受请求，但尚未处理。\n\n  ## 203（非授权信息）\n\n  服务器已成功处理了请求，但返回的信息可能来自另一来源。\n\n  ## 204（无内容）\n\n  服务器成功处理了请求，但没有返回任何内容。\n\n  ## 205（重置内容）\n\n  服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图（例如，清除表单内容以输入新内容）。\n\n  ## 206（部分内容）\n\n  服务器成功处理了部分 GET 请求。\n\n  # 3xx（重定向）\n\n  要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下\n  Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。\n\n  ## 300（多种选择）\n\n  针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。\n\n  ## 301（永久移动）\n\n  请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码告诉 Googlebot\n  某个网页或网站已永久移动到新位置。\n\n  ## 302（临时移动）\n\n  服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301\n  代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个网页或网站已经移动，因为 Googlebot\n  会继续抓取原有位置并编制索引。\n\n  ## 303（查看其他位置）\n\n  请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。对于除 HEAD 之外的所有请求，服务器会自动转到其他位置。\n\n  ## 304（未修改）\n\n  自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。\n\n  如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应（称为 If-Modified-Since HTTP 标头）。服务器可以告诉\n  Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。\n\n  ## 305（使用代理）\n\n  请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。\n\n  ## 307（临时重定向）\n\n  服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 <a\n  href=answer.py?answer=>301</a> 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot\n  某个页面或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n\n  # 4xx（请求错误）\n\n  这些状态码表示请求可能出错，妨碍了服务器的处理。\n\n  ## 400（错误请求）\n\n  服务器不理解请求的语法。\n\n  ## 401（未授权）\n\n  请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。\n\n  ## 403（禁止）\n\n  服务器拒绝请求。如果您在 Googlebot 尝试抓取您网站上的有效网页时看到此状态码（您可以在 Google\n  网站管理员工具诊断下的网络抓取页面上看到此信息），可能是您的服务器或主机拒绝了 Googlebot 访问。\n\n  ## 404（未找到）\n\n  服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。如果您的网站上没有 robots.txt 文件，而您在 Google\n  网站管理员工具“诊断”标签的 robots.txt 页上看到此状态码，则这是正确的状态码。但是，如果您有 robots.txt\n  文件而又看到此状态码，则说明您的 robots.txt 文件可能命名错误或位于错误的位置（该文件应当位于顶级域，名为 robots.txt）。如果对于\n  Googlebot 抓取的网址看到此状态码（在”诊断”标签的 HTTP 错误页面上），则表示 Googlebot\n  跟随的可能是另一个页面的无效链接（是旧链接或输入有误的链接）。\n\n  ## 405（方法禁用）\n\n  禁用请求中指定的方法。\n\n  ## 406（不接受）\n\n  无法使用请求的内容特性响应请求的网页。\n\n  ## 407（需要代理授权）\n\n  此状态码与 <a\n  href=answer.py?answer=35128>401（未授权）</a>类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。\n\n  ## 408（请求超时）\n\n  服务器等候请求时发生超时。\n\n  ## 409（冲突）\n\n  服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。\n\n  ## 410（已删除）\n\n  如果请求的资源已永久删除，服务器就会返回此响应。该代码与 404（未找到）代码类似，但在资源以前存在而现在不存在的情况下，有时会用来替代 404\n  代码。如果资源已永久移动，您应使用 301 指定资源的新位置。\n\n  ## 411（需要有效长度）\n\n  服务器不接受不含有效内容长度标头字段的请求。\n\n  ## 412（未满足前提条件）\n\n  服务器未满足请求者在请求中设置的其中一个前提条件。\n\n  ## 413（请求实体过大）\n\n  服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。\n\n  ## 414（请求的 URI 过长）\n\n  请求的 URI（通常为网址）过长，服务器无法处理。\n\n  ## 415（不支持的媒体类型）\n\n  请求的格式不受请求页面的支持。\n\n  ## 416（请求范围不符合要求）\n\n  如果页面无法提供请求的范围，则服务器会返回此状态码。\n\n  ## 417（未满足期望值）\n\n  服务器未满足”期望”请求标头字段的要求。\n\n  # 5xx（服务器错误）\n\n  这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。\n\n  ## 500（服务器内部错误）\n\n  服务器遇到错误，无法完成请求。\n\n  ## 501（尚未实施）\n\n  服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。\n\n  ## 502（错误网关）\n\n  服务器作为网关或代理，从上游服务器收到无效响应。\n\n  ## 503（服务不可用）\n\n  服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。\n\n  ## 504（网关超时）\n\n  服务器作为网关或代理，但是没有及时从上游服务器收到请求。\n\n  ## 505（HTTP 版本不受支持）\n\n  服务器不支持请求中所用的 HTTP 协议版本。\ncategories:\n  - Web开发\ntoc: false\ndate: 2017-07-20 10:00:00\n---\n\n# 100（继续）\n请求者应当继续提出请求。服务器返回此代码表示已收到请求的第一部分，正在等待其余部分。\n\n<!-- more -->\n\n# 101（切换协议）\n请求者已要求服务器切换协议，服务器已确认并准备切换。\n# 2xx（成功）\n表示成功处理了请求的状态码。\n## 200（成功）\n服务器已成功处理了请求。通常，这表示服务器提供了请求的网页。如果是对您的 robots.txt 文件显示此状态码，则表示 Googlebot 已成功检索到该文件。\n## 201（已创建）\n请求成功并且服务器创建了新的资源。\n## 202（已接受）\n服务器已接受请求，但尚未处理。\n## 203（非授权信息）\n服务器已成功处理了请求，但返回的信息可能来自另一来源。\n## 204（无内容）\n服务器成功处理了请求，但没有返回任何内容。\n## 205（重置内容）\n服务器成功处理了请求，但没有返回任何内容。与 204 响应不同，此响应要求请求者重置文档视图（例如，清除表单内容以输入新内容）。\n## 206（部分内容）\n服务器成功处理了部分 GET 请求。\n# 3xx（重定向）\n要完成请求，需要进一步操作。通常，这些状态码用来重定向。Google 建议您在每次请求中使用重定向不要超过 5 次。您可以使用网站管理员工具查看一下 Googlebot 在抓取重定向网页时是否遇到问题。诊断下的网络抓取页列出了由于重定向错误导致 Googlebot 无法抓取的网址。\n## 300（多种选择）\n针对请求，服务器可执行多种操作。服务器可根据请求者 (user agent) 选择一项操作，或提供操作列表供请求者选择。\n## 301（永久移动）\n请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置。您应使用此代码告诉 Googlebot 某个网页或网站已永久移动到新位置。\n## 302（临时移动）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 301 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个网页或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n## 303（查看其他位置）\n请求者应当对不同的位置使用单独的 GET 请求来检索响应时，服务器返回此代码。对于除 HEAD 之外的所有请求，服务器会自动转到其他位置。\n## 304（未修改）\n自从上次请求后，请求的网页未修改过。服务器返回此响应时，不会返回网页内容。\n如果网页自请求者上次请求后再也没有更改过，您应将服务器配置为返回此响应（称为 If-Modified-Since HTTP 标头）。服务器可以告诉 Googlebot 自从上次抓取后网页没有变更，进而节省带宽和开销。\n## 305（使用代理）\n请求者只能使用代理访问请求的网页。如果服务器返回此响应，还表示请求者应使用代理。\n## 307（临时重定向）\n服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求。此代码与响应 GET 和 HEAD 请求的 <a href=answer.py?answer=>301</a> 代码类似，会自动将请求者转到不同的位置，但您不应使用此代码来告诉 Googlebot 某个页面或网站已经移动，因为 Googlebot 会继续抓取原有位置并编制索引。\n# 4xx（请求错误）\n这些状态码表示请求可能出错，妨碍了服务器的处理。\n## 400（错误请求）\n服务器不理解请求的语法。\n## 401（未授权）\n请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。\n## 403（禁止）\n服务器拒绝请求。如果您在 Googlebot 尝试抓取您网站上的有效网页时看到此状态码（您可以在 Google 网站管理员工具诊断下的网络抓取页面上看到此信息），可能是您的服务器或主机拒绝了 Googlebot 访问。\n## 404（未找到）\n服务器找不到请求的网页。例如，对于服务器上不存在的网页经常会返回此代码。如果您的网站上没有 robots.txt 文件，而您在 Google 网站管理员工具“诊断”标签的 robots.txt 页上看到此状态码，则这是正确的状态码。但是，如果您有 robots.txt 文件而又看到此状态码，则说明您的 robots.txt 文件可能命名错误或位于错误的位置（该文件应当位于顶级域，名为 robots.txt）。如果对于 Googlebot 抓取的网址看到此状态码（在”诊断”标签的 HTTP 错误页面上），则表示 Googlebot 跟随的可能是另一个页面的无效链接（是旧链接或输入有误的链接）。\n## 405（方法禁用）\n禁用请求中指定的方法。\n## 406（不接受）\n无法使用请求的内容特性响应请求的网页。\n## 407（需要代理授权）\n此状态码与 <a href=answer.py?answer=35128>401（未授权）</a>类似，但指定请求者应当授权使用代理。如果服务器返回此响应，还表示请求者应当使用代理。\n## 408（请求超时）\n服务器等候请求时发生超时。\n## 409（冲突）\n服务器在完成请求时发生冲突。服务器必须在响应中包含有关冲突的信息。服务器在响应与前一个请求相冲突的 PUT 请求时可能会返回此代码，以及两个请求的差异列表。\n## 410（已删除）\n如果请求的资源已永久删除，服务器就会返回此响应。该代码与 404（未找到）代码类似，但在资源以前存在而现在不存在的情况下，有时会用来替代 404 代码。如果资源已永久移动，您应使用 301 指定资源的新位置。\n## 411（需要有效长度）\n服务器不接受不含有效内容长度标头字段的请求。\n## 412（未满足前提条件）\n服务器未满足请求者在请求中设置的其中一个前提条件。\n## 413（请求实体过大）\n服务器无法处理请求，因为请求实体过大，超出服务器的处理能力。\n## 414（请求的 URI 过长）\n请求的 URI（通常为网址）过长，服务器无法处理。\n## 415（不支持的媒体类型）\n请求的格式不受请求页面的支持。\n## 416（请求范围不符合要求）\n如果页面无法提供请求的范围，则服务器会返回此状态码。\n## 417（未满足期望值）\n服务器未满足”期望”请求标头字段的要求。\n# 5xx（服务器错误）\n这些状态码表示服务器在处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求出错。\n## 500（服务器内部错误）\n服务器遇到错误，无法完成请求。\n## 501（尚未实施）\n服务器不具备完成请求的功能。例如，服务器无法识别请求方法时可能会返回此代码。\n## 502（错误网关）\n服务器作为网关或代理，从上游服务器收到无效响应。\n## 503（服务不可用）\n服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。\n## 504（网关超时）\n服务器作为网关或代理，但是没有及时从上游服务器收到请求。\n## 505（HTTP 版本不受支持）\n服务器不支持请求中所用的 HTTP 协议版本。","slug":"网页中常见的错误码","published":1,"updated":"2019-03-23T10:44:04.306Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1en3005fgyavgpcl5c4s"},{"title":"自定义服务日志","originContent":"# access_log\n\nNginx服务器支持对服务日志的格式、大小、输出等进行配置，需要使用两个指令，分别是access_log和log_format指令。\n\n<!-- more -->\n\naccess_log指令的语法结构为：\n```\naccess_log path [format[buffer=size]];\n```\n\n> path 配置服务日志的文件存放的路径和名称\n> format 可选项，自定义服务日志的格式字符串，也可以通过「格式串的名称」使用log_format指令定义好的格式。「格式串的名称」在log_format指令中定义。\n> size，配置临时存放日志的内存缓存区大小\n\n此指令可以在http块、server块或者location块中进行设置。\n\n如果要取消记录服务日志的功能，则使用：\n```\naccess_log off;\n```\n---\n\n# log_format\n\n和access_log联合使用的另一个指令是log_format，它专门用于定义服务日志的格式，并且可以为格式字符串定义一个名字，以便access_log指令可以直接调用。其语法格式为：\n```\nlog_format name string ...;\n```\n> name，格式字符串的名字；\n> string 服务日志的格式字符串\n\n示例：\n```\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n```\n> 此指令只能在http块中进行配置","toc":false,"date":"2017-08-27T00:11:51.000Z","_content":"\n# access_log\n\nNginx服务器支持对服务日志的格式、大小、输出等进行配置，需要使用两个指令，分别是access_log和log_format指令。\n\n<!-- more -->\n\naccess_log指令的语法结构为：\n```\naccess_log path [format[buffer=size]];\n```\n\n> path 配置服务日志的文件存放的路径和名称\n> format 可选项，自定义服务日志的格式字符串，也可以通过「格式串的名称」使用log_format指令定义好的格式。「格式串的名称」在log_format指令中定义。\n> size，配置临时存放日志的内存缓存区大小\n\n此指令可以在http块、server块或者location块中进行设置。\n\n如果要取消记录服务日志的功能，则使用：\n```\naccess_log off;\n```\n---\n\n# log_format\n\n和access_log联合使用的另一个指令是log_format，它专门用于定义服务日志的格式，并且可以为格式字符串定义一个名字，以便access_log指令可以直接调用。其语法格式为：\n```\nlog_format name string ...;\n```\n> name，格式字符串的名字；\n> string 服务日志的格式字符串\n\n示例：\n```\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n```\n> 此指令只能在http块中进行配置","source":"_posts/自定义服务日志.md","raw":"---\ntitle: 自定义服务日志\ntags:\n  - nginx\noriginContent: >-\n  # access_log\n\n\n  Nginx服务器支持对服务日志的格式、大小、输出等进行配置，需要使用两个指令，分别是access_log和log_format指令。\n\n\n  <!-- more -->\n\n\n  access_log指令的语法结构为：\n\n  ```\n\n  access_log path [format[buffer=size]];\n\n  ```\n\n\n  > path 配置服务日志的文件存放的路径和名称\n\n  > format\n  可选项，自定义服务日志的格式字符串，也可以通过「格式串的名称」使用log_format指令定义好的格式。「格式串的名称」在log_format指令中定义。\n\n  > size，配置临时存放日志的内存缓存区大小\n\n\n  此指令可以在http块、server块或者location块中进行设置。\n\n\n  如果要取消记录服务日志的功能，则使用：\n\n  ```\n\n  access_log off;\n\n  ```\n\n  ---\n\n\n  # log_format\n\n\n  和access_log联合使用的另一个指令是log_format，它专门用于定义服务日志的格式，并且可以为格式字符串定义一个名字，以便access_log指令可以直接调用。其语法格式为：\n\n  ```\n\n  log_format name string ...;\n\n  ```\n\n  > name，格式字符串的名字；\n\n  > string 服务日志的格式字符串\n\n\n  示例：\n\n  ```\n\n  log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                        '$status $body_bytes_sent \"$http_referer\" '\n                        '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n  ```\n\n  > 此指令只能在http块中进行配置\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 08:11:51\n---\n\n# access_log\n\nNginx服务器支持对服务日志的格式、大小、输出等进行配置，需要使用两个指令，分别是access_log和log_format指令。\n\n<!-- more -->\n\naccess_log指令的语法结构为：\n```\naccess_log path [format[buffer=size]];\n```\n\n> path 配置服务日志的文件存放的路径和名称\n> format 可选项，自定义服务日志的格式字符串，也可以通过「格式串的名称」使用log_format指令定义好的格式。「格式串的名称」在log_format指令中定义。\n> size，配置临时存放日志的内存缓存区大小\n\n此指令可以在http块、server块或者location块中进行设置。\n\n如果要取消记录服务日志的功能，则使用：\n```\naccess_log off;\n```\n---\n\n# log_format\n\n和access_log联合使用的另一个指令是log_format，它专门用于定义服务日志的格式，并且可以为格式字符串定义一个名字，以便access_log指令可以直接调用。其语法格式为：\n```\nlog_format name string ...;\n```\n> name，格式字符串的名字；\n> string 服务日志的格式字符串\n\n示例：\n```\nlog_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n```\n> 此指令只能在http块中进行配置","slug":"自定义服务日志","published":1,"updated":"2019-03-23T10:42:44.125Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1en7005jgyavkjdot0op"},{"title":"虚拟主机","originContent":"# 虚拟主机\n虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里『主机』或『空间』是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用于HTTP、FTP及EMAIL等多项服务。将一台服务器的某项或者全部服务内容逻辑划分为多个服务单位，对外表现为多个服务器。从而充分利用服务器硬件资源。从用户角度来看，一台虚拟主机和一台独立的硬件主机是完全一样的。\n\n<!-- more -->\n\n在使用Nginx服务器提供Web服务时，利用虚拟主机的技术就可以避免为每一个要运行的网站提供单独的Nginx服务器，也无需为每个网站对应运行一组Nginx进程。虚拟主机技术使得Nginx服务器可以在同一台服务器上只运行一组Nginx进程，就可以运行多个网站。那么，如何对Nginx进行配置才能达到这种效果呢？\n\n前面提到过，每一个http块都可以包含多个server块，而每个server块就相当于一台虚拟主机，它内部可有多台主机联合提供服务，一起对外提供在逻辑上关系密切的一组服务（或网站）。我们先来学习server全局块中常见的指令机器配置。server全局块指令的作用域为本server块，其不会影响到其他的server块。","toc":false,"date":"2017-08-26T11:23:00.000Z","_content":"\n# 虚拟主机\n虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里『主机』或『空间』是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用于HTTP、FTP及EMAIL等多项服务。将一台服务器的某项或者全部服务内容逻辑划分为多个服务单位，对外表现为多个服务器。从而充分利用服务器硬件资源。从用户角度来看，一台虚拟主机和一台独立的硬件主机是完全一样的。\n\n<!-- more -->\n\n在使用Nginx服务器提供Web服务时，利用虚拟主机的技术就可以避免为每一个要运行的网站提供单独的Nginx服务器，也无需为每个网站对应运行一组Nginx进程。虚拟主机技术使得Nginx服务器可以在同一台服务器上只运行一组Nginx进程，就可以运行多个网站。那么，如何对Nginx进行配置才能达到这种效果呢？\n\n前面提到过，每一个http块都可以包含多个server块，而每个server块就相当于一台虚拟主机，它内部可有多台主机联合提供服务，一起对外提供在逻辑上关系密切的一组服务（或网站）。我们先来学习server全局块中常见的指令机器配置。server全局块指令的作用域为本server块，其不会影响到其他的server块。","source":"_posts/虚拟服务器.md","raw":"---\ntitle: 虚拟主机\ntags:\n  - nginx\noriginContent: >-\n  # 虚拟主机\n\n  虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里『主机』或『空间』是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用于HTTP、FTP及EMAIL等多项服务。将一台服务器的某项或者全部服务内容逻辑划分为多个服务单位，对外表现为多个服务器。从而充分利用服务器硬件资源。从用户角度来看，一台虚拟主机和一台独立的硬件主机是完全一样的。\n\n\n  <!-- more -->\n\n\n  在使用Nginx服务器提供Web服务时，利用虚拟主机的技术就可以避免为每一个要运行的网站提供单独的Nginx服务器，也无需为每个网站对应运行一组Nginx进程。虚拟主机技术使得Nginx服务器可以在同一台服务器上只运行一组Nginx进程，就可以运行多个网站。那么，如何对Nginx进行配置才能达到这种效果呢？\n\n\n  前面提到过，每一个http块都可以包含多个server块，而每个server块就相当于一台虚拟主机，它内部可有多台主机联合提供服务，一起对外提供在逻辑上关系密切的一组服务（或网站）。我们先来学习server全局块中常见的指令机器配置。server全局块指令的作用域为本server块，其不会影响到其他的server块。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-26 19:23:00\n---\n\n# 虚拟主机\n虚拟主机，又称虚拟服务器、主机空间或是网页空间，它是一种技术。该技术是为了节省互联网服务器硬件成本而出现的。这里『主机』或『空间』是由实体的服务器延伸而来，硬件系统可以基于服务器群，或者单个服务器等。虚拟主机技术主要应用于HTTP、FTP及EMAIL等多项服务。将一台服务器的某项或者全部服务内容逻辑划分为多个服务单位，对外表现为多个服务器。从而充分利用服务器硬件资源。从用户角度来看，一台虚拟主机和一台独立的硬件主机是完全一样的。\n\n<!-- more -->\n\n在使用Nginx服务器提供Web服务时，利用虚拟主机的技术就可以避免为每一个要运行的网站提供单独的Nginx服务器，也无需为每个网站对应运行一组Nginx进程。虚拟主机技术使得Nginx服务器可以在同一台服务器上只运行一组Nginx进程，就可以运行多个网站。那么，如何对Nginx进行配置才能达到这种效果呢？\n\n前面提到过，每一个http块都可以包含多个server块，而每个server块就相当于一台虚拟主机，它内部可有多台主机联合提供服务，一起对外提供在逻辑上关系密切的一组服务（或网站）。我们先来学习server全局块中常见的指令机器配置。server全局块指令的作用域为本server块，其不会影响到其他的server块。","slug":"虚拟服务器","published":1,"updated":"2019-03-23T10:43:38.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ena005mgyavrs0rq003"},{"title":"被遗忘的Logrotate","originContent":"我发现很多人的服务器上都运行着一些诸如每天切分Nginx日志之类的CRON脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！\n\n<!-- more -->\n\n## Logrotate的介绍\n\n显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：\n\n```\n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n\n实际运行时，Logrotate会调用配置文件「/etc/logrotate.conf」：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    minsize 1M\n    create 0664 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n这里的设置可以理解为Logrotate的缺省值，当然了，可以我们在「/etc/logrotate.d」目录里放置自己的配置文件，用来覆盖Logrotate的缺省值。\n\n## Logrotate的演示\n\n按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」：\n\n```\n/usr/local/nginx/logs/*.log {\n    daily\n    dateext\n    compress\n    rotate 7\n    sharedscripts\n    postrotate\n        kill -USR1 `cat /var/run/nginx.pid`\n    endscript\n}\n```\n\n如果你等不及CRON，可以通过如下命令来手动执行：\n\n```\nshell> logrotate -f /etc/logrotate.d/nginx\n```\n\n当然，正式执行前最好通过Debug选项来验证一下，这对调试也很重要：\n\n```\nshell> logrotate -d -f /etc/logrotate.d/nginx\n```\n\nBTW：类似的还有Verbose选项，这里就不多说了。\n\n## Logrotate的疑问\n\n问题：sharedscripts的作用是什么？\n\n大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。\n\n问题：rotate和maxage的区别是什么？\n\n它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。\n\n问题：为什么生成日志的时间是凌晨四五点？\n\n前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行：\n\n```\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\nHOME=/\n\n# run-parts\n01 * * * * root run-parts /etc/cron.hourly\n59 23 * * * root run-parts /etc/cron.daily\n22 4 * * 0 root run-parts /etc/cron.weekly\n42 4 1 * * root run-parts /etc/cron.monthly\n```\n\n如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。\n\n问题：如何告诉应用程序重新打开日志文件？\n\n以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。\n\nBTW：MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见「Rotating MySQL Slow Logs Safely」。\n\n…\n\n熟悉Apache的朋友可能会记得cronolog，不过Nginx并不支持它，有人通过mkfifo命令曲线救国，先给日志文件创建管道，再搭配cronolog轮转，虽然理论上没有问题，但效率上有折扣。另外，Debian/Ubuntu下有一个简化版工具savelog，有兴趣可以看看。\n\n原文地址：[https://huoding.com/2013/04/21/246](https://huoding.com/2013/04/21/246)","toc":false,"date":"2017-10-09T05:32:14.000Z","_content":"\n我发现很多人的服务器上都运行着一些诸如每天切分Nginx日志之类的CRON脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！\n\n<!-- more -->\n\n## Logrotate的介绍\n\n显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：\n\n```\n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n\n实际运行时，Logrotate会调用配置文件「/etc/logrotate.conf」：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    minsize 1M\n    create 0664 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n这里的设置可以理解为Logrotate的缺省值，当然了，可以我们在「/etc/logrotate.d」目录里放置自己的配置文件，用来覆盖Logrotate的缺省值。\n\n## Logrotate的演示\n\n按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」：\n\n```\n/usr/local/nginx/logs/*.log {\n    daily\n    dateext\n    compress\n    rotate 7\n    sharedscripts\n    postrotate\n        kill -USR1 `cat /var/run/nginx.pid`\n    endscript\n}\n```\n\n如果你等不及CRON，可以通过如下命令来手动执行：\n\n```\nshell> logrotate -f /etc/logrotate.d/nginx\n```\n\n当然，正式执行前最好通过Debug选项来验证一下，这对调试也很重要：\n\n```\nshell> logrotate -d -f /etc/logrotate.d/nginx\n```\n\nBTW：类似的还有Verbose选项，这里就不多说了。\n\n## Logrotate的疑问\n\n问题：sharedscripts的作用是什么？\n\n大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。\n\n问题：rotate和maxage的区别是什么？\n\n它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。\n\n问题：为什么生成日志的时间是凌晨四五点？\n\n前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行：\n\n```\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\nHOME=/\n\n# run-parts\n01 * * * * root run-parts /etc/cron.hourly\n59 23 * * * root run-parts /etc/cron.daily\n22 4 * * 0 root run-parts /etc/cron.weekly\n42 4 1 * * root run-parts /etc/cron.monthly\n```\n\n如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。\n\n问题：如何告诉应用程序重新打开日志文件？\n\n以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。\n\nBTW：MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见「Rotating MySQL Slow Logs Safely」。\n\n…\n\n熟悉Apache的朋友可能会记得cronolog，不过Nginx并不支持它，有人通过mkfifo命令曲线救国，先给日志文件创建管道，再搭配cronolog轮转，虽然理论上没有问题，但效率上有折扣。另外，Debian/Ubuntu下有一个简化版工具savelog，有兴趣可以看看。\n\n原文地址：[https://huoding.com/2013/04/21/246](https://huoding.com/2013/04/21/246)","source":"_posts/被遗忘的Logrotate.md","raw":"---\ntitle: 被遗忘的Logrotate\ntags:\n  - linux\noriginContent: >-\n  我发现很多人的服务器上都运行着一些诸如每天切分Nginx日志之类的CRON脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！\n\n\n  <!-- more -->\n\n\n  ## Logrotate的介绍\n\n\n  显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：\n\n\n  ```\n\n  #!/bin/sh\n\n\n  /usr/sbin/logrotate /etc/logrotate.conf\n\n  EXITVALUE=$?\n\n  if [ $EXITVALUE != 0 ]; then\n      /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\n  fi\n\n  exit 0\n\n  ```\n\n\n  实际运行时，Logrotate会调用配置文件「/etc/logrotate.conf」：\n\n\n  ```\n\n  # see \"man logrotate\" for details\n\n  # rotate log files weekly\n\n  weekly\n\n\n  # keep 4 weeks worth of backlogs\n\n  rotate 4\n\n\n  # create new (empty) log files after rotating old ones\n\n  create\n\n\n  # uncomment this if you want your log files compressed\n\n  #compress\n\n\n  # RPM packages drop log rotation information into this directory\n\n  include /etc/logrotate.d\n\n\n  # no packages own wtmp -- we'll rotate them here\n\n  /var/log/wtmp {\n      monthly\n      minsize 1M\n      create 0664 root utmp\n      rotate 1\n  }\n\n\n  # system-specific logs may be also be configured here.\n\n  ```\n\n\n  这里的设置可以理解为Logrotate的缺省值，当然了，可以我们在「/etc/logrotate.d」目录里放置自己的配置文件，用来覆盖Logrotate的缺省值。\n\n\n  ## Logrotate的演示\n\n\n  按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」：\n\n\n  ```\n\n  /usr/local/nginx/logs/*.log {\n      daily\n      dateext\n      compress\n      rotate 7\n      sharedscripts\n      postrotate\n          kill -USR1 `cat /var/run/nginx.pid`\n      endscript\n  }\n\n  ```\n\n\n  如果你等不及CRON，可以通过如下命令来手动执行：\n\n\n  ```\n\n  shell> logrotate -f /etc/logrotate.d/nginx\n\n  ```\n\n\n  当然，正式执行前最好通过Debug选项来验证一下，这对调试也很重要：\n\n\n  ```\n\n  shell> logrotate -d -f /etc/logrotate.d/nginx\n\n  ```\n\n\n  BTW：类似的还有Verbose选项，这里就不多说了。\n\n\n  ## Logrotate的疑问\n\n\n  问题：sharedscripts的作用是什么？\n\n\n  大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。\n\n\n  问题：rotate和maxage的区别是什么？\n\n\n  它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。\n\n\n  问题：为什么生成日志的时间是凌晨四五点？\n\n\n  前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行：\n\n\n  ```\n\n  SHELL=/bin/bash\n\n  PATH=/sbin:/bin:/usr/sbin:/usr/bin\n\n  MAILTO=root\n\n  HOME=/\n\n\n  # run-parts\n\n  01 * * * * root run-parts /etc/cron.hourly\n\n  59 23 * * * root run-parts /etc/cron.daily\n\n  22 4 * * 0 root run-parts /etc/cron.weekly\n\n  42 4 1 * * root run-parts /etc/cron.monthly\n\n  ```\n\n\n  如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。\n\n\n  问题：如何告诉应用程序重新打开日志文件？\n\n\n  以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。\n\n\n  BTW：MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见「Rotating\n  MySQL Slow Logs Safely」。\n\n\n  …\n\n\n  熟悉Apache的朋友可能会记得cronolog，不过Nginx并不支持它，有人通过mkfifo命令曲线救国，先给日志文件创建管道，再搭配cronolog轮转，虽然理论上没有问题，但效率上有折扣。另外，Debian/Ubuntu下有一个简化版工具savelog，有兴趣可以看看。\n\n\n  原文地址：[https://huoding.com/2013/04/21/246](https://huoding.com/2013/04/21/246)\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-10-09 13:32:14\n---\n\n我发现很多人的服务器上都运行着一些诸如每天切分Nginx日志之类的CRON脚本，大家似乎遗忘了Logrotate，争相发明自己的轮子，这真是让人沮丧啊！就好比明明身边躺着现成的性感美女，大家却忙着自娱自乐，罪过！\n\n<!-- more -->\n\n## Logrotate的介绍\n\n显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：\n\n```\n#!/bin/sh\n\n/usr/sbin/logrotate /etc/logrotate.conf\nEXITVALUE=$?\nif [ $EXITVALUE != 0 ]; then\n    /usr/bin/logger -t logrotate \"ALERT exited abnormally with [$EXITVALUE]\"\nfi\nexit 0\n```\n\n实际运行时，Logrotate会调用配置文件「/etc/logrotate.conf」：\n\n```\n# see \"man logrotate\" for details\n# rotate log files weekly\nweekly\n\n# keep 4 weeks worth of backlogs\nrotate 4\n\n# create new (empty) log files after rotating old ones\ncreate\n\n# uncomment this if you want your log files compressed\n#compress\n\n# RPM packages drop log rotation information into this directory\ninclude /etc/logrotate.d\n\n# no packages own wtmp -- we'll rotate them here\n/var/log/wtmp {\n    monthly\n    minsize 1M\n    create 0664 root utmp\n    rotate 1\n}\n\n# system-specific logs may be also be configured here.\n```\n\n这里的设置可以理解为Logrotate的缺省值，当然了，可以我们在「/etc/logrotate.d」目录里放置自己的配置文件，用来覆盖Logrotate的缺省值。\n\n## Logrotate的演示\n\n按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」：\n\n```\n/usr/local/nginx/logs/*.log {\n    daily\n    dateext\n    compress\n    rotate 7\n    sharedscripts\n    postrotate\n        kill -USR1 `cat /var/run/nginx.pid`\n    endscript\n}\n```\n\n如果你等不及CRON，可以通过如下命令来手动执行：\n\n```\nshell> logrotate -f /etc/logrotate.d/nginx\n```\n\n当然，正式执行前最好通过Debug选项来验证一下，这对调试也很重要：\n\n```\nshell> logrotate -d -f /etc/logrotate.d/nginx\n```\n\nBTW：类似的还有Verbose选项，这里就不多说了。\n\n## Logrotate的疑问\n\n问题：sharedscripts的作用是什么？\n\n大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。\n\n问题：rotate和maxage的区别是什么？\n\n它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。\n\n问题：为什么生成日志的时间是凌晨四五点？\n\n前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行：\n\n```\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\nHOME=/\n\n# run-parts\n01 * * * * root run-parts /etc/cron.hourly\n59 23 * * * root run-parts /etc/cron.daily\n22 4 * * 0 root run-parts /etc/cron.weekly\n42 4 1 * * root run-parts /etc/cron.monthly\n```\n\n如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。\n\n问题：如何告诉应用程序重新打开日志文件？\n\n以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。\n\nBTW：MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见「Rotating MySQL Slow Logs Safely」。\n\n…\n\n熟悉Apache的朋友可能会记得cronolog，不过Nginx并不支持它，有人通过mkfifo命令曲线救国，先给日志文件创建管道，再搭配cronolog轮转，虽然理论上没有问题，但效率上有折扣。另外，Debian/Ubuntu下有一个简化版工具savelog，有兴趣可以看看。\n\n原文地址：[https://huoding.com/2013/04/21/246](https://huoding.com/2013/04/21/246)","slug":"被遗忘的Logrotate","published":1,"updated":"2019-03-23T10:38:21.510Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ene005qgyavcdg2scgy"},{"title":"设置网站的默认首页","originContent":"指令index用于设置网站的默认首页，他一般可以有两个作用：一是，用户在发出请求访问网站时，请求地址可以不写首页名称；二是，可以对一个请求，根据其请求内容而设置不同的首页。该指令的语法结构为：\n\n```\nindex file ...;\n```\n\n<!-- more -->\n\n其中，file变量可以包括多个文件名，其间使用空格分隔，也可以包含其他变量。次变量默认为「index.html」。\n\n看一个示例：\n\n```\nlocation ~ ^/data/(.+)/web/ {\n    root    /nginxConfig/www1/;\n    index   index.$1.html index.my1.html index.html;\n}\n```\n\n当location块接收到「data/hello/web/」时，匹配成功，它首先将预置变量$1置为「hello」，然后在/data/hello/web/路径下按照index的配置次序一次寻找index.hello.html页，index.my1.html页和index.html页，首先找到哪个页面，就是用哪个页面相应请求。","toc":false,"date":"2017-08-27T13:49:14.000Z","_content":"\n指令index用于设置网站的默认首页，他一般可以有两个作用：一是，用户在发出请求访问网站时，请求地址可以不写首页名称；二是，可以对一个请求，根据其请求内容而设置不同的首页。该指令的语法结构为：\n\n```\nindex file ...;\n```\n\n<!-- more -->\n\n其中，file变量可以包括多个文件名，其间使用空格分隔，也可以包含其他变量。次变量默认为「index.html」。\n\n看一个示例：\n\n```\nlocation ~ ^/data/(.+)/web/ {\n    root    /nginxConfig/www1/;\n    index   index.$1.html index.my1.html index.html;\n}\n```\n\n当location块接收到「data/hello/web/」时，匹配成功，它首先将预置变量$1置为「hello」，然后在/data/hello/web/路径下按照index的配置次序一次寻找index.hello.html页，index.my1.html页和index.html页，首先找到哪个页面，就是用哪个页面相应请求。","source":"_posts/设置网站的默认首页.md","raw":"---\ntitle: 设置网站的默认首页\ntags:\n  - nginx\noriginContent: >-\n  指令index用于设置网站的默认首页，他一般可以有两个作用：一是，用户在发出请求访问网站时，请求地址可以不写首页名称；二是，可以对一个请求，根据其请求内容而设置不同的首页。该指令的语法结构为：\n\n\n  ```\n\n  index file ...;\n\n  ```\n\n\n  <!-- more -->\n\n\n  其中，file变量可以包括多个文件名，其间使用空格分隔，也可以包含其他变量。次变量默认为「index.html」。\n\n\n  看一个示例：\n\n\n  ```\n\n  location ~ ^/data/(.+)/web/ {\n      root    /nginxConfig/www1/;\n      index   index.$1.html index.my1.html index.html;\n  }\n\n  ```\n\n\n  当location块接收到「data/hello/web/」时，匹配成功，它首先将预置变量$1置为「hello」，然后在/data/hello/web/路径下按照index的配置次序一次寻找index.hello.html页，index.my1.html页和index.html页，首先找到哪个页面，就是用哪个页面相应请求。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 21:49:14\n---\n\n指令index用于设置网站的默认首页，他一般可以有两个作用：一是，用户在发出请求访问网站时，请求地址可以不写首页名称；二是，可以对一个请求，根据其请求内容而设置不同的首页。该指令的语法结构为：\n\n```\nindex file ...;\n```\n\n<!-- more -->\n\n其中，file变量可以包括多个文件名，其间使用空格分隔，也可以包含其他变量。次变量默认为「index.html」。\n\n看一个示例：\n\n```\nlocation ~ ^/data/(.+)/web/ {\n    root    /nginxConfig/www1/;\n    index   index.$1.html index.my1.html index.html;\n}\n```\n\n当location块接收到「data/hello/web/」时，匹配成功，它首先将预置变量$1置为「hello」，然后在/data/hello/web/路径下按照index的配置次序一次寻找index.hello.html页，index.my1.html页和index.html页，首先找到哪个页面，就是用哪个页面相应请求。","slug":"设置网站的默认首页","published":1,"updated":"2019-03-23T10:41:20.190Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1enj005tgyav5lfol9vu"},{"title":"设置webstorm自动删除行尾分号","originContent":"![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/WX20180411-181304.png)","toc":false,"date":"2018-04-11T10:11:27.000Z","_content":"\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/WX20180411-181304.png)","source":"_posts/设置webstorm自动删除行尾分号.md","raw":"---\ntitle: 设置webstorm自动删除行尾分号\ntags:\n  - 开发调试\noriginContent: >-\n  ![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/WX20180411-181304.png)\ncategories:\n  - Web开发\ntoc: false\ndate: 2018-04-11 18:11:27\n---\n\n![](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/WX20180411-181304.png)","slug":"设置webstorm自动删除行尾分号","published":1,"updated":"2019-03-23T10:17:56.136Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1enn005wgyavog0usui3"},{"title":"设置网站的错误页面","originContent":"Nginx 服务器设置网站错误页面的指令为error_page，语法结构为：\n\n```\nerror_page code ... [=[response]] uri\n```\n\n<!-- more -->\n\n> code，要处理的HTTP错误代码\n> response，可选项，将code制定的错误代码转化为新的错误代码response\n> uri，错误页面的路径或者网站地址。如果设置为路径，则是以Nginx服务器安装路径下的html目录为根路径的相对路径；如果设置为网址，则Nginx服务器会直接访问该网站获取错误页面，并返回给用户端（这里是跳转，不是抓取页面返回）。\n看几个error_page指令的示例：\n\n```\nerror_page 404 /404.html;\n```\n\n设置Nginx服务器使用『Nginx安装路径/html/404.html』页面相应404错误（'无法找到网页'错误）；\n再如：\n\n```\nerror_page 403 http://somewebsite.com/forbidden.html;\n```\n设置Nginx服务器使用'http://somewebsite.com/forbidden.html '页面相应403错误（『拒绝显示网页』错误）；\n再如：\n\n```\nerror_page 410 =301 /empty.gif;\n```\n\n设置Nginx服务器产生410的HTTP信息时，使用『Nginx安装路径/html/empty.gif』返回给用户端301消息（'已移动'消息）。\n\n---\n\n如果不想将错误页面放置到Nginx服务器的安装路径下管理，该怎么做呢？\n\n其实这个很简单，只需要另外使用一个location指令定向错误页面到新的路径下面就可以了。比如对于上面的第一个示例，我们希望Nginx服务器使用\"/myserver/errorpages/404.html\"页面相应404错误，那么在设置完：\n\n```\nerror_page 404 /404.html;\n```\n\n之后，我们再添加这样一个location块：\n\n```\nlocation /404.html {\n    root    /myserver/errorpages/;\n}\n```\n\n首先捕获\"/404.html\"请求，然后将请求定向到新的路径下面即可。\nerror_page指令可以在http块、server块和location快中配置。","toc":false,"date":"2017-08-27T13:59:16.000Z","_content":"\nNginx 服务器设置网站错误页面的指令为error_page，语法结构为：\n\n```\nerror_page code ... [=[response]] uri\n```\n\n<!-- more -->\n\n> code，要处理的HTTP错误代码\n> response，可选项，将code制定的错误代码转化为新的错误代码response\n> uri，错误页面的路径或者网站地址。如果设置为路径，则是以Nginx服务器安装路径下的html目录为根路径的相对路径；如果设置为网址，则Nginx服务器会直接访问该网站获取错误页面，并返回给用户端（这里是跳转，不是抓取页面返回）。\n看几个error_page指令的示例：\n\n```\nerror_page 404 /404.html;\n```\n\n设置Nginx服务器使用『Nginx安装路径/html/404.html』页面相应404错误（'无法找到网页'错误）；\n再如：\n\n```\nerror_page 403 http://somewebsite.com/forbidden.html;\n```\n设置Nginx服务器使用'http://somewebsite.com/forbidden.html '页面相应403错误（『拒绝显示网页』错误）；\n再如：\n\n```\nerror_page 410 =301 /empty.gif;\n```\n\n设置Nginx服务器产生410的HTTP信息时，使用『Nginx安装路径/html/empty.gif』返回给用户端301消息（'已移动'消息）。\n\n---\n\n如果不想将错误页面放置到Nginx服务器的安装路径下管理，该怎么做呢？\n\n其实这个很简单，只需要另外使用一个location指令定向错误页面到新的路径下面就可以了。比如对于上面的第一个示例，我们希望Nginx服务器使用\"/myserver/errorpages/404.html\"页面相应404错误，那么在设置完：\n\n```\nerror_page 404 /404.html;\n```\n\n之后，我们再添加这样一个location块：\n\n```\nlocation /404.html {\n    root    /myserver/errorpages/;\n}\n```\n\n首先捕获\"/404.html\"请求，然后将请求定向到新的路径下面即可。\nerror_page指令可以在http块、server块和location快中配置。","source":"_posts/设置网站的错误页面.md","raw":"---\ntitle: 设置网站的错误页面\ntags:\n  - nginx\noriginContent: >-\n  Nginx 服务器设置网站错误页面的指令为error_page，语法结构为：\n\n\n  ```\n\n  error_page code ... [=[response]] uri\n\n  ```\n\n\n  <!-- more -->\n\n\n  > code，要处理的HTTP错误代码\n\n  > response，可选项，将code制定的错误代码转化为新的错误代码response\n\n  >\n  uri，错误页面的路径或者网站地址。如果设置为路径，则是以Nginx服务器安装路径下的html目录为根路径的相对路径；如果设置为网址，则Nginx服务器会直接访问该网站获取错误页面，并返回给用户端（这里是跳转，不是抓取页面返回）。\n\n  看几个error_page指令的示例：\n\n\n  ```\n\n  error_page 404 /404.html;\n\n  ```\n\n\n  设置Nginx服务器使用『Nginx安装路径/html/404.html』页面相应404错误（'无法找到网页'错误）；\n\n  再如：\n\n\n  ```\n\n  error_page 403 http://somewebsite.com/forbidden.html;\n\n  ```\n\n  设置Nginx服务器使用'http://somewebsite.com/forbidden.html '页面相应403错误（『拒绝显示网页』错误）；\n\n  再如：\n\n\n  ```\n\n  error_page 410 =301 /empty.gif;\n\n  ```\n\n\n  设置Nginx服务器产生410的HTTP信息时，使用『Nginx安装路径/html/empty.gif』返回给用户端301消息（'已移动'消息）。\n\n\n  ---\n\n\n  如果不想将错误页面放置到Nginx服务器的安装路径下管理，该怎么做呢？\n\n\n  其实这个很简单，只需要另外使用一个location指令定向错误页面到新的路径下面就可以了。比如对于上面的第一个示例，我们希望Nginx服务器使用\"/myserver/errorpages/404.html\"页面相应404错误，那么在设置完：\n\n\n  ```\n\n  error_page 404 /404.html;\n\n  ```\n\n\n  之后，我们再添加这样一个location块：\n\n\n  ```\n\n  location /404.html {\n      root    /myserver/errorpages/;\n  }\n\n  ```\n\n\n  首先捕获\"/404.html\"请求，然后将请求定向到新的路径下面即可。\n\n  error_page指令可以在http块、server块和location快中配置。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 21:59:16\n---\n\nNginx 服务器设置网站错误页面的指令为error_page，语法结构为：\n\n```\nerror_page code ... [=[response]] uri\n```\n\n<!-- more -->\n\n> code，要处理的HTTP错误代码\n> response，可选项，将code制定的错误代码转化为新的错误代码response\n> uri，错误页面的路径或者网站地址。如果设置为路径，则是以Nginx服务器安装路径下的html目录为根路径的相对路径；如果设置为网址，则Nginx服务器会直接访问该网站获取错误页面，并返回给用户端（这里是跳转，不是抓取页面返回）。\n看几个error_page指令的示例：\n\n```\nerror_page 404 /404.html;\n```\n\n设置Nginx服务器使用『Nginx安装路径/html/404.html』页面相应404错误（'无法找到网页'错误）；\n再如：\n\n```\nerror_page 403 http://somewebsite.com/forbidden.html;\n```\n设置Nginx服务器使用'http://somewebsite.com/forbidden.html '页面相应403错误（『拒绝显示网页』错误）；\n再如：\n\n```\nerror_page 410 =301 /empty.gif;\n```\n\n设置Nginx服务器产生410的HTTP信息时，使用『Nginx安装路径/html/empty.gif』返回给用户端301消息（'已移动'消息）。\n\n---\n\n如果不想将错误页面放置到Nginx服务器的安装路径下管理，该怎么做呢？\n\n其实这个很简单，只需要另外使用一个location指令定向错误页面到新的路径下面就可以了。比如对于上面的第一个示例，我们希望Nginx服务器使用\"/myserver/errorpages/404.html\"页面相应404错误，那么在设置完：\n\n```\nerror_page 404 /404.html;\n```\n\n之后，我们再添加这样一个location块：\n\n```\nlocation /404.html {\n    root    /myserver/errorpages/;\n}\n```\n\n首先捕获\"/404.html\"请求，然后将请求定向到新的路径下面即可。\nerror_page指令可以在http块、server块和location快中配置。","slug":"设置网站的错误页面","published":1,"updated":"2019-03-23T10:39:17.339Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1enr0060gyavxhyouebd"},{"title":"配置最大连接数","originContent":"指令worker_connectionns主要用来设置允许每一个worker process同时开启的最大连接数。\n\n<!-- more -->\n\n```\nworker_connectionns number;\n```\n\n此指令的默认值为512.\n此指令只能在events块中进行配置。","toc":false,"date":"2017-08-27T00:04:02.000Z","_content":"\n指令worker_connectionns主要用来设置允许每一个worker process同时开启的最大连接数。\n\n<!-- more -->\n\n```\nworker_connectionns number;\n```\n\n此指令的默认值为512.\n此指令只能在events块中进行配置。","source":"_posts/配置最大连接数.md","raw":"---\ntitle: 配置最大连接数\ntags:\n  - nginx\noriginContent: |-\n  指令worker_connectionns主要用来设置允许每一个worker process同时开启的最大连接数。\n\n  <!-- more -->\n\n  ```\n  worker_connectionns number;\n  ```\n\n  此指令的默认值为512.\n  此指令只能在events块中进行配置。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 08:04:02\n---\n\n指令worker_connectionns主要用来设置允许每一个worker process同时开启的最大连接数。\n\n<!-- more -->\n\n```\nworker_connectionns number;\n```\n\n此指令的默认值为512.\n此指令只能在events块中进行配置。","slug":"配置最大连接数","published":1,"updated":"2019-03-23T10:42:57.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1enu0063gyav63psl2n8"},{"title":"配置允许生成的worker process数","originContent":"```\nworker_processed number | auto\n```\n> number, 指定Nginx进程最多可以产生的work process数\n> auto，设置此值，Nginx进程将自动检测","toc":false,"date":"2017-08-26T23:27:58.000Z","_content":"\n```\nworker_processed number | auto\n```\n> number, 指定Nginx进程最多可以产生的work process数\n> auto，设置此值，Nginx进程将自动检测","source":"_posts/配置允许生成的worker-process数.md","raw":"---\ntitle: 配置允许生成的worker process数\ntags:\n  - nginx\noriginContent: |-\n  ```\n  worker_processed number | auto\n  ```\n  > number, 指定Nginx进程最多可以产生的work process数\n  > auto，设置此值，Nginx进程将自动检测\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 07:27:58\n---\n\n```\nworker_processed number | auto\n```\n> number, 指定Nginx进程最多可以产生的work process数\n> auto，设置此值，Nginx进程将自动检测","slug":"配置允许生成的worker-process数","published":1,"updated":"2019-03-23T10:43:10.372Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eny0067gyavgy6ksarm"},{"title":"配置location块","originContent":"location的语法结构为：\n```\nlocation [ = | ~ | ~* | ^~ ] uri {...}\n```\n\n<!-- more -->\n\n其中，uri变量是待匹配的请求字符串，可以是不含正则表达式的字符串，如 /myserver.php等；也可以是包含有正则表达式的字符串，如 \\.php$ (表示以.php结尾的URL)等。为了下文叙述方便，我们约定，不含正则表达式的uri称谓『标准 uri』，使用正则表达式的uri成为『正则 uri』。\n\n其中方括号里的部分，是可选项，用来改变请求字符串与uri的匹配方式。在介绍四中标识的含义之前，我们需要先了解不添加此选项时，Nginx服务器是如何在server块中搜索并使用location块的uri和请求字符串匹配的。\n\n在不添加此选项时，Nginx服务器首先在server块的多个location块中搜索是否有标准uri和请求字符串匹配，如果有多个可以匹配，就记录匹配度最高的一个。然后，服务器再用location块中的正则uri和请求字符串匹配，当地一个正则uri匹配成功，结束搜索，并使用这个location块处理此请求；如果正则匹配全部失败，就使用刚才记录的匹配度最高的location块处理次请求。\n\n了解了上面的内容，皆可以解释可选项中各个标识的含义了：\n> \" = \"，用于标准uri前，要求请求字符串与uri严格匹配。如果已经匹配成功，就停止继续向下搜索并立即处理次请求。\n> \" ~ \", 用于标识uri包含正则表达式，并且区分大小写。\n> \" ~* \"， 用于标识包含正则表达式，并且不区分大小写。\n\n注意：如果uri包含正则表达式，就必须要使用『 ~ 』或者『 ~* 』标识\n\n> \"^~\"，用于标准uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即是用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配。\n\n注意：我们知道，在浏览器传送URI时对一部分字符进行URL编码，比如空格被编码为『%20』，问号被编码为『%3f』等。『^~』有一个特点是，它对uri中的这些符号将会进行编码处理。比如，如果location块收到的URI为\"/html/%20/data\",则当Nginx服务器搜索到匹配为『^~/html//data』的location时，可以匹配成功。","toc":false,"date":"2017-08-27T01:54:58.000Z","_content":"\nlocation的语法结构为：\n```\nlocation [ = | ~ | ~* | ^~ ] uri {...}\n```\n\n<!-- more -->\n\n其中，uri变量是待匹配的请求字符串，可以是不含正则表达式的字符串，如 /myserver.php等；也可以是包含有正则表达式的字符串，如 \\.php$ (表示以.php结尾的URL)等。为了下文叙述方便，我们约定，不含正则表达式的uri称谓『标准 uri』，使用正则表达式的uri成为『正则 uri』。\n\n其中方括号里的部分，是可选项，用来改变请求字符串与uri的匹配方式。在介绍四中标识的含义之前，我们需要先了解不添加此选项时，Nginx服务器是如何在server块中搜索并使用location块的uri和请求字符串匹配的。\n\n在不添加此选项时，Nginx服务器首先在server块的多个location块中搜索是否有标准uri和请求字符串匹配，如果有多个可以匹配，就记录匹配度最高的一个。然后，服务器再用location块中的正则uri和请求字符串匹配，当地一个正则uri匹配成功，结束搜索，并使用这个location块处理此请求；如果正则匹配全部失败，就使用刚才记录的匹配度最高的location块处理次请求。\n\n了解了上面的内容，皆可以解释可选项中各个标识的含义了：\n> \" = \"，用于标准uri前，要求请求字符串与uri严格匹配。如果已经匹配成功，就停止继续向下搜索并立即处理次请求。\n> \" ~ \", 用于标识uri包含正则表达式，并且区分大小写。\n> \" ~* \"， 用于标识包含正则表达式，并且不区分大小写。\n\n注意：如果uri包含正则表达式，就必须要使用『 ~ 』或者『 ~* 』标识\n\n> \"^~\"，用于标准uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即是用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配。\n\n注意：我们知道，在浏览器传送URI时对一部分字符进行URL编码，比如空格被编码为『%20』，问号被编码为『%3f』等。『^~』有一个特点是，它对uri中的这些符号将会进行编码处理。比如，如果location块收到的URI为\"/html/%20/data\",则当Nginx服务器搜索到匹配为『^~/html//data』的location时，可以匹配成功。","source":"_posts/配置location块.md","raw":"---\ntitle: 配置location块\ntags:\n  - nginx\noriginContent: >-\n  location的语法结构为：\n\n  ```\n\n  location [ = | ~ | ~* | ^~ ] uri {...}\n\n  ```\n\n\n  <!-- more -->\n\n\n  其中，uri变量是待匹配的请求字符串，可以是不含正则表达式的字符串，如 /myserver.php等；也可以是包含有正则表达式的字符串，如 \\.php$\n  (表示以.php结尾的URL)等。为了下文叙述方便，我们约定，不含正则表达式的uri称谓『标准 uri』，使用正则表达式的uri成为『正则 uri』。\n\n\n  其中方括号里的部分，是可选项，用来改变请求字符串与uri的匹配方式。在介绍四中标识的含义之前，我们需要先了解不添加此选项时，Nginx服务器是如何在server块中搜索并使用location块的uri和请求字符串匹配的。\n\n\n  在不添加此选项时，Nginx服务器首先在server块的多个location块中搜索是否有标准uri和请求字符串匹配，如果有多个可以匹配，就记录匹配度最高的一个。然后，服务器再用location块中的正则uri和请求字符串匹配，当地一个正则uri匹配成功，结束搜索，并使用这个location块处理此请求；如果正则匹配全部失败，就使用刚才记录的匹配度最高的location块处理次请求。\n\n\n  了解了上面的内容，皆可以解释可选项中各个标识的含义了：\n\n  > \" = \"，用于标准uri前，要求请求字符串与uri严格匹配。如果已经匹配成功，就停止继续向下搜索并立即处理次请求。\n\n  > \" ~ \", 用于标识uri包含正则表达式，并且区分大小写。\n\n  > \" ~* \"， 用于标识包含正则表达式，并且不区分大小写。\n\n\n  注意：如果uri包含正则表达式，就必须要使用『 ~ 』或者『 ~* 』标识\n\n\n  >\n  \"^~\"，用于标准uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即是用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配。\n\n\n  注意：我们知道，在浏览器传送URI时对一部分字符进行URL编码，比如空格被编码为『%20』，问号被编码为『%3f』等。『^~』有一个特点是，它对uri中的这些符号将会进行编码处理。比如，如果location块收到的URI为\"/html/%20/data\",则当Nginx服务器搜索到匹配为『^~/html//data』的location时，可以匹配成功。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 09:54:58\n---\n\nlocation的语法结构为：\n```\nlocation [ = | ~ | ~* | ^~ ] uri {...}\n```\n\n<!-- more -->\n\n其中，uri变量是待匹配的请求字符串，可以是不含正则表达式的字符串，如 /myserver.php等；也可以是包含有正则表达式的字符串，如 \\.php$ (表示以.php结尾的URL)等。为了下文叙述方便，我们约定，不含正则表达式的uri称谓『标准 uri』，使用正则表达式的uri成为『正则 uri』。\n\n其中方括号里的部分，是可选项，用来改变请求字符串与uri的匹配方式。在介绍四中标识的含义之前，我们需要先了解不添加此选项时，Nginx服务器是如何在server块中搜索并使用location块的uri和请求字符串匹配的。\n\n在不添加此选项时，Nginx服务器首先在server块的多个location块中搜索是否有标准uri和请求字符串匹配，如果有多个可以匹配，就记录匹配度最高的一个。然后，服务器再用location块中的正则uri和请求字符串匹配，当地一个正则uri匹配成功，结束搜索，并使用这个location块处理此请求；如果正则匹配全部失败，就使用刚才记录的匹配度最高的location块处理次请求。\n\n了解了上面的内容，皆可以解释可选项中各个标识的含义了：\n> \" = \"，用于标准uri前，要求请求字符串与uri严格匹配。如果已经匹配成功，就停止继续向下搜索并立即处理次请求。\n> \" ~ \", 用于标识uri包含正则表达式，并且区分大小写。\n> \" ~* \"， 用于标识包含正则表达式，并且不区分大小写。\n\n注意：如果uri包含正则表达式，就必须要使用『 ~ 』或者『 ~* 』标识\n\n> \"^~\"，用于标准uri前，要求Nginx服务器找到标识uri和请求字符串匹配度最高的location后，立即是用此location处理请求，而不再使用location块中的正则uri和请求字符串做匹配。\n\n注意：我们知道，在浏览器传送URI时对一部分字符进行URL编码，比如空格被编码为『%20』，问号被编码为『%3f』等。『^~』有一个特点是，它对uri中的这些符号将会进行编码处理。比如，如果location块收到的URI为\"/html/%20/data\",则当Nginx服务器搜索到匹配为『^~/html//data』的location时，可以匹配成功。","slug":"配置location块","published":1,"updated":"2019-03-23T10:42:36.117Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eo1006agyav5o7cpcjm"},{"title":"配置请求的根目录","originContent":"Web 服务器接收到网络请求之后，首先要在服务器端指定目录中寻找请求资源。在Nginx服务器中，指令root就是用来配置这个根目录的，其语法结构为：\n```\nroot path;\n```\n\n<!-- more -->\n\n其中，path为Nginx服务器接收到请求以后查找资源的根目录路径（注意这里是根目录路径，对应location里边的第一个\"/\"，而不是整个location的uri）。path变量中可以包含Nginx服务器预设的大多数变量，只有$document_root和$realpath_root不可以使用。\n\n此指令可以在http块、server块或者location块中配置。由于使用Nginx服务器多数情况下要配置多个location块对不同的请求分别作出处理，因此该指令通常在location块中进行设置。\n\n这个指令的一个实例为：\n\n```\nlocation /data/ {\n    root    /locationtest1;\n}\n```\n\n当location块接收到『/data/index.html』的请求时，将在/locationtest1/data/目录下找到index.html相应请求。","toc":false,"date":"2017-08-27T10:48:01.000Z","_content":"\nWeb 服务器接收到网络请求之后，首先要在服务器端指定目录中寻找请求资源。在Nginx服务器中，指令root就是用来配置这个根目录的，其语法结构为：\n```\nroot path;\n```\n\n<!-- more -->\n\n其中，path为Nginx服务器接收到请求以后查找资源的根目录路径（注意这里是根目录路径，对应location里边的第一个\"/\"，而不是整个location的uri）。path变量中可以包含Nginx服务器预设的大多数变量，只有$document_root和$realpath_root不可以使用。\n\n此指令可以在http块、server块或者location块中配置。由于使用Nginx服务器多数情况下要配置多个location块对不同的请求分别作出处理，因此该指令通常在location块中进行设置。\n\n这个指令的一个实例为：\n\n```\nlocation /data/ {\n    root    /locationtest1;\n}\n```\n\n当location块接收到『/data/index.html』的请求时，将在/locationtest1/data/目录下找到index.html相应请求。","source":"_posts/配置请求的根目录.md","raw":"---\ntitle: 配置请求的根目录\ntags:\n  - nginx\noriginContent: >-\n  Web 服务器接收到网络请求之后，首先要在服务器端指定目录中寻找请求资源。在Nginx服务器中，指令root就是用来配置这个根目录的，其语法结构为：\n\n  ```\n\n  root path;\n\n  ```\n\n\n  <!-- more -->\n\n\n  其中，path为Nginx服务器接收到请求以后查找资源的根目录路径（注意这里是根目录路径，对应location里边的第一个\"/\"，而不是整个location的uri）。path变量中可以包含Nginx服务器预设的大多数变量，只有$document_root和$realpath_root不可以使用。\n\n\n  此指令可以在http块、server块或者location块中配置。由于使用Nginx服务器多数情况下要配置多个location块对不同的请求分别作出处理，因此该指令通常在location块中进行设置。\n\n\n  这个指令的一个实例为：\n\n\n  ```\n\n  location /data/ {\n      root    /locationtest1;\n  }\n\n  ```\n\n\n  当location块接收到『/data/index.html』的请求时，将在/locationtest1/data/目录下找到index.html相应请求。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-27 18:48:01\n---\n\nWeb 服务器接收到网络请求之后，首先要在服务器端指定目录中寻找请求资源。在Nginx服务器中，指令root就是用来配置这个根目录的，其语法结构为：\n```\nroot path;\n```\n\n<!-- more -->\n\n其中，path为Nginx服务器接收到请求以后查找资源的根目录路径（注意这里是根目录路径，对应location里边的第一个\"/\"，而不是整个location的uri）。path变量中可以包含Nginx服务器预设的大多数变量，只有$document_root和$realpath_root不可以使用。\n\n此指令可以在http块、server块或者location块中配置。由于使用Nginx服务器多数情况下要配置多个location块对不同的请求分别作出处理，因此该指令通常在location块中进行设置。\n\n这个指令的一个实例为：\n\n```\nlocation /data/ {\n    root    /locationtest1;\n}\n```\n\n当location块接收到『/data/index.html』的请求时，将在/locationtest1/data/目录下找到index.html相应请求。","slug":"配置请求的根目录","published":1,"updated":"2019-03-23T10:41:38.037Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eoj006egyavnxdnunr3"},{"title":"配置运行Nginx服务用户（组）","originContent":"# user 指令\nuser user [group]\n    user,指定可以运行Nginx服务器的用户\n    group，可选项，指定可以运行Nginx服务器的用户组\n\n<!-- more -->\n\n只有被设置的用户或者用户组成员才有权限启动Nginx进程，如果是其他用户（test_user)尝试启动Nginx进程，将会报错\n\n如果希望所有用户都可以启动Nginx进程，有两种办法：一是将此指令行注释掉：\n\\#user [user] [group];\n或者将用户（和用户组）设置为nobody：\nuser nobody nobody;\n这也是user指令的默认配置。user指令只能在全局块中配置。\n\n> 注意：在Nginx配置文件中，每一条指令配置都必须以分号结束，不要忘记。","toc":false,"date":"2017-08-26T12:16:20.000Z","_content":"\n# user 指令\nuser user [group]\n    user,指定可以运行Nginx服务器的用户\n    group，可选项，指定可以运行Nginx服务器的用户组\n\n<!-- more -->\n\n只有被设置的用户或者用户组成员才有权限启动Nginx进程，如果是其他用户（test_user)尝试启动Nginx进程，将会报错\n\n如果希望所有用户都可以启动Nginx进程，有两种办法：一是将此指令行注释掉：\n\\#user [user] [group];\n或者将用户（和用户组）设置为nobody：\nuser nobody nobody;\n这也是user指令的默认配置。user指令只能在全局块中配置。\n\n> 注意：在Nginx配置文件中，每一条指令配置都必须以分号结束，不要忘记。","source":"_posts/配置运行Nginx服务用户（组）.md","raw":"---\ntitle: 配置运行Nginx服务用户（组）\ntags:\n  - nginx\noriginContent: |-\n  # user 指令\n  user user [group]\n      user,指定可以运行Nginx服务器的用户\n      group，可选项，指定可以运行Nginx服务器的用户组\n\n  <!-- more -->\n\n  只有被设置的用户或者用户组成员才有权限启动Nginx进程，如果是其他用户（test_user)尝试启动Nginx进程，将会报错\n\n  如果希望所有用户都可以启动Nginx进程，有两种办法：一是将此指令行注释掉：\n  \\#user [user] [group];\n  或者将用户（和用户组）设置为nobody：\n  user nobody nobody;\n  这也是user指令的默认配置。user指令只能在全局块中配置。\n\n  > 注意：在Nginx配置文件中，每一条指令配置都必须以分号结束，不要忘记。\ncategories:\n  - 后端开发\ntoc: false\ndate: 2017-08-26 20:16:20\n---\n\n# user 指令\nuser user [group]\n    user,指定可以运行Nginx服务器的用户\n    group，可选项，指定可以运行Nginx服务器的用户组\n\n<!-- more -->\n\n只有被设置的用户或者用户组成员才有权限启动Nginx进程，如果是其他用户（test_user)尝试启动Nginx进程，将会报错\n\n如果希望所有用户都可以启动Nginx进程，有两种办法：一是将此指令行注释掉：\n\\#user [user] [group];\n或者将用户（和用户组）设置为nobody：\nuser nobody nobody;\n这也是user指令的默认配置。user指令只能在全局块中配置。\n\n> 注意：在Nginx配置文件中，每一条指令配置都必须以分号结束，不要忘记。","slug":"配置运行Nginx服务用户（组）","published":1,"updated":"2019-03-23T10:43:32.537Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eon006hgyav526m3186"},{"title":"马云团队","originContent":"这也是以前收藏的一张图片，放在这里自己做个备忘吧\n\n<!-- more -->\n\n![马云团队](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E9%A9%AC%E4%BA%91%E5%9B%A2%E9%98%9F.gif)","toc":false,"date":"2017-10-13T07:05:55.000Z","_content":"\n这也是以前收藏的一张图片，放在这里自己做个备忘吧\n\n<!-- more -->\n\n![马云团队](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E9%A9%AC%E4%BA%91%E5%9B%A2%E9%98%9F.gif)","source":"_posts/马云团队.md","raw":"---\ntitle: 马云团队\ntags:\n  - plan\noriginContent: >-\n  这也是以前收藏的一张图片，放在这里自己做个备忘吧\n\n\n  <!-- more -->\n\n\n  ![马云团队](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E9%A9%AC%E4%BA%91%E5%9B%A2%E9%98%9F.gif)\ncategories:\n  - 生活玩乐\ntoc: false\ndate: 2017-10-13 15:05:55\n---\n\n这也是以前收藏的一张图片，放在这里自己做个备忘吧\n\n<!-- more -->\n\n![马云团队](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/blog/%E9%A9%AC%E4%BA%91%E5%9B%A2%E9%98%9F.gif)","slug":"马云团队","published":1,"updated":"2019-03-23T10:34:29.765Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eos006lgyav6fkp676b"},{"title":"高性能网站性能进阶指南-笔记","originContent":"大部分Javascript引擎的优化是为了快速抢占市场而不是性能，所以JavaScript一直很自然地被认为是瓶颈。但通常情况下，瓶颈不是JavaScript而是DOM，所以倒腾脚本收效甚微。\n\n尽量避免倒腾脚本，要正确并清晰的编写程序。倒腾往往越整越乱，它只会让程序更容易产生bug。\n\n<!-- more -->\n\n避免使用那些传说中能让程序更快的奇技淫巧，除非你能证明它们能给应用带来明显的质量提升。大多数情况下，他们只会降低代码质量，而不会有多大提升。不要纠结于特定浏览器的怪癖，浏览器仍在发展，最终会支持更好的编码实践。\n\n如果感觉必须要捣腾，首先要评估。我们对程序真正开销的直觉往往是错的。只有通过评估，才能有把握对性能产生积极的影响。\n\n创建快速响应的web应用-\n别把运行实践可能很长的低性能代码引入到网页中。\n\n### 拆分初始化负载-\n通过拆分来节省下载量\n\n### 无阻塞加载脚本-\n通常，大多数浏览器是并行下载组件的，但对于外部脚本并非如此。当浏览器开始下载外部脚本时，在脚本下载、解析并执行完毕之前，不会开始下载任何其他内容。\n浏览器在下载和执行脚本时出现阻塞的原因在于，脚本可能会改变页面或JavaScript的命名空间，他们会对后续内容造成影响。\n很明显脚本必须按顺序执行，但没有必要按顺序下载。\n我们真正想要的是让脚本与所有其他组件并行下载，而且希望在所有浏览器中实现。\n\n1. XHR Eval\n2. XHR 注入（XHR Injection）\n3. Script in Iframe\n4. **Script DOM Element**\n5. Script Defer\n6. document.write Script Tag\n\n**最佳方案**\n没有独立的最佳方案，真正的最佳方案取决于需求：\n![脚本下载技术的决策树](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171009-154931@2x.png)\n\n在决策树里有6中可能的结果：\n\n1. 不同域、无序\n2. 不同域、保持顺序\n3. 同域、无序、无忙指示器\n4. 同域、无序、有忙指示器\n5. 同域、保持顺序、无忙指示器\n6. 同域、保持顺序、有忙指示器\n\n### 整合异步脚本\n当异步加载的外部脚本与行内脚本之间存在代码依赖时，我们必须通过一种保持执行顺序的方法来整合这两个脚本。很显然，并没有一个能跨所有浏览器实现的简单方法。本章提出了这个问题，并给出一些解决方案：\n\n1. 代码示例：menu.js\n2. 竞争状态\n3. 异步保持顺序\n\n\t**Script Onload技术是整合异步加载外部脚本和行内脚本的首选。**他不引用任何外部脚本里的标识符，所以维护更简单。行内代码可以在外部脚本加载完毕后立即执行。事件处理也非常简单。\n\n4. 多个外部脚本\n\n\tManaged XHR技术解决了跨主流浏览器的兼容性问题。但是由于XMLHTTPRequest的同源规则，如果外部脚本部署在主页面不同的域下，该技术就无法工作。所以当脚本和页面不同域时，我们选择的方案是DOM Element 和 Doc Write技术。\n\n5. 通用解决方案\n6. 现实工作中的异步加载\n\n### 布置行内脚本\n行内脚本虽然不会产生额外的HTTP请求，但会阻塞页面上资源的并行下载，还会阻塞逐步渲染。\n1. 把行内脚本移至底部\n2. 使用异步回调启动JavaScript的执行\n\n\tsetTimeout(function(){}, 0);\n\tsetTimeout(function(){}, 250);\n\n3. 使用script的defer属性\n\n\tscript的defer属性只有Internet Explorer和Firefox3.1+支持，所以更好的方式是使用setTimeout\n\n### 编写高效的JavaScript\n\nJavaScript的执行速度取决于代码的编写方式。\n\n1. 管理作用域非常重要，因为存取非局部变量要比局部变量耗时更多。尽量避免使用会增长作用域链的结构，比如使用with语句和try-catch语句中的catch从句。如果非局部变量的使用超过一次，那么为了降低性能损耗，就应该将它存储在一个局部变量中。\n2. 存储和读取数据的方式对脚本的性能影响极大。字面量和局部变量总是最快的；存取数组元素和对象属性会引起性能损耗。如果数据元素或对象属性使用超过一次，那么为了提高存取速度，就应该将它存储到一个局部变量中。\n3. 流控制也是影响脚本执行速度的一个重要因素。条件判断有3中处理方式：if语句、switch语句和数组查找。if语句适用于少量离散值或一段区间值的判断；switch语句最好用于对3~10个离散值的判断；数组查找在吹大量离散值时效率最高。\n4. 在Javascript中，循环经常会成为性能瓶颈。为了使循环最高效，可以采用倒序的方式来处理元素，也就是在控制条件中，将迭代变量和0作比较。相比非0值，这种方式要快得多，从而显著提升数组的处理速度。如果必须要进行大量的迭代，还可以考虑使用Duff策略来提高执行速度。\n5. 谨慎使用HTMLCollection对象。每次存取这类对象的属性，都会重新查询DOM中匹配的节点。为了避免这种高昂的开销，只有在必要时才存取HTMLCollection对象，并将经常存取的值（例如length属性）存储在局部变量中。\n6. 常见的字符串操作可能会带来意料之外的性能问题。Internet Explorer处理字符串链接的速度比其他浏览器要慢很多，但这没什么大不了，除非你要一次执行1000次以上的字符串链接。你可以对Internet Explorer处理字符串链接的方式进行优化：先将所有要链接的字符串存储到数组中，然后调用join()方法合并他们。去除字符串两端的空白可能很耗时，这取决于字符串的大小。如果脚本中经常需要去除字符串两端的空白，那请确保使用最优算法。\n7. 浏览器会限制JavaScript可以运行的最长时间，有些会以执行语句的数量作为判断条件，有些则会控制JavaScript引擎执行的总时间。你可以使用定时器将任务拆分执行，从而绕开这些限制，避免浏览器弹出终止脚本运行的警告。","toc":false,"date":"2017-10-09T10:46:18.000Z","_content":"\n大部分Javascript引擎的优化是为了快速抢占市场而不是性能，所以JavaScript一直很自然地被认为是瓶颈。但通常情况下，瓶颈不是JavaScript而是DOM，所以倒腾脚本收效甚微。\n\n尽量避免倒腾脚本，要正确并清晰的编写程序。倒腾往往越整越乱，它只会让程序更容易产生bug。\n\n<!-- more -->\n\n避免使用那些传说中能让程序更快的奇技淫巧，除非你能证明它们能给应用带来明显的质量提升。大多数情况下，他们只会降低代码质量，而不会有多大提升。不要纠结于特定浏览器的怪癖，浏览器仍在发展，最终会支持更好的编码实践。\n\n如果感觉必须要捣腾，首先要评估。我们对程序真正开销的直觉往往是错的。只有通过评估，才能有把握对性能产生积极的影响。\n\n创建快速响应的web应用-\n别把运行实践可能很长的低性能代码引入到网页中。\n\n### 拆分初始化负载-\n通过拆分来节省下载量\n\n### 无阻塞加载脚本-\n通常，大多数浏览器是并行下载组件的，但对于外部脚本并非如此。当浏览器开始下载外部脚本时，在脚本下载、解析并执行完毕之前，不会开始下载任何其他内容。\n浏览器在下载和执行脚本时出现阻塞的原因在于，脚本可能会改变页面或JavaScript的命名空间，他们会对后续内容造成影响。\n很明显脚本必须按顺序执行，但没有必要按顺序下载。\n我们真正想要的是让脚本与所有其他组件并行下载，而且希望在所有浏览器中实现。\n\n1. XHR Eval\n2. XHR 注入（XHR Injection）\n3. Script in Iframe\n4. **Script DOM Element**\n5. Script Defer\n6. document.write Script Tag\n\n**最佳方案**\n没有独立的最佳方案，真正的最佳方案取决于需求：\n![脚本下载技术的决策树](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171009-154931@2x.png)\n\n在决策树里有6中可能的结果：\n\n1. 不同域、无序\n2. 不同域、保持顺序\n3. 同域、无序、无忙指示器\n4. 同域、无序、有忙指示器\n5. 同域、保持顺序、无忙指示器\n6. 同域、保持顺序、有忙指示器\n\n### 整合异步脚本\n当异步加载的外部脚本与行内脚本之间存在代码依赖时，我们必须通过一种保持执行顺序的方法来整合这两个脚本。很显然，并没有一个能跨所有浏览器实现的简单方法。本章提出了这个问题，并给出一些解决方案：\n\n1. 代码示例：menu.js\n2. 竞争状态\n3. 异步保持顺序\n\n\t**Script Onload技术是整合异步加载外部脚本和行内脚本的首选。**他不引用任何外部脚本里的标识符，所以维护更简单。行内代码可以在外部脚本加载完毕后立即执行。事件处理也非常简单。\n\n4. 多个外部脚本\n\n\tManaged XHR技术解决了跨主流浏览器的兼容性问题。但是由于XMLHTTPRequest的同源规则，如果外部脚本部署在主页面不同的域下，该技术就无法工作。所以当脚本和页面不同域时，我们选择的方案是DOM Element 和 Doc Write技术。\n\n5. 通用解决方案\n6. 现实工作中的异步加载\n\n### 布置行内脚本\n行内脚本虽然不会产生额外的HTTP请求，但会阻塞页面上资源的并行下载，还会阻塞逐步渲染。\n1. 把行内脚本移至底部\n2. 使用异步回调启动JavaScript的执行\n\n\tsetTimeout(function(){}, 0);\n\tsetTimeout(function(){}, 250);\n\n3. 使用script的defer属性\n\n\tscript的defer属性只有Internet Explorer和Firefox3.1+支持，所以更好的方式是使用setTimeout\n\n### 编写高效的JavaScript\n\nJavaScript的执行速度取决于代码的编写方式。\n\n1. 管理作用域非常重要，因为存取非局部变量要比局部变量耗时更多。尽量避免使用会增长作用域链的结构，比如使用with语句和try-catch语句中的catch从句。如果非局部变量的使用超过一次，那么为了降低性能损耗，就应该将它存储在一个局部变量中。\n2. 存储和读取数据的方式对脚本的性能影响极大。字面量和局部变量总是最快的；存取数组元素和对象属性会引起性能损耗。如果数据元素或对象属性使用超过一次，那么为了提高存取速度，就应该将它存储到一个局部变量中。\n3. 流控制也是影响脚本执行速度的一个重要因素。条件判断有3中处理方式：if语句、switch语句和数组查找。if语句适用于少量离散值或一段区间值的判断；switch语句最好用于对3~10个离散值的判断；数组查找在吹大量离散值时效率最高。\n4. 在Javascript中，循环经常会成为性能瓶颈。为了使循环最高效，可以采用倒序的方式来处理元素，也就是在控制条件中，将迭代变量和0作比较。相比非0值，这种方式要快得多，从而显著提升数组的处理速度。如果必须要进行大量的迭代，还可以考虑使用Duff策略来提高执行速度。\n5. 谨慎使用HTMLCollection对象。每次存取这类对象的属性，都会重新查询DOM中匹配的节点。为了避免这种高昂的开销，只有在必要时才存取HTMLCollection对象，并将经常存取的值（例如length属性）存储在局部变量中。\n6. 常见的字符串操作可能会带来意料之外的性能问题。Internet Explorer处理字符串链接的速度比其他浏览器要慢很多，但这没什么大不了，除非你要一次执行1000次以上的字符串链接。你可以对Internet Explorer处理字符串链接的方式进行优化：先将所有要链接的字符串存储到数组中，然后调用join()方法合并他们。去除字符串两端的空白可能很耗时，这取决于字符串的大小。如果脚本中经常需要去除字符串两端的空白，那请确保使用最优算法。\n7. 浏览器会限制JavaScript可以运行的最长时间，有些会以执行语句的数量作为判断条件，有些则会控制JavaScript引擎执行的总时间。你可以使用定时器将任务拆分执行，从而绕开这些限制，避免浏览器弹出终止脚本运行的警告。","source":"_posts/高性能网站性能进阶指南-笔记.md","raw":"---\ntitle: 高性能网站性能进阶指南-笔记\ntags:\n  - javascript\noriginContent: \"大部分Javascript引擎的优化是为了快速抢占市场而不是性能，所以JavaScript一直很自然地被认为是瓶颈。但通常情况下，瓶颈不是JavaScript而是DOM，所以倒腾脚本收效甚微。\\n\\n尽量避免倒腾脚本，要正确并清晰的编写程序。倒腾往往越整越乱，它只会让程序更容易产生bug。\\n\\n<!-- more -->\\n\\n避免使用那些传说中能让程序更快的奇技淫巧，除非你能证明它们能给应用带来明显的质量提升。大多数情况下，他们只会降低代码质量，而不会有多大提升。不要纠结于特定浏览器的怪癖，浏览器仍在发展，最终会支持更好的编码实践。\\n\\n如果感觉必须要捣腾，首先要评估。我们对程序真正开销的直觉往往是错的。只有通过评估，才能有把握对性能产生积极的影响。\\n\\n创建快速响应的web应用-\\n别把运行实践可能很长的低性能代码引入到网页中。\\n\\n### 拆分初始化负载-\\n通过拆分来节省下载量\\n\\n### 无阻塞加载脚本-\\n通常，大多数浏览器是并行下载组件的，但对于外部脚本并非如此。当浏览器开始下载外部脚本时，在脚本下载、解析并执行完毕之前，不会开始下载任何其他内容。\\n浏览器在下载和执行脚本时出现阻塞的原因在于，脚本可能会改变页面或JavaScript的命名空间，他们会对后续内容造成影响。\\n很明显脚本必须按顺序执行，但没有必要按顺序下载。\\n我们真正想要的是让脚本与所有其他组件并行下载，而且希望在所有浏览器中实现。\\n\\n1. XHR Eval\\n2. XHR 注入（XHR Injection）\\n3. Script in Iframe\\n4. **Script DOM Element**\\n5. Script Defer\\n6. document.write Script Tag\\n\\n**最佳方案**\\n没有独立的最佳方案，真正的最佳方案取决于需求：\\n![脚本下载技术的决策树](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171009-154931@2x.png)\\n\\n在决策树里有6中可能的结果：\\n\\n1. 不同域、无序\\n2. 不同域、保持顺序\\n3. 同域、无序、无忙指示器\\n4. 同域、无序、有忙指示器\\n5. 同域、保持顺序、无忙指示器\\n6. 同域、保持顺序、有忙指示器\\n\\n### 整合异步脚本\\n当异步加载的外部脚本与行内脚本之间存在代码依赖时，我们必须通过一种保持执行顺序的方法来整合这两个脚本。很显然，并没有一个能跨所有浏览器实现的简单方法。本章提出了这个问题，并给出一些解决方案：\\n\\n1. 代码示例：menu.js\\n2. 竞争状态\\n3. 异步保持顺序\\n\\n\\t**Script Onload技术是整合异步加载外部脚本和行内脚本的首选。**他不引用任何外部脚本里的标识符，所以维护更简单。行内代码可以在外部脚本加载完毕后立即执行。事件处理也非常简单。\\n\\n4. 多个外部脚本\\n\\n\\tManaged XHR技术解决了跨主流浏览器的兼容性问题。但是由于XMLHTTPRequest的同源规则，如果外部脚本部署在主页面不同的域下，该技术就无法工作。所以当脚本和页面不同域时，我们选择的方案是DOM Element 和 Doc Write技术。\\n\\n5. 通用解决方案\\n6. 现实工作中的异步加载\\n\\n### 布置行内脚本\\n行内脚本虽然不会产生额外的HTTP请求，但会阻塞页面上资源的并行下载，还会阻塞逐步渲染。\\n1. 把行内脚本移至底部\\n2. 使用异步回调启动JavaScript的执行\\n\\n\\tsetTimeout(function(){}, 0);\\n\\tsetTimeout(function(){}, 250);\\n\\n3. 使用script的defer属性\\n\\n\\tscript的defer属性只有Internet Explorer和Firefox3.1+支持，所以更好的方式是使用setTimeout\\n\\n### 编写高效的JavaScript\\n\\nJavaScript的执行速度取决于代码的编写方式。\\n\\n1. 管理作用域非常重要，因为存取非局部变量要比局部变量耗时更多。尽量避免使用会增长作用域链的结构，比如使用with语句和try-catch语句中的catch从句。如果非局部变量的使用超过一次，那么为了降低性能损耗，就应该将它存储在一个局部变量中。\\n2. 存储和读取数据的方式对脚本的性能影响极大。字面量和局部变量总是最快的；存取数组元素和对象属性会引起性能损耗。如果数据元素或对象属性使用超过一次，那么为了提高存取速度，就应该将它存储到一个局部变量中。\\n3. 流控制也是影响脚本执行速度的一个重要因素。条件判断有3中处理方式：if语句、switch语句和数组查找。if语句适用于少量离散值或一段区间值的判断；switch语句最好用于对3~10个离散值的判断；数组查找在吹大量离散值时效率最高。\\n4. 在Javascript中，循环经常会成为性能瓶颈。为了使循环最高效，可以采用倒序的方式来处理元素，也就是在控制条件中，将迭代变量和0作比较。相比非0值，这种方式要快得多，从而显著提升数组的处理速度。如果必须要进行大量的迭代，还可以考虑使用Duff策略来提高执行速度。\\n5. 谨慎使用HTMLCollection对象。每次存取这类对象的属性，都会重新查询DOM中匹配的节点。为了避免这种高昂的开销，只有在必要时才存取HTMLCollection对象，并将经常存取的值（例如length属性）存储在局部变量中。\\n6. 常见的字符串操作可能会带来意料之外的性能问题。Internet Explorer处理字符串链接的速度比其他浏览器要慢很多，但这没什么大不了，除非你要一次执行1000次以上的字符串链接。你可以对Internet Explorer处理字符串链接的方式进行优化：先将所有要链接的字符串存储到数组中，然后调用join()方法合并他们。去除字符串两端的空白可能很耗时，这取决于字符串的大小。如果脚本中经常需要去除字符串两端的空白，那请确保使用最优算法。\\n7. 浏览器会限制JavaScript可以运行的最长时间，有些会以执行语句的数量作为判断条件，有些则会控制JavaScript引擎执行的总时间。你可以使用定时器将任务拆分执行，从而绕开这些限制，避免浏览器弹出终止脚本运行的警告。\"\ncategories:\n  - 性能优化\ntoc: false\ndate: 2017-10-09 18:46:18\n---\n\n大部分Javascript引擎的优化是为了快速抢占市场而不是性能，所以JavaScript一直很自然地被认为是瓶颈。但通常情况下，瓶颈不是JavaScript而是DOM，所以倒腾脚本收效甚微。\n\n尽量避免倒腾脚本，要正确并清晰的编写程序。倒腾往往越整越乱，它只会让程序更容易产生bug。\n\n<!-- more -->\n\n避免使用那些传说中能让程序更快的奇技淫巧，除非你能证明它们能给应用带来明显的质量提升。大多数情况下，他们只会降低代码质量，而不会有多大提升。不要纠结于特定浏览器的怪癖，浏览器仍在发展，最终会支持更好的编码实践。\n\n如果感觉必须要捣腾，首先要评估。我们对程序真正开销的直觉往往是错的。只有通过评估，才能有把握对性能产生积极的影响。\n\n创建快速响应的web应用-\n别把运行实践可能很长的低性能代码引入到网页中。\n\n### 拆分初始化负载-\n通过拆分来节省下载量\n\n### 无阻塞加载脚本-\n通常，大多数浏览器是并行下载组件的，但对于外部脚本并非如此。当浏览器开始下载外部脚本时，在脚本下载、解析并执行完毕之前，不会开始下载任何其他内容。\n浏览器在下载和执行脚本时出现阻塞的原因在于，脚本可能会改变页面或JavaScript的命名空间，他们会对后续内容造成影响。\n很明显脚本必须按顺序执行，但没有必要按顺序下载。\n我们真正想要的是让脚本与所有其他组件并行下载，而且希望在所有浏览器中实现。\n\n1. XHR Eval\n2. XHR 注入（XHR Injection）\n3. Script in Iframe\n4. **Script DOM Element**\n5. Script Defer\n6. document.write Script Tag\n\n**最佳方案**\n没有独立的最佳方案，真正的最佳方案取决于需求：\n![脚本下载技术的决策树](http://houjiyi.oss-cn-beijing.aliyuncs.com/images/QQ20171009-154931@2x.png)\n\n在决策树里有6中可能的结果：\n\n1. 不同域、无序\n2. 不同域、保持顺序\n3. 同域、无序、无忙指示器\n4. 同域、无序、有忙指示器\n5. 同域、保持顺序、无忙指示器\n6. 同域、保持顺序、有忙指示器\n\n### 整合异步脚本\n当异步加载的外部脚本与行内脚本之间存在代码依赖时，我们必须通过一种保持执行顺序的方法来整合这两个脚本。很显然，并没有一个能跨所有浏览器实现的简单方法。本章提出了这个问题，并给出一些解决方案：\n\n1. 代码示例：menu.js\n2. 竞争状态\n3. 异步保持顺序\n\n\t**Script Onload技术是整合异步加载外部脚本和行内脚本的首选。**他不引用任何外部脚本里的标识符，所以维护更简单。行内代码可以在外部脚本加载完毕后立即执行。事件处理也非常简单。\n\n4. 多个外部脚本\n\n\tManaged XHR技术解决了跨主流浏览器的兼容性问题。但是由于XMLHTTPRequest的同源规则，如果外部脚本部署在主页面不同的域下，该技术就无法工作。所以当脚本和页面不同域时，我们选择的方案是DOM Element 和 Doc Write技术。\n\n5. 通用解决方案\n6. 现实工作中的异步加载\n\n### 布置行内脚本\n行内脚本虽然不会产生额外的HTTP请求，但会阻塞页面上资源的并行下载，还会阻塞逐步渲染。\n1. 把行内脚本移至底部\n2. 使用异步回调启动JavaScript的执行\n\n\tsetTimeout(function(){}, 0);\n\tsetTimeout(function(){}, 250);\n\n3. 使用script的defer属性\n\n\tscript的defer属性只有Internet Explorer和Firefox3.1+支持，所以更好的方式是使用setTimeout\n\n### 编写高效的JavaScript\n\nJavaScript的执行速度取决于代码的编写方式。\n\n1. 管理作用域非常重要，因为存取非局部变量要比局部变量耗时更多。尽量避免使用会增长作用域链的结构，比如使用with语句和try-catch语句中的catch从句。如果非局部变量的使用超过一次，那么为了降低性能损耗，就应该将它存储在一个局部变量中。\n2. 存储和读取数据的方式对脚本的性能影响极大。字面量和局部变量总是最快的；存取数组元素和对象属性会引起性能损耗。如果数据元素或对象属性使用超过一次，那么为了提高存取速度，就应该将它存储到一个局部变量中。\n3. 流控制也是影响脚本执行速度的一个重要因素。条件判断有3中处理方式：if语句、switch语句和数组查找。if语句适用于少量离散值或一段区间值的判断；switch语句最好用于对3~10个离散值的判断；数组查找在吹大量离散值时效率最高。\n4. 在Javascript中，循环经常会成为性能瓶颈。为了使循环最高效，可以采用倒序的方式来处理元素，也就是在控制条件中，将迭代变量和0作比较。相比非0值，这种方式要快得多，从而显著提升数组的处理速度。如果必须要进行大量的迭代，还可以考虑使用Duff策略来提高执行速度。\n5. 谨慎使用HTMLCollection对象。每次存取这类对象的属性，都会重新查询DOM中匹配的节点。为了避免这种高昂的开销，只有在必要时才存取HTMLCollection对象，并将经常存取的值（例如length属性）存储在局部变量中。\n6. 常见的字符串操作可能会带来意料之外的性能问题。Internet Explorer处理字符串链接的速度比其他浏览器要慢很多，但这没什么大不了，除非你要一次执行1000次以上的字符串链接。你可以对Internet Explorer处理字符串链接的方式进行优化：先将所有要链接的字符串存储到数组中，然后调用join()方法合并他们。去除字符串两端的空白可能很耗时，这取决于字符串的大小。如果脚本中经常需要去除字符串两端的空白，那请确保使用最优算法。\n7. 浏览器会限制JavaScript可以运行的最长时间，有些会以执行语句的数量作为判断条件，有些则会控制JavaScript引擎执行的总时间。你可以使用定时器将任务拆分执行，从而绕开这些限制，避免浏览器弹出终止脚本运行的警告。","slug":"高性能网站性能进阶指南-笔记","published":1,"updated":"2019-03-23T10:38:08.817Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1eov006ogyav2dmla9tu"},{"title":"nodejs redis doc","originContent":"redis - a node.js redis client\n===========================\n\n[![Build Status](https://travis-ci.org/NodeRedis/node_redis.svg?branch=master)](https://travis-ci.org/NodeRedis/node_redis)\n[![Coverage Status](https://coveralls.io/repos/NodeRedis/node_redis/badge.svg?branch=)](https://coveralls.io/r/NodeRedis/node_redis?branch=)\n[![Windows Tests](https://img.shields.io/appveyor/ci/BridgeAR/node-redis/master.svg?label=Windows%20Tests)](https://ci.appveyor.com/project/BridgeAR/node-redis/branch/master)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/NodeRedis/node_redis?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\nThis is a complete and feature rich Redis client for node.js. __It supports all\nRedis commands__ and focuses on high performance.\n\n<!-- more -->\n\nInstall with:\n\n    npm install redis\n\n## Usage Example\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\n// if you'd like to select database 3, instead of 0 (default), call\n// client.select(3, function() { /* ... */ });\n\nclient.on(\"error\", function (err) {\n    console.log(\"Error \" + err);\n});\n\nclient.set(\"string key\", \"string val\", redis.print);\nclient.hset(\"hash key\", \"hashtest 1\", \"some value\", redis.print);\nclient.hset([\"hash key\", \"hashtest 2\", \"some other value\"], redis.print);\nclient.hkeys(\"hash key\", function (err, replies) {\n    console.log(replies.length + \" replies:\");\n    replies.forEach(function (reply, i) {\n        console.log(\"    \" + i + \": \" + reply);\n    });\n    client.quit();\n});\n```\n\nThis will display:\n\n    mjr:~/work/node_redis (master)$ node example.js\n    Reply: OK\n    Reply: 0\n    Reply: 0\n    2 replies:\n        0: hashtest 1\n        1: hashtest 2\n    mjr:~/work/node_redis (master)$\n\nNote that the API is entirely asynchronous. To get data back from the server,\nyou'll need to use a callback. From v.2.6 on the API supports camelCase and\nsnake_case and all options / variables / events etc. can be used either way. It\nis recommended to use camelCase as this is the default for the Node.js\nlandscape.\n\n### Promises\n\nYou can also use node_redis with promises by promisifying node_redis with\n[bluebird](https://github.com/petkaantonov/bluebird) as in:\n\n```js\nvar redis = require('redis');\nbluebird.promisifyAll(redis.RedisClient.prototype);\nbluebird.promisifyAll(redis.Multi.prototype);\n```\n\nIt'll add a *Async* to all node_redis functions (e.g. return client.getAsync().then())\n\n```js\n// We expect a value 'foo': 'bar' to be present\n// So instead of writing client.get('foo', cb); you have to write:\nreturn client.getAsync('foo').then(function(res) {\n    console.log(res); // => 'bar'\n});\n\n// Using multi with promises looks like:\n\nreturn client.multi().get('foo').execAsync().then(function(res) {\n    console.log(res); // => 'bar'\n});\n```\n\n### Sending Commands\n\nEach Redis command is exposed as a function on the `client` object.\nAll functions take either an `args` Array plus optional `callback` Function or\na variable number of individual arguments followed by an optional callback.\nExamples:\n\n```js\nclient.hmset([\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Works the same as\nclient.hmset(\"key\", [\"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Or\nclient.hmset(\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\", function (err, res) {});\n```\n\nCare should be taken with user input if arrays are possible (via body-parser, query string or other method), as single arguments could be unintentionally interpreted as multiple args.\n\nNote that in either form the `callback` is optional:\n\n```js\nclient.set(\"some key\", \"some val\");\nclient.set([\"some other key\", \"some val\"]);\n```\n\nIf the key is missing, reply will be null. Only if the [Redis Command\nReference](http://redis.io/commands) states something else it will not be null.\n\n```js\nclient.get(\"missingkey\", function(err, reply) {\n    // reply is null when the key is missing\n    console.log(reply);\n});\n```\n\nFor a list of Redis commands, see [Redis Command Reference](http://redis.io/commands)\n\nMinimal parsing is done on the replies. Commands that return a integer return\nJavaScript Numbers, arrays return JavaScript Array. `HGETALL` returns an Object\nkeyed by the hash keys. All strings will either be returned as string or as\nbuffer depending on your setting. Please be aware that sending null, undefined\nand Boolean values will result in the value coerced to a string!\n\n# Redis Commands\n\nThis library is a 1 to 1 mapping to [Redis commands](https://redis.io/commands).\nIt is not a cache library so please refer to Redis commands page for full usage\ndetails.\n\nExample setting key to auto expire using [SET command](https://redis.io/commands/set)\n\n```js\n// this key will expire after 10 seconds\nclient.set('key', 'value!', 'EX', 10);\n```\n\n# API\n\n## Connection and other Events\n\n`client` will emit some events about the state of the connection to the Redis server.\n\n### \"ready\"\n\n`client` will emit `ready` once a connection is established. Commands issued\nbefore the `ready` event are queued, then replayed just before this event is\nemitted.\n\n### \"connect\"\n\n`client` will emit `connect` as soon as the stream is connected to the server.\n\n### \"reconnecting\"\n\n`client` will emit `reconnecting` when trying to reconnect to the Redis server\nafter losing the connection. Listeners are passed an object containing `delay`\n(in ms) and `attempt` (the attempt #) attributes.\n\n### \"error\"\n\n`client` will emit `error` when encountering an error connecting to the Redis\nserver or when any other in node_redis occurs. If you use a command without\ncallback and encounter a ReplyError it is going to be emitted to the error\nlistener.\n\nSo please attach the error listener to node_redis.\n\n### \"end\"\n\n`client` will emit `end` when an established Redis server connection has closed.\n\n### \"drain\" (deprecated)\n\n`client` will emit `drain` when the TCP connection to the Redis server has been\nbuffering, but is now writable. This event can be used to stream commands in to\nRedis and adapt to backpressure.\n\nIf the stream is buffering `client.should_buffer` is set to true. Otherwise the\nvariable is always set to false. That way you can decide when to reduce your\nsend rate and resume sending commands when you get `drain`.\n\nYou can also check the return value of each command as it will also return the\nbackpressure indicator (deprecated). If false is returned the stream had to\nbuffer.\n\n### \"warning\"\n\n`client` will emit `warning` when password was set but none is needed and if a\ndeprecated option / function / similar is used.\n\n### \"idle\" (deprecated)\n\n`client` will emit `idle` when there are no outstanding commands that are\nawaiting a response.\n\n## redis.createClient()\nIf you have `redis-server` running on the same machine as node, then the\ndefaults for port and host are probably fine and you don't need to supply any\narguments. `createClient()` returns a `RedisClient` object. Otherwise,\n`createClient()` accepts these arguments:\n\n* `redis.createClient([options])`\n* `redis.createClient(unix_socket[, options])`\n* `redis.createClient(redis_url[, options])`\n* `redis.createClient(port[, host][, options])`\n\n__Tip:__ If the Redis server runs on the same machine as the client consider\nusing unix sockets if possible to increase throughput.\n\n#### `options` object properties\n| Property  | Default   | Description |\n|-----------|-----------|-------------|\n| host      | 127.0.0.1 | IP address of the Redis server |\n| port      | 6379      | Port of the Redis server |\n| path      | null      | The UNIX socket string of the Redis server |\n| url       | null      | The URL of the Redis server. Format: `[redis:]//[[user][:password@]][host][:port][/db-number][?db=db-number[&password=bar[&option=value]]]` (More info avaliable at [IANA](http://www.iana.org/assignments/uri-schemes/prov/redis)). |\n| parser    | javascript | __Deprecated__ Use either the built-in JS parser [`javascript`]() or the native [`hiredis`]() parser. __Note__ `node_redis` < 2.6 uses hiredis as default if installed. This changed in v.2.6.0. |\n| string_numbers | null | Set to `true`, `node_redis` will return Redis number values as Strings instead of javascript Numbers. Useful if you need to handle big numbers (above `Number.MAX_SAFE_INTEGER === 2^53`). Hiredis is incapable of this behavior, so setting this option to `true` will result in the built-in javascript parser being used no matter the value of the `parser` option. |\n| return_buffers | false | If set to `true`, then all replies will be sent to callbacks as Buffers instead of Strings. |\n| detect_buffers | false | If set to `true`, then replies will be sent to callbacks as Buffers. This option lets you switch between Buffers and Strings on a per-command basis, whereas `return_buffers` applies to every command on a client. __Note__: This doesn't work properly with the pubsub mode. A subscriber has to either always return Strings or Buffers. |\n| socket_keepalive | true | If set to `true`, the keep-alive functionality is enabled on the underlying socket. |\n| no_ready_check | false |  When a connection is established to the Redis server, the server might still be loading the database from disk. While loading, the server will not respond to any commands. To work around this, `node_redis` has a \"ready check\" which sends the `INFO` command to the server. The response from the `INFO` command indicates whether the server is ready for more commands. When ready, `node_redis` emits a `ready` event. Setting `no_ready_check` to `true` will inhibit this check. |\n| enable_offline_queue |  true | By default, if there is no active connection to the Redis server, commands are added to a queue and are executed once the connection has been established. Setting `enable_offline_queue` to `false` will disable this feature and the callback will be executed immediately with an error, or an error will be emitted if no callback is specified. |\n| retry_max_delay | null | __Deprecated__ _Please use `retry_strategy` instead._ By default, every time the client tries to connect and fails, the reconnection delay almost doubles. This delay normally grows infinitely, but setting `retry_max_delay` limits it to the maximum value provided in milliseconds. |\n| connect_timeout | 3600000 | __Deprecated__ _Please use `retry_strategy` instead._ Setting `connect_timeout` limits the total time for the client to connect and reconnect. The value is provided in milliseconds and is counted from the moment a new client is created or from the time the connection is lost. The last retry is going to happen exactly at the timeout time. Default is to try connecting until the default system socket timeout has been exceeded and to try reconnecting until 1h has elapsed. |\n| max_attempts | 0 | __Deprecated__ _Please use `retry_strategy` instead._ By default, a client will try reconnecting until connected. Setting `max_attempts` limits total amount of connection attempts. Setting this to 1 will prevent any reconnect attempt. |\n| retry_unfulfilled_commands | false | If set to `true`, all commands that were unfulfilled while the connection is lost will be retried after the connection has been reestablished. Use this with caution if you use state altering commands (e.g. `incr`). This is especially useful if you use blocking commands. |\n| password | null | If set, client will run Redis auth command on connect. Alias `auth_pass` __Note__ `node_redis` < 2.5 must use `auth_pass` |\n| db | null | If set, client will run Redis `select` command on connect. |\n| family | IPv4 | You can force using IPv6 if you set the family to 'IPv6'. See Node.js [net](https://nodejs.org/api/net.html) or [dns](https://nodejs.org/api/dns.html) modules on how to use the family type. |\n| disable_resubscribing | false | If set to `true`, a client won't resubscribe after disconnecting. |\n| rename_commands | null | Passing an object with renamed commands to use instead of the original functions. For example, if you renamed the command KEYS to \"DO-NOT-USE\" then the rename_commands object would be: `{ KEYS : \"DO-NOT-USE\" }` . See the [Redis security topics](http://redis.io/topics/security) for more info. |\n| tls | null | An object containing options to pass to [tls.connect](http://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback) to set up a TLS connection to Redis (if, for example, it is set up to be accessible via a tunnel). |\n| prefix | null | A string used to prefix all used keys (e.g. `namespace:test`). Please be aware that the `keys` command will not be prefixed. The `keys` command has a \"pattern\" as argument and no key and it would be impossible to determine the existing keys in Redis if this would be prefixed. |\n| retry_strategy | function | A function that receives an options object as parameter including the retry `attempt`, the `total_retry_time` indicating how much time passed since the last time connected, the `error` why the connection was lost and the number of `times_connected` in total. If you return a number from this function, the retry will happen exactly after that time in milliseconds. If you return a non-number, no further retry will happen and all offline commands are flushed with errors. Return an error to return that specific error to all offline commands. Example below. |\n\n```js\nvar redis = require(\"redis\");\nvar client = redis.createClient({detect_buffers: true});\n\nclient.set(\"foo_rand000000000000\", \"OK\");\n\n// This will return a JavaScript String\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(reply.toString()); // Will print `OK`\n});\n\n// This will return a Buffer since original key is specified as a Buffer\nclient.get(new Buffer(\"foo_rand000000000000\"), function (err, reply) {\n    console.log(reply.toString()); // Will print `<Buffer 4f 4b>`\n});\nclient.quit();\n```\n\nretry_strategy example\n\n```js\nvar client = redis.createClient({\n    retry_strategy: function (options) {\n        if (options.error && options.error.code === 'ECONNREFUSED') {\n            // End reconnecting on a specific error and flush all commands with\n            // a individual error\n            return new Error('The server refused the connection');\n        }\n        if (options.total_retry_time > 1000 * 60 * 60) {\n            // End reconnecting after a specific timeout and flush all commands\n            // with a individual error\n            return new Error('Retry time exhausted');\n        }\n        if (options.attempt > 10) {\n            // End reconnecting with built in error\n            return undefined;\n        }\n        // reconnect after\n        return Math.min(options.attempt * 100, 3000);\n    }\n});\n```\n\n## client.auth(password[, callback])\n\nWhen connecting to a Redis server that requires authentication, the `AUTH`\ncommand must be sent as the first command after connecting. This can be tricky\nto coordinate with reconnections, the ready check, etc. To make this easier,\n`client.auth()` stashes `password` and will send it after each connection,\nincluding reconnections. `callback` is invoked only once, after the response to\nthe very first `AUTH` command sent.\nNOTE: Your call to `client.auth()` should not be inside the ready handler. If\nyou are doing this wrong, `client` will emit an error that looks\nsomething like this `Error: Ready check failed: ERR operation not permitted`.\n\n## backpressure\n\n### stream\n\nThe client exposed the used [stream](https://nodejs.org/api/stream.html) in\n`client.stream` and if the stream or client had to\n[buffer](https://nodejs.org/api/stream.html#stream_writable_write_chunk_encoding_callback)\nthe command in `client.should_buffer`. In combination this can be used to\nimplement backpressure by checking the buffer state before sending a command and\nlistening to the stream\n[drain](https://nodejs.org/api/stream.html#stream_event_drain) event.\n\n## client.quit()\n\nThis sends the quit command to the redis server and ends cleanly right after all\nrunning commands were properly handled. If this is called while reconnecting\n(and therefore no connection to the redis server exists) it is going to end the\nconnection right away instead of resulting in further reconnections! All offline\ncommands are going to be flushed with an error in that case.\n\n## client.end(flush)\n\nForcibly close the connection to the Redis server. Note that this does not wait\nuntil all replies have been parsed. If you want to exit cleanly, call\n`client.quit()` as mentioned above.\n\nYou should set flush to true, if you are not absolutely sure you do not care\nabout any other commands. If you set flush to false all still running commands\nwill silently fail.\n\nThis example closes the connection to the Redis server before the replies have\nbeen read. You probably don't want to do this:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.set(\"foo_rand000000000000\", \"some fantastic value\", function (err, reply) {\n    // This will either result in an error (flush parameter is set to true)\n    // or will silently fail and this callback will not be called at all (flush set to false)\n    console.log(err);\n});\nclient.end(true); // No further commands will be processed\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(err); // => 'The connection has already been closed.'\n});\n```\n\n`client.end()` without the flush parameter set to true should NOT be used in production!\n\n## Error handling (>= v.2.6)\n\nCurrently the following error subclasses exist:\n\n* `RedisError`: _All errors_ returned by the client\n* `ReplyError` subclass of `RedisError`: All errors returned by __Redis__ itself\n* `AbortError` subclass of `RedisError`: All commands that could not finish due\n  to what ever reason\n* `ParserError` subclass of `RedisError`: Returned in case of a parser error\n  (this should not happen)\n* `AggregateError` subclass of `AbortError`: Emitted in case multiple unresolved\n  commands without callback got rejected in debug_mode instead of lots of\n  `AbortError`s.\n\nAll error classes are exported by the module.\n\nExample:\n```js\nvar redis = require('./');\nvar assert = require('assert');\nvar client = redis.createClient();\n\nclient.on('error', function (err) {\n    assert(err instanceof Error);\n    assert(err instanceof redis.AbortError);\n    assert(err instanceof redis.AggregateError);\n    // The set and get get aggregated in here\n    assert.strictEqual(err.errors.length, 2);\n    assert.strictEqual(err.code, 'NR_CLOSED');\n});\nclient.set('foo', 123, 'bar', function (err, res) { // Too many arguments\n    assert(err instanceof redis.ReplyError); // => true\n    assert.strictEqual(err.command, 'SET');\n    assert.deepStrictEqual(err.args, ['foo', 123, 'bar']);\n\n    redis.debug_mode = true;\n    client.set('foo', 'bar');\n    client.get('foo');\n    process.nextTick(function () {\n        // Force closing the connection while the command did not yet return\n        client.end(true);\n        redis.debug_mode = false;\n    });\n});\n\n```\n\nEvery `ReplyError` contains the `command` name in all-caps and the arguments (`args`).\n\nIf node_redis emits a library error because of another error, the triggering\nerror is added to the returned error as `origin` attribute.\n\n___Error codes___\n\nnode_redis returns a `NR_CLOSED` error code if the clients connection dropped.\nIf a command unresolved command got rejected a `UNCERTAIN_STATE` code is\nreturned. A `CONNECTION_BROKEN` error code is used in case node_redis gives up\nto reconnect.\n\n## client.unref()\n\nCall `unref()` on the underlying socket connection to the Redis server, allowing\nthe program to exit once no more commands are pending.\n\nThis is an **experimental** feature, and only supports a subset of the Redis\nprotocol. Any commands where client state is saved on the Redis server, e.g.\n`*SUBSCRIBE` or the blocking `BL*` commands will *NOT* work with `.unref()`.\n\n```js\nvar redis = require(\"redis\")\nvar client = redis.createClient()\n\n/*\n    Calling unref() will allow this program to exit immediately after the get\n    command finishes. Otherwise the client would hang as long as the\n    client-server connection is alive.\n*/\nclient.unref()\nclient.get(\"foo\", function (err, value){\n    if (err) throw(err)\n    console.log(value)\n})\n```\n\n## Friendlier hash commands\n\nMost Redis commands take a single String or an Array of Strings as arguments,\nand replies are sent back as a single String or an Array of Strings. When\ndealing with hash values, there are a couple of useful exceptions to this.\n\n### client.hgetall(hash, callback)\n\nThe reply from an HGETALL command will be converted into a JavaScript Object by\n`node_redis`. That way you can interact with the responses using JavaScript\nsyntax.\n\nExample:\n\n```js\nclient.hmset(\"hosts\", \"mjr\", \"1\", \"another\", \"23\", \"home\", \"1234\");\nclient.hgetall(\"hosts\", function (err, obj) {\n    console.dir(obj);\n});\n```\n\nOutput:\n\n```js\n{ mjr: '1', another: '23', home: '1234' }\n```\n\n### client.hmset(hash, obj[, callback])\n\nMultiple values in a hash can be set by supplying an object:\n\n```js\nclient.HMSET(key2, {\n    \"0123456789\": \"abcdefghij\", // NOTE: key and value will be coerced to strings\n    \"some manner of key\": \"a type of value\"\n});\n```\n\nThe properties and values of this Object will be set as keys and values in the\nRedis hash.\n\n### client.hmset(hash, key1, val1, ... keyn, valn, [callback])\n\nMultiple values may also be set by supplying a list:\n\n```js\nclient.HMSET(key1, \"0123456789\", \"abcdefghij\", \"some manner of key\", \"a type of value\");\n```\n\n## Publish / Subscribe\n\nExample of the publish / subscribe API. This program opens two\nclient connections, subscribes to a channel on one of them, and publishes to that\nchannel on the other:\n\n```js\nvar redis = require(\"redis\");\nvar sub = redis.createClient(), pub = redis.createClient();\nvar msg_count = 0;\n\nsub.on(\"subscribe\", function (channel, count) {\n    pub.publish(\"a nice channel\", \"I am sending a message.\");\n    pub.publish(\"a nice channel\", \"I am sending a second message.\");\n    pub.publish(\"a nice channel\", \"I am sending my last message.\");\n});\n\nsub.on(\"message\", function (channel, message) {\n    console.log(\"sub channel \" + channel + \": \" + message);\n    msg_count += 1;\n    if (msg_count === 3) {\n        sub.unsubscribe();\n        sub.quit();\n        pub.quit();\n    }\n});\n\nsub.subscribe(\"a nice channel\");\n```\n\nWhen a client issues a `SUBSCRIBE` or `PSUBSCRIBE`, that connection is put into\na \"subscriber\" mode. At that point, only commands that modify the subscription\nset are valid and quit (and depending on the redis version ping as well). When\nthe subscription set is empty, the connection is put back into regular mode.\n\nIf you need to send regular commands to Redis while in subscriber mode, just\nopen another connection with a new client (hint: use `client.duplicate()`).\n\n## Subscriber Events\n\nIf a client has subscriptions active, it may emit these events:\n\n### \"message\" (channel, message)\n\nClient will emit `message` for every message received that matches an active subscription.\nListeners are passed the channel name as `channel` and the message as `message`.\n\n### \"pmessage\" (pattern, channel, message)\n\nClient will emit `pmessage` for every message received that matches an active\nsubscription pattern. Listeners are passed the original pattern used with\n`PSUBSCRIBE` as `pattern`, the sending channel name as `channel`, and the\nmessage as `message`.\n\n### \"message_buffer\" (channel, message)\n\nThis is the same as the `message` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `message` event at the same time as\nthe `message_buffer`, it is always going to emit a string.\n\n### \"pmessage_buffer\" (pattern, channel, message)\n\nThis is the same as the `pmessage` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `pmessage` event at the same time\nas the `pmessage_buffer`, it is always going to emit a string.\n\n### \"subscribe\" (channel, count)\n\nClient will emit `subscribe` in response to a `SUBSCRIBE` command. Listeners are\npassed the channel name as `channel` and the new count of subscriptions for this\nclient as `count`.\n\n### \"psubscribe\" (pattern, count)\n\nClient will emit `psubscribe` in response to a `PSUBSCRIBE` command. Listeners\nare passed the original pattern as `pattern`, and the new count of subscriptions\nfor this client as `count`.\n\n### \"unsubscribe\" (channel, count)\n\nClient will emit `unsubscribe` in response to a `UNSUBSCRIBE` command. Listeners\nare passed the channel name as `channel` and the new count of subscriptions for\nthis client as `count`. When `count` is 0, this client has left subscriber mode\nand no more subscriber events will be emitted.\n\n### \"punsubscribe\" (pattern, count)\n\nClient will emit `punsubscribe` in response to a `PUNSUBSCRIBE` command.\nListeners are passed the channel name as `channel` and the new count of\nsubscriptions for this client as `count`. When `count` is 0, this client has\nleft subscriber mode and no more subscriber events will be emitted.\n\n## client.multi([commands])\n\n`MULTI` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Multi` object by calling `client.multi()`. If any command fails to\nqueue, all commands are rolled back and none is going to be executed (For\nfurther information look at\n[transactions](http://redis.io/topics/transactions)).\n\n```js\nvar redis  = require(\"./index\"),\n    client = redis.createClient(), set_size = 20;\n\nclient.sadd(\"bigset\", \"a member\");\nclient.sadd(\"bigset\", \"another member\");\n\nwhile (set_size > 0) {\n    client.sadd(\"bigset\", \"member \" + set_size);\n    set_size -= 1;\n}\n\n// multi chain with an individual callback\nclient.multi()\n    .scard(\"bigset\")\n    .smembers(\"bigset\")\n    .keys(\"*\", function (err, replies) {\n        // NOTE: code in this callback is NOT atomic\n        // this only happens after the the .exec call finishes.\n        client.mget(replies, redis.print);\n    })\n    .dbsize()\n    .exec(function (err, replies) {\n        console.log(\"MULTI got \" + replies.length + \" replies\");\n        replies.forEach(function (reply, index) {\n            console.log(\"Reply \" + index + \": \" + reply.toString());\n        });\n    });\n```\n\n### Multi.exec([callback])\n\n`client.multi()` is a constructor that returns a `Multi` object. `Multi` objects\nshare all of the same command methods as `client` objects do. Commands are\nqueued up inside the `Multi` object until `Multi.exec()` is invoked.\n\nIf your code contains an syntax error an EXECABORT error is going to be thrown\nand all commands are going to be aborted. That error contains a `.errors`\nproperty that contains the concrete errors.\nIf all commands were queued successfully and an error is thrown by redis while\nprocessing the commands that error is going to be returned in the result array!\nNo other command is going to be aborted though than the onces failing.\n\nYou can either chain together `MULTI` commands as in the above example, or you\ncan queue individual commands while still sending regular client command as in\nthis example:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient(), multi;\n\n// start a separate multi command queue\nmulti = client.multi();\nmulti.incr(\"incr thing\", redis.print);\nmulti.incr(\"incr other thing\", redis.print);\n\n// runs immediately\nclient.mset(\"incr thing\", 100, \"incr other thing\", 1, redis.print);\n\n// drains multi queue and runs atomically\nmulti.exec(function (err, replies) {\n    console.log(replies); // 101, 2\n});\n```\n\nIn addition to adding commands to the `MULTI` queue individually, you can also\npass an array of commands and arguments to the constructor:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient();\n\nclient.multi([\n    [\"mget\", \"multifoo\", \"multibar\", redis.print],\n    [\"incr\", \"multifoo\"],\n    [\"incr\", \"multibar\"]\n]).exec(function (err, replies) {\n    console.log(replies);\n});\n```\n\n### Multi.exec_atomic([callback])\n\nIdentical to Multi.exec but with the difference that executing a single command\nwill not use transactions.\n\n## client.batch([commands])\n\nIdentical to .multi without transactions. This is recommended if you want to\nexecute many commands at once but don't have to rely on transactions.\n\n`BATCH` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Batch` object by calling `client.batch()`. The only difference\nbetween .batch and .multi is that no transaction is going to be used.\nBe aware that the errors are - just like in multi statements - in the result.\nOtherwise both, errors and results could be returned at the same time.\n\nIf you fire many commands at once this is going to boost the execution speed\nsignificantly compared to firing the same commands in a loop without waiting for\nthe result! See the benchmarks for further comparison. Please remember that all\ncommands are kept in memory until they are fired.\n\n## Monitor mode\n\nRedis supports the `MONITOR` command, which lets you see all commands received\nby the Redis server across all client connections, including from other client\nlibraries and other computers.\n\nA `monitor` event is going to be emitted for every command fired from any client\nconnected to the server including the monitoring client itself. The callback for\nthe `monitor` event takes a timestamp from the Redis server, an array of command\narguments and the raw monitoring string.\n\nExample:\n\n```js\nvar client  = require(\"redis\").createClient();\nclient.monitor(function (err, res) {\n    console.log(\"Entering monitoring mode.\");\n});\nclient.set('foo', 'bar');\n\nclient.on(\"monitor\", function (time, args, raw_reply) {\n    console.log(time + \": \" + args); // 1458910076.446514:['set', 'foo', 'bar']\n});\n```\n\n# Extras\n\nSome other things you might like to know about.\n\n## client.server_info\n\nAfter the ready probe completes, the results from the INFO command are saved in\nthe `client.server_info` object.\n\nThe `versions` key contains an array of the elements of the version string for\neasy comparison.\n\n    > client.server_info.redis_version\n    '2.3.0'\n    > client.server_info.versions\n    [ 2, 3, 0 ]\n\n## redis.print()\n\nA handy callback function for displaying return values when testing. Example:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.on(\"connect\", function () {\n    client.set(\"foo_rand000000000000\", \"some fantastic value\", redis.print);\n    client.get(\"foo_rand000000000000\", redis.print);\n});\n```\n\nThis will print:\n\n    Reply: OK\n    Reply: some fantastic value\n\nNote that this program will not exit cleanly because the client is still connected.\n\n## Multi-word commands\n\nTo execute redis multi-word commands like `SCRIPT LOAD` or `CLIENT LIST` pass\nthe second word as first parameter:\n\n    client.script('load', 'return 1');\n    client.multi().script('load', 'return 1').exec(...);\n    client.multi([['script', 'load', 'return 1']]).exec(...);\n\n## client.duplicate([options][, callback])\n\nDuplicate all current options and return a new redisClient instance. All options\npassed to the duplicate function are going to replace the original option. If\nyou pass a callback, duplicate is going to wait until the client is ready and\nreturns it in the callback. If an error occurs in the meanwhile, that is going\nto return an error instead in the callback.\n\nOne example of when to use duplicate() would be to accommodate the connection-\nblocking redis commands BRPOP, BLPOP, and BRPOPLPUSH.  If these commands\nare used on the same redisClient instance as non-blocking commands, the\nnon-blocking ones may be queued up until after the blocking ones finish.\n\n    var Redis=require('redis');\n    var client = Redis.createClient();\n    var clientBlocking = client.duplicate();\n\n    var get = function() {\n        console.log(\"get called\");\n        client.get(\"any_key\",function() { console.log(\"get returned\"); });\n        setTimeout( get, 1000 );\n    };\n    var brpop = function() {\n        console.log(\"brpop called\");\n        clientBlocking.brpop(\"nonexistent\", 5, function() {\n            console.log(\"brpop return\");\n            setTimeout( brpop, 1000 );\n        });\n    };\n    get();\n    brpop();\n\nAnother reason to use duplicate() is when multiple DBs on the same server are\naccessed via the redis SELECT command.  Each DB could use its own connection.\n\n## client.send_command(command_name[, [args][, callback]])\n\nAll Redis commands have been added to the `client` object. However, if new\ncommands are introduced before this library is updated or if you want to add\nindividual commands you can use `send_command()` to send arbitrary commands to\nRedis.\n\nAll commands are sent as multi-bulk commands. `args` can either be an Array of\narguments, or omitted / set to undefined.\n\n## client.add_command(command_name)\n\nCalling add_command will add a new command to the prototype. The exact command\nname will be used when calling using this new command. Using arbitrary arguments\nis possible as with any other command.\n\n## client.connected\n\nBoolean tracking the state of the connection to the Redis server.\n\n## client.command_queue_length\n\nThe number of commands that have been sent to the Redis server but not yet\nreplied to. You can use this to enforce some kind of maximum queue depth for\ncommands while connected.\n\n## client.offline_queue_length\n\nThe number of commands that have been queued up for a future connection. You can\nuse this to enforce some kind of maximum queue depth for pre-connection\ncommands.\n\n### Commands with Optional and Keyword arguments\n\nThis applies to anything that uses an optional `[WITHSCORES]` or `[LIMIT offset\ncount]` in the [redis.io/commands](http://redis.io/commands) documentation.\n\nExample:\n\n```js\nvar args = [ 'myzset', 1, 'one', 2, 'two', 3, 'three', 99, 'ninety-nine' ];\nclient.zadd(args, function (err, response) {\n    if (err) throw err;\n    console.log('added '+response+' items.');\n\n    // -Infinity and +Infinity also work\n    var args1 = [ 'myzset', '+inf', '-inf' ];\n    client.zrevrangebyscore(args1, function (err, response) {\n        if (err) throw err;\n        console.log('example1', response);\n        // write your code here\n    });\n\n    var max = 3, min = 1, offset = 1, count = 2;\n    var args2 = [ 'myzset', max, min, 'WITHSCORES', 'LIMIT', offset, count ];\n    client.zrevrangebyscore(args2, function (err, response) {\n        if (err) throw err;\n        console.log('example2', response);\n        // write your code here\n    });\n});\n```\n\n## Performance\n\nMuch effort has been spent to make `node_redis` as fast as possible for common\noperations.\n\n```\nLenovo T450s, i7-5600U and 12gb memory\nclients: 1, NodeJS: 6.2.0, Redis: 3.2.0, parser: javascript, connected by: tcp\n         PING,         1/1 avg/max:   0.02/  5.26 2501ms total,   46916 ops/sec\n         PING,  batch 50/1 avg/max:   0.06/  4.35 2501ms total,  755178 ops/sec\n   SET 4B str,         1/1 avg/max:   0.02/  4.75 2501ms total,   40856 ops/sec\n   SET 4B str,  batch 50/1 avg/max:   0.11/  1.51 2501ms total,  432727 ops/sec\n   SET 4B buf,         1/1 avg/max:   0.05/  2.76 2501ms total,   20659 ops/sec\n   SET 4B buf,  batch 50/1 avg/max:   0.25/  1.76 2501ms total,  194962 ops/sec\n   GET 4B str,         1/1 avg/max:   0.02/  1.55 2501ms total,   45156 ops/sec\n   GET 4B str,  batch 50/1 avg/max:   0.09/  3.15 2501ms total,  524110 ops/sec\n   GET 4B buf,         1/1 avg/max:   0.02/  3.07 2501ms total,   44563 ops/sec\n   GET 4B buf,  batch 50/1 avg/max:   0.10/  3.18 2501ms total,  473171 ops/sec\n SET 4KiB str,         1/1 avg/max:   0.03/  1.54 2501ms total,   32627 ops/sec\n SET 4KiB str,  batch 50/1 avg/max:   0.34/  1.89 2501ms total,  146861 ops/sec\n SET 4KiB buf,         1/1 avg/max:   0.05/  2.85 2501ms total,   20688 ops/sec\n SET 4KiB buf,  batch 50/1 avg/max:   0.36/  1.83 2501ms total,  138165 ops/sec\n GET 4KiB str,         1/1 avg/max:   0.02/  1.37 2501ms total,   39389 ops/sec\n GET 4KiB str,  batch 50/1 avg/max:   0.24/  1.81 2501ms total,  208157 ops/sec\n GET 4KiB buf,         1/1 avg/max:   0.02/  2.63 2501ms total,   39918 ops/sec\n GET 4KiB buf,  batch 50/1 avg/max:   0.31/  8.56 2501ms total,  161575 ops/sec\n         INCR,         1/1 avg/max:   0.02/  4.69 2501ms total,   45685 ops/sec\n         INCR,  batch 50/1 avg/max:   0.09/  3.06 2501ms total,  539964 ops/sec\n        LPUSH,         1/1 avg/max:   0.02/  3.04 2501ms total,   41253 ops/sec\n        LPUSH,  batch 50/1 avg/max:   0.12/  1.94 2501ms total,  425090 ops/sec\n    LRANGE 10,         1/1 avg/max:   0.02/  2.28 2501ms total,   39850 ops/sec\n    LRANGE 10,  batch 50/1 avg/max:   0.25/  1.85 2501ms total,  194302 ops/sec\n   LRANGE 100,         1/1 avg/max:   0.05/  2.93 2501ms total,   21026 ops/sec\n   LRANGE 100,  batch 50/1 avg/max:   1.52/  2.89 2501ms total,   32767 ops/sec\n SET 4MiB str,         1/1 avg/max:   5.16/ 15.55 2502ms total,     193 ops/sec\n SET 4MiB str,  batch 20/1 avg/max:  89.73/ 99.96 2513ms total,     223 ops/sec\n SET 4MiB buf,         1/1 avg/max:   2.23/  8.35 2501ms total,     446 ops/sec\n SET 4MiB buf,  batch 20/1 avg/max:  41.47/ 50.91 2530ms total,     482 ops/sec\n GET 4MiB str,         1/1 avg/max:   2.79/ 10.91 2502ms total,     358 ops/sec\n GET 4MiB str,  batch 20/1 avg/max: 101.61/118.11 2541ms total,     197 ops/sec\n GET 4MiB buf,         1/1 avg/max:   2.32/ 14.93 2502ms total,     430 ops/sec\n GET 4MiB buf,  batch 20/1 avg/max:  65.01/ 84.72 2536ms total,     308 ops/sec\n ```\n\n## Debugging\n\nTo get debug output run your `node_redis` application with `NODE_DEBUG=redis`.\n\nThis is also going to result in good stack traces opposed to useless ones\notherwise for any async operation.\nIf you only want to have good stack traces but not the debug output run your\napplication in development mode instead (`NODE_ENV=development`).\n\nGood stack traces are only activated in development and debug mode as this\nresults in a significant performance penalty.\n\n___Comparison___:\nUseless stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at parseError (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:158:12)\n    at parseType (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:219:14)\n```\nGood stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at new Command (/home/ruben/repos/redis/lib/command.js:9:902)\n    at RedisClient.set (/home/ruben/repos/redis/lib/commands.js:9:3238)\n    at Context.<anonymous> (/home/ruben/repos/redis/test/good_stacks.spec.js:20:20)\n    at callFnAsync (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:349:8)\n    at Test.Runnable.run (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:301:7)\n    at Runner.runTest (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:422:10)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:528:12\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:342:14)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:352:7\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:284:14)\n    at Immediate._onImmediate (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:320:5)\n    at processImmediate [as _immediateCallback] (timers.js:383:17)\n```\n\n## How to Contribute\n- Open a pull request or an issue about what you want to implement / change. We're glad for any help!\n - Please be aware that we'll only accept fully tested code.\n\n## Contributors\n\nThe original author of node_redis is [Matthew Ranney](https://github.com/mranney)\n\nThe current lead maintainer is [Ruben Bridgewater](https://github.com/BridgeAR)\n\nMany [others](https://github.com/NodeRedis/node_redis/graphs/contributors)\ncontributed to `node_redis` too. Thanks to all of them!\n\n## License\n\n[MIT](LICENSE)\n\n### Consolidation: It's time for celebration\n\nRight now there are two great redis clients around and both have some advantages\nabove each other. We speak about ioredis and node_redis. So after talking to\neach other about how we could improve in working together we (that is @luin and\n@BridgeAR) decided to work towards a single library on the long run. But step by\nstep.\n\nFirst of all, we want to split small parts of our libraries into others so that\nwe're both able to use the same code. Those libraries are going to be maintained\nunder the NodeRedis organization. This is going to reduce the maintenance\noverhead, allows others to use the very same code, if they need it and it's way\neasyer for others to contribute to both libraries.\n\nWe're very happy about this step towards working together as we both want to\ngive you the best redis experience possible.\n\nIf you want to join our cause by help maintaining something, please don't\nhesitate to contact either one of us.","toc":false,"date":"2017-10-10T14:48:05.000Z","_content":"\nredis - a node.js redis client\n===========================\n\n[![Build Status](https://travis-ci.org/NodeRedis/node_redis.svg?branch=master)](https://travis-ci.org/NodeRedis/node_redis)\n[![Coverage Status](https://coveralls.io/repos/NodeRedis/node_redis/badge.svg?branch=)](https://coveralls.io/r/NodeRedis/node_redis?branch=)\n[![Windows Tests](https://img.shields.io/appveyor/ci/BridgeAR/node-redis/master.svg?label=Windows%20Tests)](https://ci.appveyor.com/project/BridgeAR/node-redis/branch/master)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/NodeRedis/node_redis?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\nThis is a complete and feature rich Redis client for node.js. __It supports all\nRedis commands__ and focuses on high performance.\n\n<!-- more -->\n\nInstall with:\n\n    npm install redis\n\n## Usage Example\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\n// if you'd like to select database 3, instead of 0 (default), call\n// client.select(3, function() { /* ... */ });\n\nclient.on(\"error\", function (err) {\n    console.log(\"Error \" + err);\n});\n\nclient.set(\"string key\", \"string val\", redis.print);\nclient.hset(\"hash key\", \"hashtest 1\", \"some value\", redis.print);\nclient.hset([\"hash key\", \"hashtest 2\", \"some other value\"], redis.print);\nclient.hkeys(\"hash key\", function (err, replies) {\n    console.log(replies.length + \" replies:\");\n    replies.forEach(function (reply, i) {\n        console.log(\"    \" + i + \": \" + reply);\n    });\n    client.quit();\n});\n```\n\nThis will display:\n\n    mjr:~/work/node_redis (master)$ node example.js\n    Reply: OK\n    Reply: 0\n    Reply: 0\n    2 replies:\n        0: hashtest 1\n        1: hashtest 2\n    mjr:~/work/node_redis (master)$\n\nNote that the API is entirely asynchronous. To get data back from the server,\nyou'll need to use a callback. From v.2.6 on the API supports camelCase and\nsnake_case and all options / variables / events etc. can be used either way. It\nis recommended to use camelCase as this is the default for the Node.js\nlandscape.\n\n### Promises\n\nYou can also use node_redis with promises by promisifying node_redis with\n[bluebird](https://github.com/petkaantonov/bluebird) as in:\n\n```js\nvar redis = require('redis');\nbluebird.promisifyAll(redis.RedisClient.prototype);\nbluebird.promisifyAll(redis.Multi.prototype);\n```\n\nIt'll add a *Async* to all node_redis functions (e.g. return client.getAsync().then())\n\n```js\n// We expect a value 'foo': 'bar' to be present\n// So instead of writing client.get('foo', cb); you have to write:\nreturn client.getAsync('foo').then(function(res) {\n    console.log(res); // => 'bar'\n});\n\n// Using multi with promises looks like:\n\nreturn client.multi().get('foo').execAsync().then(function(res) {\n    console.log(res); // => 'bar'\n});\n```\n\n### Sending Commands\n\nEach Redis command is exposed as a function on the `client` object.\nAll functions take either an `args` Array plus optional `callback` Function or\na variable number of individual arguments followed by an optional callback.\nExamples:\n\n```js\nclient.hmset([\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Works the same as\nclient.hmset(\"key\", [\"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Or\nclient.hmset(\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\", function (err, res) {});\n```\n\nCare should be taken with user input if arrays are possible (via body-parser, query string or other method), as single arguments could be unintentionally interpreted as multiple args.\n\nNote that in either form the `callback` is optional:\n\n```js\nclient.set(\"some key\", \"some val\");\nclient.set([\"some other key\", \"some val\"]);\n```\n\nIf the key is missing, reply will be null. Only if the [Redis Command\nReference](http://redis.io/commands) states something else it will not be null.\n\n```js\nclient.get(\"missingkey\", function(err, reply) {\n    // reply is null when the key is missing\n    console.log(reply);\n});\n```\n\nFor a list of Redis commands, see [Redis Command Reference](http://redis.io/commands)\n\nMinimal parsing is done on the replies. Commands that return a integer return\nJavaScript Numbers, arrays return JavaScript Array. `HGETALL` returns an Object\nkeyed by the hash keys. All strings will either be returned as string or as\nbuffer depending on your setting. Please be aware that sending null, undefined\nand Boolean values will result in the value coerced to a string!\n\n# Redis Commands\n\nThis library is a 1 to 1 mapping to [Redis commands](https://redis.io/commands).\nIt is not a cache library so please refer to Redis commands page for full usage\ndetails.\n\nExample setting key to auto expire using [SET command](https://redis.io/commands/set)\n\n```js\n// this key will expire after 10 seconds\nclient.set('key', 'value!', 'EX', 10);\n```\n\n# API\n\n## Connection and other Events\n\n`client` will emit some events about the state of the connection to the Redis server.\n\n### \"ready\"\n\n`client` will emit `ready` once a connection is established. Commands issued\nbefore the `ready` event are queued, then replayed just before this event is\nemitted.\n\n### \"connect\"\n\n`client` will emit `connect` as soon as the stream is connected to the server.\n\n### \"reconnecting\"\n\n`client` will emit `reconnecting` when trying to reconnect to the Redis server\nafter losing the connection. Listeners are passed an object containing `delay`\n(in ms) and `attempt` (the attempt #) attributes.\n\n### \"error\"\n\n`client` will emit `error` when encountering an error connecting to the Redis\nserver or when any other in node_redis occurs. If you use a command without\ncallback and encounter a ReplyError it is going to be emitted to the error\nlistener.\n\nSo please attach the error listener to node_redis.\n\n### \"end\"\n\n`client` will emit `end` when an established Redis server connection has closed.\n\n### \"drain\" (deprecated)\n\n`client` will emit `drain` when the TCP connection to the Redis server has been\nbuffering, but is now writable. This event can be used to stream commands in to\nRedis and adapt to backpressure.\n\nIf the stream is buffering `client.should_buffer` is set to true. Otherwise the\nvariable is always set to false. That way you can decide when to reduce your\nsend rate and resume sending commands when you get `drain`.\n\nYou can also check the return value of each command as it will also return the\nbackpressure indicator (deprecated). If false is returned the stream had to\nbuffer.\n\n### \"warning\"\n\n`client` will emit `warning` when password was set but none is needed and if a\ndeprecated option / function / similar is used.\n\n### \"idle\" (deprecated)\n\n`client` will emit `idle` when there are no outstanding commands that are\nawaiting a response.\n\n## redis.createClient()\nIf you have `redis-server` running on the same machine as node, then the\ndefaults for port and host are probably fine and you don't need to supply any\narguments. `createClient()` returns a `RedisClient` object. Otherwise,\n`createClient()` accepts these arguments:\n\n* `redis.createClient([options])`\n* `redis.createClient(unix_socket[, options])`\n* `redis.createClient(redis_url[, options])`\n* `redis.createClient(port[, host][, options])`\n\n__Tip:__ If the Redis server runs on the same machine as the client consider\nusing unix sockets if possible to increase throughput.\n\n#### `options` object properties\n| Property  | Default   | Description |\n|-----------|-----------|-------------|\n| host      | 127.0.0.1 | IP address of the Redis server |\n| port      | 6379      | Port of the Redis server |\n| path      | null      | The UNIX socket string of the Redis server |\n| url       | null      | The URL of the Redis server. Format: `[redis:]//[[user][:password@]][host][:port][/db-number][?db=db-number[&password=bar[&option=value]]]` (More info avaliable at [IANA](http://www.iana.org/assignments/uri-schemes/prov/redis)). |\n| parser    | javascript | __Deprecated__ Use either the built-in JS parser [`javascript`]() or the native [`hiredis`]() parser. __Note__ `node_redis` < 2.6 uses hiredis as default if installed. This changed in v.2.6.0. |\n| string_numbers | null | Set to `true`, `node_redis` will return Redis number values as Strings instead of javascript Numbers. Useful if you need to handle big numbers (above `Number.MAX_SAFE_INTEGER === 2^53`). Hiredis is incapable of this behavior, so setting this option to `true` will result in the built-in javascript parser being used no matter the value of the `parser` option. |\n| return_buffers | false | If set to `true`, then all replies will be sent to callbacks as Buffers instead of Strings. |\n| detect_buffers | false | If set to `true`, then replies will be sent to callbacks as Buffers. This option lets you switch between Buffers and Strings on a per-command basis, whereas `return_buffers` applies to every command on a client. __Note__: This doesn't work properly with the pubsub mode. A subscriber has to either always return Strings or Buffers. |\n| socket_keepalive | true | If set to `true`, the keep-alive functionality is enabled on the underlying socket. |\n| no_ready_check | false |  When a connection is established to the Redis server, the server might still be loading the database from disk. While loading, the server will not respond to any commands. To work around this, `node_redis` has a \"ready check\" which sends the `INFO` command to the server. The response from the `INFO` command indicates whether the server is ready for more commands. When ready, `node_redis` emits a `ready` event. Setting `no_ready_check` to `true` will inhibit this check. |\n| enable_offline_queue |  true | By default, if there is no active connection to the Redis server, commands are added to a queue and are executed once the connection has been established. Setting `enable_offline_queue` to `false` will disable this feature and the callback will be executed immediately with an error, or an error will be emitted if no callback is specified. |\n| retry_max_delay | null | __Deprecated__ _Please use `retry_strategy` instead._ By default, every time the client tries to connect and fails, the reconnection delay almost doubles. This delay normally grows infinitely, but setting `retry_max_delay` limits it to the maximum value provided in milliseconds. |\n| connect_timeout | 3600000 | __Deprecated__ _Please use `retry_strategy` instead._ Setting `connect_timeout` limits the total time for the client to connect and reconnect. The value is provided in milliseconds and is counted from the moment a new client is created or from the time the connection is lost. The last retry is going to happen exactly at the timeout time. Default is to try connecting until the default system socket timeout has been exceeded and to try reconnecting until 1h has elapsed. |\n| max_attempts | 0 | __Deprecated__ _Please use `retry_strategy` instead._ By default, a client will try reconnecting until connected. Setting `max_attempts` limits total amount of connection attempts. Setting this to 1 will prevent any reconnect attempt. |\n| retry_unfulfilled_commands | false | If set to `true`, all commands that were unfulfilled while the connection is lost will be retried after the connection has been reestablished. Use this with caution if you use state altering commands (e.g. `incr`). This is especially useful if you use blocking commands. |\n| password | null | If set, client will run Redis auth command on connect. Alias `auth_pass` __Note__ `node_redis` < 2.5 must use `auth_pass` |\n| db | null | If set, client will run Redis `select` command on connect. |\n| family | IPv4 | You can force using IPv6 if you set the family to 'IPv6'. See Node.js [net](https://nodejs.org/api/net.html) or [dns](https://nodejs.org/api/dns.html) modules on how to use the family type. |\n| disable_resubscribing | false | If set to `true`, a client won't resubscribe after disconnecting. |\n| rename_commands | null | Passing an object with renamed commands to use instead of the original functions. For example, if you renamed the command KEYS to \"DO-NOT-USE\" then the rename_commands object would be: `{ KEYS : \"DO-NOT-USE\" }` . See the [Redis security topics](http://redis.io/topics/security) for more info. |\n| tls | null | An object containing options to pass to [tls.connect](http://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback) to set up a TLS connection to Redis (if, for example, it is set up to be accessible via a tunnel). |\n| prefix | null | A string used to prefix all used keys (e.g. `namespace:test`). Please be aware that the `keys` command will not be prefixed. The `keys` command has a \"pattern\" as argument and no key and it would be impossible to determine the existing keys in Redis if this would be prefixed. |\n| retry_strategy | function | A function that receives an options object as parameter including the retry `attempt`, the `total_retry_time` indicating how much time passed since the last time connected, the `error` why the connection was lost and the number of `times_connected` in total. If you return a number from this function, the retry will happen exactly after that time in milliseconds. If you return a non-number, no further retry will happen and all offline commands are flushed with errors. Return an error to return that specific error to all offline commands. Example below. |\n\n```js\nvar redis = require(\"redis\");\nvar client = redis.createClient({detect_buffers: true});\n\nclient.set(\"foo_rand000000000000\", \"OK\");\n\n// This will return a JavaScript String\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(reply.toString()); // Will print `OK`\n});\n\n// This will return a Buffer since original key is specified as a Buffer\nclient.get(new Buffer(\"foo_rand000000000000\"), function (err, reply) {\n    console.log(reply.toString()); // Will print `<Buffer 4f 4b>`\n});\nclient.quit();\n```\n\nretry_strategy example\n\n```js\nvar client = redis.createClient({\n    retry_strategy: function (options) {\n        if (options.error && options.error.code === 'ECONNREFUSED') {\n            // End reconnecting on a specific error and flush all commands with\n            // a individual error\n            return new Error('The server refused the connection');\n        }\n        if (options.total_retry_time > 1000 * 60 * 60) {\n            // End reconnecting after a specific timeout and flush all commands\n            // with a individual error\n            return new Error('Retry time exhausted');\n        }\n        if (options.attempt > 10) {\n            // End reconnecting with built in error\n            return undefined;\n        }\n        // reconnect after\n        return Math.min(options.attempt * 100, 3000);\n    }\n});\n```\n\n## client.auth(password[, callback])\n\nWhen connecting to a Redis server that requires authentication, the `AUTH`\ncommand must be sent as the first command after connecting. This can be tricky\nto coordinate with reconnections, the ready check, etc. To make this easier,\n`client.auth()` stashes `password` and will send it after each connection,\nincluding reconnections. `callback` is invoked only once, after the response to\nthe very first `AUTH` command sent.\nNOTE: Your call to `client.auth()` should not be inside the ready handler. If\nyou are doing this wrong, `client` will emit an error that looks\nsomething like this `Error: Ready check failed: ERR operation not permitted`.\n\n## backpressure\n\n### stream\n\nThe client exposed the used [stream](https://nodejs.org/api/stream.html) in\n`client.stream` and if the stream or client had to\n[buffer](https://nodejs.org/api/stream.html#stream_writable_write_chunk_encoding_callback)\nthe command in `client.should_buffer`. In combination this can be used to\nimplement backpressure by checking the buffer state before sending a command and\nlistening to the stream\n[drain](https://nodejs.org/api/stream.html#stream_event_drain) event.\n\n## client.quit()\n\nThis sends the quit command to the redis server and ends cleanly right after all\nrunning commands were properly handled. If this is called while reconnecting\n(and therefore no connection to the redis server exists) it is going to end the\nconnection right away instead of resulting in further reconnections! All offline\ncommands are going to be flushed with an error in that case.\n\n## client.end(flush)\n\nForcibly close the connection to the Redis server. Note that this does not wait\nuntil all replies have been parsed. If you want to exit cleanly, call\n`client.quit()` as mentioned above.\n\nYou should set flush to true, if you are not absolutely sure you do not care\nabout any other commands. If you set flush to false all still running commands\nwill silently fail.\n\nThis example closes the connection to the Redis server before the replies have\nbeen read. You probably don't want to do this:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.set(\"foo_rand000000000000\", \"some fantastic value\", function (err, reply) {\n    // This will either result in an error (flush parameter is set to true)\n    // or will silently fail and this callback will not be called at all (flush set to false)\n    console.log(err);\n});\nclient.end(true); // No further commands will be processed\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(err); // => 'The connection has already been closed.'\n});\n```\n\n`client.end()` without the flush parameter set to true should NOT be used in production!\n\n## Error handling (>= v.2.6)\n\nCurrently the following error subclasses exist:\n\n* `RedisError`: _All errors_ returned by the client\n* `ReplyError` subclass of `RedisError`: All errors returned by __Redis__ itself\n* `AbortError` subclass of `RedisError`: All commands that could not finish due\n  to what ever reason\n* `ParserError` subclass of `RedisError`: Returned in case of a parser error\n  (this should not happen)\n* `AggregateError` subclass of `AbortError`: Emitted in case multiple unresolved\n  commands without callback got rejected in debug_mode instead of lots of\n  `AbortError`s.\n\nAll error classes are exported by the module.\n\nExample:\n```js\nvar redis = require('./');\nvar assert = require('assert');\nvar client = redis.createClient();\n\nclient.on('error', function (err) {\n    assert(err instanceof Error);\n    assert(err instanceof redis.AbortError);\n    assert(err instanceof redis.AggregateError);\n    // The set and get get aggregated in here\n    assert.strictEqual(err.errors.length, 2);\n    assert.strictEqual(err.code, 'NR_CLOSED');\n});\nclient.set('foo', 123, 'bar', function (err, res) { // Too many arguments\n    assert(err instanceof redis.ReplyError); // => true\n    assert.strictEqual(err.command, 'SET');\n    assert.deepStrictEqual(err.args, ['foo', 123, 'bar']);\n\n    redis.debug_mode = true;\n    client.set('foo', 'bar');\n    client.get('foo');\n    process.nextTick(function () {\n        // Force closing the connection while the command did not yet return\n        client.end(true);\n        redis.debug_mode = false;\n    });\n});\n\n```\n\nEvery `ReplyError` contains the `command` name in all-caps and the arguments (`args`).\n\nIf node_redis emits a library error because of another error, the triggering\nerror is added to the returned error as `origin` attribute.\n\n___Error codes___\n\nnode_redis returns a `NR_CLOSED` error code if the clients connection dropped.\nIf a command unresolved command got rejected a `UNCERTAIN_STATE` code is\nreturned. A `CONNECTION_BROKEN` error code is used in case node_redis gives up\nto reconnect.\n\n## client.unref()\n\nCall `unref()` on the underlying socket connection to the Redis server, allowing\nthe program to exit once no more commands are pending.\n\nThis is an **experimental** feature, and only supports a subset of the Redis\nprotocol. Any commands where client state is saved on the Redis server, e.g.\n`*SUBSCRIBE` or the blocking `BL*` commands will *NOT* work with `.unref()`.\n\n```js\nvar redis = require(\"redis\")\nvar client = redis.createClient()\n\n/*\n    Calling unref() will allow this program to exit immediately after the get\n    command finishes. Otherwise the client would hang as long as the\n    client-server connection is alive.\n*/\nclient.unref()\nclient.get(\"foo\", function (err, value){\n    if (err) throw(err)\n    console.log(value)\n})\n```\n\n## Friendlier hash commands\n\nMost Redis commands take a single String or an Array of Strings as arguments,\nand replies are sent back as a single String or an Array of Strings. When\ndealing with hash values, there are a couple of useful exceptions to this.\n\n### client.hgetall(hash, callback)\n\nThe reply from an HGETALL command will be converted into a JavaScript Object by\n`node_redis`. That way you can interact with the responses using JavaScript\nsyntax.\n\nExample:\n\n```js\nclient.hmset(\"hosts\", \"mjr\", \"1\", \"another\", \"23\", \"home\", \"1234\");\nclient.hgetall(\"hosts\", function (err, obj) {\n    console.dir(obj);\n});\n```\n\nOutput:\n\n```js\n{ mjr: '1', another: '23', home: '1234' }\n```\n\n### client.hmset(hash, obj[, callback])\n\nMultiple values in a hash can be set by supplying an object:\n\n```js\nclient.HMSET(key2, {\n    \"0123456789\": \"abcdefghij\", // NOTE: key and value will be coerced to strings\n    \"some manner of key\": \"a type of value\"\n});\n```\n\nThe properties and values of this Object will be set as keys and values in the\nRedis hash.\n\n### client.hmset(hash, key1, val1, ... keyn, valn, [callback])\n\nMultiple values may also be set by supplying a list:\n\n```js\nclient.HMSET(key1, \"0123456789\", \"abcdefghij\", \"some manner of key\", \"a type of value\");\n```\n\n## Publish / Subscribe\n\nExample of the publish / subscribe API. This program opens two\nclient connections, subscribes to a channel on one of them, and publishes to that\nchannel on the other:\n\n```js\nvar redis = require(\"redis\");\nvar sub = redis.createClient(), pub = redis.createClient();\nvar msg_count = 0;\n\nsub.on(\"subscribe\", function (channel, count) {\n    pub.publish(\"a nice channel\", \"I am sending a message.\");\n    pub.publish(\"a nice channel\", \"I am sending a second message.\");\n    pub.publish(\"a nice channel\", \"I am sending my last message.\");\n});\n\nsub.on(\"message\", function (channel, message) {\n    console.log(\"sub channel \" + channel + \": \" + message);\n    msg_count += 1;\n    if (msg_count === 3) {\n        sub.unsubscribe();\n        sub.quit();\n        pub.quit();\n    }\n});\n\nsub.subscribe(\"a nice channel\");\n```\n\nWhen a client issues a `SUBSCRIBE` or `PSUBSCRIBE`, that connection is put into\na \"subscriber\" mode. At that point, only commands that modify the subscription\nset are valid and quit (and depending on the redis version ping as well). When\nthe subscription set is empty, the connection is put back into regular mode.\n\nIf you need to send regular commands to Redis while in subscriber mode, just\nopen another connection with a new client (hint: use `client.duplicate()`).\n\n## Subscriber Events\n\nIf a client has subscriptions active, it may emit these events:\n\n### \"message\" (channel, message)\n\nClient will emit `message` for every message received that matches an active subscription.\nListeners are passed the channel name as `channel` and the message as `message`.\n\n### \"pmessage\" (pattern, channel, message)\n\nClient will emit `pmessage` for every message received that matches an active\nsubscription pattern. Listeners are passed the original pattern used with\n`PSUBSCRIBE` as `pattern`, the sending channel name as `channel`, and the\nmessage as `message`.\n\n### \"message_buffer\" (channel, message)\n\nThis is the same as the `message` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `message` event at the same time as\nthe `message_buffer`, it is always going to emit a string.\n\n### \"pmessage_buffer\" (pattern, channel, message)\n\nThis is the same as the `pmessage` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `pmessage` event at the same time\nas the `pmessage_buffer`, it is always going to emit a string.\n\n### \"subscribe\" (channel, count)\n\nClient will emit `subscribe` in response to a `SUBSCRIBE` command. Listeners are\npassed the channel name as `channel` and the new count of subscriptions for this\nclient as `count`.\n\n### \"psubscribe\" (pattern, count)\n\nClient will emit `psubscribe` in response to a `PSUBSCRIBE` command. Listeners\nare passed the original pattern as `pattern`, and the new count of subscriptions\nfor this client as `count`.\n\n### \"unsubscribe\" (channel, count)\n\nClient will emit `unsubscribe` in response to a `UNSUBSCRIBE` command. Listeners\nare passed the channel name as `channel` and the new count of subscriptions for\nthis client as `count`. When `count` is 0, this client has left subscriber mode\nand no more subscriber events will be emitted.\n\n### \"punsubscribe\" (pattern, count)\n\nClient will emit `punsubscribe` in response to a `PUNSUBSCRIBE` command.\nListeners are passed the channel name as `channel` and the new count of\nsubscriptions for this client as `count`. When `count` is 0, this client has\nleft subscriber mode and no more subscriber events will be emitted.\n\n## client.multi([commands])\n\n`MULTI` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Multi` object by calling `client.multi()`. If any command fails to\nqueue, all commands are rolled back and none is going to be executed (For\nfurther information look at\n[transactions](http://redis.io/topics/transactions)).\n\n```js\nvar redis  = require(\"./index\"),\n    client = redis.createClient(), set_size = 20;\n\nclient.sadd(\"bigset\", \"a member\");\nclient.sadd(\"bigset\", \"another member\");\n\nwhile (set_size > 0) {\n    client.sadd(\"bigset\", \"member \" + set_size);\n    set_size -= 1;\n}\n\n// multi chain with an individual callback\nclient.multi()\n    .scard(\"bigset\")\n    .smembers(\"bigset\")\n    .keys(\"*\", function (err, replies) {\n        // NOTE: code in this callback is NOT atomic\n        // this only happens after the the .exec call finishes.\n        client.mget(replies, redis.print);\n    })\n    .dbsize()\n    .exec(function (err, replies) {\n        console.log(\"MULTI got \" + replies.length + \" replies\");\n        replies.forEach(function (reply, index) {\n            console.log(\"Reply \" + index + \": \" + reply.toString());\n        });\n    });\n```\n\n### Multi.exec([callback])\n\n`client.multi()` is a constructor that returns a `Multi` object. `Multi` objects\nshare all of the same command methods as `client` objects do. Commands are\nqueued up inside the `Multi` object until `Multi.exec()` is invoked.\n\nIf your code contains an syntax error an EXECABORT error is going to be thrown\nand all commands are going to be aborted. That error contains a `.errors`\nproperty that contains the concrete errors.\nIf all commands were queued successfully and an error is thrown by redis while\nprocessing the commands that error is going to be returned in the result array!\nNo other command is going to be aborted though than the onces failing.\n\nYou can either chain together `MULTI` commands as in the above example, or you\ncan queue individual commands while still sending regular client command as in\nthis example:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient(), multi;\n\n// start a separate multi command queue\nmulti = client.multi();\nmulti.incr(\"incr thing\", redis.print);\nmulti.incr(\"incr other thing\", redis.print);\n\n// runs immediately\nclient.mset(\"incr thing\", 100, \"incr other thing\", 1, redis.print);\n\n// drains multi queue and runs atomically\nmulti.exec(function (err, replies) {\n    console.log(replies); // 101, 2\n});\n```\n\nIn addition to adding commands to the `MULTI` queue individually, you can also\npass an array of commands and arguments to the constructor:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient();\n\nclient.multi([\n    [\"mget\", \"multifoo\", \"multibar\", redis.print],\n    [\"incr\", \"multifoo\"],\n    [\"incr\", \"multibar\"]\n]).exec(function (err, replies) {\n    console.log(replies);\n});\n```\n\n### Multi.exec_atomic([callback])\n\nIdentical to Multi.exec but with the difference that executing a single command\nwill not use transactions.\n\n## client.batch([commands])\n\nIdentical to .multi without transactions. This is recommended if you want to\nexecute many commands at once but don't have to rely on transactions.\n\n`BATCH` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Batch` object by calling `client.batch()`. The only difference\nbetween .batch and .multi is that no transaction is going to be used.\nBe aware that the errors are - just like in multi statements - in the result.\nOtherwise both, errors and results could be returned at the same time.\n\nIf you fire many commands at once this is going to boost the execution speed\nsignificantly compared to firing the same commands in a loop without waiting for\nthe result! See the benchmarks for further comparison. Please remember that all\ncommands are kept in memory until they are fired.\n\n## Monitor mode\n\nRedis supports the `MONITOR` command, which lets you see all commands received\nby the Redis server across all client connections, including from other client\nlibraries and other computers.\n\nA `monitor` event is going to be emitted for every command fired from any client\nconnected to the server including the monitoring client itself. The callback for\nthe `monitor` event takes a timestamp from the Redis server, an array of command\narguments and the raw monitoring string.\n\nExample:\n\n```js\nvar client  = require(\"redis\").createClient();\nclient.monitor(function (err, res) {\n    console.log(\"Entering monitoring mode.\");\n});\nclient.set('foo', 'bar');\n\nclient.on(\"monitor\", function (time, args, raw_reply) {\n    console.log(time + \": \" + args); // 1458910076.446514:['set', 'foo', 'bar']\n});\n```\n\n# Extras\n\nSome other things you might like to know about.\n\n## client.server_info\n\nAfter the ready probe completes, the results from the INFO command are saved in\nthe `client.server_info` object.\n\nThe `versions` key contains an array of the elements of the version string for\neasy comparison.\n\n    > client.server_info.redis_version\n    '2.3.0'\n    > client.server_info.versions\n    [ 2, 3, 0 ]\n\n## redis.print()\n\nA handy callback function for displaying return values when testing. Example:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.on(\"connect\", function () {\n    client.set(\"foo_rand000000000000\", \"some fantastic value\", redis.print);\n    client.get(\"foo_rand000000000000\", redis.print);\n});\n```\n\nThis will print:\n\n    Reply: OK\n    Reply: some fantastic value\n\nNote that this program will not exit cleanly because the client is still connected.\n\n## Multi-word commands\n\nTo execute redis multi-word commands like `SCRIPT LOAD` or `CLIENT LIST` pass\nthe second word as first parameter:\n\n    client.script('load', 'return 1');\n    client.multi().script('load', 'return 1').exec(...);\n    client.multi([['script', 'load', 'return 1']]).exec(...);\n\n## client.duplicate([options][, callback])\n\nDuplicate all current options and return a new redisClient instance. All options\npassed to the duplicate function are going to replace the original option. If\nyou pass a callback, duplicate is going to wait until the client is ready and\nreturns it in the callback. If an error occurs in the meanwhile, that is going\nto return an error instead in the callback.\n\nOne example of when to use duplicate() would be to accommodate the connection-\nblocking redis commands BRPOP, BLPOP, and BRPOPLPUSH.  If these commands\nare used on the same redisClient instance as non-blocking commands, the\nnon-blocking ones may be queued up until after the blocking ones finish.\n\n    var Redis=require('redis');\n    var client = Redis.createClient();\n    var clientBlocking = client.duplicate();\n\n    var get = function() {\n        console.log(\"get called\");\n        client.get(\"any_key\",function() { console.log(\"get returned\"); });\n        setTimeout( get, 1000 );\n    };\n    var brpop = function() {\n        console.log(\"brpop called\");\n        clientBlocking.brpop(\"nonexistent\", 5, function() {\n            console.log(\"brpop return\");\n            setTimeout( brpop, 1000 );\n        });\n    };\n    get();\n    brpop();\n\nAnother reason to use duplicate() is when multiple DBs on the same server are\naccessed via the redis SELECT command.  Each DB could use its own connection.\n\n## client.send_command(command_name[, [args][, callback]])\n\nAll Redis commands have been added to the `client` object. However, if new\ncommands are introduced before this library is updated or if you want to add\nindividual commands you can use `send_command()` to send arbitrary commands to\nRedis.\n\nAll commands are sent as multi-bulk commands. `args` can either be an Array of\narguments, or omitted / set to undefined.\n\n## client.add_command(command_name)\n\nCalling add_command will add a new command to the prototype. The exact command\nname will be used when calling using this new command. Using arbitrary arguments\nis possible as with any other command.\n\n## client.connected\n\nBoolean tracking the state of the connection to the Redis server.\n\n## client.command_queue_length\n\nThe number of commands that have been sent to the Redis server but not yet\nreplied to. You can use this to enforce some kind of maximum queue depth for\ncommands while connected.\n\n## client.offline_queue_length\n\nThe number of commands that have been queued up for a future connection. You can\nuse this to enforce some kind of maximum queue depth for pre-connection\ncommands.\n\n### Commands with Optional and Keyword arguments\n\nThis applies to anything that uses an optional `[WITHSCORES]` or `[LIMIT offset\ncount]` in the [redis.io/commands](http://redis.io/commands) documentation.\n\nExample:\n\n```js\nvar args = [ 'myzset', 1, 'one', 2, 'two', 3, 'three', 99, 'ninety-nine' ];\nclient.zadd(args, function (err, response) {\n    if (err) throw err;\n    console.log('added '+response+' items.');\n\n    // -Infinity and +Infinity also work\n    var args1 = [ 'myzset', '+inf', '-inf' ];\n    client.zrevrangebyscore(args1, function (err, response) {\n        if (err) throw err;\n        console.log('example1', response);\n        // write your code here\n    });\n\n    var max = 3, min = 1, offset = 1, count = 2;\n    var args2 = [ 'myzset', max, min, 'WITHSCORES', 'LIMIT', offset, count ];\n    client.zrevrangebyscore(args2, function (err, response) {\n        if (err) throw err;\n        console.log('example2', response);\n        // write your code here\n    });\n});\n```\n\n## Performance\n\nMuch effort has been spent to make `node_redis` as fast as possible for common\noperations.\n\n```\nLenovo T450s, i7-5600U and 12gb memory\nclients: 1, NodeJS: 6.2.0, Redis: 3.2.0, parser: javascript, connected by: tcp\n         PING,         1/1 avg/max:   0.02/  5.26 2501ms total,   46916 ops/sec\n         PING,  batch 50/1 avg/max:   0.06/  4.35 2501ms total,  755178 ops/sec\n   SET 4B str,         1/1 avg/max:   0.02/  4.75 2501ms total,   40856 ops/sec\n   SET 4B str,  batch 50/1 avg/max:   0.11/  1.51 2501ms total,  432727 ops/sec\n   SET 4B buf,         1/1 avg/max:   0.05/  2.76 2501ms total,   20659 ops/sec\n   SET 4B buf,  batch 50/1 avg/max:   0.25/  1.76 2501ms total,  194962 ops/sec\n   GET 4B str,         1/1 avg/max:   0.02/  1.55 2501ms total,   45156 ops/sec\n   GET 4B str,  batch 50/1 avg/max:   0.09/  3.15 2501ms total,  524110 ops/sec\n   GET 4B buf,         1/1 avg/max:   0.02/  3.07 2501ms total,   44563 ops/sec\n   GET 4B buf,  batch 50/1 avg/max:   0.10/  3.18 2501ms total,  473171 ops/sec\n SET 4KiB str,         1/1 avg/max:   0.03/  1.54 2501ms total,   32627 ops/sec\n SET 4KiB str,  batch 50/1 avg/max:   0.34/  1.89 2501ms total,  146861 ops/sec\n SET 4KiB buf,         1/1 avg/max:   0.05/  2.85 2501ms total,   20688 ops/sec\n SET 4KiB buf,  batch 50/1 avg/max:   0.36/  1.83 2501ms total,  138165 ops/sec\n GET 4KiB str,         1/1 avg/max:   0.02/  1.37 2501ms total,   39389 ops/sec\n GET 4KiB str,  batch 50/1 avg/max:   0.24/  1.81 2501ms total,  208157 ops/sec\n GET 4KiB buf,         1/1 avg/max:   0.02/  2.63 2501ms total,   39918 ops/sec\n GET 4KiB buf,  batch 50/1 avg/max:   0.31/  8.56 2501ms total,  161575 ops/sec\n         INCR,         1/1 avg/max:   0.02/  4.69 2501ms total,   45685 ops/sec\n         INCR,  batch 50/1 avg/max:   0.09/  3.06 2501ms total,  539964 ops/sec\n        LPUSH,         1/1 avg/max:   0.02/  3.04 2501ms total,   41253 ops/sec\n        LPUSH,  batch 50/1 avg/max:   0.12/  1.94 2501ms total,  425090 ops/sec\n    LRANGE 10,         1/1 avg/max:   0.02/  2.28 2501ms total,   39850 ops/sec\n    LRANGE 10,  batch 50/1 avg/max:   0.25/  1.85 2501ms total,  194302 ops/sec\n   LRANGE 100,         1/1 avg/max:   0.05/  2.93 2501ms total,   21026 ops/sec\n   LRANGE 100,  batch 50/1 avg/max:   1.52/  2.89 2501ms total,   32767 ops/sec\n SET 4MiB str,         1/1 avg/max:   5.16/ 15.55 2502ms total,     193 ops/sec\n SET 4MiB str,  batch 20/1 avg/max:  89.73/ 99.96 2513ms total,     223 ops/sec\n SET 4MiB buf,         1/1 avg/max:   2.23/  8.35 2501ms total,     446 ops/sec\n SET 4MiB buf,  batch 20/1 avg/max:  41.47/ 50.91 2530ms total,     482 ops/sec\n GET 4MiB str,         1/1 avg/max:   2.79/ 10.91 2502ms total,     358 ops/sec\n GET 4MiB str,  batch 20/1 avg/max: 101.61/118.11 2541ms total,     197 ops/sec\n GET 4MiB buf,         1/1 avg/max:   2.32/ 14.93 2502ms total,     430 ops/sec\n GET 4MiB buf,  batch 20/1 avg/max:  65.01/ 84.72 2536ms total,     308 ops/sec\n ```\n\n## Debugging\n\nTo get debug output run your `node_redis` application with `NODE_DEBUG=redis`.\n\nThis is also going to result in good stack traces opposed to useless ones\notherwise for any async operation.\nIf you only want to have good stack traces but not the debug output run your\napplication in development mode instead (`NODE_ENV=development`).\n\nGood stack traces are only activated in development and debug mode as this\nresults in a significant performance penalty.\n\n___Comparison___:\nUseless stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at parseError (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:158:12)\n    at parseType (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:219:14)\n```\nGood stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at new Command (/home/ruben/repos/redis/lib/command.js:9:902)\n    at RedisClient.set (/home/ruben/repos/redis/lib/commands.js:9:3238)\n    at Context.<anonymous> (/home/ruben/repos/redis/test/good_stacks.spec.js:20:20)\n    at callFnAsync (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:349:8)\n    at Test.Runnable.run (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:301:7)\n    at Runner.runTest (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:422:10)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:528:12\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:342:14)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:352:7\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:284:14)\n    at Immediate._onImmediate (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:320:5)\n    at processImmediate [as _immediateCallback] (timers.js:383:17)\n```\n\n## How to Contribute\n- Open a pull request or an issue about what you want to implement / change. We're glad for any help!\n - Please be aware that we'll only accept fully tested code.\n\n## Contributors\n\nThe original author of node_redis is [Matthew Ranney](https://github.com/mranney)\n\nThe current lead maintainer is [Ruben Bridgewater](https://github.com/BridgeAR)\n\nMany [others](https://github.com/NodeRedis/node_redis/graphs/contributors)\ncontributed to `node_redis` too. Thanks to all of them!\n\n## License\n\n[MIT](LICENSE)\n\n### Consolidation: It's time for celebration\n\nRight now there are two great redis clients around and both have some advantages\nabove each other. We speak about ioredis and node_redis. So after talking to\neach other about how we could improve in working together we (that is @luin and\n@BridgeAR) decided to work towards a single library on the long run. But step by\nstep.\n\nFirst of all, we want to split small parts of our libraries into others so that\nwe're both able to use the same code. Those libraries are going to be maintained\nunder the NodeRedis organization. This is going to reduce the maintenance\noverhead, allows others to use the very same code, if they need it and it's way\neasyer for others to contribute to both libraries.\n\nWe're very happy about this step towards working together as we both want to\ngive you the best redis experience possible.\n\nIf you want to join our cause by help maintaining something, please don't\nhesitate to contact either one of us.","source":"_posts/nodejs-redis-doc.md","raw":"---\ntitle: nodejs redis doc\ntags:\n  - nodejs\noriginContent: >-\n  redis - a node.js redis client\n\n  ===========================\n\n\n  [![Build\n  Status](https://travis-ci.org/NodeRedis/node_redis.svg?branch=master)](https://travis-ci.org/NodeRedis/node_redis)\n\n  [![Coverage\n  Status](https://coveralls.io/repos/NodeRedis/node_redis/badge.svg?branch=)](https://coveralls.io/r/NodeRedis/node_redis?branch=)\n\n  [![Windows\n  Tests](https://img.shields.io/appveyor/ci/BridgeAR/node-redis/master.svg?label=Windows%20Tests)](https://ci.appveyor.com/project/BridgeAR/node-redis/branch/master)\n\n  [![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/NodeRedis/node_redis?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\n\n  This is a complete and feature rich Redis client for node.js. __It supports\n  all\n\n  Redis commands__ and focuses on high performance.\n\n\n  <!-- more -->\n\n\n  Install with:\n\n      npm install redis\n\n  ## Usage Example\n\n\n  ```js\n\n  var redis = require(\"redis\"),\n      client = redis.createClient();\n\n  // if you'd like to select database 3, instead of 0 (default), call\n\n  // client.select(3, function() { /* ... */ });\n\n\n  client.on(\"error\", function (err) {\n      console.log(\"Error \" + err);\n  });\n\n\n  client.set(\"string key\", \"string val\", redis.print);\n\n  client.hset(\"hash key\", \"hashtest 1\", \"some value\", redis.print);\n\n  client.hset([\"hash key\", \"hashtest 2\", \"some other value\"], redis.print);\n\n  client.hkeys(\"hash key\", function (err, replies) {\n      console.log(replies.length + \" replies:\");\n      replies.forEach(function (reply, i) {\n          console.log(\"    \" + i + \": \" + reply);\n      });\n      client.quit();\n  });\n\n  ```\n\n\n  This will display:\n\n      mjr:~/work/node_redis (master)$ node example.js\n      Reply: OK\n      Reply: 0\n      Reply: 0\n      2 replies:\n          0: hashtest 1\n          1: hashtest 2\n      mjr:~/work/node_redis (master)$\n\n  Note that the API is entirely asynchronous. To get data back from the server,\n\n  you'll need to use a callback. From v.2.6 on the API supports camelCase and\n\n  snake_case and all options / variables / events etc. can be used either way.\n  It\n\n  is recommended to use camelCase as this is the default for the Node.js\n\n  landscape.\n\n\n  ### Promises\n\n\n  You can also use node_redis with promises by promisifying node_redis with\n\n  [bluebird](https://github.com/petkaantonov/bluebird) as in:\n\n\n  ```js\n\n  var redis = require('redis');\n\n  bluebird.promisifyAll(redis.RedisClient.prototype);\n\n  bluebird.promisifyAll(redis.Multi.prototype);\n\n  ```\n\n\n  It'll add a *Async* to all node_redis functions (e.g. return\n  client.getAsync().then())\n\n\n  ```js\n\n  // We expect a value 'foo': 'bar' to be present\n\n  // So instead of writing client.get('foo', cb); you have to write:\n\n  return client.getAsync('foo').then(function(res) {\n      console.log(res); // => 'bar'\n  });\n\n\n  // Using multi with promises looks like:\n\n\n  return client.multi().get('foo').execAsync().then(function(res) {\n      console.log(res); // => 'bar'\n  });\n\n  ```\n\n\n  ### Sending Commands\n\n\n  Each Redis command is exposed as a function on the `client` object.\n\n  All functions take either an `args` Array plus optional `callback` Function or\n\n  a variable number of individual arguments followed by an optional callback.\n\n  Examples:\n\n\n  ```js\n\n  client.hmset([\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val\n  2\"], function (err, res) {});\n\n  // Works the same as\n\n  client.hmset(\"key\", [\"test keys 1\", \"test val 1\", \"test keys 2\", \"test val\n  2\"], function (err, res) {});\n\n  // Or\n\n  client.hmset(\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\",\n  function (err, res) {});\n\n  ```\n\n\n  Care should be taken with user input if arrays are possible (via body-parser,\n  query string or other method), as single arguments could be unintentionally\n  interpreted as multiple args.\n\n\n  Note that in either form the `callback` is optional:\n\n\n  ```js\n\n  client.set(\"some key\", \"some val\");\n\n  client.set([\"some other key\", \"some val\"]);\n\n  ```\n\n\n  If the key is missing, reply will be null. Only if the [Redis Command\n\n  Reference](http://redis.io/commands) states something else it will not be\n  null.\n\n\n  ```js\n\n  client.get(\"missingkey\", function(err, reply) {\n      // reply is null when the key is missing\n      console.log(reply);\n  });\n\n  ```\n\n\n  For a list of Redis commands, see [Redis Command\n  Reference](http://redis.io/commands)\n\n\n  Minimal parsing is done on the replies. Commands that return a integer return\n\n  JavaScript Numbers, arrays return JavaScript Array. `HGETALL` returns an\n  Object\n\n  keyed by the hash keys. All strings will either be returned as string or as\n\n  buffer depending on your setting. Please be aware that sending null, undefined\n\n  and Boolean values will result in the value coerced to a string!\n\n\n  # Redis Commands\n\n\n  This library is a 1 to 1 mapping to [Redis\n  commands](https://redis.io/commands).\n\n  It is not a cache library so please refer to Redis commands page for full\n  usage\n\n  details.\n\n\n  Example setting key to auto expire using [SET\n  command](https://redis.io/commands/set)\n\n\n  ```js\n\n  // this key will expire after 10 seconds\n\n  client.set('key', 'value!', 'EX', 10);\n\n  ```\n\n\n  # API\n\n\n  ## Connection and other Events\n\n\n  `client` will emit some events about the state of the connection to the Redis\n  server.\n\n\n  ### \"ready\"\n\n\n  `client` will emit `ready` once a connection is established. Commands issued\n\n  before the `ready` event are queued, then replayed just before this event is\n\n  emitted.\n\n\n  ### \"connect\"\n\n\n  `client` will emit `connect` as soon as the stream is connected to the server.\n\n\n  ### \"reconnecting\"\n\n\n  `client` will emit `reconnecting` when trying to reconnect to the Redis server\n\n  after losing the connection. Listeners are passed an object containing `delay`\n\n  (in ms) and `attempt` (the attempt #) attributes.\n\n\n  ### \"error\"\n\n\n  `client` will emit `error` when encountering an error connecting to the Redis\n\n  server or when any other in node_redis occurs. If you use a command without\n\n  callback and encounter a ReplyError it is going to be emitted to the error\n\n  listener.\n\n\n  So please attach the error listener to node_redis.\n\n\n  ### \"end\"\n\n\n  `client` will emit `end` when an established Redis server connection has\n  closed.\n\n\n  ### \"drain\" (deprecated)\n\n\n  `client` will emit `drain` when the TCP connection to the Redis server has\n  been\n\n  buffering, but is now writable. This event can be used to stream commands in\n  to\n\n  Redis and adapt to backpressure.\n\n\n  If the stream is buffering `client.should_buffer` is set to true. Otherwise\n  the\n\n  variable is always set to false. That way you can decide when to reduce your\n\n  send rate and resume sending commands when you get `drain`.\n\n\n  You can also check the return value of each command as it will also return the\n\n  backpressure indicator (deprecated). If false is returned the stream had to\n\n  buffer.\n\n\n  ### \"warning\"\n\n\n  `client` will emit `warning` when password was set but none is needed and if a\n\n  deprecated option / function / similar is used.\n\n\n  ### \"idle\" (deprecated)\n\n\n  `client` will emit `idle` when there are no outstanding commands that are\n\n  awaiting a response.\n\n\n  ## redis.createClient()\n\n  If you have `redis-server` running on the same machine as node, then the\n\n  defaults for port and host are probably fine and you don't need to supply any\n\n  arguments. `createClient()` returns a `RedisClient` object. Otherwise,\n\n  `createClient()` accepts these arguments:\n\n\n  * `redis.createClient([options])`\n\n  * `redis.createClient(unix_socket[, options])`\n\n  * `redis.createClient(redis_url[, options])`\n\n  * `redis.createClient(port[, host][, options])`\n\n\n  __Tip:__ If the Redis server runs on the same machine as the client consider\n\n  using unix sockets if possible to increase throughput.\n\n\n  #### `options` object properties\n\n  | Property  | Default   | Description |\n\n  |-----------|-----------|-------------|\n\n  | host      | 127.0.0.1 | IP address of the Redis server |\n\n  | port      | 6379      | Port of the Redis server |\n\n  | path      | null      | The UNIX socket string of the Redis server |\n\n  | url       | null      | The URL of the Redis server. Format:\n  `[redis:]//[[user][:password@]][host][:port][/db-number][?db=db-number[&password=bar[&option=value]]]`\n  (More info avaliable at\n  [IANA](http://www.iana.org/assignments/uri-schemes/prov/redis)). |\n\n  | parser    | javascript | __Deprecated__ Use either the built-in JS parser\n  [`javascript`]() or the native [`hiredis`]() parser. __Note__ `node_redis` <\n  2.6 uses hiredis as default if installed. This changed in v.2.6.0. |\n\n  | string_numbers | null | Set to `true`, `node_redis` will return Redis number\n  values as Strings instead of javascript Numbers. Useful if you need to handle\n  big numbers (above `Number.MAX_SAFE_INTEGER === 2^53`). Hiredis is incapable\n  of this behavior, so setting this option to `true` will result in the built-in\n  javascript parser being used no matter the value of the `parser` option. |\n\n  | return_buffers | false | If set to `true`, then all replies will be sent to\n  callbacks as Buffers instead of Strings. |\n\n  | detect_buffers | false | If set to `true`, then replies will be sent to\n  callbacks as Buffers. This option lets you switch between Buffers and Strings\n  on a per-command basis, whereas `return_buffers` applies to every command on a\n  client. __Note__: This doesn't work properly with the pubsub mode. A\n  subscriber has to either always return Strings or Buffers. |\n\n  | socket_keepalive | true | If set to `true`, the keep-alive functionality is\n  enabled on the underlying socket. |\n\n  | no_ready_check | false |  When a connection is established to the Redis\n  server, the server might still be loading the database from disk. While\n  loading, the server will not respond to any commands. To work around this,\n  `node_redis` has a \"ready check\" which sends the `INFO` command to the server.\n  The response from the `INFO` command indicates whether the server is ready for\n  more commands. When ready, `node_redis` emits a `ready` event. Setting\n  `no_ready_check` to `true` will inhibit this check. |\n\n  | enable_offline_queue |  true | By default, if there is no active connection\n  to the Redis server, commands are added to a queue and are executed once the\n  connection has been established. Setting `enable_offline_queue` to `false`\n  will disable this feature and the callback will be executed immediately with\n  an error, or an error will be emitted if no callback is specified. |\n\n  | retry_max_delay | null | __Deprecated__ _Please use `retry_strategy`\n  instead._ By default, every time the client tries to connect and fails, the\n  reconnection delay almost doubles. This delay normally grows infinitely, but\n  setting `retry_max_delay` limits it to the maximum value provided in\n  milliseconds. |\n\n  | connect_timeout | 3600000 | __Deprecated__ _Please use `retry_strategy`\n  instead._ Setting `connect_timeout` limits the total time for the client to\n  connect and reconnect. The value is provided in milliseconds and is counted\n  from the moment a new client is created or from the time the connection is\n  lost. The last retry is going to happen exactly at the timeout time. Default\n  is to try connecting until the default system socket timeout has been exceeded\n  and to try reconnecting until 1h has elapsed. |\n\n  | max_attempts | 0 | __Deprecated__ _Please use `retry_strategy` instead._ By\n  default, a client will try reconnecting until connected. Setting\n  `max_attempts` limits total amount of connection attempts. Setting this to 1\n  will prevent any reconnect attempt. |\n\n  | retry_unfulfilled_commands | false | If set to `true`, all commands that\n  were unfulfilled while the connection is lost will be retried after the\n  connection has been reestablished. Use this with caution if you use state\n  altering commands (e.g. `incr`). This is especially useful if you use blocking\n  commands. |\n\n  | password | null | If set, client will run Redis auth command on connect.\n  Alias `auth_pass` __Note__ `node_redis` < 2.5 must use `auth_pass` |\n\n  | db | null | If set, client will run Redis `select` command on connect. |\n\n  | family | IPv4 | You can force using IPv6 if you set the family to 'IPv6'.\n  See Node.js [net](https://nodejs.org/api/net.html) or\n  [dns](https://nodejs.org/api/dns.html) modules on how to use the family type.\n  |\n\n  | disable_resubscribing | false | If set to `true`, a client won't resubscribe\n  after disconnecting. |\n\n  | rename_commands | null | Passing an object with renamed commands to use\n  instead of the original functions. For example, if you renamed the command\n  KEYS to \"DO-NOT-USE\" then the rename_commands object would be: `{ KEYS :\n  \"DO-NOT-USE\" }` . See the [Redis security\n  topics](http://redis.io/topics/security) for more info. |\n\n  | tls | null | An object containing options to pass to\n  [tls.connect](http://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback)\n  to set up a TLS connection to Redis (if, for example, it is set up to be\n  accessible via a tunnel). |\n\n  | prefix | null | A string used to prefix all used keys (e.g.\n  `namespace:test`). Please be aware that the `keys` command will not be\n  prefixed. The `keys` command has a \"pattern\" as argument and no key and it\n  would be impossible to determine the existing keys in Redis if this would be\n  prefixed. |\n\n  | retry_strategy | function | A function that receives an options object as\n  parameter including the retry `attempt`, the `total_retry_time` indicating how\n  much time passed since the last time connected, the `error` why the connection\n  was lost and the number of `times_connected` in total. If you return a number\n  from this function, the retry will happen exactly after that time in\n  milliseconds. If you return a non-number, no further retry will happen and all\n  offline commands are flushed with errors. Return an error to return that\n  specific error to all offline commands. Example below. |\n\n\n  ```js\n\n  var redis = require(\"redis\");\n\n  var client = redis.createClient({detect_buffers: true});\n\n\n  client.set(\"foo_rand000000000000\", \"OK\");\n\n\n  // This will return a JavaScript String\n\n  client.get(\"foo_rand000000000000\", function (err, reply) {\n      console.log(reply.toString()); // Will print `OK`\n  });\n\n\n  // This will return a Buffer since original key is specified as a Buffer\n\n  client.get(new Buffer(\"foo_rand000000000000\"), function (err, reply) {\n      console.log(reply.toString()); // Will print `<Buffer 4f 4b>`\n  });\n\n  client.quit();\n\n  ```\n\n\n  retry_strategy example\n\n\n  ```js\n\n  var client = redis.createClient({\n      retry_strategy: function (options) {\n          if (options.error && options.error.code === 'ECONNREFUSED') {\n              // End reconnecting on a specific error and flush all commands with\n              // a individual error\n              return new Error('The server refused the connection');\n          }\n          if (options.total_retry_time > 1000 * 60 * 60) {\n              // End reconnecting after a specific timeout and flush all commands\n              // with a individual error\n              return new Error('Retry time exhausted');\n          }\n          if (options.attempt > 10) {\n              // End reconnecting with built in error\n              return undefined;\n          }\n          // reconnect after\n          return Math.min(options.attempt * 100, 3000);\n      }\n  });\n\n  ```\n\n\n  ## client.auth(password[, callback])\n\n\n  When connecting to a Redis server that requires authentication, the `AUTH`\n\n  command must be sent as the first command after connecting. This can be tricky\n\n  to coordinate with reconnections, the ready check, etc. To make this easier,\n\n  `client.auth()` stashes `password` and will send it after each connection,\n\n  including reconnections. `callback` is invoked only once, after the response\n  to\n\n  the very first `AUTH` command sent.\n\n  NOTE: Your call to `client.auth()` should not be inside the ready handler. If\n\n  you are doing this wrong, `client` will emit an error that looks\n\n  something like this `Error: Ready check failed: ERR operation not permitted`.\n\n\n  ## backpressure\n\n\n  ### stream\n\n\n  The client exposed the used [stream](https://nodejs.org/api/stream.html) in\n\n  `client.stream` and if the stream or client had to\n\n  [buffer](https://nodejs.org/api/stream.html#stream_writable_write_chunk_encoding_callback)\n\n  the command in `client.should_buffer`. In combination this can be used to\n\n  implement backpressure by checking the buffer state before sending a command\n  and\n\n  listening to the stream\n\n  [drain](https://nodejs.org/api/stream.html#stream_event_drain) event.\n\n\n  ## client.quit()\n\n\n  This sends the quit command to the redis server and ends cleanly right after\n  all\n\n  running commands were properly handled. If this is called while reconnecting\n\n  (and therefore no connection to the redis server exists) it is going to end\n  the\n\n  connection right away instead of resulting in further reconnections! All\n  offline\n\n  commands are going to be flushed with an error in that case.\n\n\n  ## client.end(flush)\n\n\n  Forcibly close the connection to the Redis server. Note that this does not\n  wait\n\n  until all replies have been parsed. If you want to exit cleanly, call\n\n  `client.quit()` as mentioned above.\n\n\n  You should set flush to true, if you are not absolutely sure you do not care\n\n  about any other commands. If you set flush to false all still running commands\n\n  will silently fail.\n\n\n  This example closes the connection to the Redis server before the replies have\n\n  been read. You probably don't want to do this:\n\n\n  ```js\n\n  var redis = require(\"redis\"),\n      client = redis.createClient();\n\n  client.set(\"foo_rand000000000000\", \"some fantastic value\", function (err,\n  reply) {\n      // This will either result in an error (flush parameter is set to true)\n      // or will silently fail and this callback will not be called at all (flush set to false)\n      console.log(err);\n  });\n\n  client.end(true); // No further commands will be processed\n\n  client.get(\"foo_rand000000000000\", function (err, reply) {\n      console.log(err); // => 'The connection has already been closed.'\n  });\n\n  ```\n\n\n  `client.end()` without the flush parameter set to true should NOT be used in\n  production!\n\n\n  ## Error handling (>= v.2.6)\n\n\n  Currently the following error subclasses exist:\n\n\n  * `RedisError`: _All errors_ returned by the client\n\n  * `ReplyError` subclass of `RedisError`: All errors returned by __Redis__\n  itself\n\n  * `AbortError` subclass of `RedisError`: All commands that could not finish\n  due\n    to what ever reason\n  * `ParserError` subclass of `RedisError`: Returned in case of a parser error\n    (this should not happen)\n  * `AggregateError` subclass of `AbortError`: Emitted in case multiple\n  unresolved\n    commands without callback got rejected in debug_mode instead of lots of\n    `AbortError`s.\n\n  All error classes are exported by the module.\n\n\n  Example:\n\n  ```js\n\n  var redis = require('./');\n\n  var assert = require('assert');\n\n  var client = redis.createClient();\n\n\n  client.on('error', function (err) {\n      assert(err instanceof Error);\n      assert(err instanceof redis.AbortError);\n      assert(err instanceof redis.AggregateError);\n      // The set and get get aggregated in here\n      assert.strictEqual(err.errors.length, 2);\n      assert.strictEqual(err.code, 'NR_CLOSED');\n  });\n\n  client.set('foo', 123, 'bar', function (err, res) { // Too many arguments\n      assert(err instanceof redis.ReplyError); // => true\n      assert.strictEqual(err.command, 'SET');\n      assert.deepStrictEqual(err.args, ['foo', 123, 'bar']);\n\n      redis.debug_mode = true;\n      client.set('foo', 'bar');\n      client.get('foo');\n      process.nextTick(function () {\n          // Force closing the connection while the command did not yet return\n          client.end(true);\n          redis.debug_mode = false;\n      });\n  });\n\n\n  ```\n\n\n  Every `ReplyError` contains the `command` name in all-caps and the arguments\n  (`args`).\n\n\n  If node_redis emits a library error because of another error, the triggering\n\n  error is added to the returned error as `origin` attribute.\n\n\n  ___Error codes___\n\n\n  node_redis returns a `NR_CLOSED` error code if the clients connection dropped.\n\n  If a command unresolved command got rejected a `UNCERTAIN_STATE` code is\n\n  returned. A `CONNECTION_BROKEN` error code is used in case node_redis gives up\n\n  to reconnect.\n\n\n  ## client.unref()\n\n\n  Call `unref()` on the underlying socket connection to the Redis server,\n  allowing\n\n  the program to exit once no more commands are pending.\n\n\n  This is an **experimental** feature, and only supports a subset of the Redis\n\n  protocol. Any commands where client state is saved on the Redis server, e.g.\n\n  `*SUBSCRIBE` or the blocking `BL*` commands will *NOT* work with `.unref()`.\n\n\n  ```js\n\n  var redis = require(\"redis\")\n\n  var client = redis.createClient()\n\n\n  /*\n      Calling unref() will allow this program to exit immediately after the get\n      command finishes. Otherwise the client would hang as long as the\n      client-server connection is alive.\n  */\n\n  client.unref()\n\n  client.get(\"foo\", function (err, value){\n      if (err) throw(err)\n      console.log(value)\n  })\n\n  ```\n\n\n  ## Friendlier hash commands\n\n\n  Most Redis commands take a single String or an Array of Strings as arguments,\n\n  and replies are sent back as a single String or an Array of Strings. When\n\n  dealing with hash values, there are a couple of useful exceptions to this.\n\n\n  ### client.hgetall(hash, callback)\n\n\n  The reply from an HGETALL command will be converted into a JavaScript Object\n  by\n\n  `node_redis`. That way you can interact with the responses using JavaScript\n\n  syntax.\n\n\n  Example:\n\n\n  ```js\n\n  client.hmset(\"hosts\", \"mjr\", \"1\", \"another\", \"23\", \"home\", \"1234\");\n\n  client.hgetall(\"hosts\", function (err, obj) {\n      console.dir(obj);\n  });\n\n  ```\n\n\n  Output:\n\n\n  ```js\n\n  { mjr: '1', another: '23', home: '1234' }\n\n  ```\n\n\n  ### client.hmset(hash, obj[, callback])\n\n\n  Multiple values in a hash can be set by supplying an object:\n\n\n  ```js\n\n  client.HMSET(key2, {\n      \"0123456789\": \"abcdefghij\", // NOTE: key and value will be coerced to strings\n      \"some manner of key\": \"a type of value\"\n  });\n\n  ```\n\n\n  The properties and values of this Object will be set as keys and values in the\n\n  Redis hash.\n\n\n  ### client.hmset(hash, key1, val1, ... keyn, valn, [callback])\n\n\n  Multiple values may also be set by supplying a list:\n\n\n  ```js\n\n  client.HMSET(key1, \"0123456789\", \"abcdefghij\", \"some manner of key\", \"a type\n  of value\");\n\n  ```\n\n\n  ## Publish / Subscribe\n\n\n  Example of the publish / subscribe API. This program opens two\n\n  client connections, subscribes to a channel on one of them, and publishes to\n  that\n\n  channel on the other:\n\n\n  ```js\n\n  var redis = require(\"redis\");\n\n  var sub = redis.createClient(), pub = redis.createClient();\n\n  var msg_count = 0;\n\n\n  sub.on(\"subscribe\", function (channel, count) {\n      pub.publish(\"a nice channel\", \"I am sending a message.\");\n      pub.publish(\"a nice channel\", \"I am sending a second message.\");\n      pub.publish(\"a nice channel\", \"I am sending my last message.\");\n  });\n\n\n  sub.on(\"message\", function (channel, message) {\n      console.log(\"sub channel \" + channel + \": \" + message);\n      msg_count += 1;\n      if (msg_count === 3) {\n          sub.unsubscribe();\n          sub.quit();\n          pub.quit();\n      }\n  });\n\n\n  sub.subscribe(\"a nice channel\");\n\n  ```\n\n\n  When a client issues a `SUBSCRIBE` or `PSUBSCRIBE`, that connection is put\n  into\n\n  a \"subscriber\" mode. At that point, only commands that modify the subscription\n\n  set are valid and quit (and depending on the redis version ping as well). When\n\n  the subscription set is empty, the connection is put back into regular mode.\n\n\n  If you need to send regular commands to Redis while in subscriber mode, just\n\n  open another connection with a new client (hint: use `client.duplicate()`).\n\n\n  ## Subscriber Events\n\n\n  If a client has subscriptions active, it may emit these events:\n\n\n  ### \"message\" (channel, message)\n\n\n  Client will emit `message` for every message received that matches an active\n  subscription.\n\n  Listeners are passed the channel name as `channel` and the message as\n  `message`.\n\n\n  ### \"pmessage\" (pattern, channel, message)\n\n\n  Client will emit `pmessage` for every message received that matches an active\n\n  subscription pattern. Listeners are passed the original pattern used with\n\n  `PSUBSCRIBE` as `pattern`, the sending channel name as `channel`, and the\n\n  message as `message`.\n\n\n  ### \"message_buffer\" (channel, message)\n\n\n  This is the same as the `message` event with the exception, that it is always\n\n  going to emit a buffer. If you listen to the `message` event at the same time\n  as\n\n  the `message_buffer`, it is always going to emit a string.\n\n\n  ### \"pmessage_buffer\" (pattern, channel, message)\n\n\n  This is the same as the `pmessage` event with the exception, that it is always\n\n  going to emit a buffer. If you listen to the `pmessage` event at the same time\n\n  as the `pmessage_buffer`, it is always going to emit a string.\n\n\n  ### \"subscribe\" (channel, count)\n\n\n  Client will emit `subscribe` in response to a `SUBSCRIBE` command. Listeners\n  are\n\n  passed the channel name as `channel` and the new count of subscriptions for\n  this\n\n  client as `count`.\n\n\n  ### \"psubscribe\" (pattern, count)\n\n\n  Client will emit `psubscribe` in response to a `PSUBSCRIBE` command. Listeners\n\n  are passed the original pattern as `pattern`, and the new count of\n  subscriptions\n\n  for this client as `count`.\n\n\n  ### \"unsubscribe\" (channel, count)\n\n\n  Client will emit `unsubscribe` in response to a `UNSUBSCRIBE` command.\n  Listeners\n\n  are passed the channel name as `channel` and the new count of subscriptions\n  for\n\n  this client as `count`. When `count` is 0, this client has left subscriber\n  mode\n\n  and no more subscriber events will be emitted.\n\n\n  ### \"punsubscribe\" (pattern, count)\n\n\n  Client will emit `punsubscribe` in response to a `PUNSUBSCRIBE` command.\n\n  Listeners are passed the channel name as `channel` and the new count of\n\n  subscriptions for this client as `count`. When `count` is 0, this client has\n\n  left subscriber mode and no more subscriber events will be emitted.\n\n\n  ## client.multi([commands])\n\n\n  `MULTI` commands are queued up until an `EXEC` is issued, and then all\n  commands\n\n  are run atomically by Redis. The interface in `node_redis` is to return an\n\n  individual `Multi` object by calling `client.multi()`. If any command fails to\n\n  queue, all commands are rolled back and none is going to be executed (For\n\n  further information look at\n\n  [transactions](http://redis.io/topics/transactions)).\n\n\n  ```js\n\n  var redis  = require(\"./index\"),\n      client = redis.createClient(), set_size = 20;\n\n  client.sadd(\"bigset\", \"a member\");\n\n  client.sadd(\"bigset\", \"another member\");\n\n\n  while (set_size > 0) {\n      client.sadd(\"bigset\", \"member \" + set_size);\n      set_size -= 1;\n  }\n\n\n  // multi chain with an individual callback\n\n  client.multi()\n      .scard(\"bigset\")\n      .smembers(\"bigset\")\n      .keys(\"*\", function (err, replies) {\n          // NOTE: code in this callback is NOT atomic\n          // this only happens after the the .exec call finishes.\n          client.mget(replies, redis.print);\n      })\n      .dbsize()\n      .exec(function (err, replies) {\n          console.log(\"MULTI got \" + replies.length + \" replies\");\n          replies.forEach(function (reply, index) {\n              console.log(\"Reply \" + index + \": \" + reply.toString());\n          });\n      });\n  ```\n\n\n  ### Multi.exec([callback])\n\n\n  `client.multi()` is a constructor that returns a `Multi` object. `Multi`\n  objects\n\n  share all of the same command methods as `client` objects do. Commands are\n\n  queued up inside the `Multi` object until `Multi.exec()` is invoked.\n\n\n  If your code contains an syntax error an EXECABORT error is going to be thrown\n\n  and all commands are going to be aborted. That error contains a `.errors`\n\n  property that contains the concrete errors.\n\n  If all commands were queued successfully and an error is thrown by redis while\n\n  processing the commands that error is going to be returned in the result\n  array!\n\n  No other command is going to be aborted though than the onces failing.\n\n\n  You can either chain together `MULTI` commands as in the above example, or you\n\n  can queue individual commands while still sending regular client command as in\n\n  this example:\n\n\n  ```js\n\n  var redis  = require(\"redis\"),\n      client = redis.createClient(), multi;\n\n  // start a separate multi command queue\n\n  multi = client.multi();\n\n  multi.incr(\"incr thing\", redis.print);\n\n  multi.incr(\"incr other thing\", redis.print);\n\n\n  // runs immediately\n\n  client.mset(\"incr thing\", 100, \"incr other thing\", 1, redis.print);\n\n\n  // drains multi queue and runs atomically\n\n  multi.exec(function (err, replies) {\n      console.log(replies); // 101, 2\n  });\n\n  ```\n\n\n  In addition to adding commands to the `MULTI` queue individually, you can also\n\n  pass an array of commands and arguments to the constructor:\n\n\n  ```js\n\n  var redis  = require(\"redis\"),\n      client = redis.createClient();\n\n  client.multi([\n      [\"mget\", \"multifoo\", \"multibar\", redis.print],\n      [\"incr\", \"multifoo\"],\n      [\"incr\", \"multibar\"]\n  ]).exec(function (err, replies) {\n      console.log(replies);\n  });\n\n  ```\n\n\n  ### Multi.exec_atomic([callback])\n\n\n  Identical to Multi.exec but with the difference that executing a single\n  command\n\n  will not use transactions.\n\n\n  ## client.batch([commands])\n\n\n  Identical to .multi without transactions. This is recommended if you want to\n\n  execute many commands at once but don't have to rely on transactions.\n\n\n  `BATCH` commands are queued up until an `EXEC` is issued, and then all\n  commands\n\n  are run atomically by Redis. The interface in `node_redis` is to return an\n\n  individual `Batch` object by calling `client.batch()`. The only difference\n\n  between .batch and .multi is that no transaction is going to be used.\n\n  Be aware that the errors are - just like in multi statements - in the result.\n\n  Otherwise both, errors and results could be returned at the same time.\n\n\n  If you fire many commands at once this is going to boost the execution speed\n\n  significantly compared to firing the same commands in a loop without waiting\n  for\n\n  the result! See the benchmarks for further comparison. Please remember that\n  all\n\n  commands are kept in memory until they are fired.\n\n\n  ## Monitor mode\n\n\n  Redis supports the `MONITOR` command, which lets you see all commands received\n\n  by the Redis server across all client connections, including from other client\n\n  libraries and other computers.\n\n\n  A `monitor` event is going to be emitted for every command fired from any\n  client\n\n  connected to the server including the monitoring client itself. The callback\n  for\n\n  the `monitor` event takes a timestamp from the Redis server, an array of\n  command\n\n  arguments and the raw monitoring string.\n\n\n  Example:\n\n\n  ```js\n\n  var client  = require(\"redis\").createClient();\n\n  client.monitor(function (err, res) {\n      console.log(\"Entering monitoring mode.\");\n  });\n\n  client.set('foo', 'bar');\n\n\n  client.on(\"monitor\", function (time, args, raw_reply) {\n      console.log(time + \": \" + args); // 1458910076.446514:['set', 'foo', 'bar']\n  });\n\n  ```\n\n\n  # Extras\n\n\n  Some other things you might like to know about.\n\n\n  ## client.server_info\n\n\n  After the ready probe completes, the results from the INFO command are saved\n  in\n\n  the `client.server_info` object.\n\n\n  The `versions` key contains an array of the elements of the version string for\n\n  easy comparison.\n\n      > client.server_info.redis_version\n      '2.3.0'\n      > client.server_info.versions\n      [ 2, 3, 0 ]\n\n  ## redis.print()\n\n\n  A handy callback function for displaying return values when testing. Example:\n\n\n  ```js\n\n  var redis = require(\"redis\"),\n      client = redis.createClient();\n\n  client.on(\"connect\", function () {\n      client.set(\"foo_rand000000000000\", \"some fantastic value\", redis.print);\n      client.get(\"foo_rand000000000000\", redis.print);\n  });\n\n  ```\n\n\n  This will print:\n\n      Reply: OK\n      Reply: some fantastic value\n\n  Note that this program will not exit cleanly because the client is still\n  connected.\n\n\n  ## Multi-word commands\n\n\n  To execute redis multi-word commands like `SCRIPT LOAD` or `CLIENT LIST` pass\n\n  the second word as first parameter:\n\n      client.script('load', 'return 1');\n      client.multi().script('load', 'return 1').exec(...);\n      client.multi([['script', 'load', 'return 1']]).exec(...);\n\n  ## client.duplicate([options][, callback])\n\n\n  Duplicate all current options and return a new redisClient instance. All\n  options\n\n  passed to the duplicate function are going to replace the original option. If\n\n  you pass a callback, duplicate is going to wait until the client is ready and\n\n  returns it in the callback. If an error occurs in the meanwhile, that is going\n\n  to return an error instead in the callback.\n\n\n  One example of when to use duplicate() would be to accommodate the connection-\n\n  blocking redis commands BRPOP, BLPOP, and BRPOPLPUSH.  If these commands\n\n  are used on the same redisClient instance as non-blocking commands, the\n\n  non-blocking ones may be queued up until after the blocking ones finish.\n\n      var Redis=require('redis');\n      var client = Redis.createClient();\n      var clientBlocking = client.duplicate();\n\n      var get = function() {\n          console.log(\"get called\");\n          client.get(\"any_key\",function() { console.log(\"get returned\"); });\n          setTimeout( get, 1000 );\n      };\n      var brpop = function() {\n          console.log(\"brpop called\");\n          clientBlocking.brpop(\"nonexistent\", 5, function() {\n              console.log(\"brpop return\");\n              setTimeout( brpop, 1000 );\n          });\n      };\n      get();\n      brpop();\n\n  Another reason to use duplicate() is when multiple DBs on the same server are\n\n  accessed via the redis SELECT command.  Each DB could use its own connection.\n\n\n  ## client.send_command(command_name[, [args][, callback]])\n\n\n  All Redis commands have been added to the `client` object. However, if new\n\n  commands are introduced before this library is updated or if you want to add\n\n  individual commands you can use `send_command()` to send arbitrary commands to\n\n  Redis.\n\n\n  All commands are sent as multi-bulk commands. `args` can either be an Array of\n\n  arguments, or omitted / set to undefined.\n\n\n  ## client.add_command(command_name)\n\n\n  Calling add_command will add a new command to the prototype. The exact command\n\n  name will be used when calling using this new command. Using arbitrary\n  arguments\n\n  is possible as with any other command.\n\n\n  ## client.connected\n\n\n  Boolean tracking the state of the connection to the Redis server.\n\n\n  ## client.command_queue_length\n\n\n  The number of commands that have been sent to the Redis server but not yet\n\n  replied to. You can use this to enforce some kind of maximum queue depth for\n\n  commands while connected.\n\n\n  ## client.offline_queue_length\n\n\n  The number of commands that have been queued up for a future connection. You\n  can\n\n  use this to enforce some kind of maximum queue depth for pre-connection\n\n  commands.\n\n\n  ### Commands with Optional and Keyword arguments\n\n\n  This applies to anything that uses an optional `[WITHSCORES]` or `[LIMIT\n  offset\n\n  count]` in the [redis.io/commands](http://redis.io/commands) documentation.\n\n\n  Example:\n\n\n  ```js\n\n  var args = [ 'myzset', 1, 'one', 2, 'two', 3, 'three', 99, 'ninety-nine' ];\n\n  client.zadd(args, function (err, response) {\n      if (err) throw err;\n      console.log('added '+response+' items.');\n\n      // -Infinity and +Infinity also work\n      var args1 = [ 'myzset', '+inf', '-inf' ];\n      client.zrevrangebyscore(args1, function (err, response) {\n          if (err) throw err;\n          console.log('example1', response);\n          // write your code here\n      });\n\n      var max = 3, min = 1, offset = 1, count = 2;\n      var args2 = [ 'myzset', max, min, 'WITHSCORES', 'LIMIT', offset, count ];\n      client.zrevrangebyscore(args2, function (err, response) {\n          if (err) throw err;\n          console.log('example2', response);\n          // write your code here\n      });\n  });\n\n  ```\n\n\n  ## Performance\n\n\n  Much effort has been spent to make `node_redis` as fast as possible for common\n\n  operations.\n\n\n  ```\n\n  Lenovo T450s, i7-5600U and 12gb memory\n\n  clients: 1, NodeJS: 6.2.0, Redis: 3.2.0, parser: javascript, connected by: tcp\n           PING,         1/1 avg/max:   0.02/  5.26 2501ms total,   46916 ops/sec\n           PING,  batch 50/1 avg/max:   0.06/  4.35 2501ms total,  755178 ops/sec\n     SET 4B str,         1/1 avg/max:   0.02/  4.75 2501ms total,   40856 ops/sec\n     SET 4B str,  batch 50/1 avg/max:   0.11/  1.51 2501ms total,  432727 ops/sec\n     SET 4B buf,         1/1 avg/max:   0.05/  2.76 2501ms total,   20659 ops/sec\n     SET 4B buf,  batch 50/1 avg/max:   0.25/  1.76 2501ms total,  194962 ops/sec\n     GET 4B str,         1/1 avg/max:   0.02/  1.55 2501ms total,   45156 ops/sec\n     GET 4B str,  batch 50/1 avg/max:   0.09/  3.15 2501ms total,  524110 ops/sec\n     GET 4B buf,         1/1 avg/max:   0.02/  3.07 2501ms total,   44563 ops/sec\n     GET 4B buf,  batch 50/1 avg/max:   0.10/  3.18 2501ms total,  473171 ops/sec\n   SET 4KiB str,         1/1 avg/max:   0.03/  1.54 2501ms total,   32627 ops/sec\n   SET 4KiB str,  batch 50/1 avg/max:   0.34/  1.89 2501ms total,  146861 ops/sec\n   SET 4KiB buf,         1/1 avg/max:   0.05/  2.85 2501ms total,   20688 ops/sec\n   SET 4KiB buf,  batch 50/1 avg/max:   0.36/  1.83 2501ms total,  138165 ops/sec\n   GET 4KiB str,         1/1 avg/max:   0.02/  1.37 2501ms total,   39389 ops/sec\n   GET 4KiB str,  batch 50/1 avg/max:   0.24/  1.81 2501ms total,  208157 ops/sec\n   GET 4KiB buf,         1/1 avg/max:   0.02/  2.63 2501ms total,   39918 ops/sec\n   GET 4KiB buf,  batch 50/1 avg/max:   0.31/  8.56 2501ms total,  161575 ops/sec\n           INCR,         1/1 avg/max:   0.02/  4.69 2501ms total,   45685 ops/sec\n           INCR,  batch 50/1 avg/max:   0.09/  3.06 2501ms total,  539964 ops/sec\n          LPUSH,         1/1 avg/max:   0.02/  3.04 2501ms total,   41253 ops/sec\n          LPUSH,  batch 50/1 avg/max:   0.12/  1.94 2501ms total,  425090 ops/sec\n      LRANGE 10,         1/1 avg/max:   0.02/  2.28 2501ms total,   39850 ops/sec\n      LRANGE 10,  batch 50/1 avg/max:   0.25/  1.85 2501ms total,  194302 ops/sec\n     LRANGE 100,         1/1 avg/max:   0.05/  2.93 2501ms total,   21026 ops/sec\n     LRANGE 100,  batch 50/1 avg/max:   1.52/  2.89 2501ms total,   32767 ops/sec\n   SET 4MiB str,         1/1 avg/max:   5.16/ 15.55 2502ms total,     193 ops/sec\n   SET 4MiB str,  batch 20/1 avg/max:  89.73/ 99.96 2513ms total,     223 ops/sec\n   SET 4MiB buf,         1/1 avg/max:   2.23/  8.35 2501ms total,     446 ops/sec\n   SET 4MiB buf,  batch 20/1 avg/max:  41.47/ 50.91 2530ms total,     482 ops/sec\n   GET 4MiB str,         1/1 avg/max:   2.79/ 10.91 2502ms total,     358 ops/sec\n   GET 4MiB str,  batch 20/1 avg/max: 101.61/118.11 2541ms total,     197 ops/sec\n   GET 4MiB buf,         1/1 avg/max:   2.32/ 14.93 2502ms total,     430 ops/sec\n   GET 4MiB buf,  batch 20/1 avg/max:  65.01/ 84.72 2536ms total,     308 ops/sec\n   ```\n\n  ## Debugging\n\n\n  To get debug output run your `node_redis` application with `NODE_DEBUG=redis`.\n\n\n  This is also going to result in good stack traces opposed to useless ones\n\n  otherwise for any async operation.\n\n  If you only want to have good stack traces but not the debug output run your\n\n  application in development mode instead (`NODE_ENV=development`).\n\n\n  Good stack traces are only activated in development and debug mode as this\n\n  results in a significant performance penalty.\n\n\n  ___Comparison___:\n\n  Useless stack trace:\n\n  ```\n\n  ReplyError: ERR wrong number of arguments for 'set' command\n      at parseError (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:158:12)\n      at parseType (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:219:14)\n  ```\n\n  Good stack trace:\n\n  ```\n\n  ReplyError: ERR wrong number of arguments for 'set' command\n      at new Command (/home/ruben/repos/redis/lib/command.js:9:902)\n      at RedisClient.set (/home/ruben/repos/redis/lib/commands.js:9:3238)\n      at Context.<anonymous> (/home/ruben/repos/redis/test/good_stacks.spec.js:20:20)\n      at callFnAsync (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:349:8)\n      at Test.Runnable.run (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:301:7)\n      at Runner.runTest (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:422:10)\n      at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:528:12\n      at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:342:14)\n      at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:352:7\n      at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:284:14)\n      at Immediate._onImmediate (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:320:5)\n      at processImmediate [as _immediateCallback] (timers.js:383:17)\n  ```\n\n\n  ## How to Contribute\n\n  - Open a pull request or an issue about what you want to implement / change.\n  We're glad for any help!\n   - Please be aware that we'll only accept fully tested code.\n\n  ## Contributors\n\n\n  The original author of node_redis is [Matthew\n  Ranney](https://github.com/mranney)\n\n\n  The current lead maintainer is [Ruben\n  Bridgewater](https://github.com/BridgeAR)\n\n\n  Many [others](https://github.com/NodeRedis/node_redis/graphs/contributors)\n\n  contributed to `node_redis` too. Thanks to all of them!\n\n\n  ## License\n\n\n  [MIT](LICENSE)\n\n\n  ### Consolidation: It's time for celebration\n\n\n  Right now there are two great redis clients around and both have some\n  advantages\n\n  above each other. We speak about ioredis and node_redis. So after talking to\n\n  each other about how we could improve in working together we (that is @luin\n  and\n\n  @BridgeAR) decided to work towards a single library on the long run. But step\n  by\n\n  step.\n\n\n  First of all, we want to split small parts of our libraries into others so\n  that\n\n  we're both able to use the same code. Those libraries are going to be\n  maintained\n\n  under the NodeRedis organization. This is going to reduce the maintenance\n\n  overhead, allows others to use the very same code, if they need it and it's\n  way\n\n  easyer for others to contribute to both libraries.\n\n\n  We're very happy about this step towards working together as we both want to\n\n  give you the best redis experience possible.\n\n\n  If you want to join our cause by help maintaining something, please don't\n\n  hesitate to contact either one of us.\ncategories:\n  - NodeJS\ntoc: false\ndate: 2017-10-10 22:48:05\n---\n\nredis - a node.js redis client\n===========================\n\n[![Build Status](https://travis-ci.org/NodeRedis/node_redis.svg?branch=master)](https://travis-ci.org/NodeRedis/node_redis)\n[![Coverage Status](https://coveralls.io/repos/NodeRedis/node_redis/badge.svg?branch=)](https://coveralls.io/r/NodeRedis/node_redis?branch=)\n[![Windows Tests](https://img.shields.io/appveyor/ci/BridgeAR/node-redis/master.svg?label=Windows%20Tests)](https://ci.appveyor.com/project/BridgeAR/node-redis/branch/master)\n[![Gitter](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/NodeRedis/node_redis?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge)\n\nThis is a complete and feature rich Redis client for node.js. __It supports all\nRedis commands__ and focuses on high performance.\n\n<!-- more -->\n\nInstall with:\n\n    npm install redis\n\n## Usage Example\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\n// if you'd like to select database 3, instead of 0 (default), call\n// client.select(3, function() { /* ... */ });\n\nclient.on(\"error\", function (err) {\n    console.log(\"Error \" + err);\n});\n\nclient.set(\"string key\", \"string val\", redis.print);\nclient.hset(\"hash key\", \"hashtest 1\", \"some value\", redis.print);\nclient.hset([\"hash key\", \"hashtest 2\", \"some other value\"], redis.print);\nclient.hkeys(\"hash key\", function (err, replies) {\n    console.log(replies.length + \" replies:\");\n    replies.forEach(function (reply, i) {\n        console.log(\"    \" + i + \": \" + reply);\n    });\n    client.quit();\n});\n```\n\nThis will display:\n\n    mjr:~/work/node_redis (master)$ node example.js\n    Reply: OK\n    Reply: 0\n    Reply: 0\n    2 replies:\n        0: hashtest 1\n        1: hashtest 2\n    mjr:~/work/node_redis (master)$\n\nNote that the API is entirely asynchronous. To get data back from the server,\nyou'll need to use a callback. From v.2.6 on the API supports camelCase and\nsnake_case and all options / variables / events etc. can be used either way. It\nis recommended to use camelCase as this is the default for the Node.js\nlandscape.\n\n### Promises\n\nYou can also use node_redis with promises by promisifying node_redis with\n[bluebird](https://github.com/petkaantonov/bluebird) as in:\n\n```js\nvar redis = require('redis');\nbluebird.promisifyAll(redis.RedisClient.prototype);\nbluebird.promisifyAll(redis.Multi.prototype);\n```\n\nIt'll add a *Async* to all node_redis functions (e.g. return client.getAsync().then())\n\n```js\n// We expect a value 'foo': 'bar' to be present\n// So instead of writing client.get('foo', cb); you have to write:\nreturn client.getAsync('foo').then(function(res) {\n    console.log(res); // => 'bar'\n});\n\n// Using multi with promises looks like:\n\nreturn client.multi().get('foo').execAsync().then(function(res) {\n    console.log(res); // => 'bar'\n});\n```\n\n### Sending Commands\n\nEach Redis command is exposed as a function on the `client` object.\nAll functions take either an `args` Array plus optional `callback` Function or\na variable number of individual arguments followed by an optional callback.\nExamples:\n\n```js\nclient.hmset([\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Works the same as\nclient.hmset(\"key\", [\"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\"], function (err, res) {});\n// Or\nclient.hmset(\"key\", \"test keys 1\", \"test val 1\", \"test keys 2\", \"test val 2\", function (err, res) {});\n```\n\nCare should be taken with user input if arrays are possible (via body-parser, query string or other method), as single arguments could be unintentionally interpreted as multiple args.\n\nNote that in either form the `callback` is optional:\n\n```js\nclient.set(\"some key\", \"some val\");\nclient.set([\"some other key\", \"some val\"]);\n```\n\nIf the key is missing, reply will be null. Only if the [Redis Command\nReference](http://redis.io/commands) states something else it will not be null.\n\n```js\nclient.get(\"missingkey\", function(err, reply) {\n    // reply is null when the key is missing\n    console.log(reply);\n});\n```\n\nFor a list of Redis commands, see [Redis Command Reference](http://redis.io/commands)\n\nMinimal parsing is done on the replies. Commands that return a integer return\nJavaScript Numbers, arrays return JavaScript Array. `HGETALL` returns an Object\nkeyed by the hash keys. All strings will either be returned as string or as\nbuffer depending on your setting. Please be aware that sending null, undefined\nand Boolean values will result in the value coerced to a string!\n\n# Redis Commands\n\nThis library is a 1 to 1 mapping to [Redis commands](https://redis.io/commands).\nIt is not a cache library so please refer to Redis commands page for full usage\ndetails.\n\nExample setting key to auto expire using [SET command](https://redis.io/commands/set)\n\n```js\n// this key will expire after 10 seconds\nclient.set('key', 'value!', 'EX', 10);\n```\n\n# API\n\n## Connection and other Events\n\n`client` will emit some events about the state of the connection to the Redis server.\n\n### \"ready\"\n\n`client` will emit `ready` once a connection is established. Commands issued\nbefore the `ready` event are queued, then replayed just before this event is\nemitted.\n\n### \"connect\"\n\n`client` will emit `connect` as soon as the stream is connected to the server.\n\n### \"reconnecting\"\n\n`client` will emit `reconnecting` when trying to reconnect to the Redis server\nafter losing the connection. Listeners are passed an object containing `delay`\n(in ms) and `attempt` (the attempt #) attributes.\n\n### \"error\"\n\n`client` will emit `error` when encountering an error connecting to the Redis\nserver or when any other in node_redis occurs. If you use a command without\ncallback and encounter a ReplyError it is going to be emitted to the error\nlistener.\n\nSo please attach the error listener to node_redis.\n\n### \"end\"\n\n`client` will emit `end` when an established Redis server connection has closed.\n\n### \"drain\" (deprecated)\n\n`client` will emit `drain` when the TCP connection to the Redis server has been\nbuffering, but is now writable. This event can be used to stream commands in to\nRedis and adapt to backpressure.\n\nIf the stream is buffering `client.should_buffer` is set to true. Otherwise the\nvariable is always set to false. That way you can decide when to reduce your\nsend rate and resume sending commands when you get `drain`.\n\nYou can also check the return value of each command as it will also return the\nbackpressure indicator (deprecated). If false is returned the stream had to\nbuffer.\n\n### \"warning\"\n\n`client` will emit `warning` when password was set but none is needed and if a\ndeprecated option / function / similar is used.\n\n### \"idle\" (deprecated)\n\n`client` will emit `idle` when there are no outstanding commands that are\nawaiting a response.\n\n## redis.createClient()\nIf you have `redis-server` running on the same machine as node, then the\ndefaults for port and host are probably fine and you don't need to supply any\narguments. `createClient()` returns a `RedisClient` object. Otherwise,\n`createClient()` accepts these arguments:\n\n* `redis.createClient([options])`\n* `redis.createClient(unix_socket[, options])`\n* `redis.createClient(redis_url[, options])`\n* `redis.createClient(port[, host][, options])`\n\n__Tip:__ If the Redis server runs on the same machine as the client consider\nusing unix sockets if possible to increase throughput.\n\n#### `options` object properties\n| Property  | Default   | Description |\n|-----------|-----------|-------------|\n| host      | 127.0.0.1 | IP address of the Redis server |\n| port      | 6379      | Port of the Redis server |\n| path      | null      | The UNIX socket string of the Redis server |\n| url       | null      | The URL of the Redis server. Format: `[redis:]//[[user][:password@]][host][:port][/db-number][?db=db-number[&password=bar[&option=value]]]` (More info avaliable at [IANA](http://www.iana.org/assignments/uri-schemes/prov/redis)). |\n| parser    | javascript | __Deprecated__ Use either the built-in JS parser [`javascript`]() or the native [`hiredis`]() parser. __Note__ `node_redis` < 2.6 uses hiredis as default if installed. This changed in v.2.6.0. |\n| string_numbers | null | Set to `true`, `node_redis` will return Redis number values as Strings instead of javascript Numbers. Useful if you need to handle big numbers (above `Number.MAX_SAFE_INTEGER === 2^53`). Hiredis is incapable of this behavior, so setting this option to `true` will result in the built-in javascript parser being used no matter the value of the `parser` option. |\n| return_buffers | false | If set to `true`, then all replies will be sent to callbacks as Buffers instead of Strings. |\n| detect_buffers | false | If set to `true`, then replies will be sent to callbacks as Buffers. This option lets you switch between Buffers and Strings on a per-command basis, whereas `return_buffers` applies to every command on a client. __Note__: This doesn't work properly with the pubsub mode. A subscriber has to either always return Strings or Buffers. |\n| socket_keepalive | true | If set to `true`, the keep-alive functionality is enabled on the underlying socket. |\n| no_ready_check | false |  When a connection is established to the Redis server, the server might still be loading the database from disk. While loading, the server will not respond to any commands. To work around this, `node_redis` has a \"ready check\" which sends the `INFO` command to the server. The response from the `INFO` command indicates whether the server is ready for more commands. When ready, `node_redis` emits a `ready` event. Setting `no_ready_check` to `true` will inhibit this check. |\n| enable_offline_queue |  true | By default, if there is no active connection to the Redis server, commands are added to a queue and are executed once the connection has been established. Setting `enable_offline_queue` to `false` will disable this feature and the callback will be executed immediately with an error, or an error will be emitted if no callback is specified. |\n| retry_max_delay | null | __Deprecated__ _Please use `retry_strategy` instead._ By default, every time the client tries to connect and fails, the reconnection delay almost doubles. This delay normally grows infinitely, but setting `retry_max_delay` limits it to the maximum value provided in milliseconds. |\n| connect_timeout | 3600000 | __Deprecated__ _Please use `retry_strategy` instead._ Setting `connect_timeout` limits the total time for the client to connect and reconnect. The value is provided in milliseconds and is counted from the moment a new client is created or from the time the connection is lost. The last retry is going to happen exactly at the timeout time. Default is to try connecting until the default system socket timeout has been exceeded and to try reconnecting until 1h has elapsed. |\n| max_attempts | 0 | __Deprecated__ _Please use `retry_strategy` instead._ By default, a client will try reconnecting until connected. Setting `max_attempts` limits total amount of connection attempts. Setting this to 1 will prevent any reconnect attempt. |\n| retry_unfulfilled_commands | false | If set to `true`, all commands that were unfulfilled while the connection is lost will be retried after the connection has been reestablished. Use this with caution if you use state altering commands (e.g. `incr`). This is especially useful if you use blocking commands. |\n| password | null | If set, client will run Redis auth command on connect. Alias `auth_pass` __Note__ `node_redis` < 2.5 must use `auth_pass` |\n| db | null | If set, client will run Redis `select` command on connect. |\n| family | IPv4 | You can force using IPv6 if you set the family to 'IPv6'. See Node.js [net](https://nodejs.org/api/net.html) or [dns](https://nodejs.org/api/dns.html) modules on how to use the family type. |\n| disable_resubscribing | false | If set to `true`, a client won't resubscribe after disconnecting. |\n| rename_commands | null | Passing an object with renamed commands to use instead of the original functions. For example, if you renamed the command KEYS to \"DO-NOT-USE\" then the rename_commands object would be: `{ KEYS : \"DO-NOT-USE\" }` . See the [Redis security topics](http://redis.io/topics/security) for more info. |\n| tls | null | An object containing options to pass to [tls.connect](http://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback) to set up a TLS connection to Redis (if, for example, it is set up to be accessible via a tunnel). |\n| prefix | null | A string used to prefix all used keys (e.g. `namespace:test`). Please be aware that the `keys` command will not be prefixed. The `keys` command has a \"pattern\" as argument and no key and it would be impossible to determine the existing keys in Redis if this would be prefixed. |\n| retry_strategy | function | A function that receives an options object as parameter including the retry `attempt`, the `total_retry_time` indicating how much time passed since the last time connected, the `error` why the connection was lost and the number of `times_connected` in total. If you return a number from this function, the retry will happen exactly after that time in milliseconds. If you return a non-number, no further retry will happen and all offline commands are flushed with errors. Return an error to return that specific error to all offline commands. Example below. |\n\n```js\nvar redis = require(\"redis\");\nvar client = redis.createClient({detect_buffers: true});\n\nclient.set(\"foo_rand000000000000\", \"OK\");\n\n// This will return a JavaScript String\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(reply.toString()); // Will print `OK`\n});\n\n// This will return a Buffer since original key is specified as a Buffer\nclient.get(new Buffer(\"foo_rand000000000000\"), function (err, reply) {\n    console.log(reply.toString()); // Will print `<Buffer 4f 4b>`\n});\nclient.quit();\n```\n\nretry_strategy example\n\n```js\nvar client = redis.createClient({\n    retry_strategy: function (options) {\n        if (options.error && options.error.code === 'ECONNREFUSED') {\n            // End reconnecting on a specific error and flush all commands with\n            // a individual error\n            return new Error('The server refused the connection');\n        }\n        if (options.total_retry_time > 1000 * 60 * 60) {\n            // End reconnecting after a specific timeout and flush all commands\n            // with a individual error\n            return new Error('Retry time exhausted');\n        }\n        if (options.attempt > 10) {\n            // End reconnecting with built in error\n            return undefined;\n        }\n        // reconnect after\n        return Math.min(options.attempt * 100, 3000);\n    }\n});\n```\n\n## client.auth(password[, callback])\n\nWhen connecting to a Redis server that requires authentication, the `AUTH`\ncommand must be sent as the first command after connecting. This can be tricky\nto coordinate with reconnections, the ready check, etc. To make this easier,\n`client.auth()` stashes `password` and will send it after each connection,\nincluding reconnections. `callback` is invoked only once, after the response to\nthe very first `AUTH` command sent.\nNOTE: Your call to `client.auth()` should not be inside the ready handler. If\nyou are doing this wrong, `client` will emit an error that looks\nsomething like this `Error: Ready check failed: ERR operation not permitted`.\n\n## backpressure\n\n### stream\n\nThe client exposed the used [stream](https://nodejs.org/api/stream.html) in\n`client.stream` and if the stream or client had to\n[buffer](https://nodejs.org/api/stream.html#stream_writable_write_chunk_encoding_callback)\nthe command in `client.should_buffer`. In combination this can be used to\nimplement backpressure by checking the buffer state before sending a command and\nlistening to the stream\n[drain](https://nodejs.org/api/stream.html#stream_event_drain) event.\n\n## client.quit()\n\nThis sends the quit command to the redis server and ends cleanly right after all\nrunning commands were properly handled. If this is called while reconnecting\n(and therefore no connection to the redis server exists) it is going to end the\nconnection right away instead of resulting in further reconnections! All offline\ncommands are going to be flushed with an error in that case.\n\n## client.end(flush)\n\nForcibly close the connection to the Redis server. Note that this does not wait\nuntil all replies have been parsed. If you want to exit cleanly, call\n`client.quit()` as mentioned above.\n\nYou should set flush to true, if you are not absolutely sure you do not care\nabout any other commands. If you set flush to false all still running commands\nwill silently fail.\n\nThis example closes the connection to the Redis server before the replies have\nbeen read. You probably don't want to do this:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.set(\"foo_rand000000000000\", \"some fantastic value\", function (err, reply) {\n    // This will either result in an error (flush parameter is set to true)\n    // or will silently fail and this callback will not be called at all (flush set to false)\n    console.log(err);\n});\nclient.end(true); // No further commands will be processed\nclient.get(\"foo_rand000000000000\", function (err, reply) {\n    console.log(err); // => 'The connection has already been closed.'\n});\n```\n\n`client.end()` without the flush parameter set to true should NOT be used in production!\n\n## Error handling (>= v.2.6)\n\nCurrently the following error subclasses exist:\n\n* `RedisError`: _All errors_ returned by the client\n* `ReplyError` subclass of `RedisError`: All errors returned by __Redis__ itself\n* `AbortError` subclass of `RedisError`: All commands that could not finish due\n  to what ever reason\n* `ParserError` subclass of `RedisError`: Returned in case of a parser error\n  (this should not happen)\n* `AggregateError` subclass of `AbortError`: Emitted in case multiple unresolved\n  commands without callback got rejected in debug_mode instead of lots of\n  `AbortError`s.\n\nAll error classes are exported by the module.\n\nExample:\n```js\nvar redis = require('./');\nvar assert = require('assert');\nvar client = redis.createClient();\n\nclient.on('error', function (err) {\n    assert(err instanceof Error);\n    assert(err instanceof redis.AbortError);\n    assert(err instanceof redis.AggregateError);\n    // The set and get get aggregated in here\n    assert.strictEqual(err.errors.length, 2);\n    assert.strictEqual(err.code, 'NR_CLOSED');\n});\nclient.set('foo', 123, 'bar', function (err, res) { // Too many arguments\n    assert(err instanceof redis.ReplyError); // => true\n    assert.strictEqual(err.command, 'SET');\n    assert.deepStrictEqual(err.args, ['foo', 123, 'bar']);\n\n    redis.debug_mode = true;\n    client.set('foo', 'bar');\n    client.get('foo');\n    process.nextTick(function () {\n        // Force closing the connection while the command did not yet return\n        client.end(true);\n        redis.debug_mode = false;\n    });\n});\n\n```\n\nEvery `ReplyError` contains the `command` name in all-caps and the arguments (`args`).\n\nIf node_redis emits a library error because of another error, the triggering\nerror is added to the returned error as `origin` attribute.\n\n___Error codes___\n\nnode_redis returns a `NR_CLOSED` error code if the clients connection dropped.\nIf a command unresolved command got rejected a `UNCERTAIN_STATE` code is\nreturned. A `CONNECTION_BROKEN` error code is used in case node_redis gives up\nto reconnect.\n\n## client.unref()\n\nCall `unref()` on the underlying socket connection to the Redis server, allowing\nthe program to exit once no more commands are pending.\n\nThis is an **experimental** feature, and only supports a subset of the Redis\nprotocol. Any commands where client state is saved on the Redis server, e.g.\n`*SUBSCRIBE` or the blocking `BL*` commands will *NOT* work with `.unref()`.\n\n```js\nvar redis = require(\"redis\")\nvar client = redis.createClient()\n\n/*\n    Calling unref() will allow this program to exit immediately after the get\n    command finishes. Otherwise the client would hang as long as the\n    client-server connection is alive.\n*/\nclient.unref()\nclient.get(\"foo\", function (err, value){\n    if (err) throw(err)\n    console.log(value)\n})\n```\n\n## Friendlier hash commands\n\nMost Redis commands take a single String or an Array of Strings as arguments,\nand replies are sent back as a single String or an Array of Strings. When\ndealing with hash values, there are a couple of useful exceptions to this.\n\n### client.hgetall(hash, callback)\n\nThe reply from an HGETALL command will be converted into a JavaScript Object by\n`node_redis`. That way you can interact with the responses using JavaScript\nsyntax.\n\nExample:\n\n```js\nclient.hmset(\"hosts\", \"mjr\", \"1\", \"another\", \"23\", \"home\", \"1234\");\nclient.hgetall(\"hosts\", function (err, obj) {\n    console.dir(obj);\n});\n```\n\nOutput:\n\n```js\n{ mjr: '1', another: '23', home: '1234' }\n```\n\n### client.hmset(hash, obj[, callback])\n\nMultiple values in a hash can be set by supplying an object:\n\n```js\nclient.HMSET(key2, {\n    \"0123456789\": \"abcdefghij\", // NOTE: key and value will be coerced to strings\n    \"some manner of key\": \"a type of value\"\n});\n```\n\nThe properties and values of this Object will be set as keys and values in the\nRedis hash.\n\n### client.hmset(hash, key1, val1, ... keyn, valn, [callback])\n\nMultiple values may also be set by supplying a list:\n\n```js\nclient.HMSET(key1, \"0123456789\", \"abcdefghij\", \"some manner of key\", \"a type of value\");\n```\n\n## Publish / Subscribe\n\nExample of the publish / subscribe API. This program opens two\nclient connections, subscribes to a channel on one of them, and publishes to that\nchannel on the other:\n\n```js\nvar redis = require(\"redis\");\nvar sub = redis.createClient(), pub = redis.createClient();\nvar msg_count = 0;\n\nsub.on(\"subscribe\", function (channel, count) {\n    pub.publish(\"a nice channel\", \"I am sending a message.\");\n    pub.publish(\"a nice channel\", \"I am sending a second message.\");\n    pub.publish(\"a nice channel\", \"I am sending my last message.\");\n});\n\nsub.on(\"message\", function (channel, message) {\n    console.log(\"sub channel \" + channel + \": \" + message);\n    msg_count += 1;\n    if (msg_count === 3) {\n        sub.unsubscribe();\n        sub.quit();\n        pub.quit();\n    }\n});\n\nsub.subscribe(\"a nice channel\");\n```\n\nWhen a client issues a `SUBSCRIBE` or `PSUBSCRIBE`, that connection is put into\na \"subscriber\" mode. At that point, only commands that modify the subscription\nset are valid and quit (and depending on the redis version ping as well). When\nthe subscription set is empty, the connection is put back into regular mode.\n\nIf you need to send regular commands to Redis while in subscriber mode, just\nopen another connection with a new client (hint: use `client.duplicate()`).\n\n## Subscriber Events\n\nIf a client has subscriptions active, it may emit these events:\n\n### \"message\" (channel, message)\n\nClient will emit `message` for every message received that matches an active subscription.\nListeners are passed the channel name as `channel` and the message as `message`.\n\n### \"pmessage\" (pattern, channel, message)\n\nClient will emit `pmessage` for every message received that matches an active\nsubscription pattern. Listeners are passed the original pattern used with\n`PSUBSCRIBE` as `pattern`, the sending channel name as `channel`, and the\nmessage as `message`.\n\n### \"message_buffer\" (channel, message)\n\nThis is the same as the `message` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `message` event at the same time as\nthe `message_buffer`, it is always going to emit a string.\n\n### \"pmessage_buffer\" (pattern, channel, message)\n\nThis is the same as the `pmessage` event with the exception, that it is always\ngoing to emit a buffer. If you listen to the `pmessage` event at the same time\nas the `pmessage_buffer`, it is always going to emit a string.\n\n### \"subscribe\" (channel, count)\n\nClient will emit `subscribe` in response to a `SUBSCRIBE` command. Listeners are\npassed the channel name as `channel` and the new count of subscriptions for this\nclient as `count`.\n\n### \"psubscribe\" (pattern, count)\n\nClient will emit `psubscribe` in response to a `PSUBSCRIBE` command. Listeners\nare passed the original pattern as `pattern`, and the new count of subscriptions\nfor this client as `count`.\n\n### \"unsubscribe\" (channel, count)\n\nClient will emit `unsubscribe` in response to a `UNSUBSCRIBE` command. Listeners\nare passed the channel name as `channel` and the new count of subscriptions for\nthis client as `count`. When `count` is 0, this client has left subscriber mode\nand no more subscriber events will be emitted.\n\n### \"punsubscribe\" (pattern, count)\n\nClient will emit `punsubscribe` in response to a `PUNSUBSCRIBE` command.\nListeners are passed the channel name as `channel` and the new count of\nsubscriptions for this client as `count`. When `count` is 0, this client has\nleft subscriber mode and no more subscriber events will be emitted.\n\n## client.multi([commands])\n\n`MULTI` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Multi` object by calling `client.multi()`. If any command fails to\nqueue, all commands are rolled back and none is going to be executed (For\nfurther information look at\n[transactions](http://redis.io/topics/transactions)).\n\n```js\nvar redis  = require(\"./index\"),\n    client = redis.createClient(), set_size = 20;\n\nclient.sadd(\"bigset\", \"a member\");\nclient.sadd(\"bigset\", \"another member\");\n\nwhile (set_size > 0) {\n    client.sadd(\"bigset\", \"member \" + set_size);\n    set_size -= 1;\n}\n\n// multi chain with an individual callback\nclient.multi()\n    .scard(\"bigset\")\n    .smembers(\"bigset\")\n    .keys(\"*\", function (err, replies) {\n        // NOTE: code in this callback is NOT atomic\n        // this only happens after the the .exec call finishes.\n        client.mget(replies, redis.print);\n    })\n    .dbsize()\n    .exec(function (err, replies) {\n        console.log(\"MULTI got \" + replies.length + \" replies\");\n        replies.forEach(function (reply, index) {\n            console.log(\"Reply \" + index + \": \" + reply.toString());\n        });\n    });\n```\n\n### Multi.exec([callback])\n\n`client.multi()` is a constructor that returns a `Multi` object. `Multi` objects\nshare all of the same command methods as `client` objects do. Commands are\nqueued up inside the `Multi` object until `Multi.exec()` is invoked.\n\nIf your code contains an syntax error an EXECABORT error is going to be thrown\nand all commands are going to be aborted. That error contains a `.errors`\nproperty that contains the concrete errors.\nIf all commands were queued successfully and an error is thrown by redis while\nprocessing the commands that error is going to be returned in the result array!\nNo other command is going to be aborted though than the onces failing.\n\nYou can either chain together `MULTI` commands as in the above example, or you\ncan queue individual commands while still sending regular client command as in\nthis example:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient(), multi;\n\n// start a separate multi command queue\nmulti = client.multi();\nmulti.incr(\"incr thing\", redis.print);\nmulti.incr(\"incr other thing\", redis.print);\n\n// runs immediately\nclient.mset(\"incr thing\", 100, \"incr other thing\", 1, redis.print);\n\n// drains multi queue and runs atomically\nmulti.exec(function (err, replies) {\n    console.log(replies); // 101, 2\n});\n```\n\nIn addition to adding commands to the `MULTI` queue individually, you can also\npass an array of commands and arguments to the constructor:\n\n```js\nvar redis  = require(\"redis\"),\n    client = redis.createClient();\n\nclient.multi([\n    [\"mget\", \"multifoo\", \"multibar\", redis.print],\n    [\"incr\", \"multifoo\"],\n    [\"incr\", \"multibar\"]\n]).exec(function (err, replies) {\n    console.log(replies);\n});\n```\n\n### Multi.exec_atomic([callback])\n\nIdentical to Multi.exec but with the difference that executing a single command\nwill not use transactions.\n\n## client.batch([commands])\n\nIdentical to .multi without transactions. This is recommended if you want to\nexecute many commands at once but don't have to rely on transactions.\n\n`BATCH` commands are queued up until an `EXEC` is issued, and then all commands\nare run atomically by Redis. The interface in `node_redis` is to return an\nindividual `Batch` object by calling `client.batch()`. The only difference\nbetween .batch and .multi is that no transaction is going to be used.\nBe aware that the errors are - just like in multi statements - in the result.\nOtherwise both, errors and results could be returned at the same time.\n\nIf you fire many commands at once this is going to boost the execution speed\nsignificantly compared to firing the same commands in a loop without waiting for\nthe result! See the benchmarks for further comparison. Please remember that all\ncommands are kept in memory until they are fired.\n\n## Monitor mode\n\nRedis supports the `MONITOR` command, which lets you see all commands received\nby the Redis server across all client connections, including from other client\nlibraries and other computers.\n\nA `monitor` event is going to be emitted for every command fired from any client\nconnected to the server including the monitoring client itself. The callback for\nthe `monitor` event takes a timestamp from the Redis server, an array of command\narguments and the raw monitoring string.\n\nExample:\n\n```js\nvar client  = require(\"redis\").createClient();\nclient.monitor(function (err, res) {\n    console.log(\"Entering monitoring mode.\");\n});\nclient.set('foo', 'bar');\n\nclient.on(\"monitor\", function (time, args, raw_reply) {\n    console.log(time + \": \" + args); // 1458910076.446514:['set', 'foo', 'bar']\n});\n```\n\n# Extras\n\nSome other things you might like to know about.\n\n## client.server_info\n\nAfter the ready probe completes, the results from the INFO command are saved in\nthe `client.server_info` object.\n\nThe `versions` key contains an array of the elements of the version string for\neasy comparison.\n\n    > client.server_info.redis_version\n    '2.3.0'\n    > client.server_info.versions\n    [ 2, 3, 0 ]\n\n## redis.print()\n\nA handy callback function for displaying return values when testing. Example:\n\n```js\nvar redis = require(\"redis\"),\n    client = redis.createClient();\n\nclient.on(\"connect\", function () {\n    client.set(\"foo_rand000000000000\", \"some fantastic value\", redis.print);\n    client.get(\"foo_rand000000000000\", redis.print);\n});\n```\n\nThis will print:\n\n    Reply: OK\n    Reply: some fantastic value\n\nNote that this program will not exit cleanly because the client is still connected.\n\n## Multi-word commands\n\nTo execute redis multi-word commands like `SCRIPT LOAD` or `CLIENT LIST` pass\nthe second word as first parameter:\n\n    client.script('load', 'return 1');\n    client.multi().script('load', 'return 1').exec(...);\n    client.multi([['script', 'load', 'return 1']]).exec(...);\n\n## client.duplicate([options][, callback])\n\nDuplicate all current options and return a new redisClient instance. All options\npassed to the duplicate function are going to replace the original option. If\nyou pass a callback, duplicate is going to wait until the client is ready and\nreturns it in the callback. If an error occurs in the meanwhile, that is going\nto return an error instead in the callback.\n\nOne example of when to use duplicate() would be to accommodate the connection-\nblocking redis commands BRPOP, BLPOP, and BRPOPLPUSH.  If these commands\nare used on the same redisClient instance as non-blocking commands, the\nnon-blocking ones may be queued up until after the blocking ones finish.\n\n    var Redis=require('redis');\n    var client = Redis.createClient();\n    var clientBlocking = client.duplicate();\n\n    var get = function() {\n        console.log(\"get called\");\n        client.get(\"any_key\",function() { console.log(\"get returned\"); });\n        setTimeout( get, 1000 );\n    };\n    var brpop = function() {\n        console.log(\"brpop called\");\n        clientBlocking.brpop(\"nonexistent\", 5, function() {\n            console.log(\"brpop return\");\n            setTimeout( brpop, 1000 );\n        });\n    };\n    get();\n    brpop();\n\nAnother reason to use duplicate() is when multiple DBs on the same server are\naccessed via the redis SELECT command.  Each DB could use its own connection.\n\n## client.send_command(command_name[, [args][, callback]])\n\nAll Redis commands have been added to the `client` object. However, if new\ncommands are introduced before this library is updated or if you want to add\nindividual commands you can use `send_command()` to send arbitrary commands to\nRedis.\n\nAll commands are sent as multi-bulk commands. `args` can either be an Array of\narguments, or omitted / set to undefined.\n\n## client.add_command(command_name)\n\nCalling add_command will add a new command to the prototype. The exact command\nname will be used when calling using this new command. Using arbitrary arguments\nis possible as with any other command.\n\n## client.connected\n\nBoolean tracking the state of the connection to the Redis server.\n\n## client.command_queue_length\n\nThe number of commands that have been sent to the Redis server but not yet\nreplied to. You can use this to enforce some kind of maximum queue depth for\ncommands while connected.\n\n## client.offline_queue_length\n\nThe number of commands that have been queued up for a future connection. You can\nuse this to enforce some kind of maximum queue depth for pre-connection\ncommands.\n\n### Commands with Optional and Keyword arguments\n\nThis applies to anything that uses an optional `[WITHSCORES]` or `[LIMIT offset\ncount]` in the [redis.io/commands](http://redis.io/commands) documentation.\n\nExample:\n\n```js\nvar args = [ 'myzset', 1, 'one', 2, 'two', 3, 'three', 99, 'ninety-nine' ];\nclient.zadd(args, function (err, response) {\n    if (err) throw err;\n    console.log('added '+response+' items.');\n\n    // -Infinity and +Infinity also work\n    var args1 = [ 'myzset', '+inf', '-inf' ];\n    client.zrevrangebyscore(args1, function (err, response) {\n        if (err) throw err;\n        console.log('example1', response);\n        // write your code here\n    });\n\n    var max = 3, min = 1, offset = 1, count = 2;\n    var args2 = [ 'myzset', max, min, 'WITHSCORES', 'LIMIT', offset, count ];\n    client.zrevrangebyscore(args2, function (err, response) {\n        if (err) throw err;\n        console.log('example2', response);\n        // write your code here\n    });\n});\n```\n\n## Performance\n\nMuch effort has been spent to make `node_redis` as fast as possible for common\noperations.\n\n```\nLenovo T450s, i7-5600U and 12gb memory\nclients: 1, NodeJS: 6.2.0, Redis: 3.2.0, parser: javascript, connected by: tcp\n         PING,         1/1 avg/max:   0.02/  5.26 2501ms total,   46916 ops/sec\n         PING,  batch 50/1 avg/max:   0.06/  4.35 2501ms total,  755178 ops/sec\n   SET 4B str,         1/1 avg/max:   0.02/  4.75 2501ms total,   40856 ops/sec\n   SET 4B str,  batch 50/1 avg/max:   0.11/  1.51 2501ms total,  432727 ops/sec\n   SET 4B buf,         1/1 avg/max:   0.05/  2.76 2501ms total,   20659 ops/sec\n   SET 4B buf,  batch 50/1 avg/max:   0.25/  1.76 2501ms total,  194962 ops/sec\n   GET 4B str,         1/1 avg/max:   0.02/  1.55 2501ms total,   45156 ops/sec\n   GET 4B str,  batch 50/1 avg/max:   0.09/  3.15 2501ms total,  524110 ops/sec\n   GET 4B buf,         1/1 avg/max:   0.02/  3.07 2501ms total,   44563 ops/sec\n   GET 4B buf,  batch 50/1 avg/max:   0.10/  3.18 2501ms total,  473171 ops/sec\n SET 4KiB str,         1/1 avg/max:   0.03/  1.54 2501ms total,   32627 ops/sec\n SET 4KiB str,  batch 50/1 avg/max:   0.34/  1.89 2501ms total,  146861 ops/sec\n SET 4KiB buf,         1/1 avg/max:   0.05/  2.85 2501ms total,   20688 ops/sec\n SET 4KiB buf,  batch 50/1 avg/max:   0.36/  1.83 2501ms total,  138165 ops/sec\n GET 4KiB str,         1/1 avg/max:   0.02/  1.37 2501ms total,   39389 ops/sec\n GET 4KiB str,  batch 50/1 avg/max:   0.24/  1.81 2501ms total,  208157 ops/sec\n GET 4KiB buf,         1/1 avg/max:   0.02/  2.63 2501ms total,   39918 ops/sec\n GET 4KiB buf,  batch 50/1 avg/max:   0.31/  8.56 2501ms total,  161575 ops/sec\n         INCR,         1/1 avg/max:   0.02/  4.69 2501ms total,   45685 ops/sec\n         INCR,  batch 50/1 avg/max:   0.09/  3.06 2501ms total,  539964 ops/sec\n        LPUSH,         1/1 avg/max:   0.02/  3.04 2501ms total,   41253 ops/sec\n        LPUSH,  batch 50/1 avg/max:   0.12/  1.94 2501ms total,  425090 ops/sec\n    LRANGE 10,         1/1 avg/max:   0.02/  2.28 2501ms total,   39850 ops/sec\n    LRANGE 10,  batch 50/1 avg/max:   0.25/  1.85 2501ms total,  194302 ops/sec\n   LRANGE 100,         1/1 avg/max:   0.05/  2.93 2501ms total,   21026 ops/sec\n   LRANGE 100,  batch 50/1 avg/max:   1.52/  2.89 2501ms total,   32767 ops/sec\n SET 4MiB str,         1/1 avg/max:   5.16/ 15.55 2502ms total,     193 ops/sec\n SET 4MiB str,  batch 20/1 avg/max:  89.73/ 99.96 2513ms total,     223 ops/sec\n SET 4MiB buf,         1/1 avg/max:   2.23/  8.35 2501ms total,     446 ops/sec\n SET 4MiB buf,  batch 20/1 avg/max:  41.47/ 50.91 2530ms total,     482 ops/sec\n GET 4MiB str,         1/1 avg/max:   2.79/ 10.91 2502ms total,     358 ops/sec\n GET 4MiB str,  batch 20/1 avg/max: 101.61/118.11 2541ms total,     197 ops/sec\n GET 4MiB buf,         1/1 avg/max:   2.32/ 14.93 2502ms total,     430 ops/sec\n GET 4MiB buf,  batch 20/1 avg/max:  65.01/ 84.72 2536ms total,     308 ops/sec\n ```\n\n## Debugging\n\nTo get debug output run your `node_redis` application with `NODE_DEBUG=redis`.\n\nThis is also going to result in good stack traces opposed to useless ones\notherwise for any async operation.\nIf you only want to have good stack traces but not the debug output run your\napplication in development mode instead (`NODE_ENV=development`).\n\nGood stack traces are only activated in development and debug mode as this\nresults in a significant performance penalty.\n\n___Comparison___:\nUseless stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at parseError (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:158:12)\n    at parseType (/home/ruben/repos/redis/node_modules/redis-parser/lib/parser.js:219:14)\n```\nGood stack trace:\n```\nReplyError: ERR wrong number of arguments for 'set' command\n    at new Command (/home/ruben/repos/redis/lib/command.js:9:902)\n    at RedisClient.set (/home/ruben/repos/redis/lib/commands.js:9:3238)\n    at Context.<anonymous> (/home/ruben/repos/redis/test/good_stacks.spec.js:20:20)\n    at callFnAsync (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:349:8)\n    at Test.Runnable.run (/home/ruben/repos/redis/node_modules/mocha/lib/runnable.js:301:7)\n    at Runner.runTest (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:422:10)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:528:12\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:342:14)\n    at /home/ruben/repos/redis/node_modules/mocha/lib/runner.js:352:7\n    at next (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:284:14)\n    at Immediate._onImmediate (/home/ruben/repos/redis/node_modules/mocha/lib/runner.js:320:5)\n    at processImmediate [as _immediateCallback] (timers.js:383:17)\n```\n\n## How to Contribute\n- Open a pull request or an issue about what you want to implement / change. We're glad for any help!\n - Please be aware that we'll only accept fully tested code.\n\n## Contributors\n\nThe original author of node_redis is [Matthew Ranney](https://github.com/mranney)\n\nThe current lead maintainer is [Ruben Bridgewater](https://github.com/BridgeAR)\n\nMany [others](https://github.com/NodeRedis/node_redis/graphs/contributors)\ncontributed to `node_redis` too. Thanks to all of them!\n\n## License\n\n[MIT](LICENSE)\n\n### Consolidation: It's time for celebration\n\nRight now there are two great redis clients around and both have some advantages\nabove each other. We speak about ioredis and node_redis. So after talking to\neach other about how we could improve in working together we (that is @luin and\n@BridgeAR) decided to work towards a single library on the long run. But step by\nstep.\n\nFirst of all, we want to split small parts of our libraries into others so that\nwe're both able to use the same code. Those libraries are going to be maintained\nunder the NodeRedis organization. This is going to reduce the maintenance\noverhead, allows others to use the very same code, if they need it and it's way\neasyer for others to contribute to both libraries.\n\nWe're very happy about this step towards working together as we both want to\ngive you the best redis experience possible.\n\nIf you want to join our cause by help maintaining something, please don't\nhesitate to contact either one of us.","slug":"nodejs-redis-doc","published":1,"updated":"2019-03-23T10:36:45.451Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjtle1ew0007fgyavuswdy3v7"}],"PostAsset":[],"PostCategory":[{"post_id":"cjtle1egn0005gyavvnaluqyr","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1eh7000cgyav7748oljd"},{"post_id":"cjtle1efr0000gyavd0t049oo","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1ehb000ggyavccb3ali3"},{"post_id":"cjtle1eh2000agyavf6rjqiv7","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1ehe000jgyav3kjww1d3"},{"post_id":"cjtle1eg20001gyavrpdieoml","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1ehi000ngyavgvio3ft9"},{"post_id":"cjtle1egg0004gyav8cd4y2c9","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1ehm000qgyaveryi1c0o"},{"post_id":"cjtle1ehf000mgyavfv1dwwwo","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eht000xgyavvwbty2iy"},{"post_id":"cjtle1egw0006gyav4owv4dob","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ei10010gyav319devij"},{"post_id":"cjtle1ehj000pgyavbjsw8t1u","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ei40014gyavbn80ow68"},{"post_id":"cjtle1eho000ugyavpw05mpui","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ei90017gyav0a0wj9tl"},{"post_id":"cjtle1eh5000bgyav6pbt6dwl","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1eic001bgyavdu1pq5f4"},{"post_id":"cjtle1ehx000zgyavqqwjaot5","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eih001fgyavzcw8ig6u"},{"post_id":"cjtle1eh9000fgyavfh6vkn8d","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eim001igyav9tth7bur"},{"post_id":"cjtle1ei20013gyavrfolo7z7","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eir001mgyav1k68nk69"},{"post_id":"cjtle1ehc000igyavjwqi7771","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eiv001pgyavhrwgflon"},{"post_id":"cjtle1eie001egyav6lpu06th","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1eiz001tgyavcpy4rmz9"},{"post_id":"cjtle1ehr000wgyavi09ha456","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ej3001wgyavmmjg65yx"},{"post_id":"cjtle1eij001hgyavene3dgre","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ej60020gyav2m6chbbh"},{"post_id":"cjtle1eio001lgyavwr7ydlkb","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ejb0023gyavq6gpy66d"},{"post_id":"cjtle1ei70016gyavontbjgpw","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1eje0027gyav28b2d2v0"},{"post_id":"cjtle1eit001ogyav0f0q3crf","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eji002agyavwcbi2809"},{"post_id":"cjtle1eix001sgyav8lvhy8yg","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ejm002egyav77g7vhyy"},{"post_id":"cjtle1eia001agyaveiygztrf","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ejp002hgyavyvygxgv1"},{"post_id":"cjtle1ej1001vgyavv5lhll4c","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ejt002lgyav7rrbqoi8"},{"post_id":"cjtle1ej5001zgyavpxq8u2mo","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ejw002ogyav7g7dhvgg"},{"post_id":"cjtle1ej80022gyavzj3p6vv7","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ek2002sgyav64omsulf"},{"post_id":"cjtle1ejc0026gyavpqwggnlm","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ek5002vgyavr7nw8soc"},{"post_id":"cjtle1ejf0029gyavxyw0u61e","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ek9002zgyavj9tufuff"},{"post_id":"cjtle1ejk002dgyavwmg4s1i4","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ekc0032gyavw75oev58"},{"post_id":"cjtle1ejn002ggyav186x3j93","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ekk0035gyavk59zss0v"},{"post_id":"cjtle1ejr002kgyav17bcf8r4","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1eko0039gyavnpgx4hw0"},{"post_id":"cjtle1eju002ngyav4n4jovvc","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1eks003cgyav1q91848o"},{"post_id":"cjtle1ejy002rgyaviwr7h5a8","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ekw003ggyavnyzdxpi6"},{"post_id":"cjtle1ek4002ugyaviteh738l","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1el1003jgyavoecfjajl"},{"post_id":"cjtle1ek7002ygyav684hmmnv","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1el5003ngyavt895tz1k"},{"post_id":"cjtle1eka0031gyav8hxbouxf","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ela003qgyav54ikr2y4"},{"post_id":"cjtle1ekg0034gyavlcvvrfj1","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1elf003ugyaveibzb2bj"},{"post_id":"cjtle1ekm0038gyavuvp9skh3","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1elj003xgyav51ozbtyd"},{"post_id":"cjtle1ekq003bgyav2snmfcc6","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eln0041gyavhkn6kdcp"},{"post_id":"cjtle1eku003fgyav11cygocq","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1elq0044gyavs6e40yfe"},{"post_id":"cjtle1eky003igyav61ifwb6n","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1elu0048gyavk7254z1u"},{"post_id":"cjtle1el2003mgyavns4q5fzu","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1ely004bgyavmf1u9jen"},{"post_id":"cjtle1el8003pgyavcoxvszbl","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1em1004fgyav29hqxzp8"},{"post_id":"cjtle1elc003tgyavmupyg8hf","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1em6004igyav0wd2irkm"},{"post_id":"cjtle1elg003wgyav94gk76j2","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1emc004mgyav554rud0e"},{"post_id":"cjtle1elk0040gyav09rtlcf1","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1emf004pgyav5m2enu3s"},{"post_id":"cjtle1elo0043gyav42fneaph","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1emi004tgyavazvtpksq"},{"post_id":"cjtle1elr0047gyav42gyidrb","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eml004xgyavk5ybhf0i"},{"post_id":"cjtle1elv004agyavmwf9k843","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1emp0050gyavwyigner1"},{"post_id":"cjtle1elz004egyav60va4pe1","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1emv0055gyavfio2ckuz"},{"post_id":"cjtle1em2004hgyav57xfoe9o","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1emy0058gyavpd3txl10"},{"post_id":"cjtle1em9004lgyavs5kxhs2a","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1en2005cgyav1vux8cn1"},{"post_id":"cjtle1emj004wgyav8dfxmcmn","category_id":"cjtle1egb0002gyavc6fxe6q7","_id":"cjtle1en6005ggyavpkng2ese"},{"post_id":"cjtle1emm004zgyavpp15nf0z","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1en9005kgyavl636kuul"},{"post_id":"cjtle1emd004ogyavgj5wg1uv","category_id":"cjtle1emi004ugyavix3vzrrm","_id":"cjtle1end005ngyavpbeax7j0"},{"post_id":"cjtle1ems0053gyavjjlf0f2y","category_id":"cjtle1emi004ugyavix3vzrrm","_id":"cjtle1enh005rgyav3qjpkfrn"},{"post_id":"cjtle1emg004sgyavq3qsd5sa","category_id":"cjtle1emi004ugyavix3vzrrm","_id":"cjtle1enl005ugyav278a7v51"},{"post_id":"cjtle1en0005bgyavkog4qpfq","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1enp005xgyavbwqmnm5k"},{"post_id":"cjtle1en3005fgyavgpcl5c4s","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1ent0061gyavhoo9fng9"},{"post_id":"cjtle1en7005jgyavkjdot0op","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1enx0064gyavykc82vf7"},{"post_id":"cjtle1emw0057gyavi53xxh74","category_id":"cjtle1en2005dgyavvjk8aqzk","_id":"cjtle1eo00068gyav25k86u7u"},{"post_id":"cjtle1ena005mgyavrs0rq003","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eo3006bgyavy7lsxvfj"},{"post_id":"cjtle1ene005qgyavcdg2scgy","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eol006fgyavw9d4ewsp"},{"post_id":"cjtle1enj005tgyav5lfol9vu","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eoq006igyavau77rc50"},{"post_id":"cjtle1enn005wgyavog0usui3","category_id":"cjtle1ehm000rgyavdj2rf3zr","_id":"cjtle1eou006mgyavmzzziirm"},{"post_id":"cjtle1enr0060gyavxhyouebd","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eox006pgyavlvgp3e38"},{"post_id":"cjtle1enu0063gyav63psl2n8","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1eoz006sgyavwruddwsz"},{"post_id":"cjtle1eny0067gyavgy6ksarm","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ep0006vgyavb908u1sq"},{"post_id":"cjtle1eo1006agyav5o7cpcjm","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ep1006ygyavza7dm4xn"},{"post_id":"cjtle1eoj006egyavnxdnunr3","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ep30070gyavc3svnvfd"},{"post_id":"cjtle1eon006hgyav526m3186","category_id":"cjtle1ehe000kgyav3s2qwth8","_id":"cjtle1ep30073gyavyyklivll"},{"post_id":"cjtle1eos006lgyav6fkp676b","category_id":"cjtle1emi004ugyavix3vzrrm","_id":"cjtle1ep40075gyavqthg1mvb"},{"post_id":"cjtle1eov006ogyav2dmla9tu","category_id":"cjtle1eoz006tgyavs1nw0ml6","_id":"cjtle1ep40077gyavd6yq5gul"},{"post_id":"cjtle1ew0007fgyavuswdy3v7","category_id":"cjtle1eid001cgyavrugel09i","_id":"cjtle1ew2007hgyava9pkpthx"}],"PostTag":[{"post_id":"cjtle1efr0000gyavd0t049oo","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1eh20009gyav3iyz28e7"},{"post_id":"cjtle1eg20001gyavrpdieoml","tag_id":"cjtle1egz0008gyavuksca60k","_id":"cjtle1ehb000hgyavl9m5t4s5"},{"post_id":"cjtle1egg0004gyav8cd4y2c9","tag_id":"cjtle1eh8000egyavukiiww7f","_id":"cjtle1ehi000ogyavyyl1gj33"},{"post_id":"cjtle1ehf000mgyavfv1dwwwo","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ehn000sgyav4qzm7tkp"},{"post_id":"cjtle1egn0005gyavvnaluqyr","tag_id":"cjtle1ehf000lgyav3raj9nkh","_id":"cjtle1ehq000vgyavx3iu36tc"},{"post_id":"cjtle1egw0006gyav4owv4dob","tag_id":"cjtle1ehn000tgyavq6mold6n","_id":"cjtle1ei20012gyavv94elsfi"},{"post_id":"cjtle1ei20013gyavrfolo7z7","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1eia0019gyav7vpo0bk9"},{"post_id":"cjtle1eh2000agyavf6rjqiv7","tag_id":"cjtle1ei10011gyav5eftef7o","_id":"cjtle1eid001dgyavb22gl5x2"},{"post_id":"cjtle1eh5000bgyav6pbt6dwl","tag_id":"cjtle1eia0018gyave5av4sd5","_id":"cjtle1ein001jgyavpjim6etj"},{"post_id":"cjtle1eh9000fgyavfh6vkn8d","tag_id":"cjtle1eii001ggyavqkmha2xq","_id":"cjtle1eiw001qgyavr6g86bj9"},{"post_id":"cjtle1eit001ogyav0f0q3crf","tag_id":"cjtle1ehn000tgyavq6mold6n","_id":"cjtle1ej0001ugyavwbai2s45"},{"post_id":"cjtle1eix001sgyav8lvhy8yg","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1ej4001ygyav4sporzsr"},{"post_id":"cjtle1ehc000igyavjwqi7771","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1ej70021gyavvdp8ftlf"},{"post_id":"cjtle1ej1001vgyavv5lhll4c","tag_id":"cjtle1ehn000tgyavq6mold6n","_id":"cjtle1ejc0025gyavo9g6t2gc"},{"post_id":"cjtle1ej5001zgyavpxq8u2mo","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1ejf0028gyav2f2cm1ep"},{"post_id":"cjtle1ehj000pgyavbjsw8t1u","tag_id":"cjtle1ej3001xgyavw55ohyy3","_id":"cjtle1ejj002cgyavozj7ph0g"},{"post_id":"cjtle1ejc0026gyavpqwggnlm","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ejn002fgyavc3pgt5f2"},{"post_id":"cjtle1eho000ugyavpw05mpui","tag_id":"cjtle1ejb0024gyavvqxexx73","_id":"cjtle1ejq002igyavh5475aos"},{"post_id":"cjtle1ejf0029gyavxyw0u61e","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1eju002mgyavjwfs64ny"},{"post_id":"cjtle1ejk002dgyavwmg4s1i4","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ejx002pgyavdfm96e4g"},{"post_id":"cjtle1ehr000wgyavi09ha456","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ek3002tgyav34hm25y0"},{"post_id":"cjtle1ejn002ggyav186x3j93","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ek6002wgyav7a41oni7"},{"post_id":"cjtle1ehx000zgyavqqwjaot5","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1ek90030gyavofft3sgi"},{"post_id":"cjtle1eju002ngyav4n4jovvc","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ekf0033gyavcl6hxi8y"},{"post_id":"cjtle1ejy002rgyaviwr7h5a8","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ekm0037gyavne3ri5kx"},{"post_id":"cjtle1ei70016gyavontbjgpw","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ekp003agyavl8s9sact"},{"post_id":"cjtle1ek4002ugyaviteh738l","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ekt003egyavp1nh061e"},{"post_id":"cjtle1eia001agyaveiygztrf","tag_id":"cjtle1ek6002xgyavvongce45","_id":"cjtle1ekx003hgyavn35b5ugj"},{"post_id":"cjtle1ekm0038gyavuvp9skh3","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1el2003lgyavxbv87vey"},{"post_id":"cjtle1eie001egyav6lpu06th","tag_id":"cjtle1ek6002xgyavvongce45","_id":"cjtle1el7003ogyavmk4fzt61"},{"post_id":"cjtle1ekq003bgyav2snmfcc6","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1elc003sgyav84f1ukat"},{"post_id":"cjtle1eku003fgyav11cygocq","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1elf003vgyav70i77kz3"},{"post_id":"cjtle1eij001hgyavene3dgre","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1elk003zgyavnvarqopm"},{"post_id":"cjtle1eky003igyav61ifwb6n","tag_id":"cjtle1ehf000lgyav3raj9nkh","_id":"cjtle1eln0042gyavdq3fx7co"},{"post_id":"cjtle1eio001lgyavwr7ydlkb","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1elr0046gyava6xgc7tk"},{"post_id":"cjtle1el8003pgyavcoxvszbl","tag_id":"cjtle1eh8000egyavukiiww7f","_id":"cjtle1elu0049gyavy21mop0i"},{"post_id":"cjtle1ej80022gyavzj3p6vv7","tag_id":"cjtle1ela003rgyavl3pjwgm6","_id":"cjtle1elz004dgyavcb7tw7om"},{"post_id":"cjtle1elg003wgyav94gk76j2","tag_id":"cjtle1ehf000lgyav3raj9nkh","_id":"cjtle1em2004ggyavpo88zvcn"},{"post_id":"cjtle1ejr002kgyav17bcf8r4","tag_id":"cjtle1ek6002xgyavvongce45","_id":"cjtle1em8004kgyavp2tbn9h9"},{"post_id":"cjtle1elr0047gyav42gyidrb","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1emc004ngyavp6rcqqty"},{"post_id":"cjtle1ek7002ygyav684hmmnv","tag_id":"cjtle1elq0045gyaveekk8zru","_id":"cjtle1emf004qgyavck4y9niq"},{"post_id":"cjtle1elv004agyavmwf9k843","tag_id":"cjtle1eii001ggyavqkmha2xq","_id":"cjtle1emi004vgyavgmnzqunu"},{"post_id":"cjtle1elz004egyav60va4pe1","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1emm004ygyavkfd16qz3"},{"post_id":"cjtle1eka0031gyav8hxbouxf","tag_id":"cjtle1elq0045gyaveekk8zru","_id":"cjtle1emr0052gyavbqh73rn7"},{"post_id":"cjtle1em9004lgyavs5kxhs2a","tag_id":"cjtle1elq0045gyaveekk8zru","_id":"cjtle1emw0056gyav4i9esgmr"},{"post_id":"cjtle1ekg0034gyavlcvvrfj1","tag_id":"cjtle1em7004jgyava0rusmkj","_id":"cjtle1emz005agyavg6xacqqh"},{"post_id":"cjtle1el2003mgyavns4q5fzu","tag_id":"cjtle1emf004rgyav15iib4qx","_id":"cjtle1en3005egyav7nbex7k4"},{"post_id":"cjtle1emm004zgyavpp15nf0z","tag_id":"cjtle1eia0018gyave5av4sd5","_id":"cjtle1en6005igyavgpkymtnh"},{"post_id":"cjtle1en0005bgyavkog4qpfq","tag_id":"cjtle1elq0045gyaveekk8zru","_id":"cjtle1ena005lgyavdaau2ws7"},{"post_id":"cjtle1elc003tgyavmupyg8hf","tag_id":"cjtle1emp0051gyavlhva5yz9","_id":"cjtle1ene005ogyavxgzyr0ia"},{"post_id":"cjtle1elc003tgyavmupyg8hf","tag_id":"cjtle1emz0059gyav27vy24i6","_id":"cjtle1eni005sgyavokqbaf9l"},{"post_id":"cjtle1en3005fgyavgpcl5c4s","tag_id":"cjtle1ehn000tgyavq6mold6n","_id":"cjtle1enm005vgyav8zb4sj49"},{"post_id":"cjtle1en7005jgyavkjdot0op","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1enq005zgyavkd8n5lbr"},{"post_id":"cjtle1elk0040gyav09rtlcf1","tag_id":"cjtle1en6005hgyavez6vm23y","_id":"cjtle1enu0062gyavbifp9l31"},{"post_id":"cjtle1ena005mgyavrs0rq003","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1eny0066gyavwk072d7x"},{"post_id":"cjtle1ene005qgyavcdg2scgy","tag_id":"cjtle1eis001ngyav0v2fco8w","_id":"cjtle1eo10069gyav4voh4vih"},{"post_id":"cjtle1enj005tgyav5lfol9vu","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1eoj006dgyavwvvebtdf"},{"post_id":"cjtle1elo0043gyav42fneaph","tag_id":"cjtle1ene005pgyav58g1xwrw","_id":"cjtle1eom006ggyavsx09kdtc"},{"post_id":"cjtle1enr0060gyavxhyouebd","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1eor006kgyavjrn2kwdl"},{"post_id":"cjtle1em2004hgyav57xfoe9o","tag_id":"cjtle1ejb0024gyavvqxexx73","_id":"cjtle1eou006ngyavrqymu79d"},{"post_id":"cjtle1em2004hgyav57xfoe9o","tag_id":"cjtle1em7004jgyava0rusmkj","_id":"cjtle1eoy006rgyavyyjzvknj"},{"post_id":"cjtle1enu0063gyav63psl2n8","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ep0006ugyavaomhltwb"},{"post_id":"cjtle1eny0067gyavgy6ksarm","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ep0006xgyavmjq2kjae"},{"post_id":"cjtle1emd004ogyavgj5wg1uv","tag_id":"cjtle1enx0065gyav4v878sj2","_id":"cjtle1ep2006zgyav3jxo3qh2"},{"post_id":"cjtle1eo1006agyav5o7cpcjm","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ep30071gyav913bangn"},{"post_id":"cjtle1eoj006egyavnxdnunr3","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ep40074gyavw6epa5iy"},{"post_id":"cjtle1emg004sgyavq3qsd5sa","tag_id":"cjtle1enx0065gyav4v878sj2","_id":"cjtle1ep40076gyavpe8ee07f"},{"post_id":"cjtle1eon006hgyav526m3186","tag_id":"cjtle1egf0003gyavi8vb4sv1","_id":"cjtle1ep50078gyavp4qmhimt"},{"post_id":"cjtle1eos006lgyav6fkp676b","tag_id":"cjtle1enx0065gyav4v878sj2","_id":"cjtle1ep50079gyavxcckqhk2"},{"post_id":"cjtle1emj004wgyav8dfxmcmn","tag_id":"cjtle1eoq006jgyavdx93uqpl","_id":"cjtle1ep5007agyavty86n3p8"},{"post_id":"cjtle1eov006ogyav2dmla9tu","tag_id":"cjtle1eia0018gyave5av4sd5","_id":"cjtle1ep5007bgyav0sdyv0of"},{"post_id":"cjtle1ems0053gyavjjlf0f2y","tag_id":"cjtle1enx0065gyav4v878sj2","_id":"cjtle1ep5007cgyavqpnjnwt6"},{"post_id":"cjtle1emw0057gyavi53xxh74","tag_id":"cjtle1ep0006wgyav9awvaicf","_id":"cjtle1ep5007dgyavwqj72zg6"},{"post_id":"cjtle1enn005wgyavog0usui3","tag_id":"cjtle1ep0006wgyav9awvaicf","_id":"cjtle1ep5007egyav4rbg9h69"},{"post_id":"cjtle1ew0007fgyavuswdy3v7","tag_id":"cjtle1ejj002bgyav4n3i5jr3","_id":"cjtle1ew2007ggyavp9ydszfm"}],"Tag":[{"name":"nginx","_id":"cjtle1egf0003gyavi8vb4sv1"},{"name":"计划","_id":"cjtle1egz0008gyavuksca60k"},{"name":"基本知识","_id":"cjtle1eh8000egyavukiiww7f"},{"name":"广告","_id":"cjtle1ehf000lgyav3raj9nkh"},{"name":"运维","_id":"cjtle1ehn000tgyavq6mold6n"},{"name":"git迁移","_id":"cjtle1ei10011gyav5eftef7o"},{"name":"javascript","_id":"cjtle1eia0018gyave5av4sd5"},{"name":"域名","_id":"cjtle1eii001ggyavqkmha2xq"},{"name":"linux","_id":"cjtle1eis001ngyav0v2fco8w"},{"name":"数据库","_id":"cjtle1ej3001xgyavw55ohyy3"},{"name":"mysql","_id":"cjtle1ejb0024gyavvqxexx73"},{"name":"nodejs","_id":"cjtle1ejj002bgyav4n3i5jr3"},{"name":"redis","_id":"cjtle1ek6002xgyavvongce45"},{"name":"koajs","_id":"cjtle1ela003rgyavl3pjwgm6"},{"name":"pomelo","_id":"cjtle1elq0045gyaveekk8zru"},{"name":"vagrant","_id":"cjtle1em7004jgyava0rusmkj"},{"name":"websocket","_id":"cjtle1emf004rgyav15iib4qx"},{"name":"jenkins","_id":"cjtle1emp0051gyavlhva5yz9"},{"name":"docker","_id":"cjtle1emz0059gyav27vy24i6"},{"name":"科学上网","_id":"cjtle1en6005hgyavez6vm23y"},{"name":"electron","_id":"cjtle1ene005pgyav58g1xwrw"},{"name":"plan","_id":"cjtle1enx0065gyav4v878sj2"},{"name":"UML","_id":"cjtle1eoq006jgyavdx93uqpl"},{"name":"开发调试","_id":"cjtle1ep0006wgyav9awvaicf"}]}}